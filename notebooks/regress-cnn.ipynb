{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Class that implements a regression-cnn\n",
    "\"\"\"\n",
    "from ipywidgets import *\n",
    "import tensorflow as tf\n",
    "import vae_tests.tfutils as ut\n",
    "import vae_tests.config as config\n",
    "import numpy as np\n",
    "import vae_tests.augmentation as aug\n",
    "\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import gen_nn_ops\n",
    "\n",
    "@ops.RegisterGradient(\"MaxPoolWithArgmax\")\n",
    "def _MaxPoolWithArgmaxGrad(op, grad, some_other_arg):\n",
    "  return gen_nn_ops._max_pool_grad(op.inputs[0],\n",
    "                                   op.outputs[0],\n",
    "                                   grad,\n",
    "                                   op.get_attr(\"ksize\"),\n",
    "                                   op.get_attr(\"strides\"),\n",
    "                                   padding=op.get_attr(\"padding\"),\n",
    "                                   data_format='NHWC')\n",
    "\n",
    "\n",
    "def loss(x1, x2):\n",
    "    # Euclidean distance between x1,x2\n",
    "    l2diff = tf.sqrt( tf.reduce_sum(tf.square(tf.sub(x1, x2)),\n",
    "                                    reduction_indices=1))\n",
    "    return l2diff\n",
    "\n",
    "class RegressCNN():\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Training Parameters\n",
    "        self.learning_rate   = 0.001 #0.001\n",
    "        self.training_epochs = 1000 #1000\n",
    "        self.batch_size      = 10\n",
    "        self.size_output_pose = 2 #dimensions of the output\n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.99)\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "        #self._buildGraph()\n",
    "        self._buildGraphSimple()\n",
    "        self.defCost()\n",
    "        self.initTrain()\n",
    "        self.loadData()\n",
    "        \n",
    "    def loadData(self):\n",
    "        # read the training data\n",
    "        path = config.path\n",
    "        file = 'shelf'\n",
    "        path_data = path + file + '.npz'\n",
    "        l = np.load(path_data)\n",
    "        print (l.files)\n",
    "\n",
    "        # Parse data\n",
    "        self.train_depth = l['depth_map']\n",
    "        self.train_obj_pose = l['poses']\n",
    "              \n",
    "    \n",
    "    \n",
    "    def initTrain(self):\n",
    "        # Saver \n",
    "        save_step = 10;\n",
    "        saver = tf.train.Saver(max_to_keep=self.training_epochs) \n",
    "\n",
    "        #adam optimisation. Needs the cost function\n",
    "        self.optm = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "        \n",
    "        #init = tf.global_variables_initializer()\n",
    "        init = tf.initialize_all_variables()        \n",
    "        #sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "        \n",
    "        self.sess.run(init, feed_dict={self.phase: True})\n",
    "    \n",
    "    def defCost(self):\n",
    "        #loss =  tf.nn.l2_loss(self.pred, self.y_in)\n",
    "        #self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(self.pred,self.y_in))\n",
    "        self.cost = tf.reduce_mean(loss(self.pred,self.y_in))\n",
    "        \n",
    "    def _buildGraphSimple(self):\n",
    "        \n",
    "        self.x_in_depth = tf.placeholder(tf.float32, [None, 128, 128, 1])\n",
    "        self.y_in = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "        self.phase = tf.placeholder(tf.bool, name='phase_train')\n",
    "        phase = self.phase\n",
    "        self.conv1 = ut.conv_layer_with_bn(\n",
    "                        self.x_in_depth, [3, 3, 1, 64], phase, name=\"conv1\")\n",
    "         # see https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/vf8eH9YMwVA\n",
    "        dyn_input_shape = tf.shape(self.conv1)\n",
    "        in_batch = dyn_input_shape[0]\n",
    "        \n",
    "        self.pool1, self.pool1_indices = tf.nn.max_pool_with_argmax(\n",
    "                        self.conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],padding='SAME', name='pool1')        \n",
    "        self.conv2 = ut.conv_layer_with_bn(\n",
    "                        self.pool1, [3, 3, 64, 128], phase, name=\"conv2\")\n",
    "        self.pool2, self.pool2_indices = tf.nn.max_pool_with_argmax(\n",
    "                        self.conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool2') \n",
    "        \n",
    "        self.conv3 = ut.conv_layer_with_bn(\n",
    "                        self.pool2, [3, 3, 128, 256], phase, name=\"conv3\")\n",
    "        \n",
    "        self.pool3, self.pool3_indices = tf.nn.max_pool_with_argmax(\n",
    "                        self.conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool3')        \n",
    "    \n",
    "        \n",
    "        self.dense = tf.reshape(self.pool3, [in_batch, self.pool3.get_shape().as_list()[1]*self.pool3.get_shape().as_list()[2]*self.pool3.get_shape().as_list()[3]])\n",
    "        print('dense')\n",
    "        print(self.dense.get_shape())\n",
    "        self.full = ut.full_layer_with_bn(self.dense, [self.pool3.get_shape().as_list()[1]*self.pool3.get_shape().as_list()[2]*self.pool3.get_shape().as_list()[3], 256], phase, name=\"full\")\n",
    "        print('full')\n",
    "        print(self.full.get_shape())\n",
    "        self.pred = ut.full_layer_with_bn(self.full, [256, self.size_output_pose], phase, name=\"pred\")\n",
    "        print('pred')\n",
    "        print(self.pred.get_shape())\n",
    "    \n",
    "    def _buildGraph(self):\n",
    "        self.x_in_depth = tf.placeholder(tf.float32, [None, 128, 128, 1])\n",
    "        self.y_in = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "        self.phase = tf.placeholder(tf.bool, name='phase_train')\n",
    "        phase = self.phase\n",
    "        self.conv1 = ut.conv_layer_with_bn(\n",
    "                        self.x_in_depth, [3, 3, 1, 64], phase, name=\"conv1\")\n",
    "         # see https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/vf8eH9YMwVA\n",
    "        dyn_input_shape = tf.shape(self.conv1)\n",
    "        in_batch = dyn_input_shape[0]\n",
    "        \n",
    "        self.pool1, self.pool1_indices = tf.nn.max_pool_with_argmax(\n",
    "                        self.conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],padding='SAME', name='pool1')        \n",
    "        self.conv2 = ut.conv_layer_with_bn(\n",
    "                        self.pool1, [3, 3, 64, 128], phase, name=\"conv2\")\n",
    "        self.pool2, self.pool2_indices = tf.nn.max_pool_with_argmax(\n",
    "                        self.conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool2')       \n",
    "        self.conv3 = ut.conv_layer_with_bn(\n",
    "                        self.pool2, [3, 3, 128, 256], phase, name=\"conv3\")\n",
    "        \n",
    "        self.pool3, self.pool3_indices = tf.nn.max_pool_with_argmax(\n",
    "                        self.conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool3')        \n",
    "        self.conv4 = ut.conv_layer_with_bn(\n",
    "                        self.pool3, [3, 3, 256, 512], phase, name=\"conv4\")\n",
    "       \n",
    "        self.pool4, pool4_indices = tf.nn.max_pool_with_argmax(\n",
    "                        self.conv4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool4')\n",
    "\n",
    "        print('pool4')\n",
    "        print(self.pool4.get_shape())\n",
    "        self.dense = tf.reshape(self.pool4, [in_batch, self.pool4.get_shape().as_list()[1]*self.pool4.get_shape().as_list()[2]*512])\n",
    "        print('dense')\n",
    "        print(self.dense.get_shape())\n",
    "        self.full = ut.full_layer_with_bn(self.dense, [self.pool4.get_shape().as_list()[1]*self.pool4.get_shape().as_list()[2]*512, 256], phase, name=\"full\")\n",
    "        print('full')\n",
    "        print(self.full.get_shape())\n",
    "        self.pred = ut.full_layer_with_bn(self.full, [256, self.size_output_pose], phase, name=\"pred\")\n",
    "        print('pred')\n",
    "        print(self.pred.get_shape())\n",
    "        \n",
    "    def train(self):\n",
    "        for epoch in range(self.training_epochs):\n",
    "            avg_cost = 0.\n",
    "            test_acc = 0.\n",
    "            print('training...')\n",
    "\n",
    "\n",
    "            #1st, data augmentation\n",
    "            print('   augmenting for training...')\n",
    "            train_depth_aug = np.empty([self.train_depth.shape[0], self.train_depth.shape[1], self.train_depth.shape[2], 1])\n",
    "            for i in range(self.train_depth.shape[0]):               \n",
    "                img_aug = self.train_depth[i].reshape((self.train_depth[i].shape[0], self.train_depth[i].shape[1], 1))\n",
    "                train_depth_aug[i] = img_aug\n",
    "            print('   done')\n",
    "            print(train_depth_aug.shape)\n",
    "\n",
    "            ntrain = train_depth_aug.shape[0]\n",
    "            num_batch = int(ntrain/self.batch_size)+1\n",
    "\n",
    "\n",
    "            for i in range(num_batch):         \n",
    "                randidx = np.random.randint(ntrain, size=self.batch_size)            \n",
    "                batch_depth = train_depth_aug[randidx, :]\n",
    "                batch_y_ins = self.train_obj_pose[randidx, :]\n",
    "                         \n",
    "                \n",
    "                #img=batch_depth[0,:]\n",
    "                #img_deaug = img.reshape(img.shape[0], img.shape[1])\n",
    "                #print(img_deaug.shape)\n",
    "                #display_img_array(img_deaug)       \n",
    "                feed={self.x_in_depth: batch_depth, self.y_in : batch_y_ins , self.phase:True}\n",
    "                self.sess.run(self.optm, feed_dict=feed)\n",
    "                # Compute average loss\n",
    "                fetches = [self.cost, self.pred]\n",
    "                local_cost, prediction  = self.sess.run(fetches, feed_dict=feed)\n",
    "                \n",
    "                avg_cost = 1.\n",
    "                #avg_cost += local_cost/num_batch\n",
    "                if i == num_batch - 1:\n",
    "                    print('gt:')\n",
    "                    print(batch_y_ins)\n",
    "                    print('prediction:')\n",
    "                    print(prediction)\n",
    "                    print('cost:')\n",
    "                    print(local_cost)\n",
    "\n",
    "\n",
    "            #error_train.append(avg_cost)\n",
    "            #loss.append(avg_cost)\n",
    "            #print('avg_loss=',avg_cost)\n",
    "            print (\"Optimization Finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean_2:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#regress.train_depth.shape\n",
    "a= [0.5 , 0.3]\n",
    "b = [0.5, 0.2]\n",
    "\n",
    "tf.reduce_mean(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense\n",
      "(?, 65536)\n",
      "full\n",
      "(?, 256)\n",
      "pred\n",
      "(?, 2)\n",
      "WARNING:tensorflow:From <ipython-input-1-e4196273db74>:71 in initTrain.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "['poses', 'depth_map']\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156  0.        ]\n",
      " [ 0.43633222 -0.34906578]\n",
      " [ 0.          0.08726644]\n",
      " [-0.26179933  0.17453289]\n",
      " [-1.13446378  0.17453289]\n",
      " [-0.95993089  0.26179933]\n",
      " [-0.87266444  0.        ]\n",
      " [-0.26179933 -0.34906578]\n",
      " [ 0.34906578 -0.08726644]\n",
      " [-1.13446378 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.94552428 -0.37023351]\n",
      " [ 0.43618944 -0.51989543]\n",
      " [ 0.05079961  0.93854135]\n",
      " [-0.12351613  0.81426752]\n",
      " [-0.78326482  0.22074907]\n",
      " [-0.77452248  0.8488574 ]\n",
      " [-0.44606751 -0.74381125]\n",
      " [-0.34598401 -0.78553045]\n",
      " [ 0.91915095 -0.64921808]\n",
      " [-0.76972663 -0.54587913]]\n",
      "cost:\n",
      "0.557657\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578 -0.08726644]\n",
      " [-0.95993089 -0.43633222]\n",
      " [ 0.34906578 -0.08726644]\n",
      " [ 0.785398    0.26179933]\n",
      " [ 0.08726644 -0.43633222]\n",
      " [ 0.          0.17453289]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [-1.04719733  0.08726644]\n",
      " [-0.69813156  0.17453289]\n",
      " [ 0.785398    0.        ]]\n",
      "prediction:\n",
      "[[ 0.59001094 -0.46246263]\n",
      " [-0.80006033 -0.57070231]\n",
      " [ 0.59001094 -0.46246263]\n",
      " [ 0.7255137   0.82968318]\n",
      " [-0.13663712 -0.87885219]\n",
      " [-0.51226282  0.78330082]\n",
      " [ 0.45861748 -0.79644412]\n",
      " [-0.91051275  0.4138543 ]\n",
      " [-0.80308777  0.89540708]\n",
      " [ 0.91308421 -0.0462453 ]]\n",
      "cost:\n",
      "0.47273\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867 -0.43633222]\n",
      " [ 0.08726644  0.26179933]\n",
      " [-0.34906578 -0.26179933]\n",
      " [ 0.         -0.43633222]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [-0.69813156  0.34906578]\n",
      " [-1.13446378  0.17453289]\n",
      " [ 0.43633222  0.08726644]\n",
      " [-0.69813156  0.26179933]\n",
      " [-0.08726644 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.54546642 -0.44075644]\n",
      " [ 0.38735539  0.65159547]\n",
      " [-0.63861525 -0.50076699]\n",
      " [ 0.49610734 -0.85641205]\n",
      " [ 0.94760084 -0.48819783]\n",
      " [-0.53522635  0.8885873 ]\n",
      " [-0.91561645  0.55740714]\n",
      " [ 0.75660622 -0.18651818]\n",
      " [-0.69945848  0.84987569]\n",
      " [ 0.49644917 -0.79200268]]\n",
      "cost:\n",
      "0.479644\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.         -0.08726644]\n",
      " [-0.17453289 -0.08726644]\n",
      " [-0.61086511  0.17453289]\n",
      " [ 0.52359867  0.17453289]\n",
      " [-1.04719733  0.26179933]\n",
      " [-1.04719733 -0.17453289]\n",
      " [-0.43633222  0.17453289]\n",
      " [-1.04719733 -0.08726644]\n",
      " [ 0.17453289  0.34906578]\n",
      " [ 0.785398   -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.53565007 -0.80090141]\n",
      " [ 0.00634286 -0.73106015]\n",
      " [-0.5098846   0.65496039]\n",
      " [ 0.8609497   0.6306296 ]\n",
      " [-0.63128853  0.90035367]\n",
      " [-0.88845289 -0.65091157]\n",
      " [-0.20247574  0.56425261]\n",
      " [-0.86725891 -0.27950746]\n",
      " [ 0.68933058  0.42719185]\n",
      " [ 0.88610297 -0.74868417]]\n",
      "cost:\n",
      "0.561913\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578  0.26179933]\n",
      " [-0.69813156 -0.34906578]\n",
      " [-0.08726644 -0.34906578]\n",
      " [ 0.52359867  0.08726644]\n",
      " [-1.13446378  0.08726644]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [-0.61086511 -0.08726644]\n",
      " [-0.26179933  0.34906578]\n",
      " [-0.61086511  0.        ]\n",
      " [-1.13446378  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.10573867  0.86543596]\n",
      " [-0.30364701 -0.63379514]\n",
      " [ 0.5462026  -0.89525133]\n",
      " [ 0.85036248  0.1532764 ]\n",
      " [-0.85074085 -0.09738143]\n",
      " [ 0.93590158 -0.53375721]\n",
      " [-0.40462622 -0.23764427]\n",
      " [ 0.3496936   0.82903904]\n",
      " [-0.69180584 -0.27949151]\n",
      " [-0.87024915  0.71035445]]\n",
      "cost:\n",
      "0.497268\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578  0.08726644]\n",
      " [ 0.61086511  0.26179933]\n",
      " [ 0.95993089  0.08726644]\n",
      " [ 1.22173022  0.17453289]\n",
      " [-1.13446378 -0.34906578]\n",
      " [-0.17453289 -0.26179933]\n",
      " [-0.43633222 -0.26179933]\n",
      " [-1.22173022  0.17453289]\n",
      " [-0.43633222 -0.34906578]\n",
      " [ 0.26179933 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.39640072  0.05219102]\n",
      " [ 0.70363414  0.95538819]\n",
      " [ 0.91555339  0.17391504]\n",
      " [ 0.90930438  0.44322062]\n",
      " [-0.84747374 -0.32016388]\n",
      " [-0.34951711 -0.59898627]\n",
      " [-0.62705946 -0.5423559 ]\n",
      " [-0.74395812  0.64400017]\n",
      " [-0.57874596 -0.57048702]\n",
      " [ 0.27238026 -0.71387804]]\n",
      "cost:\n",
      "0.348652\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644  0.08726644]\n",
      " [-0.95993089  0.17453289]\n",
      " [ 0.785398   -0.34906578]\n",
      " [-0.52359867  0.08726644]\n",
      " [-1.22173022  0.34906578]\n",
      " [-1.04719733  0.        ]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [ 0.34906578  0.        ]\n",
      " [-0.69813156  0.17453289]\n",
      " [ 0.52359867  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.13213477  0.00989729]\n",
      " [-0.78405553  0.53578728]\n",
      " [ 0.93263233 -0.81610674]\n",
      " [-0.40686244 -0.3619161 ]\n",
      " [-0.66727412  0.80254531]\n",
      " [-0.90309078 -0.13899182]\n",
      " [ 0.77641404 -0.85796988]\n",
      " [ 0.29662722 -0.1657844 ]\n",
      " [-0.50893229  0.44336045]\n",
      " [ 0.77266884  0.79049087]]\n",
      "cost:\n",
      "0.405734\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398   -0.08726644]\n",
      " [-0.34906578 -0.26179933]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [-0.08726644 -0.26179933]\n",
      " [-0.34906578  0.34906578]\n",
      " [-0.87266444  0.08726644]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [-1.22173022  0.34906578]\n",
      " [ 0.34906578 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.86112463  0.10026703]\n",
      " [-0.21440986 -0.52675837]\n",
      " [ 0.51368219 -0.58561474]\n",
      " [ 0.9525826  -0.25904009]\n",
      " [ 0.18576416 -0.50029963]\n",
      " [ 0.10385267  0.85942256]\n",
      " [-0.90573305  0.23467177]\n",
      " [ 0.53655434 -0.43742767]\n",
      " [-0.76209378  0.90681511]\n",
      " [ 0.5351547  -0.43762219]]\n",
      "cost:\n",
      "0.374042\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578 -0.17453289]\n",
      " [-0.87266444 -0.43633222]\n",
      " [ 0.08726644  0.08726644]\n",
      " [ 0.95993089 -0.34906578]\n",
      " [-0.52359867  0.08726644]\n",
      " [ 0.34906578 -0.43633222]\n",
      " [-1.13446378  0.        ]\n",
      " [-0.785398   -0.08726644]\n",
      " [ 0.17453289  0.34906578]\n",
      " [-0.08726644  0.26179933]]\n",
      "prediction:\n",
      "[[-0.18319359 -0.3163037 ]\n",
      " [-0.67258406 -0.60025483]\n",
      " [ 0.27421647  0.37621304]\n",
      " [ 0.9639138  -0.66554677]\n",
      " [-0.37519577  0.13808733]\n",
      " [ 0.72745514 -0.73840439]\n",
      " [-0.90406352  0.11743627]\n",
      " [-0.79054648 -0.02745819]\n",
      " [ 0.43362531  0.85885924]\n",
      " [ 0.24217822  0.79400921]]\n",
      "cost:\n",
      "0.329497\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.          0.        ]\n",
      " [-1.13446378  0.34906578]\n",
      " [-1.04719733 -0.26179933]\n",
      " [ 0.26179933  0.26179933]\n",
      " [ 0.95993089  0.17453289]\n",
      " [ 0.34906578 -0.43633222]\n",
      " [-0.785398   -0.08726644]\n",
      " [-0.26179933  0.26179933]\n",
      " [ 1.13446378  0.34906578]\n",
      " [-1.04719733 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.06006366 -0.10260615]\n",
      " [-0.81790018  0.75913399]\n",
      " [-0.79478157 -0.67741388]\n",
      " [ 0.34105656  0.52629238]\n",
      " [ 0.93738848  0.21328464]\n",
      " [ 0.36640871 -0.70850229]\n",
      " [-0.57261527 -0.22640528]\n",
      " [-0.03903416  0.49790323]\n",
      " [ 0.89972097  0.71595776]\n",
      " [-0.76687038 -0.68902516]]\n",
      "cost:\n",
      "0.310868\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578 -0.17453289]\n",
      " [ 0.61086511 -0.17453289]\n",
      " [-0.26179933 -0.08726644]\n",
      " [ 0.26179933 -0.08726644]\n",
      " [-0.52359867 -0.34906578]\n",
      " [-0.95993089 -0.26179933]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [-0.08726644  0.08726644]\n",
      " [-0.26179933  0.26179933]\n",
      " [-0.61086511 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.34443849  0.13778187]\n",
      " [ 0.84908313 -0.22333145]\n",
      " [-0.36485985  0.15340215]\n",
      " [ 0.25506443 -0.29350409]\n",
      " [-0.47021031 -0.36667955]\n",
      " [-0.92677593 -0.23753235]\n",
      " [ 0.96813196 -0.47916317]\n",
      " [-0.06730706  0.45154548]\n",
      " [-0.15339106  0.9473322 ]\n",
      " [-0.48318848 -0.3830114 ]]\n",
      "cost:\n",
      "0.259192\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.22173022 -0.08726644]\n",
      " [-0.17453289  0.08726644]\n",
      " [ 0.         -0.08726644]\n",
      " [ 0.87266444  0.08726644]\n",
      " [-1.22173022  0.        ]\n",
      " [ 0.26179933  0.17453289]\n",
      " [-0.87266444  0.26179933]\n",
      " [ 0.          0.34906578]\n",
      " [ 0.         -0.43633222]\n",
      " [ 0.61086511 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.88258213 -0.27672309]\n",
      " [-0.26947352 -0.09956098]\n",
      " [ 0.29245585 -0.43063131]\n",
      " [ 0.90110004  0.07650612]\n",
      " [-0.87812686 -0.17629451]\n",
      " [ 0.700526    0.36344606]\n",
      " [-0.76302248  0.82658929]\n",
      " [ 0.05269307  0.81794202]\n",
      " [ 0.06403232 -0.63252413]\n",
      " [ 0.8431313  -0.41491741]]\n",
      "cost:\n",
      "0.343013\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.22173022 -0.08726644]\n",
      " [-0.17453289 -0.34906578]\n",
      " [ 0.08726644 -0.34906578]\n",
      " [-0.34906578  0.17453289]\n",
      " [ 0.34906578  0.34906578]\n",
      " [ 0.52359867  0.08726644]\n",
      " [ 0.61086511  0.17453289]\n",
      " [-0.61086511  0.        ]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [ 0.          0.        ]]\n",
      "prediction:\n",
      "[[ 0.95700693 -0.24267733]\n",
      " [-0.79242557 -0.51954883]\n",
      " [-0.18131366 -0.49519786]\n",
      " [-0.87915349  0.47400382]\n",
      " [ 0.16402011  0.89113951]\n",
      " [ 0.61546397  0.06574976]\n",
      " [ 0.58635688  0.53382999]\n",
      " [-0.84873474 -0.02740944]\n",
      " [ 0.38060513 -0.43120179]\n",
      " [ 0.00475967 -0.11171029]]\n",
      "cost:\n",
      "0.346276\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511 -0.08726644]\n",
      " [ 0.95993089 -0.43633222]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [ 0.          0.08726644]\n",
      " [ 0.785398    0.        ]\n",
      " [ 1.13446378 -0.08726644]\n",
      " [-0.26179933 -0.43633222]\n",
      " [-0.17453289 -0.26179933]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [-1.04719733  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.68385881 -0.00992646]\n",
      " [ 0.66694093 -0.40648746]\n",
      " [ 0.67417383 -0.31485268]\n",
      " [-0.55109966  0.19929928]\n",
      " [ 0.82722437  0.07594068]\n",
      " [ 0.70267695  0.02154266]\n",
      " [-0.81425619 -0.45282176]\n",
      " [-0.77505374 -0.04864584]\n",
      " [-0.17234769 -0.03438024]\n",
      " [-0.91466147  0.9281593 ]]\n",
      "cost:\n",
      "0.413563\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.43633222  0.17453289]\n",
      " [ 0.69813156  0.17453289]\n",
      " [ 0.         -0.26179933]\n",
      " [-0.17453289 -0.26179933]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [ 0.34906578 -0.34906578]\n",
      " [-0.61086511  0.26179933]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [ 0.61086511  0.26179933]\n",
      " [ 0.69813156  0.        ]]\n",
      "prediction:\n",
      "[[-0.7707932   0.34753755]\n",
      " [ 0.83976108  0.31133536]\n",
      " [-0.43309477 -0.38563761]\n",
      " [-0.7372033  -0.3719798 ]\n",
      " [ 0.00803181 -0.42108664]\n",
      " [-0.08225713 -0.47927445]\n",
      " [-0.92397702  0.75244659]\n",
      " [ 0.82074237 -0.22017114]\n",
      " [ 0.61772549  0.75267637]\n",
      " [ 0.78364831 -0.05501904]]\n",
      "cost:\n",
      "0.394291\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511  0.08726644]\n",
      " [-0.52359867  0.34906578]\n",
      " [ 1.04719733 -0.43633222]\n",
      " [-1.04719733 -0.08726644]\n",
      " [-0.95993089 -0.26179933]\n",
      " [-1.04719733  0.26179933]\n",
      " [ 0.785398   -0.17453289]\n",
      " [-0.26179933 -0.08726644]\n",
      " [-0.34906578 -0.17453289]\n",
      " [ 0.95993089 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.76024008 -0.01748065]\n",
      " [-0.32782534  0.84212995]\n",
      " [ 0.77533937 -0.26149744]\n",
      " [-0.85323882 -0.11331467]\n",
      " [-0.86074841 -0.32451466]\n",
      " [-0.73534858  0.70764565]\n",
      " [ 0.84420627 -0.20564328]\n",
      " [-0.137412   -0.17232741]\n",
      " [-0.35093898 -0.19696407]\n",
      " [ 0.82212782 -0.26058999]]\n",
      "cost:\n",
      "0.22968\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933 -0.17453289]\n",
      " [-0.52359867 -0.43633222]\n",
      " [-0.95993089  0.        ]\n",
      " [-0.34906578  0.26179933]\n",
      " [-0.52359867  0.08726644]\n",
      " [-0.34906578 -0.08726644]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [-0.52359867  0.08726644]\n",
      " [ 0.34906578 -0.08726644]\n",
      " [ 0.87266444  0.34906578]]\n",
      "prediction:\n",
      "[[-0.09729709 -0.24855857]\n",
      " [-0.39385906 -0.54275334]\n",
      " [-0.91041255 -0.02498822]\n",
      " [-0.50416428  0.73069751]\n",
      " [-0.45502141  0.04106309]\n",
      " [-0.04715296 -0.12767771]\n",
      " [ 0.49794716 -0.2308071 ]\n",
      " [-0.45502141  0.04106309]\n",
      " [ 0.6747064  -0.23065069]\n",
      " [ 0.97893995  0.74852747]]\n",
      "cost:\n",
      "0.237946\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733 -0.26179933]\n",
      " [-0.69813156 -0.17453289]\n",
      " [-1.13446378 -0.26179933]\n",
      " [-0.87266444 -0.43633222]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [-0.87266444  0.08726644]\n",
      " [ 0.61086511  0.26179933]\n",
      " [ 0.34906578  0.34906578]\n",
      " [ 0.08726644  0.26179933]]\n",
      "prediction:\n",
      "[[-0.76931572 -0.43357423]\n",
      " [-0.55457628 -0.21678466]\n",
      " [-0.79074091 -0.43226305]\n",
      " [-0.63595903 -0.48105109]\n",
      " [ 0.83988082 -0.01751677]\n",
      " [ 0.90295142 -0.08916351]\n",
      " [-0.78407013  0.13198955]\n",
      " [ 0.78982347  0.61632204]\n",
      " [ 0.46742472  0.64609951]\n",
      " [ 0.26401266  0.44556984]]\n",
      "cost:\n",
      "0.265998\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511 -0.08726644]\n",
      " [-0.52359867  0.34906578]\n",
      " [-0.17453289  0.08726644]\n",
      " [ 0.785398    0.        ]\n",
      " [-0.69813156 -0.34906578]\n",
      " [-0.17453289 -0.08726644]\n",
      " [-0.26179933 -0.43633222]\n",
      " [-0.43633222  0.34906578]\n",
      " [-0.61086511  0.26179933]\n",
      " [-0.34906578 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.49982065 -0.14720961]\n",
      " [-0.36355874  0.59215069]\n",
      " [ 0.06828985  0.0225718 ]\n",
      " [ 0.99077123 -0.05651482]\n",
      " [-0.75447667 -0.42179111]\n",
      " [ 0.14054659 -0.14088021]\n",
      " [-0.08719472 -0.42799634]\n",
      " [-0.01303614  0.5762223 ]\n",
      " [-0.737809    0.47431695]\n",
      " [ 0.10307056 -0.4232668 ]]\n",
      "cost:\n",
      "0.26482\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644  0.        ]\n",
      " [ 0.87266444  0.34906578]\n",
      " [-1.04719733  0.17453289]\n",
      " [-0.61086511 -0.43633222]\n",
      " [ 0.08726644  0.08726644]\n",
      " [-0.26179933 -0.34906578]\n",
      " [-0.785398    0.17453289]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [-0.34906578  0.26179933]]\n",
      "prediction:\n",
      "[[  8.44959021e-02  -3.03002074e-04]\n",
      " [  8.76300573e-01   5.81810236e-01]\n",
      " [ -8.41795206e-01   1.62234649e-01]\n",
      " [ -7.96862841e-01  -3.97050172e-01]\n",
      " [ -1.55563280e-02   1.63796335e-01]\n",
      " [ -3.80145729e-01  -3.94466370e-01]\n",
      " [ -8.09237123e-01   1.56771079e-01]\n",
      " [  9.03706491e-01  -3.94506633e-01]\n",
      " [  8.41942608e-01  -4.26113635e-01]\n",
      " [ -2.57957727e-01   5.29561996e-01]]\n",
      "cost:\n",
      "0.146582\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156  0.        ]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [-0.61086511 -0.08726644]\n",
      " [-1.13446378 -0.08726644]\n",
      " [ 1.22173022  0.34906578]\n",
      " [-0.34906578 -0.08726644]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [-0.785398   -0.34906578]\n",
      " [-1.13446378  0.34906578]]\n",
      "prediction:\n",
      "[[-0.56899607  0.06913813]\n",
      " [ 0.40914372 -0.30698779]\n",
      " [-0.53799075 -0.02713644]\n",
      " [-0.86653364  0.00626802]\n",
      " [ 0.88193947  0.56672937]\n",
      " [-0.13944024 -0.03327686]\n",
      " [ 0.72946674 -0.40138876]\n",
      " [ 0.9337914  -0.29606283]\n",
      " [-0.7027899  -0.415995  ]\n",
      " [-0.66838974  0.56458867]]\n",
      "cost:\n",
      "0.233466\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644  0.26179933]\n",
      " [ 0.95993089  0.26179933]\n",
      " [ 0.08726644 -0.08726644]\n",
      " [ 0.17453289  0.17453289]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [-1.04719733  0.08726644]\n",
      " [-0.17453289 -0.26179933]\n",
      " [-0.52359867  0.08726644]\n",
      " [ 0.43633222  0.34906578]\n",
      " [ 0.52359867  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.02358307  0.22745752]\n",
      " [ 0.85258442  0.34857669]\n",
      " [-0.21743456 -0.36680931]\n",
      " [-0.03469423  0.11823853]\n",
      " [ 0.89519596 -0.26461217]\n",
      " [-0.95309371  0.05776358]\n",
      " [-0.44244117 -0.65643197]\n",
      " [-0.85750872 -0.00837965]\n",
      " [ 0.26443258  0.37707531]\n",
      " [ 0.69183028 -0.0211429 ]]\n",
      "cost:\n",
      "0.232659\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.43633222 -0.34906578]\n",
      " [ 1.04719733 -0.26179933]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [-0.95993089  0.08726644]\n",
      " [-1.04719733  0.17453289]\n",
      " [ 0.34906578 -0.43633222]\n",
      " [-0.95993089 -0.17453289]\n",
      " [ 0.43633222  0.17453289]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [-1.04719733 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.31496128 -0.36714971]\n",
      " [ 0.84934485 -0.28805929]\n",
      " [ 0.86363494 -0.02293806]\n",
      " [-0.76910788  0.18933216]\n",
      " [-0.78736514  0.44734171]\n",
      " [ 0.21318541 -0.39728644]\n",
      " [-0.81285936 -0.10345355]\n",
      " [ 0.50872517  0.48176202]\n",
      " [ 0.85183561 -0.02967856]\n",
      " [-0.78248668 -0.28906006]]\n",
      "cost:\n",
      "0.211891\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644  0.34906578]\n",
      " [-0.17453289 -0.43633222]\n",
      " [ 0.34906578 -0.43633222]\n",
      " [-0.43633222  0.08726644]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [-0.61086511  0.17453289]\n",
      " [ 0.08726644  0.26179933]\n",
      " [ 0.785398    0.08726644]\n",
      " [-0.69813156 -0.26179933]\n",
      " [-1.04719733 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.27693343  0.39467445]\n",
      " [ 0.09121168 -0.40997222]\n",
      " [ 0.6129185  -0.41377252]\n",
      " [-0.30877817  0.11668377]\n",
      " [ 0.85087669 -0.3569333 ]\n",
      " [-0.80252206  0.25802806]\n",
      " [ 0.40619612  0.3224664 ]\n",
      " [ 0.90063173  0.06065137]\n",
      " [-0.82362831 -0.24667144]\n",
      " [-0.93583733 -0.0778871 ]]\n",
      "cost:\n",
      "0.228301\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511 -0.17453289]\n",
      " [ 1.22173022 -0.34906578]\n",
      " [-0.52359867  0.34906578]\n",
      " [-0.43633222  0.26179933]\n",
      " [-0.69813156  0.        ]\n",
      " [ 0.43633222 -0.43633222]\n",
      " [ 0.          0.17453289]\n",
      " [ 1.22173022  0.08726644]\n",
      " [-0.69813156  0.34906578]\n",
      " [ 0.785398    0.        ]]\n",
      "prediction:\n",
      "[[ 0.60681796 -0.32255995]\n",
      " [ 0.75874394 -0.45774034]\n",
      " [-0.75686222  0.27987814]\n",
      " [-0.75668418  0.20454603]\n",
      " [-0.85901725 -0.0540571 ]\n",
      " [ 0.29593962 -0.49499893]\n",
      " [-0.17895436  0.16889325]\n",
      " [ 0.89623302  0.05251924]\n",
      " [-0.85240096  0.25882253]\n",
      " [ 0.83370507 -0.01064764]]\n",
      "cost:\n",
      "0.224885\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398    0.34906578]\n",
      " [ 0.          0.17453289]\n",
      " [-0.52359867 -0.43633222]\n",
      " [-1.04719733  0.08726644]\n",
      " [-0.26179933  0.08726644]\n",
      " [-1.04719733  0.26179933]\n",
      " [ 1.22173022  0.        ]\n",
      " [ 0.34906578  0.17453289]\n",
      " [ 0.69813156  0.26179933]\n",
      " [ 0.         -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.80621725  0.23975465]\n",
      " [-0.05383852  0.1364754 ]\n",
      " [-0.45945331 -0.52022016]\n",
      " [-0.91438204 -0.0511931 ]\n",
      " [-0.29865891 -0.01922818]\n",
      " [-0.92397606  0.18635672]\n",
      " [ 0.92060292 -0.03410686]\n",
      " [ 0.32641071  0.04460608]\n",
      " [ 0.76479542  0.16667172]\n",
      " [-0.04983037 -0.50649345]]\n",
      "cost:\n",
      "0.1369\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.22173022 -0.43633222]\n",
      " [ 1.22173022 -0.43633222]\n",
      " [-0.52359867  0.34906578]\n",
      " [ 0.17453289 -0.26179933]\n",
      " [ 0.17453289 -0.34906578]\n",
      " [-0.87266444  0.26179933]\n",
      " [ 1.13446378  0.34906578]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [-0.52359867  0.34906578]\n",
      " [ 0.43633222 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.8475526  -0.29142594]\n",
      " [ 0.84757328 -0.29139823]\n",
      " [-0.79376918  0.30967394]\n",
      " [-0.20446609 -0.19386171]\n",
      " [-0.20222734 -0.27526876]\n",
      " [-0.93899381  0.18672283]\n",
      " [ 0.86044818  0.30237624]\n",
      " [ 0.22389176 -0.2136056 ]\n",
      " [-0.79376918  0.30967394]\n",
      " [ 0.22389176 -0.2136056 ]]\n",
      "cost:\n",
      "0.293134\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289 -0.26179933]\n",
      " [ 0.43633222  0.26179933]\n",
      " [-0.95993089 -0.43633222]\n",
      " [-0.08726644  0.        ]\n",
      " [-0.87266444  0.17453289]\n",
      " [-0.95993089 -0.17453289]\n",
      " [ 0.26179933  0.        ]\n",
      " [-1.04719733  0.        ]\n",
      " [-0.34906578  0.17453289]\n",
      " [-1.22173022 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.66879469 -0.34107783]\n",
      " [ 0.97168958  0.30689758]\n",
      " [-0.51550055 -0.48502272]\n",
      " [ 0.21118066  0.00515667]\n",
      " [-0.25335327  0.2388096 ]\n",
      " [-0.4323276  -0.25057977]\n",
      " [ 0.60671985  0.00245198]\n",
      " [-0.89942449 -0.0297394 ]\n",
      " [ 0.22720146  0.24125543]\n",
      " [-0.87887204 -0.1129209 ]]\n",
      "cost:\n",
      "0.435871\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398    0.08726644]\n",
      " [ 0.43633222  0.17453289]\n",
      " [-0.26179933 -0.17453289]\n",
      " [-1.13446378  0.34906578]\n",
      " [-0.26179933 -0.26179933]\n",
      " [ 0.95993089 -0.43633222]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [-0.52359867 -0.17453289]\n",
      " [ 0.95993089  0.26179933]\n",
      " [-0.26179933  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.69417101  0.02690139]\n",
      " [ 0.36534169  0.18454435]\n",
      " [-0.49130306 -0.23332132]\n",
      " [-0.95045489  0.28189775]\n",
      " [-0.39533824 -0.32499686]\n",
      " [ 0.90677607 -0.40299693]\n",
      " [ 0.14338025 -0.19699246]\n",
      " [-0.78095233 -0.22877383]\n",
      " [ 0.8920995   0.26782808]\n",
      " [-0.42738917  0.18499631]]\n",
      "cost:\n",
      "0.135979\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156  0.34906578]\n",
      " [-0.87266444 -0.17453289]\n",
      " [-0.43633222  0.26179933]\n",
      " [ 1.04719733 -0.34906578]\n",
      " [-0.87266444 -0.43633222]\n",
      " [ 0.43633222  0.26179933]\n",
      " [-1.04719733 -0.43633222]\n",
      " [ 0.52359867  0.34906578]\n",
      " [ 1.22173022 -0.08726644]\n",
      " [-0.87266444  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.70390791  0.21446416]\n",
      " [-0.70839047 -0.1788798 ]\n",
      " [-0.40076214  0.1748504 ]\n",
      " [ 0.89434707 -0.34218848]\n",
      " [-0.79183006 -0.39040956]\n",
      " [ 0.33118364  0.14941667]\n",
      " [-0.82158524 -0.3777715 ]\n",
      " [ 0.48799583  0.22483543]\n",
      " [ 0.91000831 -0.10502699]\n",
      " [-0.82776976  0.15649572]]\n",
      "cost:\n",
      "0.15819\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.43633222 -0.43633222]\n",
      " [-0.34906578 -0.17453289]\n",
      " [ 0.61086511 -0.43633222]\n",
      " [ 0.43633222  0.34906578]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [-0.26179933  0.        ]\n",
      " [-0.34906578 -0.17453289]\n",
      " [ 0.785398    0.08726644]\n",
      " [-0.785398    0.        ]\n",
      " [ 1.04719733 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.65745664 -0.43349314]\n",
      " [-0.41999987 -0.11889148]\n",
      " [ 0.54331714 -0.41369179]\n",
      " [ 0.57141185  0.41492909]\n",
      " [ 0.18230766 -0.10565975]\n",
      " [-0.40620774  0.09848418]\n",
      " [-0.41999987 -0.11889148]\n",
      " [ 0.73870283  0.18082097]\n",
      " [-0.9712202   0.04897393]\n",
      " [ 0.94291294 -0.09850372]]\n",
      "cost:\n",
      "0.129286\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378  0.26179933]\n",
      " [ 0.69813156  0.26179933]\n",
      " [-0.34906578 -0.43633222]\n",
      " [-0.26179933 -0.26179933]\n",
      " [ 0.785398   -0.43633222]\n",
      " [ 0.08726644  0.        ]\n",
      " [-1.04719733 -0.43633222]\n",
      " [ 1.22173022  0.        ]\n",
      " [ 0.785398   -0.17453289]\n",
      " [-0.52359867  0.        ]]\n",
      "prediction:\n",
      "[[ 0.82363421  0.34133378]\n",
      " [ 0.52401817  0.32603142]\n",
      " [-0.67077738 -0.35714582]\n",
      " [-0.54098499 -0.20981881]\n",
      " [ 0.47169226 -0.3626529 ]\n",
      " [-0.01109389  0.03093812]\n",
      " [-0.96019852 -0.2993052 ]\n",
      " [ 0.90611398  0.05234992]\n",
      " [ 0.54385698 -0.10027155]\n",
      " [-0.76734465  0.07180642]]\n",
      "cost:\n",
      "0.253612\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089  0.17453289]\n",
      " [ 0.43633222  0.26179933]\n",
      " [ 0.08726644  0.        ]\n",
      " [-1.22173022 -0.34906578]\n",
      " [-1.04719733 -0.43633222]\n",
      " [-0.26179933 -0.34906578]\n",
      " [ 0.08726644  0.26179933]\n",
      " [ 0.61086511  0.08726644]\n",
      " [ 0.26179933 -0.43633222]\n",
      " [-0.08726644  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.93013704  0.13550496]\n",
      " [ 0.65474463  0.2562272 ]\n",
      " [-0.13217108 -0.03840705]\n",
      " [-0.92981499 -0.27994794]\n",
      " [-0.92563319 -0.32839179]\n",
      " [-0.3234283  -0.32898387]\n",
      " [ 0.06665477  0.23642562]\n",
      " [ 0.83609915  0.06617673]\n",
      " [ 0.28285754 -0.36460689]\n",
      " [-0.21282591  0.23995523]]\n",
      "cost:\n",
      "0.147884\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733 -0.26179933]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [-0.52359867 -0.17453289]\n",
      " [ 0.69813156  0.        ]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [ 0.08726644 -0.43633222]\n",
      " [ 0.69813156 -0.43633222]\n",
      " [ 0.34906578 -0.43633222]\n",
      " [ 0.785398    0.34906578]\n",
      " [ 1.04719733 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.6947003  -0.05040427]\n",
      " [-0.48231024  0.07286593]\n",
      " [-0.98425108  0.03501968]\n",
      " [ 0.09337852  0.13893376]\n",
      " [ 0.66384709  0.06231233]\n",
      " [-0.42827508 -0.25650677]\n",
      " [ 0.11090991 -0.32316381]\n",
      " [-0.46733835 -0.29158357]\n",
      " [ 0.53325325  0.47256127]\n",
      " [ 0.90193319 -0.27852389]]\n",
      "cost:\n",
      "0.533656\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398    0.17453289]\n",
      " [ 0.95993089  0.08726644]\n",
      " [-0.61086511  0.08726644]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [-0.69813156 -0.26179933]\n",
      " [ 0.87266444  0.        ]\n",
      " [ 0.          0.08726644]\n",
      " [-0.17453289 -0.08726644]\n",
      " [-0.08726644  0.17453289]]\n",
      "prediction:\n",
      "[[-0.91236502  0.25741607]\n",
      " [ 0.85581225  0.13434903]\n",
      " [-0.87388682  0.11497521]\n",
      " [ 0.90409905 -0.23175259]\n",
      " [ 0.29564121 -0.21483706]\n",
      " [-0.79873371 -0.48958713]\n",
      " [ 0.79641747 -0.03886708]\n",
      " [ 0.01901444  0.07809228]\n",
      " [-0.09067368 -0.2400751 ]\n",
      " [-0.0894666   0.24793284]]\n",
      "cost:\n",
      "0.151308\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644  0.        ]\n",
      " [ 0.17453289 -0.34906578]\n",
      " [ 0.43633222  0.17453289]\n",
      " [ 0.34906578  0.34906578]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [-0.43633222 -0.43633222]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [-0.26179933 -0.34906578]\n",
      " [-0.69813156 -0.17453289]\n",
      " [ 0.         -0.34906578]]\n",
      "prediction:\n",
      "[[-0.10639797  0.08501514]\n",
      " [ 0.16110864 -0.24448517]\n",
      " [ 0.52849489  0.29320472]\n",
      " [ 0.38922569  0.39943933]\n",
      " [ 0.87301338  0.02188353]\n",
      " [-0.8646518  -0.34012261]\n",
      " [ 0.90373433 -0.0487115 ]\n",
      " [-0.6490041  -0.2840836 ]\n",
      " [-0.95745081 -0.05241011]\n",
      " [ 0.12671827 -0.25417474]]\n",
      "cost:\n",
      "0.201957\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444 -0.43633222]\n",
      " [ 0.43633222  0.26179933]\n",
      " [-0.87266444 -0.43633222]\n",
      " [-0.34906578 -0.17453289]\n",
      " [-0.95993089 -0.17453289]\n",
      " [-1.04719733  0.08726644]\n",
      " [ 0.26179933  0.17453289]\n",
      " [-1.22173022  0.26179933]\n",
      " [ 0.87266444 -0.26179933]\n",
      " [ 1.22173022  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.82021356 -0.36928287]\n",
      " [ 0.53510582  0.23423117]\n",
      " [-0.78491175 -0.36679915]\n",
      " [-0.42962369 -0.19552805]\n",
      " [-0.82917368 -0.1573059 ]\n",
      " [-0.8010394   0.03899828]\n",
      " [ 0.22282544  0.12082195]\n",
      " [-0.76603401  0.26058391]\n",
      " [ 0.88129866 -0.25124553]\n",
      " [ 0.87992591  0.21416774]]\n",
      "cost:\n",
      "0.164642\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578  0.17453289]\n",
      " [ 1.04719733  0.08726644]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [-1.22173022 -0.26179933]\n",
      " [-0.08726644  0.34906578]\n",
      " [-0.34906578 -0.08726644]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [-0.26179933  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.09531564  0.18443431]\n",
      " [ 0.87871772  0.06930739]\n",
      " [ 0.77324212 -0.39652374]\n",
      " [ 0.82892859 -0.07085165]\n",
      " [-0.97224808 -0.25826493]\n",
      " [-0.28959745  0.35571536]\n",
      " [-0.77597332 -0.08667992]\n",
      " [ 0.18203846 -0.37980944]\n",
      " [ 0.18428329 -0.09070063]\n",
      " [-0.57393712  0.20259745]]\n",
      "cost:\n",
      "0.246434\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733 -0.17453289]\n",
      " [-1.13446378 -0.26179933]\n",
      " [-1.22173022 -0.08726644]\n",
      " [ 1.13446378  0.08726644]\n",
      " [-0.69813156  0.08726644]\n",
      " [ 0.785398   -0.08726644]\n",
      " [-0.785398   -0.34906578]\n",
      " [ 0.         -0.17453289]\n",
      " [-0.87266444  0.08726644]\n",
      " [ 0.08726644  0.17453289]]\n",
      "prediction:\n",
      "[[-0.68831408 -0.18280402]\n",
      " [-0.7017839  -0.33813685]\n",
      " [-0.7765221  -0.00448145]\n",
      " [ 0.96297765  0.13741499]\n",
      " [-0.39381415  0.23402493]\n",
      " [ 0.93512625 -0.08252629]\n",
      " [-0.41728973 -0.46192411]\n",
      " [ 0.21893176 -0.24248737]\n",
      " [-0.61781776  0.20910884]\n",
      " [ 0.33993328  0.21714097]]\n",
      "cost:\n",
      "0.307047\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511 -0.08726644]\n",
      " [-1.04719733 -0.34906578]\n",
      " [ 0.87266444  0.08726644]\n",
      " [ 1.04719733  0.26179933]\n",
      " [-0.17453289 -0.34906578]\n",
      " [ 0.         -0.43633222]\n",
      " [ 1.04719733  0.08726644]\n",
      " [-1.04719733  0.        ]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [ 0.26179933  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.54087055 -0.07634538]\n",
      " [-0.93352926 -0.29194549]\n",
      " [ 0.79180455  0.100388  ]\n",
      " [ 0.71797955  0.33697954]\n",
      " [-0.37897161 -0.34528363]\n",
      " [-0.10065439 -0.3926034 ]\n",
      " [ 0.84982806  0.09035017]\n",
      " [-0.95535874  0.01731204]\n",
      " [-0.00242445 -0.14892298]\n",
      " [ 0.16339101  0.25771496]]\n",
      "cost:\n",
      "0.144486\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644  0.        ]\n",
      " [ 1.13446378 -0.34906578]\n",
      " [-0.26179933 -0.26179933]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [-0.61086511 -0.43633222]\n",
      " [-1.13446378 -0.17453289]\n",
      " [-1.22173022  0.34906578]\n",
      " [ 0.17453289 -0.26179933]\n",
      " [-0.08726644 -0.34906578]\n",
      " [ 0.61086511 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.25478485  0.19753525]\n",
      " [ 0.91247547 -0.18082444]\n",
      " [-0.31395906 -0.08939289]\n",
      " [ 0.91026336 -0.04378251]\n",
      " [-0.78386354 -0.34057423]\n",
      " [-0.9178142   0.036998  ]\n",
      " [-0.86077654  0.48369408]\n",
      " [ 0.19139528 -0.06498136]\n",
      " [ 0.0113813  -0.18347745]\n",
      " [ 0.59663582 -0.31303012]]\n",
      "cost:\n",
      "0.249803\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644 -0.43633222]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [ 1.13446378  0.        ]\n",
      " [ 0.43633222  0.26179933]\n",
      " [ 0.61086511  0.26179933]\n",
      " [ 1.04719733  0.34906578]\n",
      " [ 0.08726644 -0.08726644]\n",
      " [ 0.43633222  0.34906578]\n",
      " [-0.34906578  0.08726644]]\n",
      "prediction:\n",
      "[[-0.20035723 -0.47918603]\n",
      " [-0.34005278 -0.24143185]\n",
      " [ 0.15398906 -0.25196806]\n",
      " [ 0.96616906 -0.06976032]\n",
      " [-0.30585796  0.13947363]\n",
      " [-0.03974106  0.15630525]\n",
      " [ 0.89930809  0.27129406]\n",
      " [-0.36555192 -0.23467164]\n",
      " [-0.43244323  0.24735656]\n",
      " [-0.95937216 -0.02248614]]\n",
      "cost:\n",
      "0.495823\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089  0.26179933]\n",
      " [ 0.785398    0.        ]\n",
      " [-0.52359867 -0.34906578]\n",
      " [ 0.43633222  0.        ]\n",
      " [ 0.         -0.34906578]\n",
      " [-0.43633222  0.34906578]\n",
      " [-0.43633222  0.26179933]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [-0.26179933  0.34906578]\n",
      " [-0.52359867 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.92263776  0.18194127]\n",
      " [ 0.91244471 -0.0095397 ]\n",
      " [-0.62688589 -0.31387046]\n",
      " [ 0.6931839  -0.02386254]\n",
      " [ 0.00278905 -0.30809689]\n",
      " [-0.4462634   0.2433822 ]\n",
      " [-0.59942865  0.18725997]\n",
      " [ 0.95127177 -0.32945356]\n",
      " [-0.14146467  0.23706785]\n",
      " [-0.54420191 -0.35433111]]\n",
      "cost:\n",
      "0.129077\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089 -0.34906578]\n",
      " [ 0.61086511  0.08726644]\n",
      " [-0.69813156  0.34906578]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [ 0.69813156  0.17453289]\n",
      " [-0.69813156 -0.43633222]\n",
      " [ 0.26179933  0.        ]\n",
      " [-0.785398    0.17453289]\n",
      " [-0.785398   -0.26179933]\n",
      " [-0.43633222  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.85907221 -0.37547392]\n",
      " [ 0.67937422  0.03427999]\n",
      " [-0.74388182  0.28067076]\n",
      " [ 0.89507991 -0.10973387]\n",
      " [ 0.78773355  0.12095127]\n",
      " [-0.72894788 -0.42348346]\n",
      " [ 0.16725703 -0.03657031]\n",
      " [-0.84890646  0.09967977]\n",
      " [-0.84865582 -0.32234842]\n",
      " [-0.37335995  0.27805409]]\n",
      "cost:\n",
      "0.0861585\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.43633222]\n",
      " [ 0.61086511 -0.17453289]\n",
      " [ 1.22173022  0.        ]\n",
      " [-0.87266444 -0.17453289]\n",
      " [-0.17453289 -0.17453289]\n",
      " [-0.69813156  0.34906578]\n",
      " [ 0.95993089  0.08726644]\n",
      " [ 0.61086511  0.34906578]\n",
      " [-0.17453289 -0.26179933]\n",
      " [-0.08726644  0.26179933]]\n",
      "prediction:\n",
      "[[-0.88791972 -0.41000172]\n",
      " [ 0.61710215 -0.2262142 ]\n",
      " [ 0.86524916  0.00315342]\n",
      " [-0.92753905 -0.19975686]\n",
      " [-0.13575155 -0.18296757]\n",
      " [-0.79727894  0.28256345]\n",
      " [ 0.88214856  0.02412405]\n",
      " [ 0.64181286  0.28421369]\n",
      " [-0.06269237 -0.29572654]\n",
      " [ 0.09905922  0.25064713]]\n",
      "cost:\n",
      "0.135154\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644 -0.43633222]\n",
      " [-1.13446378  0.26179933]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [-0.17453289  0.26179933]\n",
      " [ 1.13446378  0.34906578]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [-0.34906578  0.26179933]\n",
      " [-1.22173022  0.        ]\n",
      " [-0.08726644 -0.26179933]\n",
      " [ 0.26179933 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.08534598 -0.37262633]\n",
      " [-0.89725274  0.2166829 ]\n",
      " [ 0.82267702 -0.07819872]\n",
      " [-0.34688497  0.19956905]\n",
      " [ 0.92656672  0.25637391]\n",
      " [ 0.83771449 -0.32873085]\n",
      " [-0.52875745  0.21930638]\n",
      " [-0.91996157 -0.04985743]\n",
      " [-0.2627852  -0.26067513]\n",
      " [ 0.16531537 -0.26186019]]\n",
      "cost:\n",
      "0.174451\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.17453289]\n",
      " [ 0.26179933  0.34906578]\n",
      " [ 0.17453289  0.26179933]\n",
      " [ 0.87266444  0.        ]\n",
      " [ 0.95993089 -0.34906578]\n",
      " [-0.52359867  0.        ]\n",
      " [ 0.17453289  0.        ]\n",
      " [-0.17453289 -0.43633222]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [-0.26179933 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.94918889 -0.08896744]\n",
      " [-0.17586811  0.35411906]\n",
      " [-0.09869982  0.29452986]\n",
      " [ 0.90317613  0.04683631]\n",
      " [ 0.90496731 -0.28328666]\n",
      " [-0.85546654  0.07242153]\n",
      " [ 0.15823932  0.02583118]\n",
      " [-0.28358752 -0.35969308]\n",
      " [ 0.74167931 -0.29410055]\n",
      " [-0.53585148 -0.29550508]]\n",
      "cost:\n",
      "0.191145\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398   -0.34906578]\n",
      " [ 0.          0.08726644]\n",
      " [ 0.87266444  0.08726644]\n",
      " [-0.87266444  0.        ]\n",
      " [-0.785398   -0.08726644]\n",
      " [ 0.17453289 -0.34906578]\n",
      " [-0.26179933 -0.17453289]\n",
      " [ 1.04719733  0.17453289]\n",
      " [ 1.04719733  0.26179933]\n",
      " [ 0.43633222  0.        ]]\n",
      "prediction:\n",
      "[[ 0.53838968 -0.43589219]\n",
      " [-0.21103744  0.07438699]\n",
      " [ 0.80997789  0.0945689 ]\n",
      " [-0.93887991 -0.01617112]\n",
      " [-0.92514837 -0.08535296]\n",
      " [-0.13919568 -0.4284367 ]\n",
      " [-0.66028166 -0.21893206]\n",
      " [ 0.85270077  0.22538136]\n",
      " [ 0.81537926  0.32227471]\n",
      " [ 0.18757011  0.00586257]]\n",
      "cost:\n",
      "0.215829\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156 -0.26179933]\n",
      " [ 1.22173022  0.26179933]\n",
      " [ 0.34906578  0.        ]\n",
      " [ 0.26179933  0.08726644]\n",
      " [ 0.52359867 -0.43633222]\n",
      " [ 0.08726644  0.        ]\n",
      " [ 0.52359867  0.26179933]\n",
      " [-0.95993089 -0.26179933]\n",
      " [ 0.17453289  0.34906578]\n",
      " [ 0.43633222  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.73862803 -0.35185421]\n",
      " [ 0.79834521  0.19094837]\n",
      " [ 0.42454359 -0.07167906]\n",
      " [ 0.06722937 -0.00137897]\n",
      " [ 0.1007774  -0.45244521]\n",
      " [-0.18247202 -0.07094444]\n",
      " [ 0.12550396  0.24898742]\n",
      " [-0.9938454  -0.31098476]\n",
      " [-0.30202496  0.29010487]\n",
      " [ 0.3758502   0.02784028]]\n",
      "cost:\n",
      "0.257098\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222  0.34906578]\n",
      " [ 0.785398    0.26179933]\n",
      " [ 0.95993089  0.34906578]\n",
      " [-0.61086511 -0.34906578]\n",
      " [-0.34906578  0.        ]\n",
      " [-0.43633222  0.17453289]\n",
      " [-0.17453289  0.        ]\n",
      " [-0.87266444  0.26179933]\n",
      " [-0.08726644  0.08726644]\n",
      " [ 0.          0.17453289]]\n",
      "prediction:\n",
      "[[ 0.45430216  0.2128024 ]\n",
      " [ 0.86691213  0.06681714]\n",
      " [ 0.92647958  0.20298317]\n",
      " [-0.87310576 -0.59352505]\n",
      " [ 0.26371649 -0.16583993]\n",
      " [-0.64501303 -0.01866572]\n",
      " [ 0.13775106 -0.13740942]\n",
      " [-0.96109217  0.11623884]\n",
      " [ 0.02995447 -0.14710148]\n",
      " [-0.034579    0.01428076]]\n",
      "cost:\n",
      "0.271384\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.26179933 -0.34906578]\n",
      " [ 0.87266444 -0.26179933]\n",
      " [-0.26179933 -0.08726644]\n",
      " [ 0.         -0.17453289]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [ 0.08726644  0.34906578]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [ 0.         -0.08726644]\n",
      " [ 0.26179933  0.34906578]\n",
      " [ 0.08726644 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.28653279 -0.30875099]\n",
      " [ 0.70219165 -0.20168659]\n",
      " [-0.99516791 -0.0165164 ]\n",
      " [-0.19092473 -0.09994324]\n",
      " [ 0.50803554 -0.11589185]\n",
      " [ 0.38594961  0.37039527]\n",
      " [ 0.07525072 -0.11877652]\n",
      " [-0.04590197 -0.02292276]\n",
      " [ 0.67138517  0.36750978]\n",
      " [ 0.01163415 -0.3628653 ]]\n",
      "cost:\n",
      "0.268179\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933  0.26179933]\n",
      " [-0.17453289 -0.17453289]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [ 0.52359867  0.08726644]\n",
      " [-0.17453289 -0.34906578]\n",
      " [-0.52359867 -0.34906578]\n",
      " [ 1.04719733 -0.34906578]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [-0.43633222 -0.08726644]\n",
      " [-0.95993089  0.26179933]]\n",
      "prediction:\n",
      "[[-0.27319762  0.34085712]\n",
      " [-0.14615116 -0.11237817]\n",
      " [ 0.91279197 -0.01897293]\n",
      " [ 0.40607819  0.14897501]\n",
      " [-0.22170813 -0.33820832]\n",
      " [-0.82301766 -0.33564958]\n",
      " [ 0.87503618 -0.30112401]\n",
      " [ 0.75041592 -0.12127071]\n",
      " [-0.66040432 -0.01014648]\n",
      " [-0.95453417  0.2905502 ]]\n",
      "cost:\n",
      "0.135811\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511 -0.08726644]\n",
      " [-1.22173022 -0.34906578]\n",
      " [ 0.34906578  0.17453289]\n",
      " [-0.08726644 -0.17453289]\n",
      " [ 0.34906578  0.        ]\n",
      " [ 0.95993089 -0.34906578]\n",
      " [-1.13446378 -0.43633222]\n",
      " [-0.26179933 -0.26179933]\n",
      " [ 0.785398    0.17453289]\n",
      " [ 0.34906578 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.69290924  0.05935589]\n",
      " [-0.95292735 -0.24081562]\n",
      " [ 0.30735901  0.34792268]\n",
      " [-0.06562068 -0.04273823]\n",
      " [ 0.37516233  0.09333465]\n",
      " [ 0.82426655 -0.30213451]\n",
      " [-0.95446378 -0.33088845]\n",
      " [-0.55099058 -0.1683647 ]\n",
      " [ 0.79667175  0.32390469]\n",
      " [ 0.37359133 -0.23563869]]\n",
      "cost:\n",
      "0.170834\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933 -0.43633222]\n",
      " [-0.61086511  0.26179933]\n",
      " [-0.26179933 -0.08726644]\n",
      " [-0.52359867 -0.34906578]\n",
      " [-0.08726644 -0.34906578]\n",
      " [ 0.08726644  0.        ]\n",
      " [-0.52359867 -0.17453289]\n",
      " [-0.95993089  0.17453289]\n",
      " [-0.785398   -0.34906578]\n",
      " [ 0.95993089 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.04558255 -0.34485549]\n",
      " [-0.58168358  0.40007243]\n",
      " [-0.08167262  0.06819266]\n",
      " [-0.43860358 -0.26748034]\n",
      " [ 0.25899124 -0.23884326]\n",
      " [ 0.24613361  0.11421464]\n",
      " [-0.37632886 -0.02811493]\n",
      " [-0.74790633  0.26676822]\n",
      " [-0.77483767 -0.27118483]\n",
      " [ 0.99372411 -0.229256  ]]\n",
      "cost:\n",
      "0.201878\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089 -0.17453289]\n",
      " [ 1.22173022 -0.43633222]\n",
      " [ 0.17453289  0.34906578]\n",
      " [-0.785398    0.        ]\n",
      " [ 0.34906578 -0.08726644]\n",
      " [-0.69813156  0.17453289]\n",
      " [-0.52359867 -0.08726644]\n",
      " [-0.69813156  0.34906578]\n",
      " [-0.87266444 -0.43633222]\n",
      " [-0.43633222  0.34906578]]\n",
      "prediction:\n",
      "[[-0.84373176 -0.20939074]\n",
      " [ 0.98753458 -0.39469895]\n",
      " [ 0.46555564  0.21075058]\n",
      " [-0.3111749  -0.03400363]\n",
      " [ 0.65519488 -0.14436468]\n",
      " [-0.55785561  0.1352765 ]\n",
      " [ 0.26940653 -0.11358321]\n",
      " [-0.71322089  0.25960147]\n",
      " [-0.74482369 -0.43988708]\n",
      " [-0.29471561  0.25539735]]\n",
      "cost:\n",
      "0.279577\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511 -0.43633222]\n",
      " [ 0.17453289  0.        ]\n",
      " [-1.13446378  0.26179933]\n",
      " [ 0.17453289 -0.43633222]\n",
      " [ 0.43633222  0.34906578]\n",
      " [ 0.08726644  0.        ]\n",
      " [ 0.43633222 -0.34906578]\n",
      " [ 0.69813156  0.26179933]\n",
      " [-0.95993089 -0.08726644]\n",
      " [ 1.22173022 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.73393327 -0.36414269]\n",
      " [ 0.12963989  0.00343673]\n",
      " [-0.9493652   0.23018214]\n",
      " [ 0.11349119 -0.37007973]\n",
      " [ 0.55685747  0.31500959]\n",
      " [ 0.10700829  0.02654047]\n",
      " [ 0.41461664 -0.32593974]\n",
      " [ 0.85407519  0.24638957]\n",
      " [-0.92349136 -0.07154434]\n",
      " [ 0.90009362 -0.20927468]]\n",
      "cost:\n",
      "0.11779\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156  0.26179933]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [-1.13446378  0.08726644]\n",
      " [ 0.          0.34906578]\n",
      " [ 1.22173022  0.17453289]\n",
      " [ 0.61086511  0.26179933]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [-0.61086511  0.        ]\n",
      " [ 0.95993089  0.08726644]]\n",
      "prediction:\n",
      "[[-0.88824201  0.17566615]\n",
      " [ 0.5536018  -0.42713088]\n",
      " [-0.94810164  0.03012438]\n",
      " [-0.05773587  0.27208433]\n",
      " [ 0.86146241  0.06951014]\n",
      " [ 0.63098931  0.18743758]\n",
      " [ 0.21967265 -0.37179774]\n",
      " [ 0.21967265 -0.37179774]\n",
      " [-0.85895705 -0.05258298]\n",
      " [ 0.85560191 -0.0120592 ]]\n",
      "cost:\n",
      "0.166903\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156  0.        ]\n",
      " [-0.61086511 -0.17453289]\n",
      " [ 0.43633222  0.34906578]\n",
      " [-1.13446378 -0.26179933]\n",
      " [-0.785398    0.        ]\n",
      " [ 1.04719733 -0.17453289]\n",
      " [ 0.95993089 -0.34906578]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [ 0.61086511  0.17453289]\n",
      " [ 0.08726644 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.83934224  0.03539075]\n",
      " [-0.69400936 -0.13674183]\n",
      " [ 0.32453075  0.41671652]\n",
      " [-0.8683356  -0.27740714]\n",
      " [-0.88728559  0.02990009]\n",
      " [ 0.86580151 -0.18730892]\n",
      " [ 0.82415611 -0.40370265]\n",
      " [ 0.86636829 -0.2086048 ]\n",
      " [ 0.55897266  0.272405  ]\n",
      " [-0.1072057  -0.0568283 ]]\n",
      "cost:\n",
      "0.147575\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089  0.34906578]\n",
      " [-0.34906578 -0.43633222]\n",
      " [ 0.          0.17453289]\n",
      " [ 0.26179933  0.34906578]\n",
      " [-1.13446378 -0.17453289]\n",
      " [-0.69813156 -0.43633222]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [-1.13446378 -0.43633222]\n",
      " [ 1.13446378  0.08726644]\n",
      " [ 0.52359867  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.81346041  0.218448  ]\n",
      " [-0.09086581 -0.36454979]\n",
      " [-0.0591391   0.09065852]\n",
      " [ 0.15927033  0.23481043]\n",
      " [-0.93711185 -0.11464997]\n",
      " [-0.77804393 -0.37443244]\n",
      " [ 0.8406468  -0.14309238]\n",
      " [-0.90899813 -0.32804397]\n",
      " [ 0.89033264  0.03652849]\n",
      " [ 0.349765    0.24258319]]\n",
      "cost:\n",
      "0.211341\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933  0.08726644]\n",
      " [-0.34906578 -0.17453289]\n",
      " [ 0.43633222  0.26179933]\n",
      " [ 0.785398    0.26179933]\n",
      " [-0.08726644 -0.17453289]\n",
      " [-1.04719733  0.        ]\n",
      " [-0.08726644 -0.34906578]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [ 0.43633222  0.        ]\n",
      " [ 0.08726644  0.17453289]]\n",
      "prediction:\n",
      "[[-0.55339259  0.05551824]\n",
      " [-0.71089482 -0.22166345]\n",
      " [ 0.54890954  0.29578912]\n",
      " [ 0.88333756  0.26125151]\n",
      " [-0.24114183 -0.23921391]\n",
      " [-0.97469169 -0.04251992]\n",
      " [-0.42944542 -0.41756922]\n",
      " [ 0.83209825 -0.32764485]\n",
      " [ 0.8324315  -0.04404892]\n",
      " [-0.12625585  0.20355359]]\n",
      "cost:\n",
      "0.240315\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511  0.        ]\n",
      " [ 0.43633222 -0.43633222]\n",
      " [ 0.         -0.34906578]\n",
      " [-1.13446378 -0.26179933]\n",
      " [ 0.08726644  0.17453289]\n",
      " [ 0.87266444  0.08726644]\n",
      " [-0.87266444 -0.43633222]\n",
      " [ 1.22173022 -0.34906578]\n",
      " [-0.34906578 -0.26179933]\n",
      " [ 0.69813156  0.17453289]]\n",
      "prediction:\n",
      "[[-0.80515581  0.1141407 ]\n",
      " [ 0.66852462 -0.35445374]\n",
      " [-0.02002781 -0.26049602]\n",
      " [-0.92349076 -0.1165892 ]\n",
      " [ 0.07632229  0.26917687]\n",
      " [ 0.87706465  0.1761409 ]\n",
      " [-0.89090133 -0.32587573]\n",
      " [ 0.88268298 -0.2089687 ]\n",
      " [-0.48505139 -0.08847567]\n",
      " [ 0.71793509  0.32600126]]\n",
      "cost:\n",
      "0.185459\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444 -0.43633222]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [-0.08726644 -0.26179933]\n",
      " [ 0.17453289 -0.34906578]\n",
      " [-1.04719733  0.08726644]\n",
      " [-0.26179933 -0.08726644]\n",
      " [ 0.87266444 -0.26179933]\n",
      " [ 1.04719733  0.26179933]\n",
      " [-0.26179933  0.17453289]\n",
      " [ 0.43633222  0.26179933]]\n",
      "prediction:\n",
      "[[-0.91054291 -0.39342386]\n",
      " [ 0.80658972 -0.06302895]\n",
      " [-0.0245403  -0.22125772]\n",
      " [ 0.19748165 -0.30373791]\n",
      " [-0.97064424  0.09665991]\n",
      " [-0.36754757 -0.04809568]\n",
      " [ 0.76844102 -0.25663483]\n",
      " [ 0.88122523  0.26964951]\n",
      " [-0.312392    0.21987323]\n",
      " [ 0.45035538  0.30741301]]\n",
      "cost:\n",
      "0.100062\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156  0.        ]\n",
      " [-0.785398    0.08726644]\n",
      " [ 0.61086511  0.        ]\n",
      " [ 1.22173022  0.17453289]\n",
      " [ 0.43633222  0.26179933]\n",
      " [ 0.34906578  0.17453289]\n",
      " [-1.13446378 -0.08726644]\n",
      " [-0.34906578  0.        ]\n",
      " [-1.22173022 -0.08726644]\n",
      " [ 0.26179933 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.72571194 -0.01179521]\n",
      " [-0.84990466  0.14017949]\n",
      " [ 0.87269109 -0.03156155]\n",
      " [ 0.92267841  0.17700303]\n",
      " [ 0.65983897  0.3308154 ]\n",
      " [ 0.58455884  0.16925853]\n",
      " [-0.88471496 -0.29762849]\n",
      " [-0.20179264 -0.07815161]\n",
      " [-0.84212112 -0.31568882]\n",
      " [ 0.4189443  -0.46355999]]\n",
      "cost:\n",
      "0.241097\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398   -0.26179933]\n",
      " [-1.22173022  0.34906578]\n",
      " [ 0.          0.26179933]\n",
      " [-1.13446378  0.08726644]\n",
      " [-1.04719733 -0.17453289]\n",
      " [ 0.         -0.08726644]\n",
      " [ 0.17453289  0.34906578]\n",
      " [ 1.04719733 -0.26179933]\n",
      " [-0.26179933 -0.26179933]\n",
      " [-0.17453289 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.54085279 -0.25271472]\n",
      " [-0.73052788  0.31426457]\n",
      " [ 0.23247136  0.26121646]\n",
      " [-0.89028144  0.1014936 ]\n",
      " [-0.71028769 -0.16315468]\n",
      " [ 0.14765888 -0.06992158]\n",
      " [ 0.51231372  0.29377022]\n",
      " [ 0.99099052 -0.22990049]\n",
      " [-0.00603583 -0.24661274]\n",
      " [ 0.06423121 -0.38960856]]\n",
      "cost:\n",
      "0.26064\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156  0.34906578]\n",
      " [-0.26179933 -0.26179933]\n",
      " [-1.22173022 -0.34906578]\n",
      " [-0.52359867 -0.08726644]\n",
      " [-0.43633222  0.26179933]\n",
      " [-0.17453289 -0.43633222]\n",
      " [ 0.69813156  0.17453289]\n",
      " [ 0.95993089 -0.34906578]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [-0.43633222 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.66533613  0.35454836]\n",
      " [-0.04255772 -0.16009146]\n",
      " [-0.9768815  -0.22797295]\n",
      " [-0.53959286  0.03308431]\n",
      " [-0.52404541  0.31338719]\n",
      " [ 0.08805358 -0.32765266]\n",
      " [ 0.82411325  0.23005749]\n",
      " [ 0.93421543 -0.2246719 ]\n",
      " [ 0.51008117 -0.06795353]\n",
      " [-0.74568152 -0.33316919]]\n",
      "cost:\n",
      "0.199831\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.43633222]\n",
      " [-0.17453289 -0.26179933]\n",
      " [-0.87266444  0.26179933]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [-0.69813156 -0.43633222]\n",
      " [-0.43633222 -0.08726644]\n",
      " [-0.785398    0.26179933]\n",
      " [ 0.          0.34906578]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [-0.52359867 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.82658088 -0.2793735 ]\n",
      " [-0.08209908 -0.15140249]\n",
      " [-0.79925781  0.28299013]\n",
      " [ 0.98960042 -0.13392034]\n",
      " [-0.5302161  -0.30524424]\n",
      " [-0.18851371 -0.01312172]\n",
      " [-0.6111992   0.29061794]\n",
      " [ 0.32108715  0.33839652]\n",
      " [ 0.80859047 -0.15817131]\n",
      " [-0.31047264 -0.29224789]]\n",
      "cost:\n",
      "0.252885\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156  0.        ]\n",
      " [ 0.95993089  0.        ]\n",
      " [-0.785398    0.34906578]\n",
      " [-0.61086511  0.34906578]\n",
      " [-0.08726644 -0.43633222]\n",
      " [ 1.13446378  0.08726644]\n",
      " [-1.13446378  0.08726644]\n",
      " [-0.95993089 -0.08726644]\n",
      " [-0.43633222  0.        ]\n",
      " [ 0.17453289  0.34906578]]\n",
      "prediction:\n",
      "[[-0.63240284 -0.0846037 ]\n",
      " [ 0.96263474 -0.07146272]\n",
      " [-0.60405713  0.24378738]\n",
      " [-0.44625574  0.25334966]\n",
      " [ 0.11917821 -0.51725554]\n",
      " [ 0.96464008 -0.02459085]\n",
      " [-0.80728799 -0.01154034]\n",
      " [-0.8001923  -0.27147448]\n",
      " [-0.30069873 -0.1003872 ]\n",
      " [ 0.30142674  0.23725188]]\n",
      "cost:\n",
      "0.19273\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378  0.26179933]\n",
      " [ 0.61086511  0.08726644]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [-0.95993089 -0.17453289]\n",
      " [ 0.         -0.17453289]\n",
      " [ 0.87266444  0.        ]\n",
      " [ 0.          0.08726644]\n",
      " [ 0.87266444 -0.34906578]\n",
      " [-1.04719733 -0.26179933]\n",
      " [-0.26179933 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.90896106  0.39825478]\n",
      " [ 0.67554057  0.20798391]\n",
      " [ 0.87548596 -0.0679801 ]\n",
      " [-0.89479613 -0.09979456]\n",
      " [-0.02724499 -0.1283461 ]\n",
      " [ 0.87560469  0.08162557]\n",
      " [-0.00798968  0.17909175]\n",
      " [ 0.79956722 -0.35632077]\n",
      " [-0.87296647 -0.25805157]\n",
      " [-0.24522591 -0.32769895]]\n",
      "cost:\n",
      "0.128195\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578 -0.43633222]\n",
      " [ 0.34906578  0.26179933]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [-0.95993089  0.08726644]\n",
      " [-0.61086511 -0.08726644]\n",
      " [-1.04719733  0.        ]\n",
      " [ 0.69813156  0.08726644]\n",
      " [ 1.13446378 -0.08726644]\n",
      " [-1.13446378  0.26179933]\n",
      " [-1.13446378 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.12097406 -0.42914486]\n",
      " [ 0.5877797   0.29979494]\n",
      " [ 0.9186976  -0.19498883]\n",
      " [-0.86592615  0.09998856]\n",
      " [-0.43779349 -0.08629912]\n",
      " [-0.83767611  0.00950449]\n",
      " [ 0.84550953  0.10091624]\n",
      " [ 0.90647846 -0.10695718]\n",
      " [-0.73968422  0.28083083]\n",
      " [-0.68325305 -0.36843219]]\n",
      "cost:\n",
      "0.238804\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089  0.26179933]\n",
      " [ 1.04719733 -0.17453289]\n",
      " [-0.61086511 -0.43633222]\n",
      " [ 1.22173022 -0.43633222]\n",
      " [ 0.43633222  0.34906578]\n",
      " [-0.08726644  0.17453289]\n",
      " [-1.13446378  0.34906578]\n",
      " [-0.95993089 -0.17453289]\n",
      " [ 0.26179933  0.08726644]\n",
      " [-0.785398   -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.88992226  0.23855042]\n",
      " [ 0.89173841 -0.16637202]\n",
      " [-0.50052291 -0.4142504 ]\n",
      " [ 0.82246947 -0.36410123]\n",
      " [ 0.45753905  0.27352369]\n",
      " [-0.00242826  0.10835583]\n",
      " [-0.85592377  0.25345817]\n",
      " [-0.9080103  -0.19849266]\n",
      " [ 0.22015673  0.01549284]\n",
      " [-0.87238646 -0.09057906]]\n",
      "cost:\n",
      "0.145548\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156  0.17453289]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [ 0.26179933  0.34906578]\n",
      " [-0.08726644 -0.34906578]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [-0.87266444  0.34906578]\n",
      " [ 0.52359867  0.17453289]\n",
      " [ 0.26179933  0.17453289]\n",
      " [-0.34906578  0.34906578]\n",
      " [-0.17453289 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.87623411  0.06016088]\n",
      " [ 0.96235222 -0.41277894]\n",
      " [ 0.11534275  0.25828829]\n",
      " [-0.14248972 -0.35068524]\n",
      " [ 0.80015075 -0.22555155]\n",
      " [-0.96065724  0.22222905]\n",
      " [ 0.69556832  0.06877813]\n",
      " [ 0.15120228  0.06083618]\n",
      " [-0.50220287  0.25135344]\n",
      " [-0.19906533 -0.28158978]]\n",
      "cost:\n",
      "0.137406\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289 -0.34906578]\n",
      " [-0.34906578  0.26179933]\n",
      " [ 0.         -0.34906578]\n",
      " [-0.26179933  0.26179933]\n",
      " [ 0.34906578  0.34906578]\n",
      " [-1.13446378  0.        ]\n",
      " [-0.95993089  0.34906578]\n",
      " [ 0.34906578  0.08726644]\n",
      " [ 0.43633222  0.26179933]\n",
      " [-0.43633222 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.29977423 -0.39108849]\n",
      " [-0.0483382   0.13970974]\n",
      " [ 0.11010659 -0.38874865]\n",
      " [-0.01590353  0.13765393]\n",
      " [ 0.84623796  0.23095576]\n",
      " [-0.98029929 -0.092637  ]\n",
      " [-0.87106681  0.2084285 ]\n",
      " [ 0.62297469 -0.01097003]\n",
      " [ 0.92143303  0.15673839]\n",
      " [-0.26773918 -0.34090182]]\n",
      "cost:\n",
      "0.267996\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398   -0.08726644]\n",
      " [ 1.13446378  0.26179933]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [-0.95993089 -0.17453289]\n",
      " [ 0.52359867 -0.43633222]\n",
      " [ 0.87266444  0.17453289]\n",
      " [-1.22173022  0.26179933]\n",
      " [ 1.13446378  0.26179933]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [-0.26179933  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.59765816 -0.12107147]\n",
      " [ 0.69804561  0.20850515]\n",
      " [ 0.62901121 -0.13471533]\n",
      " [-0.9739688  -0.19585057]\n",
      " [ 0.09414284 -0.41347218]\n",
      " [ 0.74509251  0.14340687]\n",
      " [-0.94074064  0.20016032]\n",
      " [ 0.69802046  0.20852873]\n",
      " [ 0.44805601 -0.4311254 ]\n",
      " [-0.63201392  0.11136954]]\n",
      "cost:\n",
      "0.307918\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156 -0.34906578]\n",
      " [ 1.04719733  0.34906578]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [-0.61086511 -0.08726644]\n",
      " [-0.87266444 -0.34906578]\n",
      " [-0.52359867 -0.43633222]\n",
      " [-1.04719733 -0.08726644]\n",
      " [ 1.13446378  0.        ]\n",
      " [ 0.61086511 -0.43633222]\n",
      " [-1.22173022 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.72339815 -0.2499112 ]\n",
      " [ 0.82471108  0.42982516]\n",
      " [ 0.76912427  0.06378327]\n",
      " [-0.61623204  0.05197058]\n",
      " [-0.85200357 -0.23791412]\n",
      " [-0.401124   -0.35239387]\n",
      " [-0.92361236  0.07217339]\n",
      " [ 0.89830017  0.08312674]\n",
      " [ 0.58884895 -0.33835962]\n",
      " [-0.81244493  0.08239368]]\n",
      "cost:\n",
      "0.190236\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156  0.        ]\n",
      " [ 0.69813156  0.08726644]\n",
      " [-0.26179933  0.08726644]\n",
      " [ 0.61086511  0.        ]\n",
      " [ 0.43633222 -0.34906578]\n",
      " [ 0.61086511 -0.34906578]\n",
      " [ 1.13446378 -0.34906578]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [ 0.          0.34906578]]\n",
      "prediction:\n",
      "[[-0.99077976  0.05801877]\n",
      " [ 0.38337785  0.17893711]\n",
      " [-0.80804569  0.16214596]\n",
      " [ 0.38419825  0.05751294]\n",
      " [-0.07305712 -0.31181568]\n",
      " [ 0.33771667 -0.30525404]\n",
      " [ 0.76085997 -0.27768385]\n",
      " [ 0.84310859 -0.02513441]\n",
      " [ 0.67639905 -0.34382865]\n",
      " [-0.24630734  0.39390787]]\n",
      "cost:\n",
      "0.351014\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222 -0.43633222]\n",
      " [-1.22173022  0.08726644]\n",
      " [-0.785398    0.        ]\n",
      " [ 0.34906578 -0.34906578]\n",
      " [-0.17453289  0.26179933]\n",
      " [-1.13446378 -0.43633222]\n",
      " [-0.52359867  0.17453289]\n",
      " [-0.17453289  0.08726644]\n",
      " [ 1.04719733 -0.17453289]\n",
      " [-0.08726644  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.82009429 -0.3817527 ]\n",
      " [-0.85061896  0.08404609]\n",
      " [-0.7246834  -0.03143211]\n",
      " [ 0.70059085 -0.32105979]\n",
      " [-0.12230901  0.23844345]\n",
      " [-0.88019884 -0.36484575]\n",
      " [-0.46117145  0.15545347]\n",
      " [-0.16182458  0.07056315]\n",
      " [ 0.9820801  -0.164875  ]\n",
      " [ 0.07679397  0.31183833]]\n",
      "cost:\n",
      "0.182141\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156 -0.08726644]\n",
      " [-0.08726644  0.26179933]\n",
      " [-0.26179933 -0.34906578]\n",
      " [-0.34906578 -0.26179933]\n",
      " [ 0.785398    0.34906578]\n",
      " [-0.34906578  0.26179933]\n",
      " [-0.43633222  0.08726644]\n",
      " [ 1.13446378 -0.08726644]\n",
      " [ 0.785398    0.26179933]\n",
      " [-1.22173022  0.        ]]\n",
      "prediction:\n",
      "[[ 0.65915066 -0.15480496]\n",
      " [-0.17765033  0.19757749]\n",
      " [-0.41376826 -0.42655164]\n",
      " [-0.60682505 -0.3669579 ]\n",
      " [ 0.89339089  0.29059681]\n",
      " [-0.63842523  0.18372624]\n",
      " [-0.71338212 -0.01381092]\n",
      " [ 0.86150336 -0.19156815]\n",
      " [ 0.89802742  0.21936607]\n",
      " [-0.95700371 -0.07883221]]\n",
      "cost:\n",
      "0.204403\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378  0.08726644]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [ 0.95993089 -0.26179933]\n",
      " [-0.69813156 -0.17453289]\n",
      " [-0.61086511 -0.08726644]\n",
      " [-0.87266444  0.17453289]\n",
      " [ 0.52359867  0.26179933]\n",
      " [-0.43633222 -0.08726644]\n",
      " [ 0.08726644 -0.43633222]\n",
      " [ 0.08726644 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.95253664  0.1748976 ]\n",
      " [ 0.7453534  -0.00683091]\n",
      " [ 0.87444007 -0.29578504]\n",
      " [-0.86451763 -0.17149027]\n",
      " [-0.76049179 -0.00943203]\n",
      " [-0.93364     0.30177462]\n",
      " [ 0.44278023  0.37077785]\n",
      " [-0.50340509 -0.00845661]\n",
      " [-0.04879234 -0.41660839]\n",
      " [ 0.07662445 -0.25680912]]\n",
      "cost:\n",
      "0.125177\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444 -0.17453289]\n",
      " [ 0.95993089 -0.26179933]\n",
      " [-0.69813156  0.34906578]\n",
      " [ 0.17453289  0.26179933]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [-0.17453289  0.        ]\n",
      " [-0.43633222  0.26179933]\n",
      " [ 0.69813156  0.17453289]\n",
      " [-0.785398   -0.43633222]\n",
      " [-0.52359867 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.86994028 -0.21128881]\n",
      " [ 0.96496761 -0.29776195]\n",
      " [-0.88085693  0.31992647]\n",
      " [ 0.19611531  0.21848403]\n",
      " [ 0.39167136 -0.1076856 ]\n",
      " [-0.33933905 -0.0383643 ]\n",
      " [-0.53457057  0.24580367]\n",
      " [ 0.73074442  0.16094729]\n",
      " [-0.81386697 -0.41984558]\n",
      " [-0.8513537  -0.20702301]]\n",
      "cost:\n",
      "0.128007\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933 -0.08726644]\n",
      " [-1.04719733 -0.43633222]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [-0.52359867 -0.26179933]\n",
      " [-0.43633222  0.        ]\n",
      " [ 0.52359867 -0.08726644]\n",
      " [ 0.17453289  0.08726644]\n",
      " [ 0.69813156  0.26179933]\n",
      " [ 1.13446378  0.26179933]\n",
      " [ 0.87266444 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.39935878 -0.0634467 ]\n",
      " [-0.96116358 -0.4569563 ]\n",
      " [ 0.64629471 -0.13702612]\n",
      " [-0.86709905 -0.3110756 ]\n",
      " [-0.750485    0.04540612]\n",
      " [ 0.38740391 -0.12574495]\n",
      " [ 0.02361255  0.12562953]\n",
      " [ 0.67349374  0.3549971 ]\n",
      " [ 0.92424178  0.29840392]\n",
      " [ 0.83865643 -0.13241167]]\n",
      "cost:\n",
      "0.162792\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156  0.26179933]\n",
      " [ 0.26179933 -0.43633222]\n",
      " [-1.04719733  0.17453289]\n",
      " [ 1.04719733  0.26179933]\n",
      " [ 1.13446378 -0.34906578]\n",
      " [-1.13446378  0.        ]\n",
      " [-0.17453289  0.17453289]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [ 0.17453289  0.17453289]\n",
      " [ 0.785398   -0.26179933]]\n",
      "prediction:\n",
      "[[-0.8657918   0.23522814]\n",
      " [ 0.30490595 -0.43903282]\n",
      " [-0.9414888   0.10081677]\n",
      " [ 0.84205407  0.24894495]\n",
      " [ 0.88081437 -0.34884956]\n",
      " [-0.90381426 -0.02383295]\n",
      " [-0.28341976  0.12990025]\n",
      " [ 0.67251682 -0.20264852]\n",
      " [ 0.13047753  0.16980623]\n",
      " [ 0.80203283 -0.29491949]]\n",
      "cost:\n",
      "0.126997\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444 -0.43633222]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [-0.43633222 -0.34906578]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [-0.43633222 -0.17453289]\n",
      " [ 0.34906578 -0.08726644]\n",
      " [-0.17453289  0.        ]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [ 0.26179933 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.66878879 -0.54327679]\n",
      " [ 0.94062543  0.12372693]\n",
      " [-0.96767491 -0.35230914]\n",
      " [ 0.1973941   0.13237524]\n",
      " [ 0.50541401 -0.10145736]\n",
      " [-0.96193093  0.00108303]\n",
      " [ 0.44124496  0.26020035]\n",
      " [-0.1291942   0.16331939]\n",
      " [ 0.26313365  0.06936821]\n",
      " [ 0.159199   -0.10927176]]\n",
      "cost:\n",
      "0.336153\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089 -0.26179933]\n",
      " [ 0.34906578 -0.34906578]\n",
      " [-0.52359867  0.34906578]\n",
      " [-1.22173022  0.        ]\n",
      " [ 0.08726644 -0.34906578]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [-0.52359867 -0.17453289]\n",
      " [ 1.04719733  0.        ]\n",
      " [ 0.785398    0.08726644]\n",
      " [-0.43633222  0.34906578]]\n",
      "prediction:\n",
      "[[-0.8963185  -0.2783646 ]\n",
      " [ 0.31412449 -0.33092573]\n",
      " [-0.63963008  0.34320855]\n",
      " [-0.86090159  0.0429127 ]\n",
      " [-0.08907248 -0.31943926]\n",
      " [ 0.92450118 -0.23814636]\n",
      " [-0.68153358 -0.18843132]\n",
      " [ 0.90644521  0.03617528]\n",
      " [ 0.89773977  0.11198396]\n",
      " [-0.43146932  0.33651364]]\n",
      "cost:\n",
      "0.140712\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.22173022 -0.43633222]\n",
      " [ 1.13446378  0.34906578]\n",
      " [-0.43633222 -0.08726644]\n",
      " [-1.13446378  0.26179933]\n",
      " [-0.95993089  0.        ]\n",
      " [ 0.69813156 -0.43633222]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [ 0.43633222 -0.34906578]\n",
      " [-0.26179933 -0.26179933]\n",
      " [ 0.34906578  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.73729265 -0.3223269 ]\n",
      " [ 0.86062658  0.28414017]\n",
      " [-0.64408261 -0.04839858]\n",
      " [-0.96331698  0.24431202]\n",
      " [-0.9153738   0.0232512 ]\n",
      " [ 0.6557045  -0.36838439]\n",
      " [ 0.86968607 -0.13239577]\n",
      " [ 0.19620125 -0.30125159]\n",
      " [-0.46053407 -0.21431571]\n",
      " [ 0.2928037   0.31197178]]\n",
      "cost:\n",
      "0.216398\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867 -0.26179933]\n",
      " [ 0.69813156  0.        ]\n",
      " [ 0.52359867  0.26179933]\n",
      " [-0.26179933  0.34906578]\n",
      " [ 0.17453289  0.26179933]\n",
      " [-0.785398    0.17453289]\n",
      " [-0.34906578  0.08726644]\n",
      " [-0.61086511  0.34906578]\n",
      " [-1.22173022 -0.34906578]\n",
      " [ 1.13446378 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.7378186  -0.3603802 ]\n",
      " [ 0.88097447 -0.04698385]\n",
      " [ 0.64164209  0.15840085]\n",
      " [-0.35243022  0.22379145]\n",
      " [ 0.16066334  0.139241  ]\n",
      " [-0.91373724  0.08133494]\n",
      " [-0.50787276 -0.02474516]\n",
      " [-0.77066326  0.22373012]\n",
      " [-0.8892135  -0.38781253]\n",
      " [ 0.94234723 -0.3965517 ]]\n",
      "cost:\n",
      "0.194818\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222 -0.34906578]\n",
      " [ 0.17453289 -0.26179933]\n",
      " [-0.87266444 -0.43633222]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [-0.08726644 -0.43633222]\n",
      " [-0.785398    0.08726644]\n",
      " [-0.08726644  0.17453289]\n",
      " [ 0.61086511  0.08726644]\n",
      " [-0.34906578  0.08726644]\n",
      " [-0.34906578  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.90749699 -0.29272452]\n",
      " [ 0.42500013 -0.22253397]\n",
      " [-0.8869071  -0.37123993]\n",
      " [ 0.40012339 -0.03878333]\n",
      " [-0.09055451 -0.37473986]\n",
      " [-0.87617987  0.0963065 ]\n",
      " [-0.19322011  0.20629983]\n",
      " [ 0.97450614  0.1352407 ]\n",
      " [-0.63006413  0.11512677]\n",
      " [-0.58313298  0.30069178]]\n",
      "cost:\n",
      "0.217539\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644 -0.08726644]\n",
      " [-1.04719733 -0.08726644]\n",
      " [ 1.22173022 -0.43633222]\n",
      " [ 0.95993089  0.17453289]\n",
      " [-0.26179933  0.        ]\n",
      " [ 0.61086511 -0.26179933]\n",
      " [ 0.52359867  0.08726644]\n",
      " [ 0.17453289 -0.34906578]\n",
      " [-0.43633222  0.17453289]\n",
      " [-1.22173022  0.26179933]]\n",
      "prediction:\n",
      "[[-0.05458802 -0.0696829 ]\n",
      " [-0.94951093 -0.09453243]\n",
      " [ 0.88041812 -0.40024921]\n",
      " [ 0.94029355  0.19763651]\n",
      " [-0.25882867  0.00571995]\n",
      " [ 0.64209223 -0.29101732]\n",
      " [ 0.53160346  0.1250578 ]\n",
      " [-0.01830032 -0.38077542]\n",
      " [-0.51516342  0.19523574]\n",
      " [-0.92783237  0.28615034]]\n",
      "cost:\n",
      "0.12741\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089  0.08726644]\n",
      " [ 1.13446378  0.26179933]\n",
      " [-1.13446378 -0.17453289]\n",
      " [ 0.785398    0.26179933]\n",
      " [-1.22173022 -0.43633222]\n",
      " [ 0.52359867  0.26179933]\n",
      " [-0.43633222  0.08726644]\n",
      " [-0.17453289 -0.43633222]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [-0.61086511  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.86227107 -0.00325304]\n",
      " [ 0.84755462  0.18920411]\n",
      " [-0.91934109 -0.18531235]\n",
      " [ 0.7475481   0.20671336]\n",
      " [-0.89845717 -0.38638607]\n",
      " [ 0.47710714  0.21103893]\n",
      " [-0.59655404  0.03968487]\n",
      " [-0.25069159 -0.40988556]\n",
      " [ 0.83504438 -0.29247281]\n",
      " [-0.81419659  0.21815844]]\n",
      "cost:\n",
      "0.186399\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644 -0.17453289]\n",
      " [-1.22173022  0.17453289]\n",
      " [-1.04719733 -0.08726644]\n",
      " [ 0.52359867 -0.08726644]\n",
      " [-0.34906578 -0.26179933]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [ 0.17453289  0.34906578]\n",
      " [ 0.785398   -0.08726644]\n",
      " [ 0.43633222  0.08726644]\n",
      " [ 1.13446378 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.11054222 -0.32631409]\n",
      " [-0.93612629  0.27815798]\n",
      " [-0.97128016 -0.12554465]\n",
      " [ 0.56359971 -0.16427878]\n",
      " [-0.62040561 -0.3706995 ]\n",
      " [ 0.85144234 -0.08568165]\n",
      " [ 0.17970508  0.43431854]\n",
      " [ 0.7195701  -0.0765179 ]\n",
      " [ 0.33201447  0.13194726]\n",
      " [ 0.83805913 -0.08761466]]\n",
      "cost:\n",
      "0.159206\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089  0.34906578]\n",
      " [ 0.87266444 -0.26179933]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [-0.08726644 -0.26179933]\n",
      " [-0.61086511  0.34906578]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [ 0.69813156  0.26179933]\n",
      " [-0.08726644 -0.17453289]\n",
      " [ 0.         -0.17453289]\n",
      " [ 0.         -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.81225127  0.3172358 ]\n",
      " [ 0.74176502 -0.25471532]\n",
      " [ 0.21858828 -0.02961904]\n",
      " [-0.43649372 -0.22382802]\n",
      " [-0.99241906  0.30756944]\n",
      " [ 0.7439698  -0.14234376]\n",
      " [ 0.75981289  0.26848742]\n",
      " [-0.32793143 -0.13351229]\n",
      " [-0.31300676 -0.13975744]\n",
      " [-0.22216228 -0.35605085]]\n",
      "cost:\n",
      "0.225646\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.26179933]\n",
      " [ 0.95993089  0.        ]\n",
      " [-0.43633222 -0.17453289]\n",
      " [ 0.785398    0.34906578]\n",
      " [ 0.17453289  0.        ]\n",
      " [ 1.13446378 -0.08726644]\n",
      " [-0.95993089  0.08726644]\n",
      " [-0.61086511 -0.17453289]\n",
      " [ 0.08726644  0.26179933]\n",
      " [-1.04719733 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.85724413 -0.27571318]\n",
      " [ 0.93335479  0.02500909]\n",
      " [-0.35465783 -0.19767588]\n",
      " [ 0.84685105  0.38684335]\n",
      " [ 0.1595958  -0.02195486]\n",
      " [ 0.93154287 -0.09627043]\n",
      " [-0.83307111  0.15183419]\n",
      " [-0.59098041 -0.18870717]\n",
      " [ 0.12035418  0.27382973]\n",
      " [-0.85772008 -0.39046338]]\n",
      "cost:\n",
      "0.109668\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398   -0.34906578]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [-0.69813156 -0.08726644]\n",
      " [-0.43633222 -0.08726644]\n",
      " [ 1.22173022  0.17453289]\n",
      " [ 0.34906578  0.26179933]\n",
      " [ 0.43633222 -0.34906578]\n",
      " [-0.43633222  0.        ]\n",
      " [-0.52359867 -0.17453289]\n",
      " [-0.52359867  0.34906578]]\n",
      "prediction:\n",
      "[[-0.86275381 -0.3328512 ]\n",
      " [ 0.91896433 -0.31339011]\n",
      " [-0.85330898 -0.04746437]\n",
      " [-0.41552007 -0.03779284]\n",
      " [ 0.97494763  0.18329872]\n",
      " [ 0.45598856  0.27137771]\n",
      " [ 0.59557414 -0.29636309]\n",
      " [-0.56084192  0.03224901]\n",
      " [-0.60440886 -0.14517523]\n",
      " [-0.52475739  0.3740049 ]]\n",
      "cost:\n",
      "0.127819\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578  0.        ]\n",
      " [-1.22173022  0.34906578]\n",
      " [-0.43633222 -0.43633222]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [ 0.          0.        ]\n",
      " [-1.13446378  0.34906578]\n",
      " [ 0.34906578  0.        ]\n",
      " [ 0.69813156  0.        ]\n",
      " [-1.04719733  0.26179933]\n",
      " [ 1.22173022 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.18478094 -0.02215609]\n",
      " [-0.82957995  0.26123589]\n",
      " [-0.16648749 -0.4965331 ]\n",
      " [ 0.82549834 -0.15322153]\n",
      " [-0.00171633 -0.02697234]\n",
      " [-0.90219474  0.26455534]\n",
      " [ 0.60663903 -0.02757259]\n",
      " [ 0.81234699 -0.01212583]\n",
      " [-0.93336445  0.20591868]\n",
      " [ 0.9409076  -0.32758602]]\n",
      "cost:\n",
      "0.213198\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511  0.17453289]\n",
      " [-1.13446378  0.26179933]\n",
      " [ 0.34906578  0.        ]\n",
      " [ 0.95993089  0.        ]\n",
      " [-1.04719733  0.26179933]\n",
      " [-1.04719733  0.08726644]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [-0.34906578 -0.17453289]\n",
      " [-1.04719733 -0.26179933]\n",
      " [-0.17453289  0.        ]]\n",
      "prediction:\n",
      "[[-0.52721429  0.20595422]\n",
      " [-0.72281265  0.26501769]\n",
      " [ 0.58791304 -0.0174877 ]\n",
      " [ 0.96618807 -0.04986827]\n",
      " [-0.75411803  0.28679508]\n",
      " [-0.84148932  0.02438772]\n",
      " [ 0.95693946 -0.21490942]\n",
      " [-0.06537957 -0.33923295]\n",
      " [-0.70789349 -0.48885629]\n",
      " [ 0.06981695 -0.05505194]]\n",
      "cost:\n",
      "0.243974\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089 -0.26179933]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [ 0.61086511  0.        ]\n",
      " [-0.61086511 -0.17453289]\n",
      " [-0.785398    0.26179933]\n",
      " [-1.04719733  0.        ]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [-0.61086511 -0.08726644]\n",
      " [-1.13446378  0.34906578]\n",
      " [ 0.26179933 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.90266788 -0.30964786]\n",
      " [ 0.86038154 -0.20944826]\n",
      " [ 0.60532403  0.01857488]\n",
      " [-0.65285444 -0.19551571]\n",
      " [-0.73444307  0.35471466]\n",
      " [-0.92642426  0.05205754]\n",
      " [ 0.9064495  -0.20544155]\n",
      " [-0.66069144 -0.0862646 ]\n",
      " [-0.79795033  0.3940945 ]\n",
      " [ 0.26330492 -0.29652697]]\n",
      "cost:\n",
      "0.122734\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644  0.34906578]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [ 0.52359867  0.17453289]\n",
      " [-0.52359867  0.17453289]\n",
      " [ 0.          0.        ]\n",
      " [-0.69813156 -0.08726644]\n",
      " [ 0.08726644  0.34906578]\n",
      " [ 0.26179933  0.34906578]\n",
      " [-0.26179933  0.26179933]\n",
      " [ 0.17453289  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.26977313  0.2172149 ]\n",
      " [ 0.89056402 -0.5088762 ]\n",
      " [ 0.88446701 -0.05047547]\n",
      " [-0.92448992 -0.06295501]\n",
      " [-0.0056816  -0.10363793]\n",
      " [-0.98274797 -0.35985935]\n",
      " [ 0.21834922  0.22294298]\n",
      " [ 0.50716317  0.21795852]\n",
      " [-0.15083694  0.04843505]\n",
      " [ 0.3198756  -0.03584262]]\n",
      "cost:\n",
      "0.306084\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398    0.17453289]\n",
      " [ 1.13446378 -0.34906578]\n",
      " [-0.95993089  0.34906578]\n",
      " [-0.69813156 -0.43633222]\n",
      " [ 0.61086511  0.        ]\n",
      " [-0.17453289  0.17453289]\n",
      " [-0.17453289  0.08726644]\n",
      " [ 0.34906578  0.08726644]\n",
      " [-0.61086511  0.        ]\n",
      " [-0.34906578 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.91817778  0.18492667]\n",
      " [ 0.94236779 -0.33199191]\n",
      " [-0.91183782  0.30810344]\n",
      " [-0.84195614 -0.40919846]\n",
      " [ 0.74609065 -0.02251392]\n",
      " [-0.05902452  0.15525407]\n",
      " [-0.12059075  0.04074819]\n",
      " [ 0.48270372  0.05775804]\n",
      " [-0.88898337 -0.00838148]\n",
      " [-0.41110265 -0.34888935]]\n",
      "cost:\n",
      "0.133814\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644  0.08726644]\n",
      " [ 0.08726644  0.        ]\n",
      " [ 0.34906578  0.08726644]\n",
      " [-0.34906578 -0.43633222]\n",
      " [-0.95993089  0.17453289]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [-0.87266444 -0.34906578]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [-0.08726644 -0.17453289]\n",
      " [ 0.785398   -0.34906578]]\n",
      "prediction:\n",
      "[[-0.01796294  0.23707424]\n",
      " [-0.028439    0.05966623]\n",
      " [ 0.54319185  0.22640717]\n",
      " [-0.50092375 -0.37499201]\n",
      " [-0.93217421  0.36136946]\n",
      " [ 0.84128451 -0.09774638]\n",
      " [-0.93200469 -0.28895035]\n",
      " [ 0.17657556 -0.11164207]\n",
      " [-0.25949469 -0.04367776]\n",
      " [ 0.97609431 -0.30574831]]\n",
      "cost:\n",
      "0.187618\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578  0.08726644]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [-1.04719733  0.        ]\n",
      " [ 0.785398   -0.26179933]\n",
      " [ 1.22173022  0.        ]\n",
      " [-0.69813156  0.34906578]\n",
      " [ 1.13446378  0.17453289]\n",
      " [ 0.95993089 -0.34906578]\n",
      " [-0.95993089  0.26179933]\n",
      " [-0.95993089 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.27200297  0.05860919]\n",
      " [ 0.17346495 -0.11526398]\n",
      " [-0.89135784 -0.04574262]\n",
      " [ 0.77469534 -0.35388884]\n",
      " [ 0.87216192 -0.0574166 ]\n",
      " [-0.53986168  0.32980537]\n",
      " [ 0.88396031  0.15925901]\n",
      " [ 0.82756114 -0.43543515]\n",
      " [-0.84891272  0.28625774]\n",
      " [-0.91895336 -0.13910364]]\n",
      "cost:\n",
      "0.146783\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578  0.26179933]\n",
      " [-1.22173022 -0.34906578]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [ 0.69813156  0.08726644]\n",
      " [ 0.17453289 -0.34906578]\n",
      " [-0.61086511 -0.26179933]\n",
      " [-0.43633222  0.34906578]\n",
      " [-0.95993089  0.26179933]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [ 0.61086511  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.27066559  0.19461726]\n",
      " [-0.91272473 -0.27865338]\n",
      " [ 0.49864548 -0.16203618]\n",
      " [ 0.85427773  0.06096171]\n",
      " [ 0.16374592 -0.31413972]\n",
      " [-0.7628513  -0.23439932]\n",
      " [-0.47386551  0.24741842]\n",
      " [-0.95303786  0.23513986]\n",
      " [ 0.94249928 -0.32208297]\n",
      " [ 0.68385845  0.28317383]]\n",
      "cost:\n",
      "0.129068\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644  0.34906578]\n",
      " [-0.87266444 -0.08726644]\n",
      " [ 0.87266444  0.34906578]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [ 0.          0.        ]\n",
      " [ 0.43633222  0.17453289]\n",
      " [ 0.          0.26179933]\n",
      " [-0.61086511 -0.34906578]\n",
      " [-0.61086511  0.26179933]\n",
      " [-0.08726644 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.16482644  0.24701044]\n",
      " [-0.9358421  -0.1314877 ]\n",
      " [ 0.97111702  0.228864  ]\n",
      " [ 0.91555285 -0.21258271]\n",
      " [-0.00617998 -0.00263976]\n",
      " [ 0.53833973  0.10026868]\n",
      " [-0.02885476  0.16840993]\n",
      " [-0.85499787 -0.3899436 ]\n",
      " [-0.80228281  0.14851457]\n",
      " [-0.02051677 -0.42947185]]\n",
      "cost:\n",
      "0.13491\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222 -0.26179933]\n",
      " [ 1.22173022 -0.34906578]\n",
      " [-0.17453289  0.        ]\n",
      " [-0.08726644 -0.43633222]\n",
      " [-0.26179933  0.        ]\n",
      " [ 0.26179933  0.26179933]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [ 0.         -0.17453289]\n",
      " [-0.43633222 -0.26179933]\n",
      " [-0.52359867  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.55321664 -0.19421247]\n",
      " [ 0.87399912 -0.29170245]\n",
      " [-0.00344297  0.05761623]\n",
      " [-0.36380717 -0.36273462]\n",
      " [-0.30761489  0.07161684]\n",
      " [ 0.59398699  0.33615544]\n",
      " [ 0.94105375 -0.0248607 ]\n",
      " [-0.07183982 -0.10647807]\n",
      " [-0.97601372 -0.21595569]\n",
      " [-0.90300369  0.38015032]]\n",
      "cost:\n",
      "0.252396\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.26179933]\n",
      " [-1.13446378 -0.34906578]\n",
      " [-1.04719733  0.08726644]\n",
      " [ 0.95993089 -0.34906578]\n",
      " [ 1.04719733  0.34906578]\n",
      " [ 0.87266444  0.26179933]\n",
      " [ 0.34906578 -0.34906578]\n",
      " [ 0.26179933 -0.08726644]\n",
      " [-1.04719733 -0.34906578]\n",
      " [-0.17453289  0.08726644]]\n",
      "prediction:\n",
      "[[-0.83016396 -0.17129289]\n",
      " [-0.85002077 -0.26906872]\n",
      " [-0.85476148  0.11948416]\n",
      " [ 0.91603667 -0.29432544]\n",
      " [ 0.87478626  0.35954911]\n",
      " [ 0.90683854  0.32050744]\n",
      " [ 0.40064645 -0.30082792]\n",
      " [ 0.23172586 -0.0175036 ]\n",
      " [-0.86182791 -0.27566615]\n",
      " [-0.06771626  0.10656647]]\n",
      "cost:\n",
      "0.15734\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867  0.08726644]\n",
      " [ 1.13446378  0.        ]\n",
      " [ 1.04719733 -0.17453289]\n",
      " [ 0.08726644 -0.43633222]\n",
      " [-0.69813156  0.08726644]\n",
      " [-1.13446378 -0.43633222]\n",
      " [ 0.43633222  0.34906578]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [-0.26179933 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.77920771  0.19065237]\n",
      " [ 0.89791465  0.11152418]\n",
      " [ 0.80780983 -0.04850786]\n",
      " [-0.00823746 -0.29272914]\n",
      " [-0.94826937  0.16613452]\n",
      " [-0.93956333 -0.27425063]\n",
      " [ 0.26837298  0.39869025]\n",
      " [ 0.81346166 -0.2751072 ]\n",
      " [ 0.76177645 -0.3168543 ]\n",
      " [-0.36005107 -0.13497975]]\n",
      "cost:\n",
      "0.235379\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578  0.08726644]\n",
      " [-0.61086511  0.        ]\n",
      " [ 0.87266444  0.34906578]\n",
      " [ 0.785398    0.34906578]\n",
      " [ 0.785398   -0.26179933]\n",
      " [-0.26179933 -0.34906578]\n",
      " [-0.43633222 -0.26179933]\n",
      " [ 0.785398   -0.26179933]\n",
      " [-0.08726644 -0.08726644]\n",
      " [ 0.26179933 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.64462823  0.11561048]\n",
      " [-0.96449381  0.00817494]\n",
      " [ 0.88411093  0.35639307]\n",
      " [ 0.80336565  0.35158774]\n",
      " [ 0.83489239 -0.26689011]\n",
      " [-0.54252863 -0.34718379]\n",
      " [-0.90647805 -0.25048649]\n",
      " [ 0.83489239 -0.26689011]\n",
      " [-0.19276229 -0.04409586]\n",
      " [ 0.2336681  -0.12166328]]\n",
      "cost:\n",
      "0.170678\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089  0.34906578]\n",
      " [ 0.785398   -0.43633222]\n",
      " [ 0.785398   -0.34906578]\n",
      " [-1.04719733  0.34906578]\n",
      " [-1.04719733 -0.43633222]\n",
      " [ 0.785398   -0.26179933]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [-0.61086511  0.34906578]\n",
      " [-1.04719733 -0.17453289]\n",
      " [ 0.95993089 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.73418915  0.32512182]\n",
      " [ 0.77412546 -0.3018378 ]\n",
      " [ 0.83484817 -0.20022573]\n",
      " [-0.78801012  0.31718597]\n",
      " [-0.90735137 -0.29717147]\n",
      " [ 0.84456849 -0.10858798]\n",
      " [ 0.4267385  -0.21683106]\n",
      " [-0.23298636  0.3230491 ]\n",
      " [-0.92229134 -0.07520854]\n",
      " [ 0.90612674 -0.18556102]]\n",
      "cost:\n",
      "0.201588\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.26179933  0.08726644]\n",
      " [-0.34906578 -0.08726644]\n",
      " [-0.43633222  0.26179933]\n",
      " [ 0.95993089  0.17453289]\n",
      " [-1.13446378  0.08726644]\n",
      " [ 0.69813156  0.34906578]\n",
      " [ 0.08726644  0.17453289]\n",
      " [-0.26179933 -0.17453289]\n",
      " [ 0.26179933  0.34906578]\n",
      " [-0.26179933  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.36346689 -0.10219292]\n",
      " [-0.43457714 -0.37361518]\n",
      " [-0.74450421  0.18026543]\n",
      " [ 0.97147048  0.03433684]\n",
      " [-0.97714257 -0.07655996]\n",
      " [ 0.91153502  0.238711  ]\n",
      " [ 0.08822416  0.00774879]\n",
      " [-0.39354634 -0.50180131]\n",
      " [ 0.26712582  0.28344485]\n",
      " [-0.26007152 -0.07228296]]\n",
      "cost:\n",
      "0.218566\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.         -0.08726644]\n",
      " [-0.61086511  0.08726644]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [-0.785398   -0.17453289]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [ 0.61086511  0.17453289]\n",
      " [ 1.22173022  0.08726644]\n",
      " [-0.95993089  0.08726644]\n",
      " [-0.34906578 -0.43633222]\n",
      " [ 0.43633222  0.08726644]]\n",
      "prediction:\n",
      "[[-0.04667621 -0.07451482]\n",
      " [-0.66962457  0.17324637]\n",
      " [ 0.21231525 -0.09853122]\n",
      " [-0.86936069 -0.20370302]\n",
      " [ 0.66690993 -0.323881  ]\n",
      " [ 0.84680307  0.26286617]\n",
      " [ 0.97228038  0.1813294 ]\n",
      " [-0.96663213  0.12954381]\n",
      " [-0.29870859 -0.49455217]\n",
      " [ 0.1956939   0.11134681]]\n",
      "cost:\n",
      "0.150204\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511  0.17453289]\n",
      " [-0.34906578 -0.26179933]\n",
      " [ 0.95993089  0.08726644]\n",
      " [ 1.22173022  0.17453289]\n",
      " [ 1.22173022 -0.34906578]\n",
      " [ 0.95993089  0.08726644]\n",
      " [ 0.08726644  0.08726644]\n",
      " [-0.95993089  0.34906578]\n",
      " [ 0.17453289  0.26179933]\n",
      " [ 1.22173022 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.30976266  0.10654629]\n",
      " [-0.8662194  -0.40988788]\n",
      " [ 0.72647023  0.00897786]\n",
      " [ 0.68684363  0.12398205]\n",
      " [ 0.48791814 -0.47872505]\n",
      " [ 0.72697508  0.00914794]\n",
      " [-0.06014694  0.02021846]\n",
      " [-0.99387485  0.24147192]\n",
      " [-0.01879341  0.1962775 ]\n",
      " [ 0.64862752 -0.20718007]]\n",
      "cost:\n",
      "0.368542\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867  0.        ]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [ 0.43633222  0.08726644]\n",
      " [-0.95993089  0.08726644]\n",
      " [ 0.43633222  0.08726644]\n",
      " [-0.61086511 -0.08726644]\n",
      " [ 1.13446378 -0.34906578]\n",
      " [-0.785398   -0.08726644]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [ 0.61086511  0.08726644]]\n",
      "prediction:\n",
      "[[-0.66371512  0.01522166]\n",
      " [ 0.5765456  -0.40587142]\n",
      " [ 0.5610078   0.220928  ]\n",
      " [-0.93924081  0.15982243]\n",
      " [ 0.56127918  0.22124232]\n",
      " [-0.77333319 -0.07005322]\n",
      " [ 0.94662058 -0.37460536]\n",
      " [-0.92459971 -0.12361684]\n",
      " [ 0.10154352 -0.28177407]\n",
      " [ 0.8719551   0.21320121]]\n",
      "cost:\n",
      "0.147127\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289  0.34906578]\n",
      " [-1.04719733  0.26179933]\n",
      " [-0.43633222  0.08726644]\n",
      " [ 0.69813156  0.26179933]\n",
      " [ 0.17453289  0.26179933]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [ 0.08726644  0.17453289]\n",
      " [-0.34906578  0.        ]\n",
      " [-0.17453289  0.34906578]\n",
      " [ 1.22173022  0.08726644]]\n",
      "prediction:\n",
      "[[-0.34467736  0.23781557]\n",
      " [-0.98667532  0.01724604]\n",
      " [-0.60834682 -0.16792554]\n",
      " [ 0.71647632  0.05464639]\n",
      " [ 0.07596124  0.07328462]\n",
      " [ 0.88499993 -0.54128325]\n",
      " [-0.00732506 -0.07718207]\n",
      " [-0.39439496 -0.23324013]\n",
      " [-0.34379384  0.23792706]\n",
      " [ 0.95695549 -0.13301502]]\n",
      "cost:\n",
      "0.268064\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.26179933 -0.34906578]\n",
      " [-0.87266444 -0.17453289]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [-1.04719733  0.        ]\n",
      " [-0.87266444  0.34906578]\n",
      " [-0.26179933 -0.34906578]\n",
      " [-0.17453289 -0.43633222]\n",
      " [ 0.         -0.34906578]\n",
      " [-0.08726644 -0.17453289]\n",
      " [-0.52359867  0.        ]]\n",
      "prediction:\n",
      "[[ 0.67359626 -0.2270143 ]\n",
      " [-0.73110801 -0.08871048]\n",
      " [ 0.99393672  0.0196311 ]\n",
      " [-0.91923469  0.09439448]\n",
      " [-0.74916863  0.43920854]\n",
      " [-0.19106159 -0.2888428 ]\n",
      " [-0.06007879 -0.36298007]\n",
      " [ 0.28544596 -0.25080752]\n",
      " [ 0.06005176 -0.01597564]\n",
      " [-0.35814995  0.1193806 ]]\n",
      "cost:\n",
      "0.197756\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444 -0.08726644]\n",
      " [ 1.22173022  0.26179933]\n",
      " [ 1.13446378  0.        ]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [ 0.52359867 -0.43633222]\n",
      " [-0.61086511 -0.17453289]\n",
      " [-0.61086511  0.        ]\n",
      " [-0.34906578 -0.34906578]\n",
      " [-1.13446378 -0.34906578]\n",
      " [ 1.04719733 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.91879332  0.03942479]\n",
      " [ 0.83202767  0.44175407]\n",
      " [ 0.92105842  0.11934737]\n",
      " [ 0.29653233 -0.15701874]\n",
      " [ 0.53405321 -0.36824748]\n",
      " [-0.68237442 -0.07847279]\n",
      " [-0.64420867  0.11322732]\n",
      " [-0.41691732 -0.31093782]\n",
      " [-0.93439877 -0.22808783]\n",
      " [ 0.91989249 -0.09322103]]\n",
      "cost:\n",
      "0.169515\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.22173022 -0.26179933]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [-0.87266444 -0.34906578]\n",
      " [ 0.17453289 -0.43633222]\n",
      " [ 0.26179933  0.34906578]\n",
      " [ 0.61086511 -0.26179933]\n",
      " [-0.95993089  0.17453289]\n",
      " [ 0.17453289  0.26179933]\n",
      " [ 0.52359867  0.26179933]\n",
      " [ 0.52359867  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.9011119  -0.22981261]\n",
      " [ 0.5353781  -0.24833487]\n",
      " [-0.97097224 -0.32291299]\n",
      " [ 0.04276671 -0.34759989]\n",
      " [ 0.10932697  0.24739259]\n",
      " [ 0.75945991 -0.25164869]\n",
      " [-0.9785111   0.05647686]\n",
      " [ 0.04631595  0.17320873]\n",
      " [ 0.55953705  0.19238411]\n",
      " [ 0.44237101  0.2651771 ]]\n",
      "cost:\n",
      "0.140318\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644 -0.43633222]\n",
      " [-0.87266444  0.08726644]\n",
      " [ 0.785398    0.34906578]\n",
      " [-0.52359867 -0.17453289]\n",
      " [-0.34906578  0.17453289]\n",
      " [-0.87266444  0.08726644]\n",
      " [ 1.22173022  0.        ]\n",
      " [-0.95993089 -0.26179933]\n",
      " [ 0.69813156  0.08726644]\n",
      " [ 0.52359867  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.11914072 -0.45655861]\n",
      " [-0.87529504  0.03812814]\n",
      " [ 0.82337499  0.26000831]\n",
      " [-0.66249907 -0.27434638]\n",
      " [-0.42994809  0.12947051]\n",
      " [-0.87529504  0.03812814]\n",
      " [ 0.94984323 -0.03337238]\n",
      " [-0.8495692  -0.39037791]\n",
      " [ 0.91435438  0.03957562]\n",
      " [ 0.53845745  0.27925661]]\n",
      "cost:\n",
      "0.123278\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578 -0.26179933]\n",
      " [ 1.04719733 -0.43633222]\n",
      " [ 0.34906578  0.26179933]\n",
      " [-1.13446378 -0.17453289]\n",
      " [ 1.13446378  0.34906578]\n",
      " [-1.13446378  0.        ]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [ 0.34906578  0.17453289]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [ 0.          0.08726644]]\n",
      "prediction:\n",
      "[[-0.47261062 -0.25586724]\n",
      " [ 0.80713898 -0.43117672]\n",
      " [ 0.17346622  0.25346047]\n",
      " [-0.96511376 -0.16458273]\n",
      " [ 0.69490087  0.33103606]\n",
      " [-0.96796721  0.04440819]\n",
      " [ 0.83214766 -0.26777974]\n",
      " [ 0.20658176  0.16185634]\n",
      " [ 0.82713896 -0.16914451]\n",
      " [-0.07499258  0.09888018]]\n",
      "cost:\n",
      "0.19757\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578  0.08726644]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [-0.26179933  0.26179933]\n",
      " [ 0.          0.34906578]\n",
      " [-0.08726644 -0.43633222]\n",
      " [ 0.          0.08726644]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [-0.87266444  0.17453289]\n",
      " [ 0.         -0.26179933]\n",
      " [-1.13446378  0.26179933]]\n",
      "prediction:\n",
      "[[-0.24313097  0.01214237]\n",
      " [ 0.96350372 -0.09885302]\n",
      " [-0.16839667  0.20264539]\n",
      " [ 0.17851059  0.2830044 ]\n",
      " [-0.11100004 -0.44591671]\n",
      " [-0.01346358  0.05318748]\n",
      " [ 0.95330143 -0.30599362]\n",
      " [-0.89872134  0.1101299 ]\n",
      " [-0.05577948 -0.32748047]\n",
      " [-0.9582805   0.15960607]]\n",
      "cost:\n",
      "0.120287\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398   -0.17453289]\n",
      " [ 0.          0.34906578]\n",
      " [-0.17453289 -0.43633222]\n",
      " [-0.26179933 -0.08726644]\n",
      " [ 0.17453289  0.        ]\n",
      " [ 0.         -0.34906578]\n",
      " [-0.69813156  0.        ]\n",
      " [-0.95993089  0.08726644]\n",
      " [-0.17453289  0.17453289]\n",
      " [-0.87266444 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.99521708 -0.18276113]\n",
      " [ 0.14704475  0.38792595]\n",
      " [-0.06812698 -0.38095218]\n",
      " [-0.13154246 -0.05727609]\n",
      " [ 0.34740373  0.03201043]\n",
      " [ 0.09826791 -0.32006431]\n",
      " [-0.63174599  0.03321803]\n",
      " [-0.85325098  0.12466517]\n",
      " [ 0.02318538  0.25048745]\n",
      " [-0.87770218 -0.25906384]]\n",
      "cost:\n",
      "0.129878\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511 -0.08726644]\n",
      " [ 0.17453289  0.34906578]\n",
      " [ 0.43633222 -0.34906578]\n",
      " [-0.95993089  0.34906578]\n",
      " [-0.785398    0.34906578]\n",
      " [-0.69813156  0.        ]\n",
      " [ 1.04719733  0.17453289]\n",
      " [ 0.34906578  0.34906578]\n",
      " [-1.13446378  0.17453289]\n",
      " [ 0.95993089 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.72129482 -0.18780421]\n",
      " [ 0.11696947  0.18410809]\n",
      " [ 0.38540122 -0.42933166]\n",
      " [-0.88740361  0.21294926]\n",
      " [-0.7424739   0.20306395]\n",
      " [-0.73250449 -0.09985338]\n",
      " [ 0.94966602  0.04735129]\n",
      " [ 0.27862677  0.21508862]\n",
      " [-0.93327147  0.04551144]\n",
      " [ 0.90683484 -0.4662033 ]]\n",
      "cost:\n",
      "0.14427\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933  0.34906578]\n",
      " [ 0.26179933 -0.08726644]\n",
      " [-0.26179933  0.17453289]\n",
      " [-0.87266444 -0.08726644]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [-0.61086511 -0.17453289]\n",
      " [-0.26179933 -0.08726644]\n",
      " [-0.34906578 -0.43633222]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [-0.785398   -0.26179933]]\n",
      "prediction:\n",
      "[[-0.21881022  0.45159692]\n",
      " [ 0.45462605 -0.00134686]\n",
      " [-0.25308225  0.27427968]\n",
      " [-0.80894709 -0.01515508]\n",
      " [ 0.9931069  -0.01015513]\n",
      " [-0.5688144  -0.14622046]\n",
      " [-0.22421746 -0.04910934]\n",
      " [-0.38472587 -0.43605796]\n",
      " [ 0.79697752 -0.22036707]\n",
      " [-0.88286138 -0.24379648]]\n",
      "cost:\n",
      "0.126369\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398    0.        ]\n",
      " [ 1.13446378 -0.08726644]\n",
      " [-1.13446378  0.17453289]\n",
      " [-0.61086511  0.34906578]\n",
      " [-0.17453289 -0.34906578]\n",
      " [ 0.61086511  0.26179933]\n",
      " [-0.08726644 -0.34906578]\n",
      " [ 0.95993089  0.08726644]\n",
      " [-0.17453289  0.        ]\n",
      " [ 0.08726644  0.34906578]]\n",
      "prediction:\n",
      "[[-0.90664828 -0.09455027]\n",
      " [ 0.95355201 -0.19272766]\n",
      " [-0.93825614  0.06836596]\n",
      " [-0.73274183  0.26882178]\n",
      " [-0.1519897  -0.43667209]\n",
      " [ 0.70367873  0.20166917]\n",
      " [-0.08072877 -0.42711666]\n",
      " [ 0.94035596  0.006144  ]\n",
      " [-0.10423608 -0.04250616]\n",
      " [ 0.17245999  0.29548767]]\n",
      "cost:\n",
      "0.127779\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289 -0.34906578]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [-0.17453289 -0.34906578]\n",
      " [-1.13446378 -0.43633222]\n",
      " [-0.52359867 -0.08726644]\n",
      " [ 0.34906578 -0.34906578]\n",
      " [-0.26179933 -0.43633222]\n",
      " [ 0.43633222  0.34906578]\n",
      " [-0.87266444  0.17453289]\n",
      " [ 0.95993089 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.24603981 -0.17672604]\n",
      " [ 0.30846873 -0.0810342 ]\n",
      " [-0.07613117 -0.1969486 ]\n",
      " [-0.95898587 -0.26330101]\n",
      " [-0.47602281  0.05099842]\n",
      " [ 0.58740377 -0.21082896]\n",
      " [-0.19908851 -0.30793864]\n",
      " [ 0.57596326  0.46408239]\n",
      " [-0.90801954  0.3354696 ]\n",
      " [ 0.98627901 -0.05141963]]\n",
      "cost:\n",
      "0.18371\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398    0.        ]\n",
      " [ 1.22173022  0.26179933]\n",
      " [ 0.17453289 -0.43633222]\n",
      " [ 0.785398    0.26179933]\n",
      " [-0.52359867 -0.08726644]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [-0.87266444  0.08726644]\n",
      " [ 0.43633222  0.26179933]\n",
      " [ 0.61086511  0.26179933]\n",
      " [-1.04719733 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.89914632 -0.05531789]\n",
      " [ 0.93990594  0.18611255]\n",
      " [ 0.17328911 -0.40884522]\n",
      " [ 0.88574445  0.20940942]\n",
      " [-0.5705865  -0.10839594]\n",
      " [ 0.59618461 -0.30548981]\n",
      " [-0.91957229  0.03897652]\n",
      " [ 0.36553973  0.22891018]\n",
      " [ 0.72513199  0.23031877]\n",
      " [-0.89589781 -0.41300318]]\n",
      "cost:\n",
      "0.111225\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222 -0.34906578]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [-0.69813156 -0.08726644]\n",
      " [ 0.52359867  0.26179933]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [ 0.69813156  0.34906578]\n",
      " [ 0.785398   -0.34906578]\n",
      " [-1.13446378 -0.08726644]\n",
      " [-0.61086511  0.        ]]\n",
      "prediction:\n",
      "[[ 0.15469424 -0.27591735]\n",
      " [ 0.41796723 -0.1734654 ]\n",
      " [-0.90383387 -0.0078666 ]\n",
      " [ 0.40053251  0.34823796]\n",
      " [ 0.20372953 -0.17933416]\n",
      " [ 0.9000833  -0.36321855]\n",
      " [ 0.68307257  0.39582899]\n",
      " [ 0.88780481 -0.27895144]\n",
      " [-0.97688806  0.0149389 ]\n",
      " [-0.81230313  0.06920726]]\n",
      "cost:\n",
      "0.169849\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.26179933 -0.08726644]\n",
      " [ 0.95993089 -0.34906578]\n",
      " [ 0.52359867 -0.17453289]\n",
      " [-0.87266444  0.        ]\n",
      " [ 0.61086511  0.17453289]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [ 0.69813156  0.26179933]\n",
      " [-0.95993089  0.        ]\n",
      " [-1.13446378 -0.17453289]\n",
      " [-0.43633222  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.24243428 -0.06907661]\n",
      " [ 0.91936612 -0.39364195]\n",
      " [ 0.60522187 -0.17550756]\n",
      " [-0.87232721 -0.01022372]\n",
      " [ 0.7693615   0.26791272]\n",
      " [ 0.5213666  -0.38803208]\n",
      " [ 0.81123704  0.33564037]\n",
      " [-0.93223721 -0.00386224]\n",
      " [-0.94742388 -0.17116579]\n",
      " [-0.27969196  0.20578913]]\n",
      "cost:\n",
      "0.0911522\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867 -0.08726644]\n",
      " [-0.26179933  0.34906578]\n",
      " [-0.69813156 -0.26179933]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [-0.61086511 -0.17453289]\n",
      " [ 0.87266444  0.26179933]\n",
      " [-0.26179933  0.        ]\n",
      " [ 0.26179933  0.08726644]\n",
      " [-0.17453289 -0.34906578]\n",
      " [ 1.04719733 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.57302427 -0.08379228]\n",
      " [-0.30856118  0.40026626]\n",
      " [-0.97302806 -0.27729666]\n",
      " [ 0.82291341 -0.20897025]\n",
      " [-0.94404882 -0.15242174]\n",
      " [ 0.86713529  0.31438604]\n",
      " [-0.26683688  0.02950659]\n",
      " [ 0.25313592  0.10932107]\n",
      " [-0.24225423 -0.36752495]\n",
      " [ 0.90264499 -0.2034734 ]]\n",
      "cost:\n",
      "0.111276\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511 -0.34906578]\n",
      " [ 0.785398    0.08726644]\n",
      " [-0.87266444  0.08726644]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [-1.13446378 -0.17453289]\n",
      " [-0.43633222  0.17453289]\n",
      " [-1.22173022 -0.26179933]\n",
      " [ 0.         -0.17453289]\n",
      " [ 0.87266444  0.        ]\n",
      " [ 1.13446378 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.72375476 -0.40430787]\n",
      " [ 0.86321986  0.23442754]\n",
      " [-0.89838648  0.20171447]\n",
      " [ 0.90455741 -0.04584869]\n",
      " [-0.85764861 -0.1959745 ]\n",
      " [-0.56366718  0.3858425 ]\n",
      " [-0.79957849 -0.31492209]\n",
      " [-0.08606335 -0.131256  ]\n",
      " [ 0.89009899  0.0596038 ]\n",
      " [ 0.87445152 -0.16038947]]\n",
      "cost:\n",
      "0.184727\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156  0.26179933]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [ 0.95993089  0.26179933]\n",
      " [ 0.26179933 -0.43633222]\n",
      " [-0.61086511 -0.34906578]\n",
      " [-0.34906578  0.26179933]\n",
      " [-0.34906578  0.17453289]\n",
      " [-0.52359867 -0.26179933]\n",
      " [-0.43633222 -0.08726644]\n",
      " [ 0.87266444  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.56356269  0.19329633]\n",
      " [ 0.94932437 -0.2794005 ]\n",
      " [ 0.83644593  0.21011966]\n",
      " [ 0.43384391 -0.37639952]\n",
      " [-0.97045535 -0.32739571]\n",
      " [-0.31403857  0.22166647]\n",
      " [-0.29875582  0.11823344]\n",
      " [-0.93033755 -0.26043746]\n",
      " [-0.59461665 -0.10884675]\n",
      " [ 0.77252078  0.26982436]]\n",
      "cost:\n",
      "0.192323\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578  0.26179933]\n",
      " [-0.785398    0.08726644]\n",
      " [ 0.52359867  0.17453289]\n",
      " [ 0.26179933 -0.43633222]\n",
      " [ 0.785398   -0.26179933]\n",
      " [-0.17453289 -0.43633222]\n",
      " [ 0.34906578  0.26179933]\n",
      " [-1.04719733 -0.34906578]\n",
      " [-1.22173022  0.17453289]\n",
      " [-1.04719733 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.12744774  0.29050931]\n",
      " [-0.67264944  0.09253871]\n",
      " [ 0.89306164  0.19123633]\n",
      " [ 0.39337873 -0.37267327]\n",
      " [ 0.97935104 -0.2272878 ]\n",
      " [-0.08157792 -0.34781325]\n",
      " [ 0.68119234  0.2857278 ]\n",
      " [-0.84695387 -0.26748419]\n",
      " [-0.84025985  0.16480891]\n",
      " [-0.9172672  -0.10097344]]\n",
      "cost:\n",
      "0.251173\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578 -0.26179933]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [-0.34906578 -0.17453289]\n",
      " [-1.04719733 -0.26179933]\n",
      " [-0.87266444  0.34906578]\n",
      " [-1.22173022 -0.26179933]\n",
      " [ 0.69813156  0.08726644]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [-0.52359867  0.17453289]\n",
      " [-1.13446378 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.04376465 -0.24549901]\n",
      " [ 0.6369344  -0.21383789]\n",
      " [-0.07508534 -0.11618115]\n",
      " [-0.8303147  -0.25774544]\n",
      " [-0.65763474  0.44896787]\n",
      " [-0.77129346 -0.22592242]\n",
      " [ 0.94674474  0.16246603]\n",
      " [ 0.98416758 -0.03785047]\n",
      " [-0.41027427  0.31141374]\n",
      " [-0.84297752 -0.2308905 ]]\n",
      "cost:\n",
      "0.259424\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.22173022 -0.34906578]\n",
      " [ 0.52359867 -0.17453289]\n",
      " [ 0.          0.        ]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [-0.08726644 -0.17453289]\n",
      " [-0.785398    0.34906578]\n",
      " [-0.87266444  0.17453289]\n",
      " [-0.17453289 -0.08726644]\n",
      " [-0.69813156 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.99282289 -0.29827043]\n",
      " [ 0.87827533 -0.10783527]\n",
      " [-0.23143342  0.0530198 ]\n",
      " [ 0.08597706 -0.21327607]\n",
      " [ 0.16402444 -0.12499668]\n",
      " [-0.04989292 -0.12769406]\n",
      " [-0.83268511  0.45038122]\n",
      " [-0.87960219  0.32171959]\n",
      " [-0.22000924 -0.01257819]\n",
      " [-0.81999993 -0.28728893]]\n",
      "cost:\n",
      "0.147513\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.          0.34906578]\n",
      " [ 0.61086511 -0.43633222]\n",
      " [ 0.87266444  0.26179933]\n",
      " [ 1.13446378 -0.34906578]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [ 0.34906578  0.08726644]\n",
      " [-0.52359867 -0.17453289]\n",
      " [ 1.22173022  0.17453289]\n",
      " [-0.43633222  0.26179933]\n",
      " [-0.61086511  0.08726644]]\n",
      "prediction:\n",
      "[[-0.09635144  0.29801816]\n",
      " [ 0.41979724 -0.38933092]\n",
      " [ 0.78947031  0.22109455]\n",
      " [ 0.89777452 -0.34034312]\n",
      " [ 0.16026649 -0.27383026]\n",
      " [ 0.14335978  0.02248944]\n",
      " [-0.89808881 -0.19478472]\n",
      " [ 0.93150216  0.09337325]\n",
      " [-0.72532141  0.21889471]\n",
      " [-0.98006934  0.03171805]]\n",
      "cost:\n",
      "0.229509\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156  0.34906578]\n",
      " [-0.17453289 -0.17453289]\n",
      " [-1.22173022  0.08726644]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [ 0.          0.17453289]\n",
      " [-0.26179933  0.08726644]\n",
      " [ 0.26179933  0.08726644]\n",
      " [ 0.785398    0.26179933]\n",
      " [ 0.52359867 -0.43633222]\n",
      " [-0.43633222  0.26179933]]\n",
      "prediction:\n",
      "[[-0.87642622  0.27196008]\n",
      " [-0.03569309 -0.32248539]\n",
      " [-0.97775477 -0.00892577]\n",
      " [ 0.95788503 -0.17496832]\n",
      " [ 0.03265167  0.13932073]\n",
      " [-0.25630501 -0.0160007 ]\n",
      " [ 0.1580493  -0.00518073]\n",
      " [ 0.94012111  0.18548645]\n",
      " [ 0.64499706 -0.55251265]\n",
      " [-0.49541479  0.18442269]]\n",
      "cost:\n",
      "0.150999\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156  0.26179933]\n",
      " [-0.17453289  0.17453289]\n",
      " [-0.52359867 -0.26179933]\n",
      " [-0.43633222 -0.17453289]\n",
      " [-0.785398    0.26179933]\n",
      " [-0.26179933  0.17453289]\n",
      " [ 0.52359867  0.08726644]\n",
      " [ 1.13446378 -0.08726644]\n",
      " [ 0.95993089  0.17453289]\n",
      " [-0.95993089 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.77807969  0.23441441]\n",
      " [-0.1361579   0.16665302]\n",
      " [-0.66963726 -0.40343571]\n",
      " [-0.51596475 -0.30666551]\n",
      " [-0.92695069  0.26645851]\n",
      " [-0.25867987  0.16034196]\n",
      " [ 0.74871135  0.0077389 ]\n",
      " [ 0.93544078 -0.20647317]\n",
      " [ 0.93249786  0.10904546]\n",
      " [-0.94615251 -0.41284594]]\n",
      "cost:\n",
      "0.133097\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644  0.08726644]\n",
      " [ 0.17453289  0.34906578]\n",
      " [ 0.69813156 -0.43633222]\n",
      " [-0.785398   -0.17453289]\n",
      " [ 0.26179933 -0.34906578]\n",
      " [-1.13446378 -0.43633222]\n",
      " [ 0.87266444  0.26179933]\n",
      " [ 0.34906578 -0.08726644]\n",
      " [-0.61086511  0.        ]\n",
      " [ 0.26179933 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.01162128  0.13832216]\n",
      " [ 0.48275724  0.36564505]\n",
      " [ 0.8815459  -0.32383081]\n",
      " [-0.92098147 -0.08129473]\n",
      " [ 0.28137055 -0.27916026]\n",
      " [-0.96974874 -0.28662914]\n",
      " [ 0.96600044  0.33204693]\n",
      " [ 0.37744269 -0.03919377]\n",
      " [-0.80372864  0.0376971 ]\n",
      " [ 0.26867849 -0.36704978]]\n",
      "cost:\n",
      "0.153363\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444  0.        ]\n",
      " [ 0.69813156  0.26179933]\n",
      " [ 0.785398    0.08726644]\n",
      " [ 0.26179933  0.34906578]\n",
      " [-0.69813156 -0.08726644]\n",
      " [-0.26179933  0.17453289]\n",
      " [-0.43633222  0.17453289]\n",
      " [-0.17453289 -0.08726644]\n",
      " [-0.69813156  0.        ]\n",
      " [-0.95993089  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.94524091 -0.10291358]\n",
      " [ 0.89684916  0.16154872]\n",
      " [ 0.91230422 -0.06171181]\n",
      " [ 0.32347932  0.3781285 ]\n",
      " [-0.7972182  -0.49464214]\n",
      " [-0.24842925  0.03009433]\n",
      " [-0.43594196  0.07473011]\n",
      " [-0.1560275  -0.40050283]\n",
      " [-0.74792087 -0.11026406]\n",
      " [-0.97168547  0.02237675]]\n",
      "cost:\n",
      "0.186388\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222  0.26179933]\n",
      " [ 0.61086511  0.34906578]\n",
      " [-0.95993089 -0.34906578]\n",
      " [-0.87266444 -0.08726644]\n",
      " [ 0.785398    0.26179933]\n",
      " [ 0.08726644  0.17453289]\n",
      " [-0.43633222 -0.26179933]\n",
      " [-0.52359867 -0.34906578]\n",
      " [-0.34906578  0.        ]\n",
      " [-0.52359867  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.72774076  0.18810689]\n",
      " [ 0.91248107  0.26215595]\n",
      " [-0.9282909  -0.3934457 ]\n",
      " [-0.86506999 -0.13200192]\n",
      " [ 0.9839679   0.18391584]\n",
      " [ 0.19481942  0.0650814 ]\n",
      " [-0.3813214  -0.33494142]\n",
      " [-0.59425622 -0.39923418]\n",
      " [-0.4100208  -0.05365639]\n",
      " [-0.54636979  0.13216312]]\n",
      "cost:\n",
      "0.138858\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733  0.26179933]\n",
      " [-0.17453289  0.        ]\n",
      " [-0.34906578  0.17453289]\n",
      " [ 0.17453289 -0.26179933]\n",
      " [ 0.26179933  0.08726644]\n",
      " [-0.43633222  0.08726644]\n",
      " [ 0.17453289  0.17453289]\n",
      " [-0.69813156  0.34906578]\n",
      " [-0.95993089 -0.43633222]\n",
      " [-0.61086511 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.8586598   0.18721455]\n",
      " [-0.13548391 -0.04985709]\n",
      " [-0.24353224  0.13497005]\n",
      " [ 0.90016001 -0.3427121 ]\n",
      " [ 0.98596293  0.00183441]\n",
      " [-0.69599557  0.04372596]\n",
      " [ 0.7845152   0.12911224]\n",
      " [-0.64884353  0.2843563 ]\n",
      " [-0.8895489  -0.50284427]\n",
      " [-0.30417225 -0.25230801]]\n",
      "cost:\n",
      "0.320764\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578  0.        ]\n",
      " [-1.22173022 -0.26179933]\n",
      " [-0.69813156 -0.43633222]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [-0.87266444  0.34906578]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [-1.22173022  0.26179933]\n",
      " [ 0.785398   -0.17453289]\n",
      " [-0.87266444  0.08726644]\n",
      " [-1.13446378 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.48369136  0.08131561]\n",
      " [-0.76498765 -0.18250598]\n",
      " [-0.31059992 -0.3645587 ]\n",
      " [ 0.73066574 -0.17824996]\n",
      " [-0.70927858  0.36488616]\n",
      " [ 0.730281   -0.17820242]\n",
      " [-0.80839485  0.33502945]\n",
      " [ 0.99210161 -0.08776371]\n",
      " [-0.6824882   0.13950534]\n",
      " [-0.77911055 -0.33586907]]\n",
      "cost:\n",
      "0.300114\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089 -0.43633222]\n",
      " [ 1.04719733 -0.34906578]\n",
      " [ 0.43633222  0.        ]\n",
      " [-0.785398    0.08726644]\n",
      " [-0.61086511  0.17453289]\n",
      " [-0.61086511 -0.26179933]\n",
      " [ 1.13446378 -0.34906578]\n",
      " [-0.95993089  0.26179933]\n",
      " [-0.17453289  0.        ]\n",
      " [ 1.04719733  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.83190125 -0.38594911]\n",
      " [ 0.87677616 -0.31171101]\n",
      " [ 0.28433749 -0.00102463]\n",
      " [-0.9130367   0.07759403]\n",
      " [-0.78905171  0.19694977]\n",
      " [-0.74311292 -0.24700551]\n",
      " [ 0.84966052 -0.30772936]\n",
      " [-0.94485694  0.2801131 ]\n",
      " [-0.1918553  -0.01373609]\n",
      " [ 0.88021028  0.2903513 ]]\n",
      "cost:\n",
      "0.140775\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644  0.17453289]\n",
      " [-0.87266444  0.34906578]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [-0.785398    0.08726644]\n",
      " [-0.43633222  0.08726644]\n",
      " [-0.08726644 -0.08726644]\n",
      " [-1.22173022  0.17453289]\n",
      " [-0.17453289 -0.26179933]\n",
      " [-0.785398   -0.17453289]\n",
      " [-1.22173022  0.17453289]]\n",
      "prediction:\n",
      "[[-0.03769206  0.12575029]\n",
      " [-0.48062858  0.31172878]\n",
      " [ 0.99793595 -0.40932184]\n",
      " [-0.7299583   0.06887079]\n",
      " [-0.54546136  0.05884932]\n",
      " [ 0.13940659 -0.12970899]\n",
      " [-0.6595279   0.13096936]\n",
      " [-0.03798714 -0.40814325]\n",
      " [ 0.04423812 -0.31463718]\n",
      " [-0.6595279   0.13096936]]\n",
      "cost:\n",
      "0.378524\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398   -0.34906578]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [ 0.785398    0.08726644]\n",
      " [ 0.17453289  0.26179933]\n",
      " [-0.17453289  0.34906578]\n",
      " [ 0.52359867 -0.17453289]\n",
      " [ 0.52359867  0.26179933]\n",
      " [-0.87266444  0.26179933]\n",
      " [-1.22173022 -0.17453289]\n",
      " [-0.34906578 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.82495898 -0.3661412 ]\n",
      " [ 0.89226967 -0.20617259]\n",
      " [ 0.84883863  0.0269009 ]\n",
      " [ 0.01354154  0.20756319]\n",
      " [-0.33061227  0.26025942]\n",
      " [ 0.53286529 -0.21275496]\n",
      " [ 0.48714384  0.21310991]\n",
      " [-0.97067249  0.2104249 ]\n",
      " [-0.96659136 -0.22946905]\n",
      " [-0.51489127 -0.34800136]]\n",
      "cost:\n",
      "0.136199\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867  0.26179933]\n",
      " [ 0.34906578  0.26179933]\n",
      " [-1.22173022 -0.17453289]\n",
      " [-0.69813156  0.26179933]\n",
      " [-0.61086511 -0.26179933]\n",
      " [-1.13446378  0.        ]\n",
      " [-0.26179933  0.26179933]\n",
      " [-0.785398   -0.34906578]\n",
      " [ 0.52359867 -0.08726644]\n",
      " [ 0.95993089 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.28809819  0.21239038]\n",
      " [ 0.53590584  0.19830649]\n",
      " [-0.75619388 -0.23977245]\n",
      " [-0.61967647  0.21744907]\n",
      " [-0.2967976  -0.35612121]\n",
      " [-0.91335255  0.0137962 ]\n",
      " [-0.00950546  0.19271232]\n",
      " [-0.67512584 -0.43655193]\n",
      " [ 0.85926712 -0.14605811]\n",
      " [ 0.99290562 -0.11289409]]\n",
      "cost:\n",
      "0.233252\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.22173022  0.17453289]\n",
      " [-0.785398   -0.08726644]\n",
      " [ 0.87266444  0.        ]\n",
      " [-0.785398   -0.34906578]\n",
      " [-0.95993089  0.08726644]\n",
      " [-0.26179933 -0.08726644]\n",
      " [-0.52359867  0.17453289]\n",
      " [ 0.69813156  0.08726644]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [-0.95993089  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.93879175  0.15659691]\n",
      " [-0.79081631 -0.14963821]\n",
      " [ 0.94187593 -0.02178803]\n",
      " [-0.69406641 -0.52932632]\n",
      " [-0.89189941  0.09518668]\n",
      " [-0.15572651 -0.16845649]\n",
      " [-0.4858416   0.23808596]\n",
      " [ 0.76788253  0.08233269]\n",
      " [ 0.80026805 -0.30698991]\n",
      " [-0.90847623  0.22907566]]\n",
      "cost:\n",
      "0.120891\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.22173022  0.        ]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [-1.13446378 -0.34906578]\n",
      " [ 0.61086511 -0.17453289]\n",
      " [-0.95993089 -0.08726644]\n",
      " [ 0.87266444  0.34906578]\n",
      " [ 0.61086511  0.26179933]\n",
      " [ 0.785398   -0.08726644]\n",
      " [-1.04719733 -0.34906578]\n",
      " [-0.69813156 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.84401166  0.05145232]\n",
      " [ 0.80442703 -0.35716856]\n",
      " [-0.80062294 -0.31848466]\n",
      " [ 0.81767523 -0.12931792]\n",
      " [-0.90937054 -0.02519421]\n",
      " [ 0.72248244  0.37606829]\n",
      " [ 0.57864749  0.34085324]\n",
      " [ 0.96503782  0.0032593 ]\n",
      " [-0.82817757 -0.32528475]\n",
      " [-0.65478408 -0.00469693]]\n",
      "cost:\n",
      "0.210028\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867 -0.26179933]\n",
      " [ 0.26179933  0.26179933]\n",
      " [-0.95993089  0.        ]\n",
      " [ 0.34906578  0.        ]\n",
      " [-0.17453289  0.17453289]\n",
      " [-0.785398    0.        ]\n",
      " [-0.95993089 -0.26179933]\n",
      " [-0.08726644  0.08726644]\n",
      " [-0.95993089 -0.08726644]\n",
      " [-0.34906578  0.        ]]\n",
      "prediction:\n",
      "[[ 0.22187021 -0.40586177]\n",
      " [ 0.95032847  0.34530094]\n",
      " [-0.93797475 -0.01687725]\n",
      " [ 0.98599249 -0.05562971]\n",
      " [-0.1185623   0.26182064]\n",
      " [-0.65056443 -0.00436591]\n",
      " [-0.50299406 -0.43984348]\n",
      " [-0.00831083  0.10638989]\n",
      " [-0.82158351 -0.17176445]\n",
      " [-0.13738681 -0.03195668]]\n",
      "cost:\n",
      "0.33063\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289 -0.34906578]\n",
      " [ 1.04719733  0.        ]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [ 0.34906578  0.17453289]\n",
      " [-0.17453289  0.17453289]\n",
      " [-0.52359867 -0.08726644]\n",
      " [-1.13446378  0.34906578]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [-1.13446378 -0.43633222]\n",
      " [ 0.87266444  0.17453289]]\n",
      "prediction:\n",
      "[[-0.19904569 -0.36670259]\n",
      " [ 0.88562936 -0.02441868]\n",
      " [ 0.865592   -0.10756434]\n",
      " [ 0.08996375  0.18603215]\n",
      " [-0.23965186  0.18549073]\n",
      " [-0.62929004 -0.09234533]\n",
      " [-0.96720827  0.31788036]\n",
      " [ 0.82069355 -0.29385915]\n",
      " [-0.9538992  -0.41094914]\n",
      " [ 0.83068532  0.20180507]]\n",
      "cost:\n",
      "0.152616\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156  0.26179933]\n",
      " [ 0.785398    0.17453289]\n",
      " [-0.26179933  0.08726644]\n",
      " [ 0.52359867 -0.17453289]\n",
      " [ 1.22173022 -0.08726644]\n",
      " [-0.95993089  0.08726644]\n",
      " [-1.04719733  0.26179933]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [-0.87266444 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.71437836  0.28886965]\n",
      " [ 0.8526848   0.20179136]\n",
      " [-0.2405684   0.09878287]\n",
      " [ 0.4862029  -0.30594471]\n",
      " [ 0.92962831 -0.15946802]\n",
      " [-0.91879356  0.10522152]\n",
      " [-0.88596547  0.27988479]\n",
      " [ 0.45084119 -0.42234212]\n",
      " [ 0.92724943 -0.31555292]\n",
      " [-0.89010459 -0.14436226]]\n",
      "cost:\n",
      "0.115369\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289  0.        ]\n",
      " [ 0.34906578 -0.08726644]\n",
      " [ 0.785398   -0.08726644]\n",
      " [-0.26179933 -0.34906578]\n",
      " [ 0.26179933  0.26179933]\n",
      " [ 0.87266444  0.34906578]\n",
      " [ 0.         -0.26179933]\n",
      " [ 0.52359867 -0.08726644]\n",
      " [-0.26179933 -0.26179933]\n",
      " [ 0.43633222  0.17453289]]\n",
      "prediction:\n",
      "[[-0.35854062  0.00551131]\n",
      " [ 0.26772824 -0.07392742]\n",
      " [ 0.86644614 -0.03525907]\n",
      " [-0.97357208 -0.38955787]\n",
      " [ 0.31600285  0.28350297]\n",
      " [ 0.9638896   0.34823525]\n",
      " [-0.26429272 -0.33654025]\n",
      " [ 0.52019441 -0.09275499]\n",
      " [-0.96048796 -0.29543829]\n",
      " [ 0.22966607  0.18921305]]\n",
      "cost:\n",
      "0.241315\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444 -0.26179933]\n",
      " [-0.26179933 -0.26179933]\n",
      " [ 0.785398   -0.34906578]\n",
      " [ 1.04719733 -0.17453289]\n",
      " [-0.785398    0.34906578]\n",
      " [-1.13446378  0.17453289]\n",
      " [-0.87266444  0.08726644]\n",
      " [-1.22173022  0.34906578]\n",
      " [-0.87266444 -0.26179933]\n",
      " [ 0.17453289 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.6770137  -0.25883976]\n",
      " [-0.06650034 -0.26100922]\n",
      " [ 0.96930629 -0.36894298]\n",
      " [ 0.98894221 -0.12188333]\n",
      " [-0.5651682   0.37153643]\n",
      " [-0.77039689  0.14719795]\n",
      " [-0.70006323  0.0847403 ]\n",
      " [-0.56614089  0.30255726]\n",
      " [-0.6770137  -0.25883976]\n",
      " [ 0.16786104 -0.08973192]]\n",
      "cost:\n",
      "0.227358\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444 -0.26179933]\n",
      " [ 0.52359867  0.34906578]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [-0.69813156  0.08726644]\n",
      " [-0.17453289  0.17453289]\n",
      " [-0.08726644  0.        ]\n",
      " [ 0.61086511 -0.17453289]\n",
      " [ 1.22173022  0.        ]\n",
      " [-1.13446378  0.17453289]\n",
      " [-0.08726644  0.34906578]]\n",
      "prediction:\n",
      "[[-0.91147637 -0.44376686]\n",
      " [ 0.80752581  0.32565272]\n",
      " [ 0.12031429 -0.17952935]\n",
      " [-0.81005943 -0.01162259]\n",
      " [-0.04838271  0.1024312 ]\n",
      " [-0.08693743 -0.07577826]\n",
      " [ 0.91284716 -0.35117894]\n",
      " [ 0.96632177 -0.1713703 ]\n",
      " [-0.9607752   0.04097475]\n",
      " [-0.01660425  0.31797323]]\n",
      "cost:\n",
      "0.190213\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.43633222  0.34906578]\n",
      " [-0.08726644  0.17453289]\n",
      " [-0.17453289 -0.43633222]\n",
      " [-0.785398    0.26179933]\n",
      " [-0.34906578  0.08726644]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [-1.04719733 -0.17453289]\n",
      " [-0.52359867 -0.43633222]\n",
      " [ 0.69813156 -0.43633222]\n",
      " [-1.22173022  0.34906578]]\n",
      "prediction:\n",
      "[[-0.21165258  0.28241104]\n",
      " [-0.00750409  0.12298948]\n",
      " [-0.06661842 -0.34944853]\n",
      " [-0.67567194  0.21273257]\n",
      " [-0.35229191  0.07390565]\n",
      " [ 0.99117529 -0.13677803]\n",
      " [-0.91858256 -0.15232842]\n",
      " [-0.26848906 -0.35946921]\n",
      " [ 0.94705224 -0.35887134]\n",
      " [-0.80945385  0.24910069]]\n",
      "cost:\n",
      "0.173269\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578 -0.34906578]\n",
      " [ 0.         -0.26179933]\n",
      " [-1.13446378  0.26179933]\n",
      " [-1.22173022 -0.17453289]\n",
      " [-1.04719733 -0.17453289]\n",
      " [ 0.87266444 -0.26179933]\n",
      " [-1.13446378  0.26179933]\n",
      " [-0.43633222 -0.17453289]\n",
      " [-1.22173022  0.        ]\n",
      " [ 0.26179933 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.75773668 -0.36211726]\n",
      " [ 0.25672823 -0.25668404]\n",
      " [-0.70248628  0.39123693]\n",
      " [-0.68700039 -0.17008504]\n",
      " [-0.76914465 -0.1546187 ]\n",
      " [ 0.99548537 -0.24840257]\n",
      " [-0.70248628  0.39123693]\n",
      " [-0.05623172 -0.13101238]\n",
      " [-0.81174052  0.07135546]\n",
      " [ 0.49796936 -0.0126373 ]]\n",
      "cost:\n",
      "0.355104\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.22173022 -0.43633222]\n",
      " [-1.04719733  0.        ]\n",
      " [ 0.87266444  0.34906578]\n",
      " [ 0.61086511  0.08726644]\n",
      " [-0.17453289  0.        ]\n",
      " [-0.87266444 -0.34906578]\n",
      " [ 0.         -0.08726644]\n",
      " [-0.785398   -0.34906578]\n",
      " [ 0.87266444  0.17453289]\n",
      " [-0.17453289  0.08726644]]\n",
      "prediction:\n",
      "[[-0.85545158 -0.39050928]\n",
      " [-0.92159569  0.03387388]\n",
      " [ 0.93964988  0.34486258]\n",
      " [ 0.84577072  0.10557517]\n",
      " [-0.18832207  0.00132637]\n",
      " [-0.7724666  -0.35710701]\n",
      " [ 0.05058162 -0.09065797]\n",
      " [-0.707183   -0.35672197]\n",
      " [ 0.97185695  0.2069792 ]\n",
      " [-0.17210609  0.11613463]]\n",
      "cost:\n",
      "0.117895\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222  0.08726644]\n",
      " [-0.08726644 -0.26179933]\n",
      " [-1.13446378 -0.08726644]\n",
      " [-0.87266444  0.17453289]\n",
      " [-0.52359867 -0.43633222]\n",
      " [-0.08726644 -0.43633222]\n",
      " [ 1.13446378 -0.08726644]\n",
      " [ 0.95993089  0.26179933]\n",
      " [ 1.13446378 -0.08726644]\n",
      " [-0.43633222  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.46980286  0.12275294]\n",
      " [-0.10134926 -0.24185769]\n",
      " [-0.95719254 -0.07148837]\n",
      " [-0.93764609  0.23116626]\n",
      " [-0.66524893 -0.40972725]\n",
      " [-0.10783417 -0.39411044]\n",
      " [ 0.93273026 -0.06635055]\n",
      " [ 0.8750304   0.33032769]\n",
      " [ 0.93273026 -0.06635055]\n",
      " [-0.51838553  0.2134859 ]]\n",
      "cost:\n",
      "0.113402\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511 -0.08726644]\n",
      " [-0.52359867 -0.34906578]\n",
      " [ 0.785398    0.08726644]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [-0.87266444  0.17453289]\n",
      " [ 0.87266444  0.17453289]\n",
      " [-1.22173022  0.08726644]\n",
      " [ 0.          0.26179933]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [-0.87266444  0.        ]]\n",
      "prediction:\n",
      "[[ 0.56984025 -0.14420958]\n",
      " [-0.66488606 -0.44658417]\n",
      " [ 0.8246358   0.04688239]\n",
      " [ 0.89240551 -0.36192223]\n",
      " [-0.94322962  0.18314935]\n",
      " [ 0.9070496   0.17916347]\n",
      " [-0.91319662  0.10766857]\n",
      " [-0.00287637  0.35672975]\n",
      " [ 0.71697831 -0.2790688 ]\n",
      " [-0.90711826 -0.03235146]]\n",
      "cost:\n",
      "0.130582\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733  0.        ]\n",
      " [ 0.43633222  0.34906578]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [-0.08726644 -0.43633222]\n",
      " [-0.61086511 -0.34906578]\n",
      " [ 0.61086511  0.08726644]\n",
      " [-0.61086511 -0.26179933]\n",
      " [ 0.          0.17453289]\n",
      " [ 0.95993089 -0.26179933]\n",
      " [-0.52359867  0.34906578]]\n",
      "prediction:\n",
      "[[-0.97216338 -0.01663732]\n",
      " [ 0.41822734  0.31206939]\n",
      " [ 0.95710397 -0.05213737]\n",
      " [-0.01835767 -0.4091436 ]\n",
      " [-0.76265764 -0.34571755]\n",
      " [ 0.75041246  0.09294969]\n",
      " [-0.78925967 -0.25816086]\n",
      " [-0.01842577  0.17444408]\n",
      " [ 0.94632453 -0.25132608]\n",
      " [-0.70176601  0.32493311]]\n",
      "cost:\n",
      "0.0974138\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578  0.        ]\n",
      " [-0.08726644 -0.08726644]\n",
      " [ 0.          0.34906578]\n",
      " [-0.87266444  0.34906578]\n",
      " [-0.87266444 -0.43633222]\n",
      " [-0.26179933 -0.08726644]\n",
      " [-0.34906578  0.26179933]\n",
      " [ 0.95993089 -0.43633222]\n",
      " [ 0.          0.26179933]\n",
      " [-1.04719733  0.08726644]]\n",
      "prediction:\n",
      "[[-0.16520497 -0.03919927]\n",
      " [-0.04609618 -0.16299771]\n",
      " [ 0.07836818  0.25621635]\n",
      " [-0.66543847  0.21798413]\n",
      " [-0.81489801 -0.43598607]\n",
      " [-0.18337259 -0.15662712]\n",
      " [-0.22411257  0.17357883]\n",
      " [ 0.99824917 -0.43825924]\n",
      " [ 0.03103762  0.17564307]\n",
      " [-0.76762766  0.01302996]]\n",
      "cost:\n",
      "0.137552\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398    0.34906578]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [-0.785398    0.17453289]\n",
      " [-0.61086511  0.26179933]\n",
      " [ 0.43633222  0.08726644]\n",
      " [-1.04719733  0.08726644]\n",
      " [ 1.04719733  0.34906578]\n",
      " [-1.04719733  0.08726644]\n",
      " [ 0.          0.17453289]]\n",
      "prediction:\n",
      "[[ 0.84141982  0.23605803]\n",
      " [ 0.93693185 -0.46892518]\n",
      " [ 0.26624551 -0.44349793]\n",
      " [-0.79439914  0.03079432]\n",
      " [-0.63626719  0.14913151]\n",
      " [ 0.44160858 -0.05824488]\n",
      " [-0.94002628 -0.06145309]\n",
      " [ 0.93360281  0.23797284]\n",
      " [-0.94009483 -0.0614638 ]\n",
      " [-0.03297275  0.09832411]]\n",
      "cost:\n",
      "0.167368\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644 -0.34906578]\n",
      " [ 1.13446378  0.26179933]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [ 0.          0.34906578]\n",
      " [ 0.17453289 -0.26179933]\n",
      " [-0.785398    0.26179933]\n",
      " [ 1.13446378 -0.34906578]\n",
      " [-0.08726644 -0.08726644]\n",
      " [ 0.61086511  0.34906578]\n",
      " [ 1.22173022 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.31834722 -0.33293745]\n",
      " [ 0.75693017  0.21959759]\n",
      " [ 0.04954335 -0.0604635 ]\n",
      " [-0.27398676  0.30215618]\n",
      " [-0.00784152 -0.27466214]\n",
      " [-0.99648494  0.18482247]\n",
      " [ 0.87462944 -0.35751864]\n",
      " [-0.21147929 -0.04880568]\n",
      " [ 0.19688869  0.23865314]\n",
      " [ 0.90277082 -0.1773698 ]]\n",
      "cost:\n",
      "0.256227\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222  0.17453289]\n",
      " [ 0.95993089  0.26179933]\n",
      " [-1.22173022 -0.08726644]\n",
      " [-0.87266444 -0.43633222]\n",
      " [ 0.52359867  0.08726644]\n",
      " [-1.13446378 -0.08726644]\n",
      " [-0.61086511 -0.26179933]\n",
      " [-1.22173022 -0.17453289]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [-0.43633222  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.60642338  0.26322123]\n",
      " [ 0.99271488  0.32934108]\n",
      " [-0.84737957 -0.05194689]\n",
      " [-0.68746901 -0.45638326]\n",
      " [ 0.78621471  0.15268116]\n",
      " [-0.87171161 -0.06005335]\n",
      " [-0.31188187 -0.28336146]\n",
      " [-0.81671453 -0.17600119]\n",
      " [ 0.57199615 -0.19325928]\n",
      " [-0.16831551  0.13720773]]\n",
      "cost:\n",
      "0.247835\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511 -0.08726644]\n",
      " [-1.22173022 -0.08726644]\n",
      " [-1.13446378  0.        ]\n",
      " [ 0.87266444 -0.26179933]\n",
      " [ 0.785398    0.        ]\n",
      " [-0.52359867  0.34906578]\n",
      " [-0.52359867 -0.43633222]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [ 0.08726644 -0.08726644]\n",
      " [-0.26179933 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.80580425 -0.00504756]\n",
      " [-0.9250766  -0.03891781]\n",
      " [-0.96366328  0.08556194]\n",
      " [ 0.95958543 -0.28857747]\n",
      " [ 0.9468013   0.07372216]\n",
      " [-0.328729    0.48435342]\n",
      " [-0.53265595 -0.4742628 ]\n",
      " [ 0.18964425 -0.03942552]\n",
      " [ 0.0803758  -0.04352469]\n",
      " [-0.34391361 -0.16391549]]\n",
      "cost:\n",
      "0.142504\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933  0.26179933]\n",
      " [ 1.22173022  0.26179933]\n",
      " [ 0.87266444  0.08726644]\n",
      " [-0.52359867 -0.26179933]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [-0.43633222 -0.43633222]\n",
      " [-1.13446378  0.17453289]\n",
      " [-0.785398   -0.26179933]\n",
      " [ 0.34906578  0.17453289]\n",
      " [ 1.22173022 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.20787673  0.25095883]\n",
      " [ 0.93765318  0.26419422]\n",
      " [ 0.87543696  0.07653708]\n",
      " [-0.61062831 -0.24677163]\n",
      " [ 0.33135706 -0.17281994]\n",
      " [-0.38760218 -0.38354701]\n",
      " [-0.97195333  0.20887658]\n",
      " [-0.92080349 -0.21429032]\n",
      " [ 0.30020452  0.16913296]\n",
      " [ 0.92689472 -0.36823705]]\n",
      "cost:\n",
      "0.118947\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511  0.        ]\n",
      " [-0.95993089  0.08726644]\n",
      " [ 0.43633222  0.17453289]\n",
      " [-0.08726644  0.34906578]\n",
      " [-0.43633222  0.08726644]\n",
      " [ 0.17453289 -0.43633222]\n",
      " [-0.26179933 -0.08726644]\n",
      " [-0.61086511 -0.34906578]\n",
      " [ 0.61086511  0.34906578]\n",
      " [-1.13446378  0.        ]]\n",
      "prediction:\n",
      "[[ 0.98178899 -0.07152642]\n",
      " [-0.91524684  0.01300078]\n",
      " [ 0.72959888  0.09795567]\n",
      " [-0.32130858  0.3221395 ]\n",
      " [-0.34046787  0.05842842]\n",
      " [ 0.14693014 -0.46328837]\n",
      " [-0.29904673 -0.11702936]\n",
      " [-0.57336581 -0.4179377 ]\n",
      " [ 0.93797398  0.26029068]\n",
      " [-0.93619257 -0.08192787]]\n",
      "cost:\n",
      "0.182137\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378 -0.17453289]\n",
      " [ 0.26179933 -0.08726644]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [ 0.87266444 -0.34906578]\n",
      " [-1.13446378  0.        ]\n",
      " [-1.04719733  0.26179933]\n",
      " [-1.13446378 -0.26179933]\n",
      " [-1.04719733 -0.26179933]\n",
      " [-0.52359867  0.08726644]\n",
      " [-0.95993089 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.96679902 -0.08469377]\n",
      " [ 0.27524295  0.03988133]\n",
      " [ 0.94417369 -0.18771467]\n",
      " [ 0.92039645 -0.28785345]\n",
      " [-0.83254915  0.12662965]\n",
      " [-0.77330065  0.47361121]\n",
      " [-0.77896106 -0.16371274]\n",
      " [-0.7777462  -0.19343883]\n",
      " [-0.27865121  0.19794324]\n",
      " [-0.68958354 -0.39197493]]\n",
      "cost:\n",
      "0.254613\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733  0.26179933]\n",
      " [ 1.22173022  0.17453289]\n",
      " [ 0.52359867 -0.43633222]\n",
      " [ 0.34906578 -0.43633222]\n",
      " [-0.08726644  0.17453289]\n",
      " [ 1.13446378  0.26179933]\n",
      " [-0.87266444 -0.08726644]\n",
      " [-1.13446378  0.17453289]\n",
      " [-0.52359867 -0.34906578]\n",
      " [-0.26179933  0.08726644]]\n",
      "prediction:\n",
      "[[-0.90476072  0.21789952]\n",
      " [ 0.96303183  0.16022786]\n",
      " [ 0.7304616  -0.39622742]\n",
      " [ 0.46274272 -0.39708522]\n",
      " [-0.09657712  0.10247442]\n",
      " [ 0.9641161   0.2267068 ]\n",
      " [-0.84000504 -0.09859973]\n",
      " [-0.90785778  0.14970198]\n",
      " [-0.48513955 -0.36221978]\n",
      " [-0.33196297  0.04503   ]]\n",
      "cost:\n",
      "0.137077\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398   -0.43633222]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [-0.43633222  0.        ]\n",
      " [ 1.04719733 -0.26179933]\n",
      " [-0.52359867  0.        ]\n",
      " [-1.04719733 -0.34906578]\n",
      " [ 0.34906578  0.34906578]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [ 0.69813156  0.26179933]\n",
      " [ 1.04719733  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.47876674 -0.37745866]\n",
      " [ 0.69922626 -0.33463323]\n",
      " [-0.5602113   0.02306895]\n",
      " [ 0.66467929 -0.19342367]\n",
      " [-0.74946153  0.0323072 ]\n",
      " [-0.99688715 -0.26211876]\n",
      " [ 0.34567153  0.29744688]\n",
      " [ 0.59277678 -0.12146809]\n",
      " [ 0.56249261  0.24076064]\n",
      " [ 0.80440927  0.26863134]]\n",
      "cost:\n",
      "0.231915\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156 -0.17453289]\n",
      " [-0.87266444  0.17453289]\n",
      " [-0.785398    0.17453289]\n",
      " [-0.69813156  0.26179933]\n",
      " [ 0.34906578  0.        ]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [ 1.04719733  0.        ]\n",
      " [ 0.61086511  0.        ]\n",
      " [-0.785398    0.26179933]\n",
      " [ 0.69813156  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.70722169 -0.31040108]\n",
      " [-0.94349325  0.10326666]\n",
      " [-0.9034037   0.09968527]\n",
      " [-0.83080268  0.25911734]\n",
      " [ 0.25438115 -0.07731315]\n",
      " [ 0.83504635 -0.52625966]\n",
      " [ 0.93976927 -0.08115385]\n",
      " [ 0.70641005 -0.10896733]\n",
      " [-0.88031089  0.23934211]\n",
      " [ 0.75454468  0.01167726]]\n",
      "cost:\n",
      "0.141537\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156 -0.17453289]\n",
      " [ 0.69813156  0.17453289]\n",
      " [ 0.43633222  0.34906578]\n",
      " [-1.22173022 -0.43633222]\n",
      " [-0.34906578  0.17453289]\n",
      " [-0.34906578  0.34906578]\n",
      " [ 0.34906578 -0.43633222]\n",
      " [ 0.43633222 -0.43633222]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [-0.95993089 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.94338703 -0.0848437 ]\n",
      " [ 0.93898505  0.17551921]\n",
      " [ 0.37041563  0.31685337]\n",
      " [-0.97025669 -0.28589484]\n",
      " [-0.35798928  0.14212038]\n",
      " [-0.4504641   0.29466379]\n",
      " [ 0.21581174 -0.3234691 ]\n",
      " [ 0.41260412 -0.32880098]\n",
      " [ 0.52650744 -0.17427509]\n",
      " [-0.96646708 -0.16825928]]\n",
      "cost:\n",
      "0.152127\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644 -0.17453289]\n",
      " [ 0.08726644 -0.43633222]\n",
      " [-0.61086511 -0.43633222]\n",
      " [ 0.69813156 -0.43633222]\n",
      " [-0.61086511  0.26179933]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [-0.95993089  0.08726644]\n",
      " [ 1.04719733 -0.43633222]\n",
      " [-0.34906578  0.17453289]\n",
      " [ 1.13446378 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.11667902 -0.02035943]\n",
      " [-0.01512805 -0.26667199]\n",
      " [-0.80389351 -0.27198565]\n",
      " [ 0.66482627 -0.23253518]\n",
      " [-0.86185038  0.41351965]\n",
      " [ 0.91749537 -0.08431314]\n",
      " [-0.97861105  0.20928846]\n",
      " [ 0.90478039 -0.23899086]\n",
      " [-0.42942277  0.30099848]\n",
      " [ 0.90728796 -0.2337625 ]]\n",
      "cost:\n",
      "0.238036\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222 -0.17453289]\n",
      " [ 0.785398   -0.17453289]\n",
      " [ 0.34906578  0.        ]\n",
      " [ 0.43633222  0.34906578]\n",
      " [ 0.87266444  0.34906578]\n",
      " [-0.26179933  0.17453289]\n",
      " [-0.61086511  0.        ]\n",
      " [-0.34906578 -0.43633222]\n",
      " [-0.08726644 -0.26179933]\n",
      " [-0.61086511 -0.26179933]]\n",
      "prediction:\n",
      "[[  5.79118490e-01  -2.10092857e-01]\n",
      " [  9.15698767e-01  -1.64326474e-01]\n",
      " [  4.58436280e-01   5.48072101e-04]\n",
      " [  4.72984403e-01   3.13730955e-01]\n",
      " [  9.49907064e-01   3.29466969e-01]\n",
      " [ -2.29370162e-01   1.70498893e-01]\n",
      " [ -9.73056555e-01   6.34486899e-02]\n",
      " [ -3.80525857e-01  -4.22541529e-01]\n",
      " [ -2.15626918e-02  -2.54576355e-01]\n",
      " [ -9.69714046e-01  -2.49428496e-01]]\n",
      "cost:\n",
      "0.137772\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289 -0.08726644]\n",
      " [-1.22173022 -0.34906578]\n",
      " [ 0.95993089 -0.34906578]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [-1.13446378 -0.26179933]\n",
      " [-0.08726644  0.34906578]\n",
      " [-0.08726644 -0.26179933]\n",
      " [-0.17453289  0.26179933]\n",
      " [ 0.95993089  0.17453289]\n",
      " [-1.04719733  0.26179933]]\n",
      "prediction:\n",
      "[[-0.15471093 -0.05710062]\n",
      " [-0.88184726 -0.34050235]\n",
      " [ 0.89511788 -0.34535456]\n",
      " [ 0.94282949 -0.15873869]\n",
      " [-0.91591883 -0.25412253]\n",
      " [-0.0338183   0.32785633]\n",
      " [-0.00788422 -0.24698715]\n",
      " [-0.12752482  0.24471007]\n",
      " [ 0.95590609  0.14136969]\n",
      " [-0.92630279  0.22502476]]\n",
      "cost:\n",
      "0.103101\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578 -0.17453289]\n",
      " [ 0.785398   -0.17453289]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [ 0.61086511 -0.34906578]\n",
      " [-0.95993089 -0.43633222]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [ 0.43633222  0.34906578]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [ 0.61086511  0.34906578]]\n",
      "prediction:\n",
      "[[-0.75004452 -0.11212627]\n",
      " [ 0.94598824 -0.08948036]\n",
      " [ 0.5961988   0.015022  ]\n",
      " [ 0.18278448 -0.11960474]\n",
      " [ 0.68418503 -0.2987341 ]\n",
      " [-0.9964816  -0.37112975]\n",
      " [-0.09347182 -0.10222366]\n",
      " [ 0.04170566  0.38114899]\n",
      " [ 0.22088698 -0.22083621]\n",
      " [ 0.56015539  0.38359079]]\n",
      "cost:\n",
      "0.206814\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644  0.        ]\n",
      " [-0.69813156 -0.17453289]\n",
      " [ 1.04719733  0.08726644]\n",
      " [ 0.34906578  0.        ]\n",
      " [-0.785398   -0.34906578]\n",
      " [-1.13446378 -0.43633222]\n",
      " [-1.22173022  0.08726644]\n",
      " [-0.785398    0.08726644]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [-0.08726644  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.02085969 -0.01161817]\n",
      " [-0.65712607 -0.20093127]\n",
      " [ 0.99773127  0.1403524 ]\n",
      " [ 0.60158575  0.05599119]\n",
      " [-0.70190024 -0.43875349]\n",
      " [-0.7020191  -0.48129994]\n",
      " [-0.7560063   0.18461838]\n",
      " [-0.71556413  0.16184437]\n",
      " [ 0.34366283 -0.1155032 ]\n",
      " [ 0.05841459  0.25479698]]\n",
      "cost:\n",
      "0.19618\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578 -0.08726644]\n",
      " [-0.43633222 -0.43633222]\n",
      " [ 0.26179933  0.34906578]\n",
      " [-1.04719733  0.34906578]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [-0.69813156  0.        ]\n",
      " [-0.95993089  0.17453289]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [-0.17453289  0.        ]\n",
      " [ 0.17453289 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.18776086 -0.06153445]\n",
      " [-0.37868381 -0.35879946]\n",
      " [ 0.46398857  0.33840564]\n",
      " [-0.88998544  0.31642097]\n",
      " [ 0.99673039 -0.33279228]\n",
      " [-0.77781999 -0.00522885]\n",
      " [-0.87686324  0.16034049]\n",
      " [ 0.45259348 -0.1285128 ]\n",
      " [-0.0383173  -0.02844445]\n",
      " [ 0.31947535 -0.35496143]]\n",
      "cost:\n",
      "0.146108\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511 -0.17453289]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [ 0.785398   -0.08726644]\n",
      " [-0.69813156  0.26179933]\n",
      " [-0.61086511 -0.08726644]\n",
      " [-0.17453289 -0.43633222]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [-1.13446378 -0.17453289]\n",
      " [ 0.95993089  0.34906578]\n",
      " [ 0.87266444  0.34906578]]\n",
      "prediction:\n",
      "[[-0.76637363 -0.13714044]\n",
      " [ 0.76539898 -0.38110524]\n",
      " [ 0.70893949 -0.05743027]\n",
      " [-0.84192139  0.26050958]\n",
      " [-0.84539855 -0.04095088]\n",
      " [-0.16488914 -0.42329076]\n",
      " [ 0.79616696 -0.06610955]\n",
      " [-0.97463393 -0.14641739]\n",
      " [ 0.91376466  0.2956709 ]\n",
      " [ 0.87226045  0.29765102]]\n",
      "cost:\n",
      "0.107926\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378  0.34906578]\n",
      " [-0.08726644 -0.17453289]\n",
      " [ 0.95993089  0.34906578]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [ 0.17453289 -0.26179933]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [ 0.52359867 -0.08726644]\n",
      " [-0.43633222 -0.17453289]\n",
      " [-0.17453289  0.        ]\n",
      " [ 1.22173022  0.26179933]]\n",
      "prediction:\n",
      "[[  8.93156528e-01   3.25866878e-01]\n",
      " [ -3.08581263e-01  -1.70429081e-01]\n",
      " [  8.54367614e-01   3.44814032e-01]\n",
      " [  1.10484660e-01  -1.25956878e-01]\n",
      " [  1.77733421e-01  -3.17847759e-01]\n",
      " [  2.24056602e-01  -3.57912391e-01]\n",
      " [  4.73901629e-02  -1.13216147e-01]\n",
      " [ -9.96729195e-01  -2.35535294e-01]\n",
      " [ -6.47839665e-01  -6.30617142e-05]\n",
      " [  7.95614243e-01   2.42564917e-01]]\n",
      "cost:\n",
      "0.357405\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867 -0.34906578]\n",
      " [ 0.43633222 -0.43633222]\n",
      " [-0.87266444  0.26179933]\n",
      " [ 0.26179933 -0.08726644]\n",
      " [-1.22173022 -0.26179933]\n",
      " [-0.17453289  0.        ]\n",
      " [ 0.785398    0.        ]\n",
      " [ 0.69813156 -0.43633222]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [ 1.13446378 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.35390148 -0.26396993]\n",
      " [ 0.21804066 -0.36434686]\n",
      " [-0.9798677   0.46424353]\n",
      " [ 0.08543454  0.04650636]\n",
      " [-0.98273009 -0.13527918]\n",
      " [-0.20867549  0.05151911]\n",
      " [ 0.7591961   0.13020644]\n",
      " [ 0.50197983 -0.35975239]\n",
      " [ 0.86976314 -0.05548815]\n",
      " [ 0.88151115 -0.03973224]]\n",
      "cost:\n",
      "0.198171\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.43633222 -0.08726644]\n",
      " [ 1.13446378  0.26179933]\n",
      " [ 0.785398   -0.26179933]\n",
      " [-1.13446378 -0.17453289]\n",
      " [ 1.13446378  0.        ]\n",
      " [ 1.13446378  0.        ]\n",
      " [-0.26179933 -0.43633222]\n",
      " [-0.08726644  0.26179933]\n",
      " [-0.61086511 -0.26179933]\n",
      " [ 0.08726644  0.        ]]\n",
      "prediction:\n",
      "[[-0.6519863  -0.07081649]\n",
      " [ 0.83808267  0.32426915]\n",
      " [ 0.70897686 -0.27671343]\n",
      " [-0.98288482 -0.16110849]\n",
      " [ 0.92556453  0.04317291]\n",
      " [ 0.92556453  0.04317291]\n",
      " [-0.43855518 -0.44629756]\n",
      " [-0.17868289  0.29907548]\n",
      " [-0.9062227  -0.28138414]\n",
      " [ 0.02762351 -0.0160736 ]]\n",
      "cost:\n",
      "0.180937\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.22173022 -0.26179933]\n",
      " [ 0.          0.08726644]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [-1.04719733  0.17453289]\n",
      " [ 0.87266444  0.17453289]\n",
      " [ 0.08726644  0.34906578]\n",
      " [ 0.17453289  0.        ]\n",
      " [-1.13446378  0.        ]\n",
      " [ 1.13446378  0.        ]\n",
      " [ 0.52359867  0.17453289]]\n",
      "prediction:\n",
      "[[-0.8986904  -0.50547838]\n",
      " [-0.139415    0.03113729]\n",
      " [ 0.36532819 -0.39058983]\n",
      " [-0.93218797  0.09915861]\n",
      " [ 0.94129562  0.09252704]\n",
      " [ 0.0522561   0.33248568]\n",
      " [ 0.14304286 -0.06680648]\n",
      " [-0.94959909 -0.09627385]\n",
      " [ 0.96650487 -0.10888583]\n",
      " [ 0.685754    0.10195971]]\n",
      "cost:\n",
      "0.171489\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867 -0.08726644]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [ 1.13446378  0.26179933]\n",
      " [ 1.13446378  0.        ]\n",
      " [-0.95993089  0.26179933]\n",
      " [-0.26179933  0.17453289]\n",
      " [ 0.785398   -0.43633222]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [-0.17453289 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.4843573  -0.05261416]\n",
      " [ 0.73441088 -0.1613559 ]\n",
      " [ 0.20245031 -0.14057261]\n",
      " [ 0.71425748  0.2924037 ]\n",
      " [ 0.86058205  0.02296464]\n",
      " [-0.99819833  0.29562211]\n",
      " [-0.37627092  0.19313937]\n",
      " [ 0.30506578 -0.40843508]\n",
      " [ 0.14230265 -0.13747834]\n",
      " [-0.286614   -0.42090318]]\n",
      "cost:\n",
      "0.227294\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644  0.26179933]\n",
      " [-0.43633222  0.        ]\n",
      " [ 0.34906578  0.26179933]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [-0.785398    0.08726644]\n",
      " [-1.22173022  0.26179933]\n",
      " [ 0.34906578  0.08726644]\n",
      " [-0.69813156  0.17453289]\n",
      " [ 1.04719733 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.12554729  0.2054691 ]\n",
      " [-0.25252309 -0.14863105]\n",
      " [ 0.41700286  0.23863287]\n",
      " [ 0.71818316 -0.54079342]\n",
      " [ 0.1489874  -0.22142211]\n",
      " [-0.84829217 -0.03152345]\n",
      " [-0.97611457  0.18009721]\n",
      " [ 0.36622334  0.02884937]\n",
      " [-0.74711394  0.0794911 ]\n",
      " [ 0.99243957 -0.30690947]]\n",
      "cost:\n",
      "0.164041\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.43633222 -0.43633222]\n",
      " [-0.52359867 -0.17453289]\n",
      " [ 0.69813156  0.08726644]\n",
      " [-1.22173022  0.        ]\n",
      " [-0.87266444  0.08726644]\n",
      " [-1.04719733  0.17453289]\n",
      " [ 0.         -0.43633222]\n",
      " [-0.52359867  0.08726644]\n",
      " [-0.17453289 -0.43633222]\n",
      " [-0.52359867 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.14479803 -0.38305506]\n",
      " [-0.43057957 -0.11017103]\n",
      " [ 0.99857432  0.12195491]\n",
      " [-0.83412182  0.00913484]\n",
      " [-0.45502678  0.15560138]\n",
      " [-0.81093103  0.26129183]\n",
      " [ 0.28762451 -0.39375907]\n",
      " [-0.16294214  0.2062231 ]\n",
      " [-0.05073782 -0.39052606]\n",
      " [-0.14389905 -0.0142592 ]]\n",
      "cost:\n",
      "0.296369\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578  0.17453289]\n",
      " [-0.26179933 -0.43633222]\n",
      " [-0.95993089 -0.26179933]\n",
      " [-0.08726644 -0.34906578]\n",
      " [-0.87266444  0.08726644]\n",
      " [-0.52359867 -0.34906578]\n",
      " [-0.785398   -0.17453289]\n",
      " [-0.87266444  0.08726644]\n",
      " [ 0.34906578  0.17453289]\n",
      " [-0.69813156 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.98522884  0.29377705]\n",
      " [-0.05310209 -0.35955694]\n",
      " [-0.81521487 -0.19885811]\n",
      " [-0.03036058 -0.25885946]\n",
      " [-0.81799614  0.15250777]\n",
      " [-0.53644627 -0.27237687]\n",
      " [-0.41276276 -0.10612281]\n",
      " [-0.81778967  0.15249285]\n",
      " [ 0.98522884  0.29377705]\n",
      " [-0.23374517 -0.28792745]]\n",
      "cost:\n",
      "0.287669\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644 -0.26179933]\n",
      " [ 0.43633222  0.17453289]\n",
      " [-0.08726644 -0.26179933]\n",
      " [-0.785398    0.26179933]\n",
      " [ 0.08726644  0.        ]\n",
      " [-1.22173022 -0.43633222]\n",
      " [-1.13446378 -0.34906578]\n",
      " [-1.22173022 -0.34906578]\n",
      " [ 0.43633222 -0.43633222]\n",
      " [ 0.95993089 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.02013954 -0.13866174]\n",
      " [ 0.78459036  0.34006354]\n",
      " [-0.02001862 -0.13865599]\n",
      " [-0.64117825  0.41842052]\n",
      " [ 0.37634969  0.11630601]\n",
      " [-0.90171707 -0.26106882]\n",
      " [-0.89562017 -0.18575843]\n",
      " [-0.85873139 -0.19248046]\n",
      " [ 0.65243065 -0.30267844]\n",
      " [ 0.99337262 -0.24039648]]\n",
      "cost:\n",
      "0.260798\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222 -0.08726644]\n",
      " [ 0.95993089  0.        ]\n",
      " [-0.95993089  0.        ]\n",
      " [ 0.785398   -0.08726644]\n",
      " [-0.17453289  0.17453289]\n",
      " [ 0.         -0.17453289]\n",
      " [-0.43633222 -0.26179933]\n",
      " [ 0.          0.08726644]\n",
      " [-0.34906578  0.        ]\n",
      " [ 0.785398    0.08726644]]\n",
      "prediction:\n",
      "[[ 0.40419397 -0.1822722 ]\n",
      " [ 0.95275569  0.00740974]\n",
      " [-0.99464464 -0.00513574]\n",
      " [ 0.85454845 -0.14994518]\n",
      " [-0.24750787  0.3583976 ]\n",
      " [-0.10269865 -0.36110339]\n",
      " [-0.60328448 -0.4870255 ]\n",
      " [-0.09144778  0.10218836]\n",
      " [-0.53997338 -0.01037795]\n",
      " [ 0.84573603  0.23786674]]\n",
      "cost:\n",
      "0.137626\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156 -0.08726644]\n",
      " [-0.34906578  0.08726644]\n",
      " [-1.22173022  0.26179933]\n",
      " [ 0.52359867 -0.17453289]\n",
      " [-1.22173022 -0.43633222]\n",
      " [-0.08726644  0.08726644]\n",
      " [-0.95993089  0.34906578]\n",
      " [ 0.43633222 -0.43633222]\n",
      " [ 0.95993089 -0.34906578]\n",
      " [-0.08726644 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.92293924 -0.0354746 ]\n",
      " [-0.41332629  0.12181928]\n",
      " [-0.93961036  0.28957167]\n",
      " [ 0.72189432 -0.12336835]\n",
      " [-0.89949077 -0.35079801]\n",
      " [-0.09067283  0.14160308]\n",
      " [-0.90217239  0.33392024]\n",
      " [ 0.49944946 -0.36938313]\n",
      " [ 0.97928512 -0.29879755]\n",
      " [-0.08622577 -0.09198482]]\n",
      "cost:\n",
      "0.146791\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.26179933 -0.34906578]\n",
      " [-0.69813156  0.        ]\n",
      " [-0.52359867  0.17453289]\n",
      " [-0.34906578  0.08726644]\n",
      " [-1.04719733  0.08726644]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [ 0.61086511  0.26179933]\n",
      " [ 0.          0.        ]\n",
      " [ 0.08726644  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.12461176 -0.44426706]\n",
      " [-0.93146574 -0.08483557]\n",
      " [-0.64662808  0.14008604]\n",
      " [-0.47637245  0.04087089]\n",
      " [-0.96154201  0.02464454]\n",
      " [ 0.47157755 -0.12132522]\n",
      " [ 0.97448295 -0.45130688]\n",
      " [ 0.96367556  0.26891854]\n",
      " [-0.02202442 -0.01533413]\n",
      " [ 0.14698522  0.27614424]]\n",
      "cost:\n",
      "0.156943\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.43633222]\n",
      " [-0.34906578 -0.43633222]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [ 0.43633222 -0.43633222]\n",
      " [-0.52359867  0.17453289]\n",
      " [-1.22173022  0.26179933]\n",
      " [-0.08726644 -0.08726644]\n",
      " [-1.13446378  0.34906578]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [ 1.04719733  0.        ]]\n",
      "prediction:\n",
      "[[-0.90104926 -0.3439768 ]\n",
      " [-0.30825084 -0.35052675]\n",
      " [ 0.97257483 -0.05422681]\n",
      " [ 0.58398628 -0.34872368]\n",
      " [-0.45410448  0.21989746]\n",
      " [-0.9210946   0.24320216]\n",
      " [-0.00103174 -0.02811252]\n",
      " [-0.89300126  0.33934966]\n",
      " [ 0.41518942 -0.10852031]\n",
      " [ 0.96612537  0.03286877]]\n",
      "cost:\n",
      "0.170576\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867 -0.17453289]\n",
      " [-0.61086511 -0.34906578]\n",
      " [ 1.04719733  0.08726644]\n",
      " [ 0.95993089 -0.26179933]\n",
      " [-0.43633222  0.34906578]\n",
      " [ 0.61086511  0.17453289]\n",
      " [-0.17453289 -0.26179933]\n",
      " [-0.52359867  0.34906578]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [ 0.17453289  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.55766749 -0.20829052]\n",
      " [-0.98689079 -0.38244915]\n",
      " [ 0.91864383  0.04331828]\n",
      " [ 0.90199244 -0.30001923]\n",
      " [-0.74587947  0.32170585]\n",
      " [ 0.62905365  0.16044919]\n",
      " [-0.20050585 -0.29905719]\n",
      " [-0.93963492  0.32163295]\n",
      " [ 0.63549602 -0.11028823]\n",
      " [ 0.17894426  0.07461997]]\n",
      "cost:\n",
      "0.147396\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.26179933 -0.34906578]\n",
      " [ 0.69813156  0.17453289]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [ 0.43633222  0.        ]\n",
      " [ 0.34906578  0.17453289]\n",
      " [-1.04719733 -0.08726644]\n",
      " [ 0.95993089  0.26179933]]\n",
      "prediction:\n",
      "[[-0.02553033 -0.35406831]\n",
      " [ 0.48094058  0.27320862]\n",
      " [ 0.81733084 -0.16240801]\n",
      " [-0.20691098 -0.23972389]\n",
      " [ 0.39681947 -0.06074619]\n",
      " [ 0.19765154 -0.36918092]\n",
      " [ 0.2232351   0.02031976]\n",
      " [ 0.06371295  0.25299227]\n",
      " [-0.99860877 -0.06798121]\n",
      " [ 0.84018952  0.37634757]]\n",
      "cost:\n",
      "0.258255\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444  0.34906578]\n",
      " [ 0.61086511 -0.34906578]\n",
      " [ 0.17453289  0.26179933]\n",
      " [ 0.         -0.08726644]\n",
      " [ 0.69813156 -0.43633222]\n",
      " [ 0.785398    0.26179933]\n",
      " [-0.69813156 -0.43633222]\n",
      " [-0.08726644  0.26179933]\n",
      " [ 0.52359867  0.17453289]\n",
      " [ 0.61086511 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.82767129  0.26177403]\n",
      " [ 0.49995169 -0.2938011 ]\n",
      " [-0.01026515  0.21120247]\n",
      " [-0.04877149 -0.10545998]\n",
      " [ 0.64305341 -0.36732289]\n",
      " [ 0.59876871  0.17896628]\n",
      " [-0.99875724 -0.37784582]\n",
      " [-0.24441972  0.20272836]\n",
      " [ 0.2568883   0.12700027]\n",
      " [ 0.44307956 -0.23203686]]\n",
      "cost:\n",
      "0.167373\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733 -0.26179933]\n",
      " [-0.34906578  0.        ]\n",
      " [-0.61086511  0.26179933]\n",
      " [ 0.95993089  0.26179933]\n",
      " [ 0.08726644 -0.34906578]\n",
      " [ 1.04719733  0.        ]\n",
      " [-0.87266444 -0.17453289]\n",
      " [ 0.43633222  0.08726644]\n",
      " [-0.95993089  0.        ]\n",
      " [ 0.43633222  0.        ]]\n",
      "prediction:\n",
      "[[ 0.92960727 -0.37048122]\n",
      " [-0.44105288 -0.00552149]\n",
      " [-0.74859083  0.2977294 ]\n",
      " [ 0.91740161  0.30926508]\n",
      " [-0.005926   -0.45556998]\n",
      " [ 0.88512641 -0.00707868]\n",
      " [-0.96541089 -0.25793695]\n",
      " [ 0.37250856  0.08068383]\n",
      " [-0.96365851 -0.02692569]\n",
      " [ 0.37535641  0.00119867]]\n",
      "cost:\n",
      "0.103915\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.         -0.17453289]\n",
      " [-0.26179933 -0.26179933]\n",
      " [-0.08726644  0.08726644]\n",
      " [-0.08726644 -0.26179933]\n",
      " [ 0.08726644 -0.43633222]\n",
      " [ 0.26179933  0.08726644]\n",
      " [ 1.13446378  0.08726644]\n",
      " [-0.26179933  0.34906578]\n",
      " [-0.785398   -0.26179933]\n",
      " [ 0.87266444 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.03657402 -0.12631372]\n",
      " [-0.55170697 -0.20382011]\n",
      " [ 0.03912491  0.17305815]\n",
      " [-0.13581072 -0.19038978]\n",
      " [ 0.07937528 -0.36989647]\n",
      " [ 0.35507473  0.13545804]\n",
      " [ 0.94031501  0.15775399]\n",
      " [-0.43756381  0.45876059]\n",
      " [-0.99515754 -0.16660511]\n",
      " [ 0.95997208 -0.28137937]]\n",
      "cost:\n",
      "0.152172\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378 -0.17453289]\n",
      " [ 0.69813156  0.        ]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [-0.17453289 -0.34906578]\n",
      " [-0.34906578  0.26179933]\n",
      " [ 0.          0.17453289]\n",
      " [ 0.87266444 -0.34906578]\n",
      " [-0.26179933 -0.26179933]\n",
      " [ 0.          0.26179933]\n",
      " [ 0.87266444 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.9262352  -0.11845198]\n",
      " [ 0.37001804  0.06687168]\n",
      " [ 0.42738432 -0.3037062 ]\n",
      " [-0.28684327 -0.31882465]\n",
      " [-0.99665403  0.34863776]\n",
      " [-0.22726031  0.22084251]\n",
      " [ 0.8876667  -0.31788835]\n",
      " [-0.65299618 -0.22567719]\n",
      " [-0.26283509  0.32338843]\n",
      " [ 0.68476301 -0.12231193]]\n",
      "cost:\n",
      "0.255094\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089  0.26179933]\n",
      " [ 1.04719733 -0.43633222]\n",
      " [ 0.43633222  0.17453289]\n",
      " [-0.52359867 -0.34906578]\n",
      " [-0.08726644  0.26179933]\n",
      " [ 0.95993089 -0.26179933]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [-0.26179933 -0.17453289]\n",
      " [ 0.34906578  0.08726644]\n",
      " [-1.13446378  0.08726644]]\n",
      "prediction:\n",
      "[[-0.96249545  0.30600479]\n",
      " [ 0.87697679 -0.40469107]\n",
      " [ 0.51561427  0.19345684]\n",
      " [-0.76558387 -0.33393729]\n",
      " [ 0.02486566  0.27395672]\n",
      " [ 0.90677327 -0.25144175]\n",
      " [ 0.93297303 -0.23919608]\n",
      " [-0.42840648 -0.1667636 ]\n",
      " [ 0.31384057  0.07905021]\n",
      " [-0.96917975  0.07021227]]\n",
      "cost:\n",
      "0.136709\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933  0.08726644]\n",
      " [ 0.87266444  0.26179933]\n",
      " [ 1.04719733  0.        ]\n",
      " [ 1.04719733  0.17453289]\n",
      " [-0.61086511 -0.08726644]\n",
      " [-0.785398    0.26179933]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [ 1.13446378  0.        ]\n",
      " [-1.13446378  0.26179933]\n",
      " [-0.34906578 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.17529933  0.05023416]\n",
      " [ 0.84383374  0.23246659]\n",
      " [ 0.8141616  -0.07389186]\n",
      " [ 0.932473    0.10183387]\n",
      " [-0.71854281 -0.16613206]\n",
      " [-0.91394204  0.220466  ]\n",
      " [ 0.16815117 -0.44205093]\n",
      " [ 0.8425833  -0.07090941]\n",
      " [-0.98742884  0.18630157]\n",
      " [-0.2871531  -0.46475127]]\n",
      "cost:\n",
      "0.165942\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733  0.34906578]\n",
      " [-1.13446378 -0.08726644]\n",
      " [-0.43633222 -0.34906578]\n",
      " [-0.17453289 -0.17453289]\n",
      " [-1.04719733 -0.26179933]\n",
      " [-0.61086511  0.08726644]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [ 0.785398   -0.34906578]\n",
      " [-1.04719733  0.        ]\n",
      " [-0.43633222  0.34906578]]\n",
      "prediction:\n",
      "[[-0.74896502  0.34991318]\n",
      " [-0.76347476 -0.07477971]\n",
      " [-0.19268812 -0.36064768]\n",
      " [-0.10850389 -0.17155011]\n",
      " [-0.72212803 -0.24702899]\n",
      " [-0.39430854  0.10713033]\n",
      " [ 0.91025698 -0.05721042]\n",
      " [ 0.99707323 -0.33141091]\n",
      " [-0.79267615  0.01341318]\n",
      " [-0.17188103  0.34683388]]\n",
      "cost:\n",
      "0.272894\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156 -0.17453289]\n",
      " [-1.13446378  0.08726644]\n",
      " [ 0.87266444 -0.34906578]\n",
      " [-0.52359867  0.26179933]\n",
      " [ 0.34906578  0.08726644]\n",
      " [ 1.04719733  0.08726644]\n",
      " [-0.08726644 -0.26179933]\n",
      " [ 1.22173022  0.        ]\n",
      " [-0.95993089 -0.43633222]\n",
      " [ 0.69813156  0.26179933]]\n",
      "prediction:\n",
      "[[-0.85966265 -0.17548871]\n",
      " [-0.95915377  0.12171423]\n",
      " [ 0.82078266 -0.39049348]\n",
      " [-0.60848379  0.28421104]\n",
      " [ 0.29476929  0.10101021]\n",
      " [ 0.94961756  0.06951659]\n",
      " [-0.13930096 -0.27649724]\n",
      " [ 0.91338098 -0.01893742]\n",
      " [-0.94721091 -0.41373852]\n",
      " [ 0.744681    0.27566886]]\n",
      "cost:\n",
      "0.108707\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.08726644]\n",
      " [-0.61086511 -0.17453289]\n",
      " [ 0.43633222 -0.43633222]\n",
      " [-0.26179933 -0.34906578]\n",
      " [-1.13446378 -0.26179933]\n",
      " [ 1.13446378  0.        ]\n",
      " [-0.26179933  0.08726644]\n",
      " [ 1.13446378  0.17453289]\n",
      " [-0.87266444 -0.08726644]\n",
      " [-0.17453289  0.17453289]]\n",
      "prediction:\n",
      "[[-0.92112899 -0.06926803]\n",
      " [-0.4894318  -0.14359096]\n",
      " [ 0.50040483 -0.43319976]\n",
      " [-0.10864529 -0.35549766]\n",
      " [-0.85865545 -0.23583649]\n",
      " [ 0.98349309  0.08855373]\n",
      " [-0.1606198   0.16220312]\n",
      " [ 0.9740088   0.31126809]\n",
      " [-0.88358688 -0.04940298]\n",
      " [-0.06851882  0.28483465]]\n",
      "cost:\n",
      "0.153801\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156  0.34906578]\n",
      " [ 0.          0.        ]\n",
      " [-1.22173022 -0.17453289]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [ 0.08726644 -0.34906578]\n",
      " [-0.61086511 -0.26179933]\n",
      " [-0.95993089 -0.17453289]\n",
      " [-0.43633222  0.26179933]\n",
      " [-0.95993089  0.34906578]\n",
      " [-0.87266444  0.34906578]]\n",
      "prediction:\n",
      "[[-0.29911739  0.25119519]\n",
      " [-0.00297132  0.00406656]\n",
      " [-0.80763531 -0.24536379]\n",
      " [ 0.99884659 -0.12381712]\n",
      " [ 0.20295152 -0.37555501]\n",
      " [-0.12949726 -0.34327498]\n",
      " [-0.7717365  -0.24772996]\n",
      " [-0.1034383   0.20017222]\n",
      " [-0.60911423  0.23584853]\n",
      " [-0.50528765  0.23916502]]\n",
      "cost:\n",
      "0.278884\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933 -0.08726644]\n",
      " [ 0.69813156  0.        ]\n",
      " [ 0.69813156 -0.43633222]\n",
      " [-1.22173022  0.26179933]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [ 0.34906578  0.26179933]\n",
      " [ 0.95993089  0.17453289]\n",
      " [ 0.785398    0.26179933]\n",
      " [-1.13446378 -0.17453289]\n",
      " [ 0.69813156  0.34906578]]\n",
      "prediction:\n",
      "[[-0.36934194 -0.159987  ]\n",
      " [ 0.67504328 -0.04227786]\n",
      " [ 0.62837708 -0.50149208]\n",
      " [-0.98247826  0.1767783 ]\n",
      " [ 0.26502207 -0.26699838]\n",
      " [ 0.15749614  0.19245121]\n",
      " [ 0.92986888  0.07961174]\n",
      " [ 0.72965717  0.18427198]\n",
      " [-0.98650825 -0.25666392]\n",
      " [ 0.56500328  0.27104685]]\n",
      "cost:\n",
      "0.144435\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867  0.08726644]\n",
      " [-0.34906578 -0.17453289]\n",
      " [-0.69813156  0.26179933]\n",
      " [-1.22173022  0.26179933]\n",
      " [-0.87266444 -0.34906578]\n",
      " [-0.17453289 -0.43633222]\n",
      " [ 0.          0.        ]\n",
      " [-0.52359867 -0.34906578]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [ 1.22173022  0.        ]]\n",
      "prediction:\n",
      "[[-0.43837106  0.15430079]\n",
      " [-0.17473064 -0.09228395]\n",
      " [-0.66114032  0.35245776]\n",
      " [-0.94186234  0.31878814]\n",
      " [-0.84299409 -0.24230239]\n",
      " [-0.04462995 -0.33989978]\n",
      " [-0.04440183  0.00499699]\n",
      " [-0.32151288 -0.25157666]\n",
      " [ 0.98448998 -0.31214067]\n",
      " [ 0.9844963   0.04156641]]\n",
      "cost:\n",
      "0.163433\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222 -0.17453289]\n",
      " [-0.17453289 -0.08726644]\n",
      " [ 1.13446378  0.26179933]\n",
      " [-1.04719733  0.08726644]\n",
      " [ 0.785398   -0.26179933]\n",
      " [-0.17453289 -0.08726644]\n",
      " [ 0.34906578  0.17453289]\n",
      " [ 0.61086511  0.34906578]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [ 0.87266444  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.1842434  -0.22027415]\n",
      " [-0.3188765  -0.0953832 ]\n",
      " [ 0.87517726  0.22327258]\n",
      " [-0.99870563  0.06023644]\n",
      " [ 0.56107575 -0.32180175]\n",
      " [-0.3188765  -0.0953832 ]\n",
      " [ 0.13252844  0.15166281]\n",
      " [ 0.37655014  0.31851315]\n",
      " [ 0.55835247 -0.49015638]\n",
      " [ 0.75857306  0.05484879]]\n",
      "cost:\n",
      "0.198674\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398    0.        ]\n",
      " [ 0.61086511  0.26179933]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [ 0.87266444 -0.26179933]\n",
      " [ 1.22173022  0.08726644]\n",
      " [-0.34906578  0.34906578]\n",
      " [ 0.17453289  0.26179933]\n",
      " [-0.52359867 -0.34906578]\n",
      " [-0.52359867 -0.08726644]\n",
      " [ 0.95993089 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.99462551  0.0054872 ]\n",
      " [ 0.60530996  0.22876818]\n",
      " [ 0.85010403 -0.25822991]\n",
      " [ 0.79076761 -0.35111138]\n",
      " [ 0.82127231  0.05232462]\n",
      " [-0.40262377  0.34494805]\n",
      " [ 0.14508498  0.22964974]\n",
      " [-0.81984746 -0.41603482]\n",
      " [-0.776021   -0.10947787]\n",
      " [ 0.8496452  -0.14854622]]\n",
      "cost:\n",
      "0.168464\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089  0.34906578]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [-1.22173022 -0.26179933]\n",
      " [ 0.17453289  0.17453289]\n",
      " [-0.08726644  0.        ]\n",
      " [-0.43633222  0.17453289]\n",
      " [ 0.61086511  0.        ]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [-0.17453289  0.        ]\n",
      " [ 0.785398    0.26179933]]\n",
      "prediction:\n",
      "[[-0.9678629   0.31257105]\n",
      " [ 0.96050012 -0.34629223]\n",
      " [-0.97896808 -0.36264312]\n",
      " [ 0.0930013   0.11576506]\n",
      " [-0.1056008  -0.04573514]\n",
      " [-0.54095614  0.15028481]\n",
      " [ 0.72237563 -0.00990476]\n",
      " [ 0.59207737 -0.36078084]\n",
      " [-0.17465328 -0.06807907]\n",
      " [ 0.92389858  0.26389268]]\n",
      "cost:\n",
      "0.127086\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444  0.17453289]\n",
      " [-0.87266444 -0.17453289]\n",
      " [ 0.17453289  0.34906578]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [ 0.34906578  0.08726644]\n",
      " [-0.26179933  0.08726644]\n",
      " [ 0.95993089  0.17453289]\n",
      " [-1.04719733 -0.08726644]\n",
      " [-0.87266444  0.34906578]\n",
      " [-1.04719733 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.95335996  0.06988669]\n",
      " [-0.86498803 -0.28077349]\n",
      " [ 0.20802112  0.27900806]\n",
      " [ 0.83713651 -0.53067648]\n",
      " [ 0.35910326  0.05868333]\n",
      " [-0.30047405  0.05044001]\n",
      " [ 0.97291547  0.06221309]\n",
      " [-0.9205578  -0.15798956]\n",
      " [-0.74653834  0.24666217]\n",
      " [-0.92054474 -0.157997  ]]\n",
      "cost:\n",
      "0.106647\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.22173022 -0.17453289]\n",
      " [-0.34906578  0.08726644]\n",
      " [ 0.43633222  0.        ]\n",
      " [ 0.26179933  0.34906578]\n",
      " [-0.69813156  0.        ]\n",
      " [-0.61086511  0.08726644]\n",
      " [ 0.34906578  0.17453289]\n",
      " [ 0.785398   -0.26179933]\n",
      " [-0.69813156 -0.34906578]\n",
      " [ 0.08726644 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.97299439 -0.25635424]\n",
      " [-0.19592457  0.08373075]\n",
      " [ 0.85357904  0.0156428 ]\n",
      " [ 0.5399667   0.38696963]\n",
      " [-0.87395942 -0.00966956]\n",
      " [-0.54337335  0.09064895]\n",
      " [ 0.5953753   0.18924044]\n",
      " [ 0.99134952 -0.31450343]\n",
      " [-0.74725115 -0.44286886]\n",
      " [ 0.08455089 -0.13034143]]\n",
      "cost:\n",
      "0.196536\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578  0.        ]\n",
      " [-0.17453289 -0.34906578]\n",
      " [ 0.52359867  0.        ]\n",
      " [-0.34906578 -0.17453289]\n",
      " [ 0.61086511 -0.26179933]\n",
      " [ 0.87266444 -0.34906578]\n",
      " [-0.17453289  0.17453289]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [-0.69813156  0.08726644]\n",
      " [ 0.61086511 -0.26179933]]\n",
      "prediction:\n",
      "[[  9.94140655e-02   1.25038460e-01]\n",
      " [ -3.38091016e-01  -3.57490391e-01]\n",
      " [  3.85329813e-01   1.25187874e-01]\n",
      " [ -7.72345304e-01  -1.05388433e-01]\n",
      " [  5.74560881e-01  -2.27394521e-01]\n",
      " [  8.87146115e-01  -3.46359104e-01]\n",
      " [ -4.08145100e-01   3.78905416e-01]\n",
      " [  9.49117064e-01   6.29037560e-04]\n",
      " [ -9.96328712e-01   2.50252157e-01]\n",
      " [  5.74560881e-01  -2.27394521e-01]]\n",
      "cost:\n",
      "0.195509\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289  0.17453289]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [-1.04719733  0.        ]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [ 0.87266444  0.17453289]\n",
      " [ 0.26179933 -0.34906578]\n",
      " [-0.69813156  0.17453289]\n",
      " [-0.95993089  0.17453289]\n",
      " [ 0.         -0.17453289]\n",
      " [ 0.43633222  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.15121661  0.17945333]\n",
      " [ 0.26572961 -0.26706493]\n",
      " [-0.92737615 -0.053409  ]\n",
      " [ 0.96322817 -0.15475801]\n",
      " [ 0.96975291  0.18281184]\n",
      " [ 0.16920342 -0.51516151]\n",
      " [-0.87170416  0.17344978]\n",
      " [-0.97107351  0.1590011 ]\n",
      " [-0.03919208 -0.27586475]\n",
      " [ 0.51071191  0.19137159]]\n",
      "cost:\n",
      "0.102578\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511  0.34906578]\n",
      " [-0.08726644  0.08726644]\n",
      " [ 0.785398   -0.43633222]\n",
      " [-0.69813156  0.        ]\n",
      " [-0.52359867  0.17453289]\n",
      " [-0.43633222 -0.17453289]\n",
      " [ 1.22173022  0.34906578]\n",
      " [-0.95993089 -0.08726644]\n",
      " [-0.69813156  0.17453289]\n",
      " [ 0.43633222 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.79004306  0.27655101]\n",
      " [-0.06882117  0.0414352 ]\n",
      " [ 0.92460829 -0.45997068]\n",
      " [-0.72450215 -0.05833724]\n",
      " [-0.60892653  0.11742703]\n",
      " [-0.37260187 -0.2294548 ]\n",
      " [ 0.98534817  0.25009063]\n",
      " [-0.97166157 -0.13370723]\n",
      " [-0.8610878   0.10622434]\n",
      " [ 0.45117387 -0.37289318]]\n",
      "cost:\n",
      "0.114366\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644 -0.08726644]\n",
      " [ 0.785398    0.26179933]\n",
      " [-0.69813156 -0.34906578]\n",
      " [-0.26179933  0.08726644]\n",
      " [ 1.22173022  0.08726644]\n",
      " [ 1.22173022  0.26179933]\n",
      " [-0.08726644  0.26179933]\n",
      " [-0.43633222 -0.26179933]\n",
      " [-1.22173022  0.08726644]\n",
      " [-1.13446378 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.07080449 -0.13387853]\n",
      " [ 0.85946387  0.20805119]\n",
      " [-0.65747356 -0.47679764]\n",
      " [-0.25702992  0.04011224]\n",
      " [ 0.97318542  0.04302144]\n",
      " [ 0.95474571  0.2262343 ]\n",
      " [-0.0345507   0.21682884]\n",
      " [-0.33203697 -0.37739852]\n",
      " [-0.95884043  0.06323089]\n",
      " [-0.94680738 -0.26531228]]\n",
      "cost:\n",
      "0.154162\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733  0.        ]\n",
      " [ 0.43633222  0.26179933]\n",
      " [-1.22173022 -0.43633222]\n",
      " [ 0.87266444 -0.26179933]\n",
      " [ 0.87266444  0.08726644]\n",
      " [ 0.61086511 -0.43633222]\n",
      " [ 0.          0.        ]\n",
      " [-0.69813156  0.34906578]\n",
      " [ 0.61086511 -0.17453289]\n",
      " [ 1.22173022  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.82413042 -0.00386881]\n",
      " [ 0.32411295  0.24844693]\n",
      " [-0.99367613 -0.39124727]\n",
      " [ 0.73277223 -0.26999944]\n",
      " [ 0.62126589  0.08712967]\n",
      " [ 0.47314692 -0.41889188]\n",
      " [ 0.05837234  0.00924851]\n",
      " [-0.97958887  0.30422723]\n",
      " [ 0.53011656 -0.17986751]\n",
      " [ 0.71743572  0.18045251]]\n",
      "cost:\n",
      "0.202829\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.26179933  0.17453289]\n",
      " [-0.87266444 -0.17453289]\n",
      " [ 0.52359867 -0.17453289]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [-0.26179933 -0.34906578]\n",
      " [-0.61086511 -0.34906578]\n",
      " [-0.785398    0.08726644]\n",
      " [ 1.22173022  0.08726644]\n",
      " [-0.43633222 -0.17453289]\n",
      " [ 0.52359867 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.41525197  0.39752442]\n",
      " [-0.97129464 -0.11460913]\n",
      " [ 0.78162462 -0.13164823]\n",
      " [ 0.11423405 -0.13139746]\n",
      " [-0.09775661 -0.30428129]\n",
      " [-0.69499928 -0.31082076]\n",
      " [-0.95143253  0.23401041]\n",
      " [ 0.98989749  0.24458565]\n",
      " [-0.32092327 -0.07057786]\n",
      " [ 0.76433992 -0.33841571]]\n",
      "cost:\n",
      "0.185906\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511  0.26179933]\n",
      " [-0.61086511  0.08726644]\n",
      " [-0.52359867 -0.26179933]\n",
      " [-0.69813156 -0.43633222]\n",
      " [-0.87266444  0.26179933]\n",
      " [-0.26179933 -0.08726644]\n",
      " [-0.26179933 -0.34906578]\n",
      " [-0.26179933 -0.43633222]\n",
      " [-0.43633222 -0.26179933]\n",
      " [ 0.34906578  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.99754739  0.28707859]\n",
      " [-0.65905327  0.12394933]\n",
      " [-0.42647886 -0.20650306]\n",
      " [-0.6348474  -0.35151017]\n",
      " [-0.96290618  0.29785603]\n",
      " [-0.16280529 -0.02720959]\n",
      " [-0.12537183 -0.29035947]\n",
      " [-0.16539635 -0.36114928]\n",
      " [-0.218503   -0.21420601]\n",
      " [ 0.8386606   0.19477488]]\n",
      "cost:\n",
      "0.186238\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733  0.08726644]\n",
      " [-0.43633222  0.08726644]\n",
      " [-0.785398   -0.43633222]\n",
      " [ 0.17453289  0.26179933]\n",
      " [-0.785398    0.        ]\n",
      " [ 0.          0.17453289]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [-0.52359867  0.        ]\n",
      " [-1.04719733 -0.26179933]\n",
      " [-0.61086511  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.98846209  0.0547234 ]\n",
      " [-0.23924758  0.10310114]\n",
      " [-0.79786402 -0.51816618]\n",
      " [ 0.2712267   0.2905567 ]\n",
      " [-0.90215403 -0.05481314]\n",
      " [ 0.05222922  0.18239862]\n",
      " [ 0.97941434 -0.26935714]\n",
      " [-0.35032174 -0.02752758]\n",
      " [-0.91234797 -0.35092694]\n",
      " [-0.53663015  0.07650562]]\n",
      "cost:\n",
      "0.130264\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511 -0.17453289]\n",
      " [ 0.43633222  0.26179933]\n",
      " [ 0.87266444  0.34906578]\n",
      " [-0.87266444  0.26179933]\n",
      " [ 0.         -0.43633222]\n",
      " [ 0.34906578  0.17453289]\n",
      " [-0.08726644 -0.08726644]\n",
      " [ 0.785398    0.17453289]\n",
      " [ 0.61086511  0.17453289]\n",
      " [-0.61086511 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.57759011 -0.27447069]\n",
      " [ 0.33836168  0.16918838]\n",
      " [ 0.9212293   0.24478859]\n",
      " [-0.99653864  0.16966406]\n",
      " [ 0.00366306 -0.4675    ]\n",
      " [ 0.23298824  0.08293426]\n",
      " [-0.17926259 -0.13964789]\n",
      " [ 0.86614901  0.06386257]\n",
      " [ 0.60354966  0.07148499]\n",
      " [-0.9321776  -0.40911257]]\n",
      "cost:\n",
      "0.136185\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089  0.26179933]\n",
      " [ 1.13446378  0.26179933]\n",
      " [-0.95993089  0.17453289]\n",
      " [-0.95993089 -0.43633222]\n",
      " [ 1.13446378  0.17453289]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [-0.08726644  0.08726644]\n",
      " [-0.34906578  0.        ]\n",
      " [ 0.34906578  0.26179933]\n",
      " [-0.69813156 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.93073565  0.19250759]\n",
      " [ 0.96336371  0.19280851]\n",
      " [-0.91631114  0.0692584 ]\n",
      " [-0.90209514 -0.463177  ]\n",
      " [ 0.96793008  0.0976997 ]\n",
      " [ 0.88230526 -0.45617151]\n",
      " [-0.04776873  0.03492825]\n",
      " [-0.23577109 -0.05362766]\n",
      " [ 0.29000261  0.17497012]\n",
      " [-0.71540523 -0.16352409]]\n",
      "cost:\n",
      "0.101697\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578 -0.26179933]\n",
      " [-0.95993089 -0.34906578]\n",
      " [ 1.13446378  0.        ]\n",
      " [ 0.26179933 -0.34906578]\n",
      " [-0.95993089  0.17453289]\n",
      " [ 0.61086511 -0.17453289]\n",
      " [ 1.22173022  0.26179933]\n",
      " [ 0.34906578  0.26179933]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [-0.17453289  0.08726644]]\n",
      "prediction:\n",
      "[[-0.38405553 -0.28200155]\n",
      " [-0.97629333 -0.349756  ]\n",
      " [ 0.89729035  0.01356661]\n",
      " [ 0.25283349 -0.33253166]\n",
      " [-0.99016571  0.18625051]\n",
      " [ 0.46290752 -0.14182839]\n",
      " [ 0.86894023  0.28404811]\n",
      " [ 0.27706891  0.32411692]\n",
      " [ 0.88958883 -0.15625586]\n",
      " [-0.13114823  0.11648422]]\n",
      "cost:\n",
      "0.124368\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444 -0.43633222]\n",
      " [ 1.22173022 -0.43633222]\n",
      " [-0.785398   -0.43633222]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [ 0.95993089  0.26179933]\n",
      " [-1.04719733  0.        ]\n",
      " [ 0.         -0.26179933]\n",
      " [ 0.          0.17453289]\n",
      " [-0.87266444  0.        ]\n",
      " [ 0.61086511 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.86216426 -0.2720747 ]\n",
      " [ 0.9014585  -0.22913381]\n",
      " [-0.86246151 -0.28843331]\n",
      " [ 0.13775326 -0.05862245]\n",
      " [ 0.95194322  0.42665839]\n",
      " [-0.98328102  0.07375173]\n",
      " [-0.06675778 -0.16486654]\n",
      " [-0.06346804  0.30071041]\n",
      " [-0.9460302   0.07784615]\n",
      " [ 0.58712125 -0.27341983]]\n",
      "cost:\n",
      "0.162761\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578 -0.43633222]\n",
      " [ 0.61086511  0.        ]\n",
      " [-1.13446378 -0.26179933]\n",
      " [ 1.04719733 -0.43633222]\n",
      " [ 0.17453289  0.17453289]\n",
      " [-0.52359867 -0.43633222]\n",
      " [-1.22173022  0.34906578]\n",
      " [-0.87266444  0.26179933]\n",
      " [-0.61086511 -0.43633222]\n",
      " [-0.69813156  0.08726644]]\n",
      "prediction:\n",
      "[[-0.1037178  -0.27768177]\n",
      " [ 0.9405787  -0.03123103]\n",
      " [-0.91369003 -0.15637033]\n",
      " [ 0.99561322 -0.3023622 ]\n",
      " [ 0.28655437  0.18121487]\n",
      " [-0.31378153 -0.28539687]\n",
      " [-0.88065368  0.3255043 ]\n",
      " [-0.78821373  0.29562715]\n",
      " [-0.35475287 -0.28352657]\n",
      " [-0.47983277  0.12400191]]\n",
      "cost:\n",
      "0.233473\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156  0.34906578]\n",
      " [ 1.04719733  0.        ]\n",
      " [ 0.69813156  0.08726644]\n",
      " [-0.43633222  0.08726644]\n",
      " [-0.785398   -0.43633222]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [-0.34906578  0.17453289]\n",
      " [-0.34906578 -0.34906578]\n",
      " [-0.52359867  0.08726644]\n",
      " [ 0.87266444 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.72143412  0.37744865]\n",
      " [ 0.87840283 -0.02153052]\n",
      " [ 0.54857326  0.07677192]\n",
      " [-0.43506971  0.07539122]\n",
      " [-0.99751115 -0.44355783]\n",
      " [ 0.84721428 -0.11075187]\n",
      " [-0.33447561  0.16937955]\n",
      " [-0.44887173 -0.35912111]\n",
      " [-0.71472293  0.07249108]\n",
      " [ 0.81607449 -0.18374543]]\n",
      "cost:\n",
      "0.0980435\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089  0.        ]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [-0.08726644 -0.17453289]\n",
      " [ 0.87266444  0.        ]\n",
      " [-0.61086511  0.17453289]\n",
      " [ 0.17453289  0.26179933]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [-0.52359867 -0.08726644]\n",
      " [ 0.26179933  0.26179933]\n",
      " [-0.17453289  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.96376878 -0.00700598]\n",
      " [ 0.90074617 -0.3240532 ]\n",
      " [-0.57775289 -0.31876925]\n",
      " [ 0.93523312 -0.01418203]\n",
      " [-0.98952091  0.19352694]\n",
      " [-0.10780614  0.30551994]\n",
      " [-0.35200217 -0.35860065]\n",
      " [-0.89238292 -0.18280865]\n",
      " [ 0.06365048  0.32387674]\n",
      " [-0.26613054  0.08964757]]\n",
      "cost:\n",
      "0.301546\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644 -0.34906578]\n",
      " [-0.43633222  0.08726644]\n",
      " [-0.61086511 -0.08726644]\n",
      " [-0.52359867 -0.43633222]\n",
      " [-0.34906578  0.        ]\n",
      " [ 1.22173022  0.34906578]\n",
      " [-1.13446378 -0.17453289]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [-1.04719733 -0.26179933]\n",
      " [-0.95993089  0.        ]]\n",
      "prediction:\n",
      "[[ 0.23146097 -0.3052699 ]\n",
      " [-0.27716371  0.2069419 ]\n",
      " [-0.39245981 -0.00253672]\n",
      " [-0.47246227 -0.41500106]\n",
      " [-0.2465377   0.09233446]\n",
      " [ 0.99882489  0.41690049]\n",
      " [-0.81420195 -0.09828656]\n",
      " [ 0.61204875 -0.13669933]\n",
      " [-0.81460309 -0.22501686]\n",
      " [-0.77565694  0.11019053]]\n",
      "cost:\n",
      "0.205558\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444 -0.43633222]\n",
      " [ 0.34906578  0.08726644]\n",
      " [-0.17453289  0.26179933]\n",
      " [-0.17453289  0.26179933]\n",
      " [ 1.13446378 -0.08726644]\n",
      " [-1.22173022 -0.34906578]\n",
      " [ 0.785398    0.17453289]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [ 0.87266444 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.98631328 -0.41893232]\n",
      " [ 0.17596996  0.11974478]\n",
      " [-0.17161275  0.27498472]\n",
      " [-0.17145292  0.27472508]\n",
      " [ 0.80082113 -0.07150577]\n",
      " [-0.98820442 -0.32782108]\n",
      " [ 0.58625841  0.22623543]\n",
      " [ 0.8844074  -0.23575586]\n",
      " [ 0.83412611 -0.15383656]\n",
      " [ 0.64287007 -0.07949785]]\n",
      "cost:\n",
      "0.187451\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733  0.08726644]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [-0.52359867 -0.26179933]\n",
      " [ 0.08726644  0.34906578]\n",
      " [ 0.34906578  0.17453289]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [ 0.785398   -0.08726644]\n",
      " [-0.17453289  0.17453289]\n",
      " [ 0.69813156  0.        ]\n",
      " [-0.95993089  0.34906578]]\n",
      "prediction:\n",
      "[[-0.98590988  0.04454921]\n",
      " [ 0.84258354 -0.28587818]\n",
      " [-0.75799662 -0.40208891]\n",
      " [ 0.10025932  0.28523833]\n",
      " [ 0.33401206  0.11693855]\n",
      " [ 0.94627082 -0.38737693]\n",
      " [ 0.85443068 -0.14672309]\n",
      " [-0.14651009  0.10073395]\n",
      " [ 0.68641591 -0.02940975]\n",
      " [-0.9679603   0.25163782]]\n",
      "cost:\n",
      "0.111359\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398    0.34906578]\n",
      " [ 0.26179933  0.26179933]\n",
      " [ 0.26179933  0.26179933]\n",
      " [ 0.61086511  0.        ]\n",
      " [ 0.34906578  0.17453289]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [-0.43633222 -0.26179933]\n",
      " [ 0.52359867 -0.17453289]\n",
      " [-0.69813156 -0.17453289]\n",
      " [ 0.95993089 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.73891699  0.26778951]\n",
      " [ 0.11134557  0.22506888]\n",
      " [ 0.11130377  0.22507088]\n",
      " [ 0.62357163  0.00209686]\n",
      " [ 0.24472761  0.12987368]\n",
      " [ 0.199102   -0.29950315]\n",
      " [-0.91613114 -0.39495373]\n",
      " [ 0.41813993 -0.29138571]\n",
      " [-0.99691164 -0.24301191]\n",
      " [ 0.96413499 -0.10215186]]\n",
      "cost:\n",
      "0.177525\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644 -0.34906578]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [ 0.08726644  0.        ]\n",
      " [-0.61086511 -0.17453289]\n",
      " [ 0.          0.26179933]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [-1.13446378 -0.08726644]\n",
      " [ 0.26179933 -0.08726644]\n",
      " [ 0.52359867  0.34906578]\n",
      " [-0.61086511  0.08726644]]\n",
      "prediction:\n",
      "[[-0.08813161 -0.46363074]\n",
      " [ 0.99452347 -0.2368352 ]\n",
      " [ 0.16611829  0.03557359]\n",
      " [-0.81910443 -0.2367754 ]\n",
      " [-0.03360702  0.28558108]\n",
      " [ 0.29985166 -0.09274483]\n",
      " [-0.98891139 -0.12036072]\n",
      " [ 0.45931393 -0.09241581]\n",
      " [ 0.70205271  0.34670177]\n",
      " [-0.70265979  0.0953577 ]]\n",
      "cost:\n",
      "0.127376\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578  0.        ]\n",
      " [-0.34906578  0.        ]\n",
      " [ 1.04719733  0.34906578]\n",
      " [-0.87266444  0.17453289]\n",
      " [-0.26179933 -0.17453289]\n",
      " [ 0.785398    0.        ]\n",
      " [-0.785398    0.26179933]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [ 0.61086511  0.26179933]\n",
      " [-1.04719733  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.36222249 -0.11410933]\n",
      " [-0.33842871 -0.07183169]\n",
      " [ 0.96238673  0.24961308]\n",
      " [-0.94933045  0.07889281]\n",
      " [-0.21108346 -0.31632957]\n",
      " [ 0.95040578 -0.06866349]\n",
      " [-0.88604438  0.16684815]\n",
      " [ 0.6826551  -0.55659449]\n",
      " [ 0.72604108  0.15885314]\n",
      " [-0.96977365  0.04691524]]\n",
      "cost:\n",
      "0.147366\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398   -0.26179933]\n",
      " [ 0.          0.26179933]\n",
      " [-0.61086511  0.        ]\n",
      " [-0.17453289  0.26179933]\n",
      " [-1.22173022 -0.26179933]\n",
      " [-0.43633222 -0.08726644]\n",
      " [ 0.          0.        ]\n",
      " [-1.13446378  0.34906578]\n",
      " [ 1.22173022 -0.43633222]\n",
      " [ 0.69813156  0.26179933]]\n",
      "prediction:\n",
      "[[-0.80272961 -0.30931017]\n",
      " [ 0.07222544  0.19922504]\n",
      " [-0.75284779 -0.02427564]\n",
      " [-0.13569388  0.17215973]\n",
      " [-0.8598578  -0.28545436]\n",
      " [-0.46166989 -0.14828056]\n",
      " [ 0.04634615 -0.03123641]\n",
      " [-0.81430769  0.25137728]\n",
      " [ 0.99465901 -0.43789253]\n",
      " [ 0.97243392  0.20412721]]\n",
      "cost:\n",
      "0.171458\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089 -0.08726644]\n",
      " [ 0.87266444 -0.26179933]\n",
      " [-0.17453289  0.08726644]\n",
      " [-0.87266444  0.26179933]\n",
      " [-1.04719733 -0.26179933]\n",
      " [ 1.04719733 -0.43633222]\n",
      " [-0.785398    0.34906578]\n",
      " [-0.26179933 -0.34906578]\n",
      " [-1.22173022  0.34906578]\n",
      " [ 0.87266444 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.90544975 -0.05866565]\n",
      " [ 0.91142029 -0.22640954]\n",
      " [-0.13929199  0.08912079]\n",
      " [-0.92095935  0.24210274]\n",
      " [-0.96030551 -0.26001218]\n",
      " [ 0.93705702 -0.38342237]\n",
      " [-0.78601307  0.32740977]\n",
      " [-0.22989729 -0.32732633]\n",
      " [-0.83757907  0.26693654]\n",
      " [ 0.90430325 -0.05834036]]\n",
      "cost:\n",
      "0.0906533\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.26179933 -0.26179933]\n",
      " [-0.52359867  0.26179933]\n",
      " [-0.69813156 -0.43633222]\n",
      " [-1.04719733  0.26179933]\n",
      " [ 1.04719733  0.        ]\n",
      " [-0.34906578 -0.34906578]\n",
      " [-0.87266444 -0.34906578]\n",
      " [ 0.26179933  0.08726644]\n",
      " [ 0.785398    0.08726644]\n",
      " [ 0.26179933  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.18575798 -0.23106828]\n",
      " [-0.50001168  0.30305204]\n",
      " [-0.77560782 -0.39475912]\n",
      " [-0.94506067  0.30613568]\n",
      " [ 0.9905023   0.02485961]\n",
      " [-0.40155068 -0.31677634]\n",
      " [-0.92040664 -0.32222402]\n",
      " [ 0.25889036  0.09103884]\n",
      " [ 0.96698707  0.12720814]\n",
      " [ 0.25888786  0.09103741]]\n",
      "cost:\n",
      "0.0702562\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867 -0.43633222]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [ 0.52359867  0.34906578]\n",
      " [-0.69813156 -0.34906578]\n",
      " [-1.13446378 -0.08726644]\n",
      " [ 1.22173022  0.17453289]\n",
      " [-0.08726644  0.26179933]\n",
      " [ 0.17453289 -0.26179933]\n",
      " [ 0.95993089 -0.43633222]\n",
      " [ 0.785398    0.17453289]]\n",
      "prediction:\n",
      "[[ 0.3301751  -0.35004202]\n",
      " [ 0.0792627  -0.13162343]\n",
      " [ 0.37783587  0.33452299]\n",
      " [-0.92772734 -0.27789915]\n",
      " [-0.99630511 -0.05744471]\n",
      " [ 0.9346751   0.20035192]\n",
      " [-0.16978797  0.25589144]\n",
      " [ 0.05466735 -0.20914635]\n",
      " [ 0.86564088 -0.33459505]\n",
      " [ 0.80750829  0.20507854]]\n",
      "cost:\n",
      "0.16058\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089 -0.08726644]\n",
      " [-0.61086511 -0.17453289]\n",
      " [-0.69813156 -0.17453289]\n",
      " [ 0.43633222  0.17453289]\n",
      " [ 0.         -0.34906578]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [ 0.61086511 -0.17453289]\n",
      " [-1.04719733  0.26179933]\n",
      " [-0.61086511 -0.34906578]\n",
      " [-1.22173022 -0.43633222]]\n",
      "prediction:\n",
      "[[ -8.99350047e-01  -4.96438518e-03]\n",
      " [ -5.31506777e-01  -6.34789169e-02]\n",
      " [ -5.73967099e-01  -7.08462670e-02]\n",
      " [  7.56527424e-01   3.05342853e-01]\n",
      " [  3.03491950e-04  -2.99106061e-01]\n",
      " [  9.91999865e-01  -8.42705194e-04]\n",
      " [  9.63651419e-01  -9.54665691e-02]\n",
      " [ -8.44651043e-01   4.34328794e-01]\n",
      " [ -4.67059493e-01  -2.71584541e-01]\n",
      " [ -8.36386025e-01  -3.51426035e-01]]\n",
      "cost:\n",
      "0.228815\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444 -0.34906578]\n",
      " [-0.08726644 -0.08726644]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [-0.17453289  0.26179933]\n",
      " [-0.26179933  0.        ]\n",
      " [-1.04719733 -0.43633222]\n",
      " [-1.04719733 -0.08726644]\n",
      " [ 0.87266444  0.        ]\n",
      " [-1.04719733 -0.17453289]\n",
      " [-1.13446378  0.        ]]\n",
      "prediction:\n",
      "[[ 0.98271281 -0.32666686]\n",
      " [-0.09235927 -0.01581848]\n",
      " [ 0.51512206 -0.18068832]\n",
      " [-0.22687715  0.49395755]\n",
      " [-0.24247441  0.05163275]\n",
      " [-0.84505451 -0.40008897]\n",
      " [-0.81132621 -0.04510381]\n",
      " [ 0.98834318  0.02591786]\n",
      " [-0.86235815 -0.11201786]\n",
      " [-0.8320899   0.06725028]]\n",
      "cost:\n",
      "0.165854\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511 -0.34906578]\n",
      " [-0.43633222  0.17453289]\n",
      " [-0.69813156 -0.26179933]\n",
      " [ 0.52359867  0.17453289]\n",
      " [ 0.69813156  0.08726644]\n",
      " [-1.13446378  0.        ]\n",
      " [-0.34906578  0.17453289]\n",
      " [ 0.08726644 -0.34906578]\n",
      " [-1.13446378  0.17453289]\n",
      " [ 1.04719733  0.        ]]\n",
      "prediction:\n",
      "[[-0.469174   -0.42922604]\n",
      " [-0.45671865  0.16906254]\n",
      " [-0.68008637 -0.33169511]\n",
      " [ 0.75589311  0.21371424]\n",
      " [ 0.92942041  0.09429005]\n",
      " [-0.88564843  0.01527016]\n",
      " [-0.37498024  0.1710586 ]\n",
      " [ 0.19565463 -0.39895195]\n",
      " [-0.96156108  0.18410411]\n",
      " [ 0.99214542 -0.01961474]]\n",
      "cost:\n",
      "0.134942\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.26179933 -0.08726644]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [-0.26179933 -0.34906578]\n",
      " [-0.785398   -0.17453289]\n",
      " [ 0.08726644  0.26179933]\n",
      " [ 0.43633222  0.17453289]\n",
      " [-0.69813156 -0.26179933]\n",
      " [-1.22173022 -0.26179933]\n",
      " [ 0.87266444 -0.26179933]\n",
      " [ 0.17453289 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.26974285 -0.00309546]\n",
      " [ 0.92606008 -0.25756535]\n",
      " [-0.2482771  -0.24038212]\n",
      " [-0.91476315 -0.06142015]\n",
      " [ 0.0235143   0.4719497 ]\n",
      " [ 0.48872542  0.35177094]\n",
      " [-0.79095638 -0.13544171]\n",
      " [-0.97803271 -0.12948298]\n",
      " [ 0.98914373 -0.17456119]\n",
      " [ 0.08625663 -0.27069506]]\n",
      "cost:\n",
      "0.171361\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444  0.34906578]\n",
      " [ 0.         -0.17453289]\n",
      " [ 1.22173022  0.34906578]\n",
      " [-1.13446378  0.34906578]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [-0.785398    0.17453289]\n",
      " [-0.61086511  0.34906578]\n",
      " [-1.22173022 -0.26179933]\n",
      " [-1.13446378  0.26179933]\n",
      " [-0.95993089 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.60216963  0.18566495]\n",
      " [-0.04696024 -0.21435349]\n",
      " [ 0.99646056  0.19580272]\n",
      " [-0.74054253  0.20162898]\n",
      " [ 0.97261375 -0.39344001]\n",
      " [-0.57533908  0.04087069]\n",
      " [-0.42179337  0.19580977]\n",
      " [-0.69939065 -0.34117723]\n",
      " [-0.72951162  0.13077328]\n",
      " [-0.60159904 -0.35523203]]\n",
      "cost:\n",
      "0.316534\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444 -0.08726644]\n",
      " [-1.13446378  0.        ]\n",
      " [ 0.          0.        ]\n",
      " [-1.13446378  0.        ]\n",
      " [-0.95993089  0.17453289]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [-1.04719733  0.17453289]\n",
      " [-0.785398   -0.08726644]\n",
      " [ 0.69813156  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.99452829 -0.16103286]\n",
      " [-0.83218473  0.01698824]\n",
      " [-0.0252283  -0.01152429]\n",
      " [-0.83218473  0.01698824]\n",
      " [-0.84583908  0.18805736]\n",
      " [ 0.79458219 -0.5748136 ]\n",
      " [ 0.24026756 -0.16518395]\n",
      " [-0.84071672  0.17652701]\n",
      " [-0.73582298 -0.11741358]\n",
      " [ 0.9063862   0.24979447]]\n",
      "cost:\n",
      "0.181834\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089 -0.34906578]\n",
      " [ 0.26179933 -0.43633222]\n",
      " [ 1.04719733  0.26179933]\n",
      " [ 0.785398   -0.17453289]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [-0.52359867 -0.34906578]\n",
      " [-0.52359867 -0.34906578]\n",
      " [ 0.52359867  0.        ]\n",
      " [ 0.17453289 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.84600985 -0.1501321 ]\n",
      " [ 0.25048611 -0.26683635]\n",
      " [ 0.75941348  0.53430331]\n",
      " [ 0.51551473 -0.00825834]\n",
      " [ 0.74094826 -0.24892281]\n",
      " [ 0.4845131   0.00129177]\n",
      " [-0.99087989 -0.15914844]\n",
      " [-0.99087989 -0.15914844]\n",
      " [ 0.55971777  0.16532767]\n",
      " [ 0.17525649 -0.1897313 ]]\n",
      "cost:\n",
      "0.310499\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089  0.        ]\n",
      " [-0.17453289 -0.43633222]\n",
      " [-0.69813156 -0.17453289]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [-0.52359867  0.17453289]\n",
      " [-0.08726644  0.08726644]\n",
      " [-0.785398   -0.08726644]\n",
      " [ 0.43633222 -0.43633222]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [-0.61086511  0.34906578]]\n",
      "prediction:\n",
      "[[-0.96349597  0.03879707]\n",
      " [-0.08807584 -0.38697568]\n",
      " [-0.69826323 -0.13764276]\n",
      " [ 0.98593241 -0.20448743]\n",
      " [-0.47355604  0.23435928]\n",
      " [-0.06572991  0.1366923 ]\n",
      " [-0.84990144 -0.05491694]\n",
      " [ 0.51572251 -0.37790093]\n",
      " [ 0.98337692 -0.05236511]\n",
      " [-0.60408831  0.39727372]]\n",
      "cost:\n",
      "0.0758678\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644  0.34906578]\n",
      " [-0.43633222  0.        ]\n",
      " [ 0.17453289 -0.43633222]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [-0.43633222  0.26179933]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [ 1.13446378 -0.34906578]\n",
      " [-0.785398   -0.34906578]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [ 0.         -0.43633222]]\n",
      "prediction:\n",
      "[[-0.05353167  0.40249604]\n",
      " [-0.65919459  0.09638722]\n",
      " [ 0.15126234 -0.30165368]\n",
      " [ 0.31459576 -0.07061554]\n",
      " [-0.69554472  0.34784484]\n",
      " [ 0.94337881 -0.11549644]\n",
      " [ 0.94675195 -0.19379823]\n",
      " [-0.99708647 -0.20277588]\n",
      " [ 0.7146455  -0.13584195]\n",
      " [-0.04877961 -0.29869071]]\n",
      "cost:\n",
      "0.189051\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.08726644]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [ 1.04719733  0.        ]\n",
      " [ 0.43633222 -0.34906578]\n",
      " [-0.52359867 -0.17453289]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [-0.61086511  0.17453289]\n",
      " [-0.43633222  0.        ]\n",
      " [ 0.52359867  0.34906578]\n",
      " [ 0.26179933 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.99700779 -0.06022782]\n",
      " [ 0.85100394 -0.41374072]\n",
      " [ 0.91662031  0.05764461]\n",
      " [ 0.44814277 -0.35967684]\n",
      " [-0.65988648 -0.17487346]\n",
      " [ 0.91035229 -0.14231864]\n",
      " [-0.78015816  0.24315013]\n",
      " [-0.44829467  0.03468279]\n",
      " [ 0.41964969  0.43328437]\n",
      " [ 0.23198098 -0.0414028 ]]\n",
      "cost:\n",
      "0.135361\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398    0.34906578]\n",
      " [-0.69813156 -0.26179933]\n",
      " [-0.26179933  0.        ]\n",
      " [ 0.52359867  0.        ]\n",
      " [-0.87266444 -0.08726644]\n",
      " [-0.87266444  0.17453289]\n",
      " [-0.785398    0.34906578]\n",
      " [-0.69813156  0.34906578]\n",
      " [ 1.13446378 -0.08726644]\n",
      " [ 1.13446378  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.85323334  0.2022489 ]\n",
      " [-0.71246982 -0.50063288]\n",
      " [-0.33633643 -0.07540868]\n",
      " [ 0.3924928  -0.18083821]\n",
      " [-0.97098547 -0.21433671]\n",
      " [-0.91947114  0.07967012]\n",
      " [-0.53256541  0.21664658]\n",
      " [-0.49159899  0.23726681]\n",
      " [ 0.96817505 -0.29030663]\n",
      " [ 0.97730929  0.14157282]]\n",
      "cost:\n",
      "0.197741\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089 -0.08726644]\n",
      " [-0.17453289  0.        ]\n",
      " [-0.34906578 -0.34906578]\n",
      " [-1.13446378 -0.17453289]\n",
      " [ 1.13446378  0.        ]\n",
      " [-1.22173022  0.34906578]\n",
      " [-0.43633222 -0.43633222]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [ 0.61086511 -0.34906578]\n",
      " [ 0.34906578  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.91377419 -0.02871787]\n",
      " [-0.18732016  0.04275589]\n",
      " [-0.46464309 -0.3045077 ]\n",
      " [-0.98890811 -0.08223695]\n",
      " [ 0.94231355  0.04619947]\n",
      " [-0.95810562  0.36609262]\n",
      " [-0.53113306 -0.39181125]\n",
      " [ 0.91367996 -0.02871817]\n",
      " [ 0.58986902 -0.29849204]\n",
      " [ 0.15199593  0.33642593]]\n",
      "cost:\n",
      "0.132203\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867  0.        ]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [ 0.         -0.43633222]\n",
      " [ 1.13446378 -0.08726644]\n",
      " [-0.26179933 -0.08726644]\n",
      " [-1.04719733  0.34906578]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [ 0.          0.17453289]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [ 0.08726644 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.26497358  0.08196035]\n",
      " [ 0.67715371 -0.2734656 ]\n",
      " [-0.03250083 -0.35461873]\n",
      " [ 0.83656901  0.00498955]\n",
      " [-0.28962481 -0.04481518]\n",
      " [-0.99913776  0.45752352]\n",
      " [ 0.90581846 -0.15940757]\n",
      " [-0.06922081  0.23948354]\n",
      " [ 0.2927348  -0.08391074]\n",
      " [ 0.05908788 -0.28663489]]\n",
      "cost:\n",
      "0.150268\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089  0.        ]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [-0.26179933  0.34906578]\n",
      " [ 0.43633222 -0.43633222]\n",
      " [-1.13446378 -0.26179933]\n",
      " [-0.26179933  0.34906578]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [-0.34906578  0.17453289]\n",
      " [-0.26179933 -0.26179933]\n",
      " [-0.785398    0.17453289]]\n",
      "prediction:\n",
      "[[-0.84075087  0.02323753]\n",
      " [ 0.99813551 -0.15843579]\n",
      " [-0.23295121  0.31128362]\n",
      " [ 0.53130567 -0.39622164]\n",
      " [-0.93425739 -0.22557372]\n",
      " [-0.23295121  0.31128362]\n",
      " [ 0.77345276 -0.31675956]\n",
      " [-0.35793561  0.14981404]\n",
      " [-0.23269075 -0.23750885]\n",
      " [-0.84996754  0.14007242]]\n",
      "cost:\n",
      "0.103885\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444  0.26179933]\n",
      " [-0.785398   -0.17453289]\n",
      " [-0.95993089  0.34906578]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [ 0.87266444  0.08726644]\n",
      " [-0.52359867  0.        ]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [ 0.61086511  0.        ]\n",
      " [-0.69813156 -0.17453289]\n",
      " [-1.04719733 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.9702695   0.31050071]\n",
      " [-0.80156279 -0.18862405]\n",
      " [-0.95084739  0.40109891]\n",
      " [ 0.83484948 -0.34668931]\n",
      " [ 0.95887625  0.08981864]\n",
      " [-0.43614575  0.02790605]\n",
      " [ 0.42206049 -0.3364234 ]\n",
      " [ 0.45942622 -0.00893869]\n",
      " [-0.6467216  -0.18547313]\n",
      " [-0.97159517 -0.175064  ]]\n",
      "cost:\n",
      "0.0928199\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733  0.34906578]\n",
      " [-1.04719733 -0.34906578]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [-1.13446378  0.08726644]\n",
      " [-1.04719733 -0.34906578]\n",
      " [-0.52359867 -0.43633222]\n",
      " [-0.34906578 -0.43633222]\n",
      " [ 0.17453289 -0.34906578]\n",
      " [ 0.95993089  0.        ]\n",
      " [-0.43633222  0.17453289]]\n",
      "prediction:\n",
      "[[-0.79095125  0.4302527 ]\n",
      " [-0.78700322 -0.21165693]\n",
      " [ 0.99360323 -0.16170971]\n",
      " [-0.8634342   0.18295898]\n",
      " [-0.78700322 -0.21165693]\n",
      " [-0.41622278 -0.27219337]\n",
      " [-0.28463495 -0.24928544]\n",
      " [ 0.2282466  -0.2207637 ]\n",
      " [ 0.98574239  0.0454543 ]\n",
      " [-0.40148795  0.25276554]]\n",
      "cost:\n",
      "0.19885\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378 -0.43633222]\n",
      " [ 0.52359867  0.08726644]\n",
      " [ 0.69813156  0.17453289]\n",
      " [ 1.22173022 -0.43633222]\n",
      " [-0.08726644  0.34906578]\n",
      " [ 0.785398    0.        ]\n",
      " [-0.26179933  0.26179933]\n",
      " [ 0.785398   -0.08726644]\n",
      " [-0.95993089 -0.08726644]\n",
      " [ 1.13446378 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.61923015 -0.42333734]\n",
      " [ 0.35263544  0.06152392]\n",
      " [ 0.4216004   0.18369456]\n",
      " [ 0.50481796 -0.41171175]\n",
      " [-0.02537892  0.33128893]\n",
      " [ 0.55268145  0.00292545]\n",
      " [-0.34324741  0.2461541 ]\n",
      " [ 0.64565575 -0.08163316]\n",
      " [-0.99946952 -0.10107428]\n",
      " [ 0.73772407 -0.18482243]]\n",
      "cost:\n",
      "0.264098\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511 -0.34906578]\n",
      " [-0.34906578 -0.26179933]\n",
      " [ 0.43633222  0.08726644]\n",
      " [-0.785398    0.08726644]\n",
      " [-0.26179933  0.26179933]\n",
      " [ 1.04719733 -0.26179933]\n",
      " [-1.22173022 -0.34906578]\n",
      " [-0.61086511 -0.43633222]\n",
      " [-0.87266444  0.08726644]\n",
      " [-0.08726644 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.38171762 -0.28860947]\n",
      " [-0.08840829 -0.18678147]\n",
      " [ 0.78190947  0.19627529]\n",
      " [-0.69296324  0.15701799]\n",
      " [-0.07994775  0.44139251]\n",
      " [ 0.99858797 -0.13899198]\n",
      " [-0.95939159 -0.23409326]\n",
      " [-0.35098225 -0.36650956]\n",
      " [-0.79496813  0.15602829]\n",
      " [ 0.07503363 -0.19733413]]\n",
      "cost:\n",
      "0.220796\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156  0.17453289]\n",
      " [-0.43633222 -0.17453289]\n",
      " [-0.95993089 -0.26179933]\n",
      " [-0.69813156  0.17453289]\n",
      " [-0.43633222  0.26179933]\n",
      " [-1.13446378 -0.26179933]\n",
      " [ 1.13446378 -0.08726644]\n",
      " [ 0.52359867  0.17453289]\n",
      " [-0.34906578 -0.08726644]\n",
      " [-0.87266444  0.17453289]]\n",
      "prediction:\n",
      "[[-0.5091626   0.16312072]\n",
      " [-0.24420422 -0.2792072 ]\n",
      " [-0.75111473 -0.41604504]\n",
      " [-0.5091626   0.16312072]\n",
      " [-0.15174398  0.28183261]\n",
      " [-0.90303105 -0.39210308]\n",
      " [ 0.99878728 -0.15388283]\n",
      " [ 0.86293972  0.13867664]\n",
      " [-0.19393189 -0.12454575]\n",
      " [-0.72251964  0.17775637]]\n",
      "cost:\n",
      "0.221002\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644  0.08726644]\n",
      " [ 0.87266444  0.        ]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [ 0.          0.08726644]\n",
      " [ 0.08726644  0.34906578]\n",
      " [ 0.785398   -0.43633222]\n",
      " [-0.17453289 -0.08726644]\n",
      " [ 0.          0.34906578]\n",
      " [-0.95993089 -0.17453289]\n",
      " [ 0.26179933 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.00719854  0.06516991]\n",
      " [ 0.96610701 -0.01961325]\n",
      " [ 0.47650495 -0.2848573 ]\n",
      " [-0.12942819  0.03868428]\n",
      " [-0.06722514  0.33019572]\n",
      " [ 0.9054563  -0.4727526 ]\n",
      " [-0.27259073 -0.12827243]\n",
      " [-0.17340218  0.33694655]\n",
      " [-0.99872428 -0.20124882]\n",
      " [ 0.18396696 -0.11941724]]\n",
      "cost:\n",
      "0.10757\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578 -0.43633222]\n",
      " [ 0.69813156  0.        ]\n",
      " [ 0.26179933  0.34906578]\n",
      " [ 1.22173022  0.        ]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [ 0.52359867  0.26179933]\n",
      " [-0.43633222  0.26179933]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [-0.26179933  0.34906578]\n",
      " [ 0.95993089  0.17453289]]\n",
      "prediction:\n",
      "[[-0.98033631 -0.51564264]\n",
      " [ 0.05162618 -0.07356662]\n",
      " [ 0.20665172  0.23763134]\n",
      " [ 0.96578181 -0.10035072]\n",
      " [ 0.23189093 -0.36040163]\n",
      " [ 0.475642    0.13511987]\n",
      " [-0.99161798  0.15389968]\n",
      " [ 0.70242035 -0.16035369]\n",
      " [-0.42547762  0.2230193 ]\n",
      " [ 0.90336442  0.05195526]]\n",
      "cost:\n",
      "0.297713\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156  0.26179933]\n",
      " [-0.34906578  0.17453289]\n",
      " [ 1.13446378  0.26179933]\n",
      " [ 1.04719733 -0.43633222]\n",
      " [-0.26179933  0.08726644]\n",
      " [ 0.26179933  0.34906578]\n",
      " [-0.43633222  0.17453289]\n",
      " [ 0.26179933  0.17453289]\n",
      " [-0.26179933 -0.43633222]\n",
      " [ 0.          0.26179933]]\n",
      "prediction:\n",
      "[[ 0.56560242  0.10312015]\n",
      " [-0.80906785  0.04581877]\n",
      " [ 0.97219449  0.12437595]\n",
      " [ 0.9662984  -0.49461207]\n",
      " [-0.33462214 -0.04407234]\n",
      " [ 0.22469778  0.22531591]\n",
      " [-0.992616    0.04832194]\n",
      " [ 0.39052093  0.0173289 ]\n",
      " [-0.88571161 -0.51113701]\n",
      " [ 0.13429756  0.11155295]]\n",
      "cost:\n",
      "0.287963\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398    0.34906578]\n",
      " [ 1.22173022  0.34906578]\n",
      " [ 0.43633222  0.34906578]\n",
      " [-0.61086511 -0.26179933]\n",
      " [-0.43633222  0.26179933]\n",
      " [ 0.87266444  0.08726644]\n",
      " [-0.69813156  0.26179933]\n",
      " [-0.69813156  0.26179933]\n",
      " [-0.87266444  0.08726644]\n",
      " [-0.43633222 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.89348042  0.14861561]\n",
      " [ 0.97970325  0.09489901]\n",
      " [ 0.42696065  0.17670366]\n",
      " [-0.7415272  -0.40589041]\n",
      " [-0.41082299  0.11517461]\n",
      " [ 0.97405374 -0.06696913]\n",
      " [-0.87729752  0.10631519]\n",
      " [-0.87736553  0.10633031]\n",
      " [-0.94969034 -0.05537538]\n",
      " [-0.45867682 -0.56880176]]\n",
      "cost:\n",
      "0.205017\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398    0.17453289]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [ 0.61086511 -0.26179933]\n",
      " [ 0.69813156  0.17453289]\n",
      " [-0.08726644  0.17453289]\n",
      " [ 0.          0.26179933]\n",
      " [-1.04719733  0.17453289]\n",
      " [-0.95993089 -0.34906578]\n",
      " [-0.87266444  0.        ]]\n",
      "prediction:\n",
      "[[-0.79717696  0.16416121]\n",
      " [ 0.99081707 -0.21110064]\n",
      " [ 0.55365282 -0.32227406]\n",
      " [ 0.78630853 -0.31783086]\n",
      " [ 0.92585737  0.19943051]\n",
      " [-0.12654236  0.13822211]\n",
      " [ 0.0116207   0.26865816]\n",
      " [-0.95690781  0.1640183 ]\n",
      " [-0.94305694 -0.44000512]\n",
      " [-0.82850522 -0.07842144]]\n",
      "cost:\n",
      "0.1025\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378  0.08726644]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [ 0.17453289 -0.34906578]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [-0.26179933  0.34906578]\n",
      " [-0.69813156 -0.17453289]\n",
      " [ 0.87266444  0.17453289]\n",
      " [ 0.          0.17453289]\n",
      " [ 1.04719733  0.34906578]\n",
      " [ 0.95993089  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.63265169  0.02305553]\n",
      " [ 0.75588274 -0.36541575]\n",
      " [ 0.15397705 -0.42387411]\n",
      " [ 0.37330362 -0.22704628]\n",
      " [-0.38586247  0.28221074]\n",
      " [-0.99948841 -0.25445884]\n",
      " [ 0.61382222  0.10902884]\n",
      " [-0.12412516  0.11700718]\n",
      " [ 0.74574739  0.26515368]\n",
      " [ 0.5818373   0.02750911]]\n",
      "cost:\n",
      "0.261024\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289 -0.34906578]\n",
      " [-0.52359867  0.26179933]\n",
      " [ 0.26179933  0.17453289]\n",
      " [-0.26179933 -0.43633222]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [-0.34906578 -0.34906578]\n",
      " [ 0.69813156  0.17453289]\n",
      " [-0.61086511  0.08726644]\n",
      " [ 1.22173022 -0.34906578]\n",
      " [-0.61086511 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.20847173 -0.33004278]\n",
      " [-0.78741413  0.33379471]\n",
      " [ 0.2674087   0.21397056]\n",
      " [-0.2727021  -0.38106391]\n",
      " [ 0.84344745 -0.07081182]\n",
      " [-0.43879095 -0.29017213]\n",
      " [ 0.83506858  0.17186148]\n",
      " [-0.96447164  0.15727203]\n",
      " [ 0.99406612 -0.28384104]\n",
      " [-0.9635399  -0.02051426]]\n",
      "cost:\n",
      "0.17553\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089 -0.26179933]\n",
      " [ 0.34906578  0.26179933]\n",
      " [ 0.95993089 -0.43633222]\n",
      " [ 0.95993089  0.08726644]\n",
      " [ 0.785398   -0.17453289]\n",
      " [ 1.13446378  0.08726644]\n",
      " [-0.43633222  0.17453289]\n",
      " [ 0.08726644  0.26179933]\n",
      " [ 0.69813156  0.34906578]\n",
      " [-1.22173022  0.08726644]]\n",
      "prediction:\n",
      "[[-0.9785561  -0.35654584]\n",
      " [ 0.31822568  0.18059608]\n",
      " [ 0.8173902  -0.52176976]\n",
      " [ 0.83497721  0.01467279]\n",
      " [ 0.74970984 -0.2593801 ]\n",
      " [ 0.9133054   0.00368704]\n",
      " [-0.5345118   0.08442962]\n",
      " [ 0.08139894  0.16331568]\n",
      " [ 0.53481281  0.27303287]\n",
      " [-0.99497157 -0.01701218]]\n",
      "cost:\n",
      "0.148424\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444 -0.43633222]\n",
      " [-0.87266444  0.34906578]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [-0.17453289 -0.43633222]\n",
      " [ 0.61086511 -0.26179933]\n",
      " [-0.43633222 -0.26179933]\n",
      " [-0.26179933 -0.34906578]\n",
      " [ 0.34906578 -0.34906578]\n",
      " [-0.785398    0.34906578]\n",
      " [ 0.87266444 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.94921803 -0.25634682]\n",
      " [-0.95107234  0.41712418]\n",
      " [ 0.98277748 -0.04349675]\n",
      " [-0.0555106  -0.26197466]\n",
      " [ 0.70585155 -0.10446763]\n",
      " [-0.42439941 -0.14074387]\n",
      " [-0.1725767  -0.20864795]\n",
      " [ 0.40607214 -0.17772505]\n",
      " [-0.90859544  0.41684622]\n",
      " [ 0.97988194 -0.17992364]]\n",
      "cost:\n",
      "0.167492\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933 -0.43633222]\n",
      " [-0.08726644  0.26179933]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [ 0.43633222  0.17453289]\n",
      " [ 0.26179933  0.        ]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [-1.04719733 -0.43633222]\n",
      " [-0.34906578  0.34906578]\n",
      " [ 0.17453289  0.34906578]\n",
      " [-0.08726644 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.22956352 -0.37301901]\n",
      " [-0.20261042  0.20733607]\n",
      " [ 0.43550867 -0.22210017]\n",
      " [ 0.99009049  0.12845291]\n",
      " [ 0.7797401   0.00622539]\n",
      " [ 0.13628967 -0.07198523]\n",
      " [-0.99826545 -0.36775908]\n",
      " [-0.27299339  0.25726515]\n",
      " [ 0.04927065  0.27519968]\n",
      " [ 0.01807667 -0.35451931]]\n",
      "cost:\n",
      "0.197389\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.          0.        ]\n",
      " [ 0.26179933 -0.08726644]\n",
      " [-1.04719733 -0.43633222]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [ 1.13446378  0.        ]\n",
      " [ 0.69813156  0.08726644]\n",
      " [-0.43633222  0.17453289]\n",
      " [-0.785398    0.34906578]\n",
      " [ 0.         -0.17453289]\n",
      " [-0.785398    0.34906578]]\n",
      "prediction:\n",
      "[[ 0.1146024  -0.0167329 ]\n",
      " [ 0.292889   -0.1113832 ]\n",
      " [-0.99087048 -0.5691694 ]\n",
      " [ 0.39976645 -0.24527825]\n",
      " [ 0.99545431 -0.01381691]\n",
      " [ 0.86798382  0.06023774]\n",
      " [-0.26829919  0.10909745]\n",
      " [-0.79049683  0.27659142]\n",
      " [ 0.01611908 -0.22950594]\n",
      " [-0.79049683  0.27659142]]\n",
      "cost:\n",
      "0.107369\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511  0.17453289]\n",
      " [-0.34906578 -0.17453289]\n",
      " [ 0.43633222  0.08726644]\n",
      " [ 0.17453289  0.08726644]\n",
      " [ 0.61086511 -0.43633222]\n",
      " [-0.17453289  0.        ]\n",
      " [ 0.785398    0.17453289]\n",
      " [ 1.22173022 -0.08726644]\n",
      " [-0.17453289  0.17453289]\n",
      " [-0.17453289  0.        ]]\n",
      "prediction:\n",
      "[[ 0.75359952  0.19857769]\n",
      " [-0.99914849 -0.2967318 ]\n",
      " [ 0.4986279   0.0718815 ]\n",
      " [ 0.21028484  0.06826528]\n",
      " [ 0.16883171 -0.57806635]\n",
      " [-0.31311387 -0.03497397]\n",
      " [ 0.86949456  0.19766001]\n",
      " [ 0.9173227  -0.16883536]\n",
      " [-0.21803457  0.19327947]\n",
      " [-0.31311387 -0.03497397]]\n",
      "cost:\n",
      "0.211066\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378  0.        ]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [-0.34906578  0.08726644]\n",
      " [-1.04719733 -0.43633222]\n",
      " [-0.26179933  0.        ]\n",
      " [-1.04719733 -0.17453289]\n",
      " [ 1.22173022 -0.08726644]\n",
      " [-1.04719733  0.34906578]\n",
      " [ 0.34906578  0.08726644]\n",
      " [-0.08726644 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.97767985  0.02992681]\n",
      " [ 0.84174585 -0.1578255 ]\n",
      " [-0.42852247  0.11719856]\n",
      " [-0.88434237 -0.47047773]\n",
      " [-0.27111337  0.01896954]\n",
      " [-0.96891302 -0.17352243]\n",
      " [ 0.97478426 -0.08577365]\n",
      " [-0.93984926  0.41812378]\n",
      " [ 0.38407424  0.13777906]\n",
      " [-0.04513638 -0.28313342]]\n",
      "cost:\n",
      "0.11382\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933  0.08726644]\n",
      " [-0.08726644 -0.26179933]\n",
      " [-1.13446378  0.        ]\n",
      " [-0.08726644  0.        ]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [-0.61086511 -0.26179933]\n",
      " [ 0.95993089  0.34906578]\n",
      " [-0.61086511  0.17453289]]\n",
      "prediction:\n",
      "[[-0.33604941  0.13481835]\n",
      " [-0.10734968 -0.2593309 ]\n",
      " [-0.99410319 -0.0045684 ]\n",
      " [-0.12810661  0.03118198]\n",
      " [ 0.2920129  -0.26838154]\n",
      " [ 0.98574239 -0.17725472]\n",
      " [ 0.80616224 -0.35285562]\n",
      " [-0.78886074 -0.26724392]\n",
      " [ 0.93826491  0.41544339]\n",
      " [-0.76705223  0.21993557]]\n",
      "cost:\n",
      "0.0902263\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089  0.08726644]\n",
      " [ 0.69813156  0.17453289]\n",
      " [ 0.95993089 -0.26179933]\n",
      " [-0.69813156 -0.17453289]\n",
      " [ 0.785398    0.        ]\n",
      " [-0.52359867  0.26179933]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [-0.43633222 -0.08726644]\n",
      " [-1.04719733  0.        ]\n",
      " [ 0.87266444 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.90355247  0.10274356]\n",
      " [ 0.63342154  0.24052787]\n",
      " [ 0.82275903 -0.33871752]\n",
      " [-0.93867779 -0.21416271]\n",
      " [ 0.78695673 -0.01403192]\n",
      " [-0.61088324  0.36228538]\n",
      " [ 0.61866188 -0.20249702]\n",
      " [-0.49662596 -0.09939973]\n",
      " [-0.99712104  0.00530448]\n",
      " [ 0.79298258 -0.43812591]]\n",
      "cost:\n",
      "0.101477\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398   -0.08726644]\n",
      " [ 1.13446378  0.08726644]\n",
      " [-0.785398    0.34906578]\n",
      " [-1.13446378 -0.08726644]\n",
      " [ 0.69813156  0.08726644]\n",
      " [-0.785398    0.        ]\n",
      " [ 0.          0.08726644]\n",
      " [-1.04719733  0.08726644]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [-1.04719733 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.95773959 -0.17063847]\n",
      " [ 0.9922837   0.04326826]\n",
      " [-0.67944926  0.39816606]\n",
      " [-0.93201041 -0.25983536]\n",
      " [ 0.83618057  0.07296854]\n",
      " [-0.68317312 -0.06070028]\n",
      " [-0.01512414  0.10384793]\n",
      " [-0.90409553  0.0337524 ]\n",
      " [ 0.44250494 -0.51717031]\n",
      " [-0.90377748 -0.22950867]]\n",
      "cost:\n",
      "0.16299\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.26179933  0.34906578]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [-0.26179933  0.26179933]\n",
      " [ 0.26179933  0.17453289]\n",
      " [ 0.87266444 -0.26179933]\n",
      " [-0.95993089  0.08726644]\n",
      " [-0.52359867  0.        ]\n",
      " [ 0.43633222  0.        ]\n",
      " [-0.61086511  0.17453289]\n",
      " [ 0.34906578 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.12098831  0.29113534]\n",
      " [ 0.58454514 -0.16571137]\n",
      " [-0.32925397  0.19027445]\n",
      " [ 0.25485811  0.10321521]\n",
      " [ 0.99554515 -0.43851396]\n",
      " [-0.99561995  0.01323493]\n",
      " [-0.55102676 -0.10130286]\n",
      " [ 0.56705898 -0.0652703 ]\n",
      " [-0.83794475  0.08506782]\n",
      " [ 0.49358305 -0.45221737]]\n",
      "cost:\n",
      "0.152153\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289  0.17453289]\n",
      " [ 1.22173022  0.17453289]\n",
      " [ 1.04719733  0.34906578]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [-0.17453289 -0.26179933]\n",
      " [-0.34906578 -0.26179933]\n",
      " [ 0.26179933  0.        ]\n",
      " [ 0.87266444  0.08726644]\n",
      " [-0.61086511 -0.43633222]\n",
      " [ 0.95993089 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.24520567  0.1708163 ]\n",
      " [ 0.93163466  0.1989183 ]\n",
      " [ 0.82676208  0.35035938]\n",
      " [ 0.05432494 -0.24860035]\n",
      " [-0.48695132 -0.23863216]\n",
      " [-0.84673882 -0.23611231]\n",
      " [ 0.38794002  0.01215721]\n",
      " [ 0.75839823  0.09119149]\n",
      " [-0.99881095 -0.39500067]\n",
      " [ 0.75005406 -0.24093351]]\n",
      "cost:\n",
      "0.227154\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398   -0.34906578]\n",
      " [-0.785398    0.34906578]\n",
      " [-0.785398   -0.17453289]\n",
      " [ 1.22173022  0.        ]\n",
      " [-0.26179933 -0.34906578]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [ 0.52359867  0.34906578]\n",
      " [ 0.69813156  0.34906578]\n",
      " [-0.34906578  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.80884171 -0.30603951]\n",
      " [-0.97368139  0.22984301]\n",
      " [-0.99590838 -0.14760122]\n",
      " [ 0.95968086 -0.02070225]\n",
      " [-0.31880111 -0.32982716]\n",
      " [ 0.38228172 -0.17673853]\n",
      " [ 0.84825325 -0.38086042]\n",
      " [ 0.45773423  0.22006372]\n",
      " [ 0.65748847  0.21847239]\n",
      " [-0.34007949  0.21640386]]\n",
      "cost:\n",
      "0.133639\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578  0.34906578]\n",
      " [ 0.         -0.34906578]\n",
      " [ 0.43633222  0.17453289]\n",
      " [ 0.08726644  0.34906578]\n",
      " [ 0.26179933  0.26179933]\n",
      " [-0.69813156  0.34906578]\n",
      " [-1.22173022 -0.17453289]\n",
      " [ 0.95993089  0.17453289]\n",
      " [-0.34906578 -0.17453289]\n",
      " [-0.26179933 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.34831566  0.20633708]\n",
      " [ 0.02072572 -0.47972336]\n",
      " [ 0.49062711  0.04013418]\n",
      " [ 0.06037446  0.19924647]\n",
      " [ 0.25785023  0.13200007]\n",
      " [-0.85052466  0.22583376]\n",
      " [-0.99245137 -0.32408375]\n",
      " [ 0.99809551  0.05718015]\n",
      " [-0.36430413 -0.28393859]\n",
      " [-0.25788242 -0.16767445]]\n",
      "cost:\n",
      "0.148614\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578 -0.08726644]\n",
      " [-0.52359867 -0.26179933]\n",
      " [-0.95993089  0.17453289]\n",
      " [-0.08726644  0.        ]\n",
      " [-0.17453289 -0.17453289]\n",
      " [-1.13446378 -0.26179933]\n",
      " [ 0.26179933  0.34906578]\n",
      " [-0.34906578 -0.17453289]\n",
      " [-0.87266444  0.08726644]\n",
      " [ 1.04719733  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.65721923 -0.13114657]\n",
      " [-0.62053645 -0.35264343]\n",
      " [-0.87248755  0.14180264]\n",
      " [ 0.19102402  0.01742035]\n",
      " [-0.11264067 -0.20861219]\n",
      " [-0.95522916 -0.38097563]\n",
      " [ 0.37526378  0.35140359]\n",
      " [-0.37580013 -0.22125199]\n",
      " [-0.6522882   0.06559824]\n",
      " [ 0.99908745  0.30805135]]\n",
      "cost:\n",
      "0.155419\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156  0.08726644]\n",
      " [ 0.          0.08726644]\n",
      " [ 0.95993089 -0.26179933]\n",
      " [ 0.17453289  0.34906578]\n",
      " [-0.87266444 -0.43633222]\n",
      " [-0.61086511 -0.26179933]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [-0.08726644  0.08726644]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [ 0.26179933 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.88383704  0.09041486]\n",
      " [-0.01726267  0.14572866]\n",
      " [ 0.98093891 -0.25401604]\n",
      " [ 0.05443751  0.42226025]\n",
      " [-0.99476033 -0.45625031]\n",
      " [-0.80018616 -0.25796553]\n",
      " [ 0.96321911 -0.09315343]\n",
      " [-0.10410558  0.1382255 ]\n",
      " [ 0.66941673 -0.07784671]\n",
      " [ 0.33337578 -0.06615646]]\n",
      "cost:\n",
      "0.100115\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511  0.34906578]\n",
      " [ 0.          0.26179933]\n",
      " [ 1.04719733 -0.34906578]\n",
      " [ 0.69813156  0.08726644]\n",
      " [ 0.08726644 -0.08726644]\n",
      " [-0.34906578  0.34906578]\n",
      " [ 1.13446378 -0.34906578]\n",
      " [-0.17453289 -0.17453289]\n",
      " [-0.08726644  0.26179933]\n",
      " [-0.95993089 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.8367039   0.21657285]\n",
      " [ 0.06217873  0.19087289]\n",
      " [ 0.96555686 -0.4233298 ]\n",
      " [ 0.70908672  0.05997087]\n",
      " [ 0.13302165 -0.09293634]\n",
      " [-0.39848447  0.21963453]\n",
      " [ 0.96974587 -0.41657522]\n",
      " [-0.15397972 -0.1988086 ]\n",
      " [-0.1043494   0.17149794]\n",
      " [-0.99752659 -0.11052892]]\n",
      "cost:\n",
      "0.102652\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.          0.08726644]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [ 0.785398   -0.34906578]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [-1.22173022 -0.34906578]\n",
      " [-0.95993089  0.08726644]\n",
      " [ 0.785398    0.        ]\n",
      " [-0.34906578 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.05762436  0.30644009]\n",
      " [ 0.82686508 -0.05234971]\n",
      " [ 0.93740404 -0.29929355]\n",
      " [ 0.26347119 -0.23632787]\n",
      " [ 0.20346384 -0.02732861]\n",
      " [ 0.20346384 -0.02732861]\n",
      " [-0.99184626 -0.2892946 ]\n",
      " [-0.98331863  0.4000794 ]\n",
      " [ 0.96672177  0.14145401]\n",
      " [-0.51549888 -0.32583028]]\n",
      "cost:\n",
      "0.167192\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089  0.        ]\n",
      " [-0.34906578 -0.08726644]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [-1.22173022  0.26179933]\n",
      " [-1.22173022 -0.17453289]\n",
      " [-0.26179933 -0.43633222]\n",
      " [ 0.95993089 -0.43633222]\n",
      " [ 0.61086511 -0.17453289]\n",
      " [ 0.17453289  0.17453289]]\n",
      "prediction:\n",
      "[[-0.93359232  0.07470877]\n",
      " [-0.38187683 -0.0235487 ]\n",
      " [ 0.91105616 -0.2442513 ]\n",
      " [ 0.66871059 -0.15992637]\n",
      " [-0.96998656  0.42176986]\n",
      " [-0.96191776 -0.10232377]\n",
      " [-0.29431969 -0.32981399]\n",
      " [ 0.98663229 -0.30950394]\n",
      " [ 0.84657252 -0.07516531]\n",
      " [ 0.25969657  0.29764357]]\n",
      "cost:\n",
      "0.177992\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089  0.34906578]\n",
      " [ 0.26179933 -0.08726644]\n",
      " [-0.34906578  0.26179933]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [ 0.61086511  0.08726644]\n",
      " [-0.785398   -0.26179933]\n",
      " [ 1.04719733 -0.34906578]\n",
      " [-0.69813156 -0.34906578]\n",
      " [-0.08726644 -0.26179933]\n",
      " [-1.04719733 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.89942038  0.39174297]\n",
      " [ 0.24812604 -0.04606592]\n",
      " [-0.42253742  0.33368236]\n",
      " [ 0.5312469  -0.03425234]\n",
      " [ 0.80601048  0.1681626 ]\n",
      " [-0.78959167 -0.20673944]\n",
      " [ 0.99868375 -0.32285294]\n",
      " [-0.71839738 -0.30650416]\n",
      " [-0.13923739 -0.20106705]\n",
      " [-0.93619525 -0.22237802]]\n",
      "cost:\n",
      "0.0895439\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444  0.26179933]\n",
      " [-1.22173022 -0.34906578]\n",
      " [ 0.         -0.17453289]\n",
      " [-0.34906578  0.08726644]\n",
      " [ 0.61086511 -0.43633222]\n",
      " [-1.04719733  0.26179933]\n",
      " [-0.61086511 -0.17453289]\n",
      " [-0.69813156  0.34906578]\n",
      " [ 0.08726644 -0.43633222]\n",
      " [ 0.95993089  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.97717154  0.25280175]\n",
      " [-0.9665522  -0.30421013]\n",
      " [-0.08718377 -0.14899331]\n",
      " [-0.36081904  0.05325182]\n",
      " [ 0.85521126 -0.36311394]\n",
      " [-0.96938002  0.23515297]\n",
      " [-0.58796561 -0.1685079 ]\n",
      " [-0.67618155  0.30724555]\n",
      " [-0.00978068 -0.37645757]\n",
      " [ 0.98518562  0.0793175 ]]\n",
      "cost:\n",
      "0.103957\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089 -0.26179933]\n",
      " [-0.08726644  0.        ]\n",
      " [ 1.22173022  0.08726644]\n",
      " [-0.43633222 -0.08726644]\n",
      " [-1.04719733  0.08726644]\n",
      " [-0.17453289  0.34906578]\n",
      " [-1.13446378  0.        ]\n",
      " [-0.69813156 -0.17453289]\n",
      " [-0.34906578  0.        ]\n",
      " [-0.52359867 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.99359769 -0.44143027]\n",
      " [-0.0598191  -0.01040266]\n",
      " [ 0.98658478  0.11665605]\n",
      " [-0.33050093 -0.14720632]\n",
      " [-0.89944822  0.14108005]\n",
      " [-0.07533384  0.44236737]\n",
      " [-0.97750199 -0.01239311]\n",
      " [-0.53158641 -0.27228495]\n",
      " [-0.34131151 -0.00584004]\n",
      " [-0.34887069 -0.28696194]]\n",
      "cost:\n",
      "0.143218\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578  0.34906578]\n",
      " [-0.95993089  0.        ]\n",
      " [-0.34906578  0.08726644]\n",
      " [ 0.61086511  0.34906578]\n",
      " [-0.785398   -0.08726644]\n",
      " [-1.22173022 -0.17453289]\n",
      " [ 1.04719733  0.34906578]\n",
      " [-0.26179933  0.26179933]\n",
      " [-0.95993089  0.        ]\n",
      " [ 0.87266444 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.33396167  0.19361921]\n",
      " [-0.86945766 -0.07604177]\n",
      " [-0.44961274 -0.00108962]\n",
      " [ 0.78715038  0.17166863]\n",
      " [-0.75846839 -0.25043109]\n",
      " [-0.92934626 -0.55934525]\n",
      " [ 0.99206799  0.20100521]\n",
      " [-0.25959569  0.14759625]\n",
      " [-0.86945766 -0.07604177]\n",
      " [ 0.98588133 -0.25574902]]\n",
      "cost:\n",
      "0.190036\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156  0.34906578]\n",
      " [-0.34906578 -0.43633222]\n",
      " [-0.95993089  0.17453289]\n",
      " [-0.61086511  0.17453289]\n",
      " [-0.17453289  0.08726644]\n",
      " [-0.43633222  0.08726644]\n",
      " [-0.69813156 -0.43633222]\n",
      " [-0.87266444 -0.08726644]\n",
      " [-0.26179933 -0.43633222]\n",
      " [ 0.08726644 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.99946141  0.32287747]\n",
      " [ 0.11433085 -0.37804505]\n",
      " [-0.94558287  0.16819052]\n",
      " [-0.58543825  0.16758963]\n",
      " [-0.15037058  0.05464551]\n",
      " [-0.39187109  0.06799635]\n",
      " [ 0.01132876 -0.3841646 ]\n",
      " [-0.88690311 -0.09242667]\n",
      " [-0.04038303 -0.39990479]\n",
      " [ 0.17175202 -0.10718528]]\n",
      "cost:\n",
      "0.193833\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578 -0.34906578]\n",
      " [-1.22173022  0.17453289]\n",
      " [-0.26179933  0.        ]\n",
      " [-0.52359867 -0.17453289]\n",
      " [ 0.69813156  0.        ]\n",
      " [ 0.          0.26179933]\n",
      " [-0.26179933 -0.43633222]\n",
      " [ 0.69813156  0.        ]\n",
      " [-0.52359867 -0.34906578]\n",
      " [ 0.17453289  0.34906578]]\n",
      "prediction:\n",
      "[[-0.34485233 -0.32806677]\n",
      " [-0.99580586  0.13187797]\n",
      " [-0.21688509  0.00641351]\n",
      " [-0.56955707 -0.17897218]\n",
      " [ 0.98563468 -0.01386476]\n",
      " [-0.01068718  0.26721308]\n",
      " [-0.27106994 -0.40698731]\n",
      " [ 0.98562455 -0.01385345]\n",
      " [-0.54309201 -0.34374866]\n",
      " [ 0.21861762  0.33352122]]\n",
      "cost:\n",
      "0.102824\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578 -0.26179933]\n",
      " [ 0.87266444  0.26179933]\n",
      " [-0.95993089 -0.34906578]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [-0.26179933 -0.26179933]\n",
      " [-0.34906578  0.08726644]\n",
      " [-0.87266444 -0.08726644]\n",
      " [-0.69813156  0.        ]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [-1.13446378  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.45479894 -0.2776176 ]\n",
      " [ 0.99944443  0.36792523]\n",
      " [-0.83390749 -0.42825153]\n",
      " [ 0.18768819 -0.14942351]\n",
      " [-0.13602468 -0.28172922]\n",
      " [-0.29756933  0.18115602]\n",
      " [-0.76362526 -0.08493955]\n",
      " [-0.62854528  0.02702791]\n",
      " [ 0.18753932 -0.14941686]\n",
      " [-0.92788106  0.26865903]]\n",
      "cost:\n",
      "0.112287\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733 -0.26179933]\n",
      " [-0.61086511 -0.34906578]\n",
      " [-0.95993089  0.34906578]\n",
      " [ 0.34906578 -0.08726644]\n",
      " [-0.34906578  0.26179933]\n",
      " [ 0.95993089  0.        ]\n",
      " [ 0.17453289 -0.34906578]\n",
      " [-0.69813156 -0.34906578]\n",
      " [-0.34906578  0.        ]\n",
      " [ 0.69813156 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.96384627 -0.19986215]\n",
      " [-0.52430981 -0.27660114]\n",
      " [-0.93361151  0.38463628]\n",
      " [ 0.42422533 -0.02442445]\n",
      " [-0.2894417   0.34092733]\n",
      " [ 0.99830717  0.05749651]\n",
      " [ 0.15097652 -0.28423879]\n",
      " [-0.68884033 -0.28608972]\n",
      " [-0.31516492  0.08955724]\n",
      " [ 0.9046011  -0.28808469]]\n",
      "cost:\n",
      "0.097083\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156  0.        ]\n",
      " [-0.69813156 -0.34906578]\n",
      " [ 1.22173022 -0.34906578]\n",
      " [-0.26179933 -0.43633222]\n",
      " [-0.785398   -0.26179933]\n",
      " [-0.34906578  0.34906578]\n",
      " [ 0.26179933  0.        ]\n",
      " [-1.22173022 -0.17453289]\n",
      " [-0.34906578 -0.43633222]\n",
      " [ 0.26179933  0.17453289]]\n",
      "prediction:\n",
      "[[-0.78562582  0.10565203]\n",
      " [-0.62682635 -0.2363257 ]\n",
      " [ 0.99946529 -0.18757878]\n",
      " [-0.09539289 -0.32753834]\n",
      " [-0.77772111 -0.13941415]\n",
      " [-0.20781149  0.45390922]\n",
      " [ 0.4181917   0.06780915]\n",
      " [-0.94497669 -0.08207558]\n",
      " [-0.11898339 -0.29950371]\n",
      " [ 0.36871383  0.26496759]]\n",
      "cost:\n",
      "0.191264\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867  0.17453289]\n",
      " [ 0.26179933 -0.43633222]\n",
      " [ 0.43633222 -0.34906578]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [-0.43633222  0.08726644]\n",
      " [-0.785398    0.        ]\n",
      " [ 0.61086511 -0.43633222]\n",
      " [ 1.13446378  0.08726644]\n",
      " [-1.04719733  0.26179933]\n",
      " [-1.22173022  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.50210667  0.18088195]\n",
      " [ 0.22890939 -0.39484179]\n",
      " [ 0.44689852 -0.31094131]\n",
      " [ 0.96796829 -0.13713136]\n",
      " [-0.3747634   0.07794488]\n",
      " [-0.86989987  0.01034485]\n",
      " [ 0.69467044 -0.38528165]\n",
      " [ 0.97592252  0.10464305]\n",
      " [-0.97976035  0.27618143]\n",
      " [-0.98368156  0.27287009]]\n",
      "cost:\n",
      "0.0997845\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444 -0.17453289]\n",
      " [-0.52359867 -0.43633222]\n",
      " [ 1.22173022 -0.43633222]\n",
      " [ 0.43633222  0.        ]\n",
      " [ 0.          0.34906578]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [-0.87266444  0.08726644]\n",
      " [ 0.34906578  0.17453289]\n",
      " [ 0.08726644 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.98493385 -0.08796382]\n",
      " [-0.67323846 -0.29274511]\n",
      " [ 0.94356173 -0.25897378]\n",
      " [ 0.43875575 -0.00110392]\n",
      " [ 0.06480984  0.47353682]\n",
      " [ 0.39885587 -0.15676843]\n",
      " [ 0.9900161  -0.12784776]\n",
      " [-0.9863261   0.149469  ]\n",
      " [ 0.26593718  0.25030842]\n",
      " [ 0.07166295 -0.31181931]]\n",
      "cost:\n",
      "0.153748\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289 -0.17453289]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [ 0.61086511  0.34906578]\n",
      " [-0.08726644 -0.34906578]\n",
      " [-0.43633222  0.08726644]\n",
      " [ 0.95993089  0.08726644]\n",
      " [ 1.04719733  0.08726644]\n",
      " [-1.13446378 -0.43633222]\n",
      " [ 0.69813156  0.17453289]]\n",
      "prediction:\n",
      "[[-0.17683214 -0.14463913]\n",
      " [ 0.33497658 -0.15559641]\n",
      " [ 0.08032035 -0.24382436]\n",
      " [ 0.52727449  0.36338621]\n",
      " [-0.1050452  -0.35330826]\n",
      " [-0.51543182  0.11365429]\n",
      " [ 0.9083038   0.14258878]\n",
      " [ 0.93477041  0.13552321]\n",
      " [-0.9994818  -0.40769958]\n",
      " [ 0.59315801  0.21486822]]\n",
      "cost:\n",
      "0.0707784\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089  0.17453289]\n",
      " [-1.04719733  0.08726644]\n",
      " [-0.52359867  0.26179933]\n",
      " [-0.69813156  0.34906578]\n",
      " [ 0.          0.17453289]\n",
      " [ 0.61086511  0.26179933]\n",
      " [ 0.61086511  0.26179933]\n",
      " [-1.13446378 -0.17453289]\n",
      " [-0.95993089 -0.43633222]\n",
      " [ 0.          0.17453289]]\n",
      "prediction:\n",
      "[[  9.98515308e-01  -6.15969242e-04]\n",
      " [ -9.39471722e-01  -3.70990448e-02]\n",
      " [ -4.83783573e-01   1.31565765e-01]\n",
      " [ -6.74907446e-01   2.12196067e-01]\n",
      " [ -2.67230552e-02   6.04482330e-02]\n",
      " [  8.18190455e-01   1.03853025e-01]\n",
      " [  8.18190455e-01   1.03853025e-01]\n",
      " [ -9.35517430e-01  -3.02734584e-01]\n",
      " [ -8.12521815e-01  -6.02012634e-01]\n",
      " [ -2.67230552e-02   6.04482330e-02]]\n",
      "cost:\n",
      "0.183295\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644 -0.08726644]\n",
      " [-0.52359867 -0.26179933]\n",
      " [ 0.95993089  0.34906578]\n",
      " [-1.13446378 -0.08726644]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [ 0.08726644  0.17453289]\n",
      " [ 0.61086511  0.34906578]\n",
      " [ 0.95993089 -0.26179933]\n",
      " [-0.34906578  0.26179933]\n",
      " [-1.22173022  0.26179933]]\n",
      "prediction:\n",
      "[[-0.06190877 -0.18262155]\n",
      " [-0.59231031 -0.40901068]\n",
      " [ 0.93296957  0.25319302]\n",
      " [-0.98840934 -0.17339455]\n",
      " [ 0.9486953  -0.17331693]\n",
      " [ 0.17169425  0.10081447]\n",
      " [ 0.55253923  0.25114542]\n",
      " [ 0.95255846 -0.39662477]\n",
      " [-0.37865025  0.15139213]\n",
      " [-0.98782098  0.17341335]]\n",
      "cost:\n",
      "0.137054\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578  0.08726644]\n",
      " [ 0.52359867 -0.08726644]\n",
      " [-0.61086511  0.34906578]\n",
      " [-0.785398   -0.17453289]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [-0.17453289 -0.43633222]\n",
      " [-1.22173022 -0.17453289]\n",
      " [-1.04719733 -0.34906578]\n",
      " [-0.17453289  0.08726644]\n",
      " [-0.785398   -0.17453289]]\n",
      "prediction:\n",
      "[[-0.34501198  0.16058283]\n",
      " [ 0.97999048 -0.02412005]\n",
      " [-0.41595659  0.45688292]\n",
      " [-0.70357484 -0.14176099]\n",
      " [ 0.99812841 -0.00715549]\n",
      " [-0.26441723 -0.43335468]\n",
      " [-0.88688779 -0.1065048 ]\n",
      " [-0.91764438 -0.33982483]\n",
      " [-0.11089092  0.15166037]\n",
      " [-0.70357484 -0.14176099]]\n",
      "cost:\n",
      "0.198069\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733 -0.34906578]\n",
      " [-1.22173022  0.34906578]\n",
      " [ 0.87266444  0.26179933]\n",
      " [ 0.87266444  0.26179933]\n",
      " [ 1.22173022 -0.08726644]\n",
      " [ 0.95993089 -0.26179933]\n",
      " [-0.26179933  0.34906578]\n",
      " [-0.34906578  0.34906578]\n",
      " [ 1.22173022  0.34906578]\n",
      " [ 0.26179933  0.        ]]\n",
      "prediction:\n",
      "[[-0.99498755 -0.50015682]\n",
      " [-0.99220043  0.14602971]\n",
      " [ 0.8080911   0.12516458]\n",
      " [ 0.8080911   0.12516458]\n",
      " [ 0.90530473 -0.24348839]\n",
      " [ 0.80714923 -0.40814322]\n",
      " [-0.21636128  0.19342391]\n",
      " [-0.32615936  0.18397014]\n",
      " [ 0.78109336  0.14524819]\n",
      " [ 0.29143909 -0.12601031]]\n",
      "cost:\n",
      "0.227676\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156 -0.26179933]\n",
      " [ 0.08726644  0.08726644]\n",
      " [-0.52359867 -0.17453289]\n",
      " [ 1.04719733  0.        ]\n",
      " [-0.17453289  0.26179933]\n",
      " [-0.87266444 -0.17453289]\n",
      " [-1.22173022 -0.43633222]\n",
      " [-0.26179933 -0.08726644]\n",
      " [ 0.         -0.26179933]\n",
      " [ 1.13446378  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.81675583 -0.25363895]\n",
      " [ 0.10237797  0.18407393]\n",
      " [-0.55421251 -0.17947528]\n",
      " [ 0.96087009  0.05206683]\n",
      " [-0.16624992  0.40456492]\n",
      " [-0.97327572 -0.16402113]\n",
      " [-0.99021572 -0.42373294]\n",
      " [-0.28173074 -0.0501883 ]\n",
      " [ 0.01885956 -0.2806254 ]\n",
      " [ 0.98901504  0.26347163]]\n",
      "cost:\n",
      "0.106396\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156  0.17453289]\n",
      " [-0.34906578  0.        ]\n",
      " [ 0.26179933  0.34906578]\n",
      " [-0.34906578  0.17453289]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [ 0.785398   -0.26179933]\n",
      " [-0.17453289 -0.43633222]\n",
      " [ 1.13446378 -0.08726644]\n",
      " [-0.69813156  0.        ]\n",
      " [-0.785398   -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.78059     0.21474443]\n",
      " [-0.38533211  0.00935536]\n",
      " [ 0.30028707  0.398444  ]\n",
      " [-0.29267508  0.19606376]\n",
      " [ 0.07086398 -0.22627476]\n",
      " [ 0.9160279  -0.22990464]\n",
      " [-0.21091963 -0.40190125]\n",
      " [ 0.99264258 -0.04054483]\n",
      " [-0.99281335  0.01706603]\n",
      " [-0.97120351 -0.332775  ]]\n",
      "cost:\n",
      "0.110687\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089  0.08726644]\n",
      " [ 0.87266444 -0.34906578]\n",
      " [ 0.87266444 -0.34906578]\n",
      " [-0.43633222  0.08726644]\n",
      " [ 0.43633222  0.26179933]\n",
      " [ 0.08726644  0.17453289]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [-0.34906578 -0.08726644]\n",
      " [-0.43633222  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.86329234  0.13557509]\n",
      " [ 0.87327081 -0.35199869]\n",
      " [ 0.87327081 -0.35199869]\n",
      " [-0.98350596  0.11009118]\n",
      " [ 0.71533453  0.34168807]\n",
      " [ 0.14030586  0.21834771]\n",
      " [ 0.78532189 -0.36466324]\n",
      " [ 0.6759063  -0.17355044]\n",
      " [-0.97652459 -0.10413696]\n",
      " [-0.98352695  0.11008073]]\n",
      "cost:\n",
      "0.248138\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444 -0.17453289]\n",
      " [ 1.22173022  0.34906578]\n",
      " [ 0.17453289  0.08726644]\n",
      " [ 0.52359867  0.34906578]\n",
      " [-0.26179933  0.17453289]\n",
      " [-0.26179933  0.17453289]\n",
      " [-0.785398    0.        ]\n",
      " [ 0.34906578  0.34906578]\n",
      " [-0.69813156 -0.08726644]\n",
      " [-0.17453289  0.        ]]\n",
      "prediction:\n",
      "[[-0.97228456 -0.54441774]\n",
      " [ 0.99907732  0.1126481 ]\n",
      " [ 0.09544989 -0.03504664]\n",
      " [ 0.7487185   0.22614081]\n",
      " [-0.24378133  0.06341169]\n",
      " [-0.24370569  0.06340614]\n",
      " [-0.92017841 -0.16519536]\n",
      " [ 0.46064579  0.25325549]\n",
      " [-0.8078357  -0.34113356]\n",
      " [-0.16530596 -0.09865589]]\n",
      "cost:\n",
      "0.207105\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578  0.08726644]\n",
      " [-0.95993089 -0.34906578]\n",
      " [-1.13446378 -0.43633222]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [-0.17453289  0.34906578]\n",
      " [-0.95993089 -0.26179933]\n",
      " [ 0.34906578 -0.34906578]\n",
      " [-0.43633222 -0.08726644]\n",
      " [ 1.04719733  0.08726644]\n",
      " [ 0.43633222  0.        ]]\n",
      "prediction:\n",
      "[[ 0.35879219  0.14449154]\n",
      " [-0.92339361 -0.2496313 ]\n",
      " [-0.9759441  -0.31439587]\n",
      " [ 0.94066167 -0.33631217]\n",
      " [-0.12910742  0.42146558]\n",
      " [-0.94025552 -0.17691413]\n",
      " [ 0.28185919 -0.27134362]\n",
      " [-0.43177336 -0.03151849]\n",
      " [ 0.99680763  0.1690674 ]\n",
      " [ 0.43168506  0.05990008]]\n",
      "cost:\n",
      "0.0972363\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578  0.08726644]\n",
      " [-1.04719733 -0.34906578]\n",
      " [-0.17453289  0.17453289]\n",
      " [-0.61086511 -0.34906578]\n",
      " [-0.17453289  0.34906578]\n",
      " [ 0.         -0.34906578]\n",
      " [ 0.17453289  0.17453289]\n",
      " [ 0.95993089 -0.34906578]\n",
      " [-0.26179933  0.26179933]\n",
      " [ 0.69813156 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.43382889  0.07805228]\n",
      " [-0.99688816 -0.2590768 ]\n",
      " [-0.12739491  0.13970636]\n",
      " [-0.74928367 -0.27359891]\n",
      " [-0.11907806  0.29442793]\n",
      " [ 0.12322034 -0.31392372]\n",
      " [ 0.2233852   0.13454868]\n",
      " [ 0.99648196 -0.28907326]\n",
      " [-0.25689968  0.22724032]\n",
      " [ 0.92948729 -0.33381781]]\n",
      "cost:\n",
      "0.103194\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156  0.26179933]\n",
      " [-0.95993089  0.        ]\n",
      " [ 0.34906578  0.        ]\n",
      " [-0.95993089  0.17453289]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [-0.26179933  0.26179933]\n",
      " [-1.22173022  0.        ]\n",
      " [-0.26179933  0.        ]\n",
      " [-0.34906578 -0.34906578]\n",
      " [ 0.785398   -0.08726644]]\n",
      "prediction:\n",
      "[[-0.6261965   0.26453787]\n",
      " [-0.85245496 -0.04275008]\n",
      " [ 0.44936162 -0.04360389]\n",
      " [-0.83891857  0.14573865]\n",
      " [ 0.85347879 -0.44385991]\n",
      " [-0.19934407  0.26566243]\n",
      " [-0.94474459 -0.08360416]\n",
      " [-0.22007819 -0.0261525 ]\n",
      " [-0.26826015 -0.46991554]\n",
      " [ 0.99927491 -0.09533492]]\n",
      "cost:\n",
      "0.152519\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867 -0.17453289]\n",
      " [-0.52359867 -0.08726644]\n",
      " [ 0.          0.26179933]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [-0.785398   -0.08726644]\n",
      " [ 1.04719733  0.17453289]\n",
      " [-0.52359867 -0.43633222]\n",
      " [-0.69813156 -0.17453289]\n",
      " [ 0.34906578 -0.34906578]\n",
      " [ 0.34906578 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.62318337 -0.09451864]\n",
      " [-0.58696437  0.00865632]\n",
      " [-0.06077331  0.42802715]\n",
      " [ 0.36061883 -0.09694394]\n",
      " [-0.97586578  0.02759154]\n",
      " [ 0.99898469  0.28384387]\n",
      " [-0.73064458 -0.37802953]\n",
      " [-0.93994504 -0.07279082]\n",
      " [ 0.34790832 -0.27598658]\n",
      " [ 0.34790832 -0.27598658]]\n",
      "cost:\n",
      "0.146365\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933 -0.34906578]\n",
      " [ 0.08726644 -0.08726644]\n",
      " [-0.26179933 -0.17453289]\n",
      " [-0.785398   -0.17453289]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [-0.08726644 -0.43633222]\n",
      " [ 0.08726644 -0.34906578]\n",
      " [ 0.17453289 -0.43633222]\n",
      " [-0.17453289  0.26179933]\n",
      " [-0.26179933 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.1392296  -0.20300937]\n",
      " [ 0.30383158  0.07951027]\n",
      " [-0.43587437 -0.03487968]\n",
      " [-0.99797493  0.02095971]\n",
      " [ 0.99812645  0.01498638]\n",
      " [-0.03667798 -0.28754014]\n",
      " [ 0.05525995 -0.19835041]\n",
      " [ 0.4645074  -0.24746159]\n",
      " [-0.06712393  0.54354799]\n",
      " [-0.1392296  -0.20300937]]\n",
      "cost:\n",
      "0.28858\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089  0.08726644]\n",
      " [ 0.26179933 -0.08726644]\n",
      " [-0.34906578  0.17453289]\n",
      " [-1.22173022  0.        ]\n",
      " [-0.52359867  0.17453289]\n",
      " [ 0.61086511 -0.17453289]\n",
      " [-0.34906578  0.34906578]\n",
      " [ 1.22173022  0.17453289]\n",
      " [ 0.785398   -0.08726644]\n",
      " [-0.61086511  0.        ]]\n",
      "prediction:\n",
      "[[ 0.9614507   0.05691718]\n",
      " [ 0.30773145 -0.21539722]\n",
      " [-0.33840019  0.14367095]\n",
      " [-0.99825782 -0.16860706]\n",
      " [-0.64199203  0.15573584]\n",
      " [ 0.56113791 -0.51388615]\n",
      " [-0.32880318  0.35002205]\n",
      " [ 0.9626615   0.0655458 ]\n",
      " [ 0.86470801 -0.2001577 ]\n",
      " [-0.82997751 -0.05068527]]\n",
      "cost:\n",
      "0.160616\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.22173022 -0.17453289]\n",
      " [-0.52359867 -0.08726644]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [ 0.95993089  0.26179933]\n",
      " [ 0.87266444 -0.26179933]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [-1.04719733  0.26179933]\n",
      " [-0.69813156  0.26179933]\n",
      " [-0.87266444 -0.17453289]\n",
      " [ 0.34906578 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.95058376 -0.24618775]\n",
      " [-0.48140174 -0.09166542]\n",
      " [ 0.36454561 -0.07019139]\n",
      " [ 0.95360935  0.27922794]\n",
      " [ 0.89710712 -0.37410736]\n",
      " [ 0.70728028 -0.21101217]\n",
      " [-0.99224973  0.31516826]\n",
      " [-0.80727351  0.29760844]\n",
      " [-0.98131686 -0.2117682 ]\n",
      " [ 0.3262915  -0.08385737]]\n",
      "cost:\n",
      "0.0897105\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733 -0.26179933]\n",
      " [-1.13446378 -0.26179933]\n",
      " [-0.52359867 -0.08726644]\n",
      " [-0.61086511 -0.34906578]\n",
      " [ 0.785398   -0.34906578]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [-0.08726644  0.        ]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [-0.17453289 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.95988744 -0.07041024]\n",
      " [-0.97711241  0.15530209]\n",
      " [-0.5255928   0.15509143]\n",
      " [-0.55019999 -0.45368752]\n",
      " [ 0.93379712 -0.40146565]\n",
      " [ 0.99820685  0.04513185]\n",
      " [-0.15024664  0.35749388]\n",
      " [ 0.33009836  0.05950283]\n",
      " [ 0.1405482  -0.1338705 ]\n",
      " [-0.14960007 -0.14998703]]\n",
      "cost:\n",
      "0.212112\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444  0.        ]\n",
      " [-0.69813156 -0.34906578]\n",
      " [ 0.         -0.43633222]\n",
      " [ 1.04719733 -0.17453289]\n",
      " [ 1.13446378 -0.34906578]\n",
      " [ 0.26179933 -0.08726644]\n",
      " [ 0.43633222  0.26179933]\n",
      " [ 0.52359867  0.17453289]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [ 0.          0.26179933]]\n",
      "prediction:\n",
      "[[-0.998541    0.01297255]\n",
      " [-0.96071517 -0.29521152]\n",
      " [-0.06694184 -0.38162974]\n",
      " [ 0.96270663 -0.10740852]\n",
      " [ 0.94554865 -0.27772561]\n",
      " [ 0.24784702 -0.05336881]\n",
      " [ 0.41198727  0.3151933 ]\n",
      " [ 0.44783518  0.24522108]\n",
      " [ 0.61939073 -0.1998319 ]\n",
      " [ 0.00469284  0.3020668 ]]\n",
      "cost:\n",
      "0.113059\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156 -0.17453289]\n",
      " [ 0.785398    0.26179933]\n",
      " [ 0.61086511 -0.26179933]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [-0.87266444 -0.26179933]\n",
      " [ 0.08726644  0.17453289]\n",
      " [ 0.87266444  0.17453289]\n",
      " [-0.34906578 -0.17453289]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [ 1.04719733 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.47013208 -0.16858873]\n",
      " [ 0.60283577  0.39720297]\n",
      " [ 0.40701714 -0.30388579]\n",
      " [ 0.49509451 -0.2942954 ]\n",
      " [-0.99975246 -0.28276527]\n",
      " [ 0.09925523  0.22390784]\n",
      " [ 0.76757932  0.2883707 ]\n",
      " [-0.45118523 -0.15505454]\n",
      " [ 0.25193641 -0.18247068]\n",
      " [ 0.90815514 -0.04537936]]\n",
      "cost:\n",
      "0.146552\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644  0.        ]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [ 0.95993089  0.34906578]\n",
      " [-0.43633222  0.        ]\n",
      " [ 0.69813156  0.08726644]\n",
      " [-0.43633222 -0.26179933]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [ 0.08726644  0.08726644]\n",
      " [ 0.785398   -0.08726644]\n",
      " [-0.34906578  0.34906578]]\n",
      "prediction:\n",
      "[[-0.07968742 -0.01428614]\n",
      " [ 0.96211869 -0.50838536]\n",
      " [ 0.92242736  0.32066929]\n",
      " [-0.9936204  -0.06183244]\n",
      " [ 0.6675961   0.08003864]\n",
      " [-0.98851651 -0.37381816]\n",
      " [ 0.83668041 -0.1051999 ]\n",
      " [ 0.12525816  0.06009042]\n",
      " [ 0.69456327 -0.08989176]\n",
      " [-0.75927752  0.29790449]]\n",
      "cost:\n",
      "0.208105\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511  0.        ]\n",
      " [ 0.87266444 -0.34906578]\n",
      " [ 0.08726644  0.34906578]\n",
      " [-0.34906578  0.08726644]\n",
      " [ 0.61086511  0.26179933]\n",
      " [-0.08726644  0.17453289]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [ 0.95993089  0.        ]\n",
      " [-0.785398   -0.08726644]\n",
      " [ 0.69813156 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.51903224 -0.04970293]\n",
      " [ 0.77410793 -0.47756767]\n",
      " [ 0.10232008  0.35209277]\n",
      " [-0.60203922  0.06418043]\n",
      " [ 0.44585976  0.23969752]\n",
      " [-0.12420044  0.14154558]\n",
      " [ 0.77407539 -0.14981687]\n",
      " [ 0.90486169 -0.04905243]\n",
      " [-0.9997018  -0.12782818]\n",
      " [ 0.54738033 -0.38269174]]\n",
      "cost:\n",
      "0.13536\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.         -0.34906578]\n",
      " [ 0.785398   -0.08726644]\n",
      " [-0.95993089 -0.34906578]\n",
      " [-0.08726644  0.        ]\n",
      " [-0.08726644 -0.26179933]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [ 0.         -0.34906578]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [ 0.26179933 -0.43633222]\n",
      " [-0.52359867  0.17453289]]\n",
      "prediction:\n",
      "[[-0.02713345 -0.26016825]\n",
      " [ 0.99503088  0.08950056]\n",
      " [-0.99809748 -0.25854617]\n",
      " [-0.11805476  0.16205446]\n",
      " [-0.12813605 -0.15614502]\n",
      " [ 0.88980442  0.11177694]\n",
      " [-0.02713428 -0.26016814]\n",
      " [ 0.46626142  0.08314858]\n",
      " [ 0.2356644  -0.35841832]\n",
      " [-0.85532081  0.46226001]]\n",
      "cost:\n",
      "0.187358\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398    0.17453289]\n",
      " [ 0.61086511 -0.26179933]\n",
      " [ 0.87266444  0.        ]\n",
      " [ 0.69813156 -0.43633222]\n",
      " [ 0.785398    0.26179933]\n",
      " [-0.87266444  0.17453289]\n",
      " [ 0.17453289 -0.34906578]\n",
      " [-1.04719733 -0.34906578]\n",
      " [ 0.87266444  0.26179933]\n",
      " [ 0.17453289 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.81203526  0.21916659]\n",
      " [ 0.46216848 -0.19657935]\n",
      " [ 0.85123014  0.0189484 ]\n",
      " [ 0.57477182 -0.32567769]\n",
      " [ 0.71513987  0.29706869]\n",
      " [-0.98963833  0.20330356]\n",
      " [ 0.20922738 -0.26837835]\n",
      " [-0.99801445 -0.27460399]\n",
      " [ 0.86802912  0.30762109]\n",
      " [ 0.19805209 -0.33207998]]\n",
      "cost:\n",
      "0.0937745\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867 -0.17453289]\n",
      " [ 1.04719733 -0.26179933]\n",
      " [ 0.61086511 -0.34906578]\n",
      " [ 0.95993089 -0.26179933]\n",
      " [ 0.785398    0.17453289]\n",
      " [-0.26179933  0.34906578]\n",
      " [ 0.87266444  0.        ]\n",
      " [ 1.04719733  0.        ]\n",
      " [-0.52359867 -0.17453289]\n",
      " [-0.95993089  0.17453289]]\n",
      "prediction:\n",
      "[[-0.69232994 -0.17233717]\n",
      " [ 0.81575185 -0.27082321]\n",
      " [ 0.50300825 -0.37841037]\n",
      " [ 0.7645756  -0.27798304]\n",
      " [ 0.72280312  0.24720754]\n",
      " [-0.16651283  0.41615704]\n",
      " [ 0.78428435  0.01470937]\n",
      " [ 0.89403671  0.01307118]\n",
      " [-0.69225508 -0.17233868]\n",
      " [-0.99947286  0.21697925]]\n",
      "cost:\n",
      "0.139062\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.26179933]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [-0.34906578 -0.17453289]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [ 1.04719733  0.34906578]\n",
      " [ 0.61086511  0.        ]\n",
      " [-0.95993089 -0.34906578]\n",
      " [-0.61086511  0.17453289]\n",
      " [-0.785398    0.34906578]\n",
      " [-0.08726644  0.34906578]]\n",
      "prediction:\n",
      "[[-0.97514045 -0.28473282]\n",
      " [ 0.68784952 -0.10779719]\n",
      " [-0.31576216 -0.19970533]\n",
      " [ 0.49682254 -0.29608712]\n",
      " [ 0.99862158  0.27210668]\n",
      " [ 0.80877    -0.03043576]\n",
      " [-0.9476639  -0.38761947]\n",
      " [-0.55191672  0.11384238]\n",
      " [-0.77735919  0.26483586]\n",
      " [-0.06966265  0.2985799 ]]\n",
      "cost:\n",
      "0.0880274\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222 -0.08726644]\n",
      " [ 0.69813156  0.08726644]\n",
      " [-0.95993089 -0.26179933]\n",
      " [ 0.43633222 -0.43633222]\n",
      " [-0.34906578  0.34906578]\n",
      " [-0.34906578  0.26179933]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [ 0.         -0.34906578]\n",
      " [-0.61086511 -0.26179933]\n",
      " [-0.08726644 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.54287243 -0.00792919]\n",
      " [ 0.9983691   0.1859705 ]\n",
      " [-0.99665499 -0.14758185]\n",
      " [ 0.63279617 -0.3215225 ]\n",
      " [-0.23819421  0.40130159]\n",
      " [-0.27601418  0.31644753]\n",
      " [ 0.03933954 -0.16915737]\n",
      " [ 0.04310037 -0.27117386]\n",
      " [-0.80575067 -0.16985133]\n",
      " [-0.021639   -0.2586222 ]]\n",
      "cost:\n",
      "0.153076\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867 -0.08726644]\n",
      " [-0.17453289 -0.08726644]\n",
      " [ 1.13446378  0.17453289]\n",
      " [-0.785398   -0.34906578]\n",
      " [-0.785398   -0.34906578]\n",
      " [ 1.22173022  0.08726644]\n",
      " [-0.26179933 -0.08726644]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [-0.34906578 -0.34906578]\n",
      " [-0.17453289  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.59935343 -0.06753916]\n",
      " [-0.17013708 -0.03654344]\n",
      " [ 0.98261446  0.34344208]\n",
      " [-0.98593682 -0.32055271]\n",
      " [-0.98593885 -0.32056379]\n",
      " [ 0.9879415   0.22237067]\n",
      " [-0.23804162 -0.03072948]\n",
      " [ 0.36556131 -0.17672534]\n",
      " [-0.34465882 -0.33519509]\n",
      " [-0.1249331   0.28509066]]\n",
      "cost:\n",
      "0.13323\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156  0.17453289]\n",
      " [-0.08726644 -0.17453289]\n",
      " [ 0.61086511  0.26179933]\n",
      " [ 1.04719733 -0.17453289]\n",
      " [ 0.34906578  0.17453289]\n",
      " [-0.34906578 -0.43633222]\n",
      " [-0.34906578 -0.43633222]\n",
      " [-0.43633222 -0.08726644]\n",
      " [-0.95993089 -0.43633222]\n",
      " [-0.17453289  0.17453289]]\n",
      "prediction:\n",
      "[[-0.93818605  0.17601058]\n",
      " [ 0.00793135 -0.12565513]\n",
      " [ 0.79864085  0.30028704]\n",
      " [ 0.99883503 -0.11412006]\n",
      " [ 0.46888947  0.20881973]\n",
      " [-0.17507744 -0.35562888]\n",
      " [-0.17507744 -0.35562888]\n",
      " [-0.46463636 -0.05632841]\n",
      " [-0.98856032 -0.35994536]\n",
      " [-0.02426612  0.19341804]]\n",
      "cost:\n",
      "0.139931\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511 -0.08726644]\n",
      " [-0.43633222  0.08726644]\n",
      " [ 0.785398   -0.26179933]\n",
      " [ 0.34906578  0.17453289]\n",
      " [-0.52359867 -0.17453289]\n",
      " [-0.69813156  0.17453289]\n",
      " [-1.04719733  0.08726644]\n",
      " [ 0.43633222  0.26179933]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [-1.04719733 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.76538277 -0.09746398]\n",
      " [-0.36418083  0.08753731]\n",
      " [ 0.96318907 -0.31428587]\n",
      " [ 0.31663877  0.18502177]\n",
      " [-0.50145227 -0.22062908]\n",
      " [-0.74566674  0.18930756]\n",
      " [-0.9847573   0.05776981]\n",
      " [ 0.41458103  0.29878816]\n",
      " [ 0.99324369 -0.11160737]\n",
      " [-0.97386986 -0.51925457]]\n",
      "cost:\n",
      "0.0893054\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578  0.08726644]\n",
      " [ 1.22173022  0.        ]\n",
      " [ 1.22173022  0.08726644]\n",
      " [-0.95993089  0.17453289]\n",
      " [ 1.22173022  0.08726644]\n",
      " [ 1.22173022  0.        ]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [-0.87266444  0.26179933]\n",
      " [-0.69813156  0.26179933]\n",
      " [-0.95993089 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.49212158 -0.00939793]\n",
      " [ 0.89324546 -0.08393054]\n",
      " [ 0.88004953  0.03065149]\n",
      " [-0.98866183  0.12025976]\n",
      " [ 0.88012004  0.03066277]\n",
      " [ 0.8932457  -0.0839289 ]\n",
      " [ 0.88167179 -0.26185685]\n",
      " [-0.94003099  0.23512529]\n",
      " [-0.76652998  0.25039011]\n",
      " [-0.97296643 -0.59586143]]\n",
      "cost:\n",
      "0.217405\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222  0.34906578]\n",
      " [ 0.17453289 -0.26179933]\n",
      " [-0.87266444 -0.17453289]\n",
      " [ 0.17453289  0.34906578]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [ 0.         -0.08726644]\n",
      " [-0.43633222 -0.08726644]\n",
      " [-0.785398    0.34906578]\n",
      " [ 0.26179933  0.17453289]\n",
      " [ 0.61086511 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.50854349  0.25877073]\n",
      " [ 0.22932674 -0.28272563]\n",
      " [-0.99160397 -0.20559609]\n",
      " [ 0.18018202  0.26763409]\n",
      " [ 0.08979702 -0.18361579]\n",
      " [-0.03015177 -0.08909325]\n",
      " [-0.47281322 -0.08755902]\n",
      " [-0.94710052  0.22557123]\n",
      " [ 0.28162944  0.14023253]\n",
      " [ 0.99891299 -0.48038703]]\n",
      "cost:\n",
      "0.108857\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289  0.26179933]\n",
      " [-0.26179933 -0.08726644]\n",
      " [ 0.26179933  0.17453289]\n",
      " [ 1.04719733 -0.34906578]\n",
      " [ 1.22173022  0.08726644]\n",
      " [-0.52359867 -0.34906578]\n",
      " [ 1.04719733  0.        ]\n",
      " [ 1.04719733  0.08726644]\n",
      " [-0.61086511  0.17453289]\n",
      " [ 0.         -0.43633222]]\n",
      "prediction:\n",
      "[[-0.20099196  0.29849303]\n",
      " [-0.34548175 -0.11349808]\n",
      " [ 0.42972872  0.17888191]\n",
      " [ 0.92293721 -0.33856067]\n",
      " [ 0.93224561  0.08111058]\n",
      " [-0.96567452 -0.36299419]\n",
      " [ 0.80105484 -0.03402412]\n",
      " [ 0.88658619  0.11130758]\n",
      " [-0.99838287  0.2079867 ]\n",
      " [-0.10013305 -0.44120613]]\n",
      "cost:\n",
      "0.205756\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733  0.        ]\n",
      " [-0.17453289 -0.26179933]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [ 0.17453289 -0.43633222]\n",
      " [ 0.          0.34906578]\n",
      " [-0.95993089  0.34906578]\n",
      " [-0.43633222 -0.34906578]\n",
      " [ 0.69813156 -0.43633222]\n",
      " [-1.22173022  0.17453289]\n",
      " [ 0.17453289 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.93065631  0.0184901 ]\n",
      " [-0.16934364 -0.19280943]\n",
      " [ 0.99445099 -0.04296942]\n",
      " [ 0.14294198 -0.32959801]\n",
      " [ 0.03560492  0.39325979]\n",
      " [-0.90555108  0.34269121]\n",
      " [-0.46550116 -0.27153713]\n",
      " [ 0.9911325  -0.33695397]\n",
      " [-0.97168672  0.15828587]\n",
      " [ 0.14232486 -0.12598866]]\n",
      "cost:\n",
      "0.141067\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398    0.17453289]\n",
      " [-0.52359867  0.        ]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [ 1.13446378  0.17453289]\n",
      " [ 0.17453289  0.08726644]\n",
      " [ 1.13446378  0.17453289]\n",
      " [ 1.13446378  0.08726644]\n",
      " [-0.26179933  0.08726644]\n",
      " [-0.87266444  0.08726644]\n",
      " [ 1.13446378  0.08726644]]\n",
      "prediction:\n",
      "[[-0.98621285  0.19134672]\n",
      " [-0.70658159 -0.14296517]\n",
      " [ 0.59869492 -0.64255083]\n",
      " [ 0.89457709  0.14861254]\n",
      " [ 0.16569166  0.03940476]\n",
      " [ 0.89457709  0.14861254]\n",
      " [ 0.90516126 -0.00591603]\n",
      " [-0.26765707  0.02746072]\n",
      " [-0.99619895 -0.00237496]\n",
      " [ 0.90516126 -0.00591603]]\n",
      "cost:\n",
      "0.20608\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089  0.        ]\n",
      " [-0.95993089 -0.17453289]\n",
      " [ 1.22173022  0.17453289]\n",
      " [ 0.61086511 -0.34906578]\n",
      " [-0.52359867 -0.26179933]\n",
      " [-0.95993089  0.26179933]\n",
      " [-0.95993089 -0.43633222]\n",
      " [ 0.785398   -0.34906578]\n",
      " [-0.17453289 -0.08726644]\n",
      " [-0.95993089  0.26179933]]\n",
      "prediction:\n",
      "[[-0.78645205  0.01946582]\n",
      " [-0.81123006 -0.12579945]\n",
      " [ 0.99914902  0.22673935]\n",
      " [ 0.70833814 -0.27873343]\n",
      " [-0.55427885 -0.20388353]\n",
      " [-0.83238542  0.33317754]\n",
      " [-0.82200795 -0.3589136 ]\n",
      " [ 0.94941425 -0.26436496]\n",
      " [-0.23591922 -0.04763554]\n",
      " [-0.83238542  0.33317754]]\n",
      "cost:\n",
      "0.145356\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156 -0.26179933]\n",
      " [ 0.52359867 -0.08726644]\n",
      " [-0.95993089 -0.43633222]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [ 0.17453289  0.34906578]\n",
      " [ 0.95993089  0.        ]\n",
      " [-0.43633222  0.34906578]\n",
      " [-0.87266444  0.17453289]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [ 0.95993089  0.17453289]]\n",
      "prediction:\n",
      "[[-0.84491277 -0.28681371]\n",
      " [ 0.50439525 -0.10830152]\n",
      " [-0.98724085 -0.47087449]\n",
      " [ 0.96545047 -0.19762753]\n",
      " [ 0.22258705  0.29693004]\n",
      " [ 0.92152542 -0.02536614]\n",
      " [-0.50360072  0.30601582]\n",
      " [-0.98616064  0.121761  ]\n",
      " [ 0.18103962 -0.08935696]\n",
      " [ 0.97754234  0.11354776]]\n",
      "cost:\n",
      "0.0784269\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444  0.17453289]\n",
      " [-0.17453289  0.34906578]\n",
      " [-1.22173022  0.08726644]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [-0.43633222 -0.43633222]\n",
      " [-0.34906578  0.        ]\n",
      " [ 1.04719733 -0.26179933]\n",
      " [-0.87266444  0.26179933]\n",
      " [-1.04719733  0.34906578]\n",
      " [ 0.08726644 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.7372731   0.11331978]\n",
      " [-0.14764765  0.28365421]\n",
      " [-0.90433776  0.04230649]\n",
      " [ 0.93032134 -0.16042799]\n",
      " [-0.45606682 -0.43778637]\n",
      " [-0.33238986 -0.03260596]\n",
      " [ 0.99950749 -0.25803703]\n",
      " [-0.81009674  0.18513449]\n",
      " [-0.86005545  0.23770453]\n",
      " [ 0.0817612  -0.34161159]]\n",
      "cost:\n",
      "0.120273\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644  0.17453289]\n",
      " [-1.04719733  0.34906578]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [-0.17453289  0.34906578]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [ 0.34906578 -0.43633222]\n",
      " [ 0.26179933 -0.43633222]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [-0.08726644 -0.43633222]\n",
      " [ 1.04719733 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.2053159   0.20879062]\n",
      " [-0.99953002  0.3511022 ]\n",
      " [ 0.95820659 -0.10360166]\n",
      " [-0.30719742  0.38300857]\n",
      " [ 0.15723613 -0.15083107]\n",
      " [ 0.25582701 -0.25707436]\n",
      " [ 0.16885835 -0.27105391]\n",
      " [ 0.15723613 -0.15083107]\n",
      " [-0.17227134 -0.29460305]\n",
      " [ 0.97895807 -0.09158424]]\n",
      "cost:\n",
      "0.134781\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289  0.34906578]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [-0.26179933 -0.26179933]\n",
      " [-0.61086511 -0.17453289]\n",
      " [ 1.04719733  0.26179933]\n",
      " [-0.26179933 -0.26179933]\n",
      " [-0.52359867 -0.43633222]\n",
      " [ 0.87266444 -0.26179933]\n",
      " [ 1.04719733 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.1928889   0.45227614]\n",
      " [ 0.86439383 -0.01684999]\n",
      " [ 0.27420509 -0.09195263]\n",
      " [-0.49762303 -0.17232932]\n",
      " [-0.99908262 -0.06980029]\n",
      " [ 0.97258013  0.3625491 ]\n",
      " [-0.49762303 -0.17232932]\n",
      " [-0.82764816 -0.34979773]\n",
      " [ 0.81466389 -0.16094548]\n",
      " [ 0.91293448 -0.14131248]]\n",
      "cost:\n",
      "0.22237\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578  0.08726644]\n",
      " [ 0.43633222  0.34906578]\n",
      " [ 0.34906578  0.08726644]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [-0.95993089 -0.43633222]\n",
      " [-0.43633222 -0.43633222]\n",
      " [-0.08726644  0.26179933]\n",
      " [ 0.26179933 -0.43633222]\n",
      " [ 1.13446378 -0.08726644]\n",
      " [-0.61086511  0.        ]]\n",
      "prediction:\n",
      "[[-0.51744401  0.08798778]\n",
      " [ 0.23243138  0.36329648]\n",
      " [ 0.35162154  0.09630954]\n",
      " [ 0.98974556 -0.07082967]\n",
      " [-0.99597704 -0.32526991]\n",
      " [-0.45401123 -0.33210659]\n",
      " [-0.14771751  0.28662443]\n",
      " [ 0.29040393 -0.33707121]\n",
      " [ 0.98903793 -0.07083219]\n",
      " [-0.93590313  0.00823248]]\n",
      "cost:\n",
      "0.130455\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398   -0.34906578]\n",
      " [ 0.17453289  0.34906578]\n",
      " [ 0.95993089  0.34906578]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [-0.87266444  0.08726644]\n",
      " [ 0.08726644  0.34906578]\n",
      " [-0.52359867 -0.08726644]\n",
      " [-0.69813156  0.17453289]\n",
      " [-0.69813156  0.34906578]\n",
      " [-1.22173022  0.        ]]\n",
      "prediction:\n",
      "[[-0.74915516 -0.5098964 ]\n",
      " [ 0.20339599  0.20050824]\n",
      " [ 0.98296732  0.20447938]\n",
      " [ 0.99868387 -0.31719887]\n",
      " [-0.86482418 -0.02523846]\n",
      " [ 0.10292867  0.22597103]\n",
      " [-0.43760026 -0.17178169]\n",
      " [-0.67505813  0.06081668]\n",
      " [-0.5898875   0.2083028 ]\n",
      " [-0.96518713 -0.14935048]]\n",
      "cost:\n",
      "0.167527\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444 -0.26179933]\n",
      " [-0.26179933 -0.34906578]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [-0.08726644 -0.17453289]\n",
      " [ 0.17453289 -0.26179933]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [ 0.08726644  0.        ]\n",
      " [ 0.61086511  0.26179933]\n",
      " [-0.34906578 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.99913096 -0.2090994 ]\n",
      " [-0.28114286 -0.34768128]\n",
      " [ 0.99756765  0.03566498]\n",
      " [-0.08513978 -0.08800006]\n",
      " [ 0.15368372 -0.20714214]\n",
      " [ 0.21463774 -0.09129424]\n",
      " [ 0.33860508 -0.22028233]\n",
      " [-0.12599684  0.12403931]\n",
      " [ 0.67435467  0.53866756]\n",
      " [-0.40228328  0.01110457]]\n",
      "cost:\n",
      "0.121112\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444 -0.17453289]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [ 0.26179933  0.08726644]\n",
      " [ 0.         -0.26179933]\n",
      " [ 0.         -0.08726644]\n",
      " [-0.52359867  0.26179933]\n",
      " [ 0.61086511  0.34906578]\n",
      " [ 0.785398   -0.08726644]\n",
      " [ 0.95993089 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.61034399 -0.13619968]\n",
      " [ 0.48056653 -0.15585861]\n",
      " [ 0.37295082 -0.15614331]\n",
      " [-0.40360451  0.12234346]\n",
      " [ 0.05270244 -0.2725203 ]\n",
      " [-0.42010689 -0.04731841]\n",
      " [-0.99968624  0.31305408]\n",
      " [ 0.49572876  0.39427233]\n",
      " [ 0.56782389 -0.02850114]\n",
      " [ 0.98644048 -0.44413871]]\n",
      "cost:\n",
      "0.234091\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289 -0.34906578]\n",
      " [ 0.17453289 -0.34906578]\n",
      " [ 0.17453289 -0.43633222]\n",
      " [-0.52359867 -0.43633222]\n",
      " [ 0.785398    0.17453289]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [-0.95993089 -0.08726644]\n",
      " [-0.95993089  0.        ]\n",
      " [-0.34906578  0.34906578]\n",
      " [ 1.13446378 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.13288487 -0.2093249 ]\n",
      " [ 0.23310921 -0.21099645]\n",
      " [ 0.27025774 -0.28044182]\n",
      " [-0.49367398 -0.28703412]\n",
      " [ 0.85743654  0.28487462]\n",
      " [ 0.97407705  0.00418215]\n",
      " [-0.9848302   0.00162847]\n",
      " [-0.99336052  0.08930656]\n",
      " [-0.38220999  0.44754741]\n",
      " [ 0.98786837 -0.26108426]]\n",
      "cost:\n",
      "0.137537\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511 -0.43633222]\n",
      " [-0.69813156 -0.26179933]\n",
      " [-1.22173022 -0.17453289]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [-1.04719733 -0.08726644]\n",
      " [ 0.785398    0.34906578]\n",
      " [-0.61086511  0.08726644]\n",
      " [ 0.785398   -0.34906578]\n",
      " [ 0.34906578  0.08726644]\n",
      " [-1.13446378 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.58115035 -0.35323828]\n",
      " [-0.6302439  -0.17919368]\n",
      " [-0.94295841 -0.08161182]\n",
      " [ 0.95868754 -0.28672326]\n",
      " [-0.92778569  0.00498706]\n",
      " [ 0.96890765  0.45612368]\n",
      " [-0.48444703  0.19631836]\n",
      " [ 0.99516982 -0.27023247]\n",
      " [ 0.32999974  0.13839273]\n",
      " [-0.94947201 -0.07566535]]\n",
      "cost:\n",
      "0.177565\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444 -0.43633222]\n",
      " [-0.26179933  0.        ]\n",
      " [-0.34906578  0.26179933]\n",
      " [-0.95993089  0.17453289]\n",
      " [-0.43633222 -0.08726644]\n",
      " [-0.43633222  0.08726644]\n",
      " [ 1.04719733 -0.26179933]\n",
      " [-0.43633222 -0.17453289]\n",
      " [ 1.13446378 -0.08726644]\n",
      " [ 1.22173022  0.34906578]]\n",
      "prediction:\n",
      "[[-0.92400062 -0.49591786]\n",
      " [-0.31214479  0.02349293]\n",
      " [-0.27427226  0.2585263 ]\n",
      " [-0.99565178  0.15354127]\n",
      " [-0.37526786 -0.08992657]\n",
      " [-0.40186253  0.09323326]\n",
      " [ 0.97295225 -0.30862221]\n",
      " [-0.36815801 -0.20769854]\n",
      " [ 0.98847109 -0.11619829]\n",
      " [ 0.96019155  0.28262937]]\n",
      "cost:\n",
      "0.0928876\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444  0.17453289]\n",
      " [-0.08726644  0.34906578]\n",
      " [-0.69813156  0.34906578]\n",
      " [ 0.17453289 -0.43633222]\n",
      " [-0.34906578 -0.34906578]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [ 0.         -0.17453289]\n",
      " [-0.43633222  0.08726644]\n",
      " [-0.34906578  0.26179933]\n",
      " [-0.26179933  0.17453289]]\n",
      "prediction:\n",
      "[[-0.98679191  0.09843787]\n",
      " [-0.11171861  0.25363192]\n",
      " [-0.6642983   0.26031208]\n",
      " [ 0.3513321  -0.45038071]\n",
      " [-0.22217965 -0.38527483]\n",
      " [ 0.99976027 -0.16874681]\n",
      " [ 0.06152865 -0.22835639]\n",
      " [-0.42701113 -0.00338832]\n",
      " [-0.30035794  0.17195261]\n",
      " [-0.28855217  0.08012155]]\n",
      "cost:\n",
      "0.141053\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398    0.34906578]\n",
      " [ 0.          0.17453289]\n",
      " [ 0.43633222  0.        ]\n",
      " [ 0.785398   -0.43633222]\n",
      " [-0.17453289  0.        ]\n",
      " [ 1.13446378  0.08726644]\n",
      " [ 0.52359867  0.08726644]\n",
      " [-0.785398   -0.17453289]\n",
      " [ 1.22173022  0.17453289]\n",
      " [ 0.17453289  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.39718962  0.29077065]\n",
      " [-0.07012604  0.14414892]\n",
      " [ 0.40869582 -0.05605953]\n",
      " [ 0.50703526 -0.59194225]\n",
      " [-0.26531845 -0.05438825]\n",
      " [ 0.94189864  0.03386558]\n",
      " [ 0.46587828  0.02320275]\n",
      " [-0.9998166  -0.2682974 ]\n",
      " [ 0.90211391  0.11310268]\n",
      " [ 0.09763558  0.0181321 ]]\n",
      "cost:\n",
      "0.190518\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733  0.17453289]\n",
      " [-0.26179933  0.08726644]\n",
      " [ 0.26179933 -0.08726644]\n",
      " [-1.22173022 -0.17453289]\n",
      " [-0.08726644  0.        ]\n",
      " [ 0.17453289  0.34906578]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [-0.26179933  0.08726644]\n",
      " [ 0.87266444  0.        ]\n",
      " [ 0.          0.34906578]]\n",
      "prediction:\n",
      "[[-0.98204798  0.09918079]\n",
      " [-0.25185329  0.05162269]\n",
      " [ 0.37412956 -0.17429401]\n",
      " [-0.98642296 -0.26826629]\n",
      " [-0.07515477 -0.0513509 ]\n",
      " [ 0.26944834  0.27019176]\n",
      " [ 0.84656668 -0.53116614]\n",
      " [-0.25185236  0.0516228 ]\n",
      " [ 0.99899459 -0.07976526]\n",
      " [-0.04672129  0.30386314]]\n",
      "cost:\n",
      "0.133036\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644  0.        ]\n",
      " [-0.26179933  0.17453289]\n",
      " [-1.13446378 -0.34906578]\n",
      " [ 1.22173022  0.        ]\n",
      " [ 0.785398    0.        ]\n",
      " [-0.34906578  0.17453289]\n",
      " [ 1.22173022 -0.43633222]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [-0.26179933  0.26179933]\n",
      " [ 1.22173022  0.34906578]]\n",
      "prediction:\n",
      "[[-0.13971053 -0.03285739]\n",
      " [-0.28507665  0.1393791 ]\n",
      " [-0.99975008 -0.36750373]\n",
      " [ 0.89079857 -0.04539208]\n",
      " [ 0.68676788 -0.00301739]\n",
      " [-0.42261031  0.13686289]\n",
      " [ 0.93165082 -0.42402074]\n",
      " [ 0.49819064 -0.27911708]\n",
      " [-0.25155029  0.23719802]\n",
      " [ 0.86319196  0.31174806]]\n",
      "cost:\n",
      "0.146357\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644 -0.26179933]\n",
      " [ 0.         -0.43633222]\n",
      " [-0.17453289 -0.43633222]\n",
      " [-0.26179933 -0.34906578]\n",
      " [-0.785398    0.08726644]\n",
      " [ 0.785398    0.34906578]\n",
      " [ 0.87266444  0.17453289]\n",
      " [-0.785398    0.26179933]\n",
      " [-0.87266444 -0.34906578]\n",
      " [-0.43633222  0.        ]]\n",
      "prediction:\n",
      "[[-0.1090364  -0.16429251]\n",
      " [ 0.00642429 -0.32053396]\n",
      " [-0.17162605 -0.31749076]\n",
      " [-0.27746284 -0.25050658]\n",
      " [-0.94644022  0.12407096]\n",
      " [ 0.97119153  0.35133243]\n",
      " [ 0.99922186  0.20336758]\n",
      " [-0.8810159   0.28660738]\n",
      " [-0.92946136 -0.2659941 ]\n",
      " [-0.48583999  0.04055123]]\n",
      "cost:\n",
      "0.117877\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398   -0.08726644]\n",
      " [ 1.04719733  0.34906578]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [-0.61086511 -0.34906578]\n",
      " [ 0.87266444  0.17453289]\n",
      " [ 1.22173022  0.34906578]\n",
      " [ 0.43633222 -0.43633222]\n",
      " [ 0.          0.        ]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [-0.69813156 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.64182091 -0.05846792]\n",
      " [ 0.83453923  0.36422828]\n",
      " [ 0.86981785 -0.12493551]\n",
      " [-0.97861439 -0.27298427]\n",
      " [ 0.79880345  0.19059326]\n",
      " [ 0.85408783  0.33637947]\n",
      " [ 0.49787843 -0.34965879]\n",
      " [-0.05664685  0.01630816]\n",
      " [ 0.19105305 -0.20405428]\n",
      " [-0.9993307  -0.27345285]]\n",
      "cost:\n",
      "0.204244\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.26179933  0.17453289]\n",
      " [ 1.22173022  0.08726644]\n",
      " [-1.22173022  0.17453289]\n",
      " [-0.52359867  0.        ]\n",
      " [-1.04719733 -0.08726644]\n",
      " [-0.69813156  0.08726644]\n",
      " [-0.08726644 -0.17453289]\n",
      " [-0.785398   -0.26179933]\n",
      " [-0.17453289  0.34906578]\n",
      " [ 0.95993089 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.2472945   0.12866892]\n",
      " [ 0.9986676   0.04150086]\n",
      " [-0.94288647  0.15967263]\n",
      " [-0.49528635 -0.02834013]\n",
      " [-0.94424093 -0.11486356]\n",
      " [-0.64069557  0.08304932]\n",
      " [-0.1711591  -0.23508428]\n",
      " [-0.80238563 -0.34713519]\n",
      " [-0.23021114  0.34993881]\n",
      " [ 0.98688501 -0.48788944]]\n",
      "cost:\n",
      "0.114687\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222  0.08726644]\n",
      " [-0.69813156  0.17453289]\n",
      " [ 0.785398    0.34906578]\n",
      " [ 1.22173022 -0.34906578]\n",
      " [-0.26179933 -0.08726644]\n",
      " [-1.22173022 -0.17453289]\n",
      " [-0.08726644 -0.17453289]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [-0.785398    0.26179933]\n",
      " [ 0.95993089 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.4662427   0.11726452]\n",
      " [-0.82338411  0.18280677]\n",
      " [ 0.78117156  0.3513757 ]\n",
      " [ 0.94401777 -0.32590422]\n",
      " [-0.26398221 -0.07951362]\n",
      " [-0.99907583 -0.18413422]\n",
      " [-0.11288143 -0.17104258]\n",
      " [ 0.97040927 -0.24500878]\n",
      " [-0.85363555  0.263585  ]\n",
      " [ 0.8535918  -0.39654705]]\n",
      "cost:\n",
      "0.105486\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156 -0.43633222]\n",
      " [ 0.95993089  0.17453289]\n",
      " [-0.34906578  0.        ]\n",
      " [ 0.08726644  0.26179933]\n",
      " [-0.43633222  0.08726644]\n",
      " [-0.26179933 -0.26179933]\n",
      " [-0.69813156 -0.08726644]\n",
      " [ 0.26179933  0.34906578]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [-0.785398    0.08726644]]\n",
      "prediction:\n",
      "[[ 0.86239469 -0.50008631]\n",
      " [ 0.99178082  0.13526709]\n",
      " [-0.24319923 -0.03847127]\n",
      " [ 0.09408408  0.246582  ]\n",
      " [-0.4381468   0.05100369]\n",
      " [-0.22930801 -0.30425763]\n",
      " [-0.97370148 -0.12786043]\n",
      " [ 0.27363986  0.33103713]\n",
      " [ 0.95913213 -0.21617812]\n",
      " [-0.99669516  0.04468818]]\n",
      "cost:\n",
      "0.105748\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.22173022  0.26179933]\n",
      " [ 1.22173022  0.26179933]\n",
      " [-0.785398    0.08726644]\n",
      " [ 0.26179933  0.        ]\n",
      " [ 0.34906578  0.34906578]\n",
      " [ 0.95993089 -0.43633222]\n",
      " [-0.08726644  0.26179933]\n",
      " [-0.69813156 -0.26179933]\n",
      " [-0.785398    0.08726644]\n",
      " [-0.69813156 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.98377675  0.16004084]\n",
      " [ 0.98377675  0.16004084]\n",
      " [-0.97630745  0.02382686]\n",
      " [ 0.16384587 -0.0308657 ]\n",
      " [ 0.36822224  0.23005132]\n",
      " [ 0.9529928  -0.50089478]\n",
      " [-0.14324723  0.17987595]\n",
      " [-0.86240131 -0.3314442 ]\n",
      " [-0.97630745  0.02382686]\n",
      " [-0.86240131 -0.3314442 ]]\n",
      "cost:\n",
      "0.16642\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289 -0.26179933]\n",
      " [-0.26179933 -0.17453289]\n",
      " [-0.69813156 -0.34906578]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [ 0.43633222  0.26179933]\n",
      " [ 0.17453289  0.        ]\n",
      " [ 0.34906578 -0.34906578]\n",
      " [-1.22173022  0.34906578]\n",
      " [-1.22173022 -0.08726644]\n",
      " [-0.61086511 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.31988642 -0.25336111]\n",
      " [-0.23164575 -0.14947376]\n",
      " [-0.41776457 -0.34254944]\n",
      " [ 0.02341698 -0.06674495]\n",
      " [ 0.99852896  0.34278637]\n",
      " [ 0.14928475  0.02773033]\n",
      " [ 0.93778342 -0.3571417 ]\n",
      " [-0.81075525  0.39941597]\n",
      " [-0.99683374 -0.03092316]\n",
      " [-0.60099387 -0.05607612]]\n",
      "cost:\n",
      "0.249064\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444 -0.26179933]\n",
      " [-0.08726644  0.17453289]\n",
      " [-0.08726644 -0.34906578]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [-0.52359867  0.26179933]\n",
      " [ 0.87266444  0.34906578]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [-0.785398    0.17453289]\n",
      " [ 0.08726644  0.34906578]\n",
      " [-0.17453289  0.26179933]]\n",
      "prediction:\n",
      "[[-0.99418122 -0.33679646]\n",
      " [-0.1187965   0.08592335]\n",
      " [-0.10619441 -0.42241973]\n",
      " [ 0.97901648 -0.26581985]\n",
      " [-0.54676378  0.14541198]\n",
      " [ 0.92560214  0.20460275]\n",
      " [ 0.98425192 -0.35157907]\n",
      " [-0.98380679  0.08579449]\n",
      " [ 0.13519898  0.22157247]\n",
      " [-0.18365386  0.15922049]]\n",
      "cost:\n",
      "0.155487\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733  0.        ]\n",
      " [-0.08726644  0.17453289]\n",
      " [-1.13446378 -0.26179933]\n",
      " [-0.17453289 -0.08726644]\n",
      " [-0.61086511 -0.43633222]\n",
      " [ 0.61086511  0.08726644]\n",
      " [ 0.69813156  0.08726644]\n",
      " [-0.52359867  0.34906578]\n",
      " [-0.61086511  0.34906578]\n",
      " [-0.95993089  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.99883139 -0.05687773]\n",
      " [-0.07032149  0.07031661]\n",
      " [-0.97877383 -0.37960508]\n",
      " [-0.16721553 -0.14896132]\n",
      " [-0.4846881  -0.53655899]\n",
      " [ 0.81332356  0.03052737]\n",
      " [ 0.92809129  0.02651386]\n",
      " [-0.50377643  0.23983914]\n",
      " [-0.60645306  0.22925015]\n",
      " [-0.97167647  0.06623857]]\n",
      "cost:\n",
      "0.13867\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867 -0.43633222]\n",
      " [-0.43633222 -0.26179933]\n",
      " [ 0.95993089  0.17453289]\n",
      " [-0.34906578 -0.08726644]\n",
      " [ 0.785398   -0.34906578]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [-0.34906578  0.26179933]\n",
      " [-1.13446378 -0.26179933]\n",
      " [ 1.04719733 -0.34906578]\n",
      " [-0.08726644 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.4816612  -0.32866797]\n",
      " [-0.42161638 -0.1882523 ]\n",
      " [ 0.90601575  0.34934852]\n",
      " [-0.33074397 -0.00601293]\n",
      " [ 0.75395727 -0.22842295]\n",
      " [ 0.80947912  0.02229914]\n",
      " [-0.333482    0.42233762]\n",
      " [-0.99977434 -0.13827987]\n",
      " [ 0.93067575 -0.23825917]\n",
      " [-0.03589755 -0.19883627]]\n",
      "cost:\n",
      "0.129404\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.43633222  0.08726644]\n",
      " [ 0.52359867  0.08726644]\n",
      " [-1.04719733 -0.43633222]\n",
      " [-0.26179933 -0.34906578]\n",
      " [-0.69813156 -0.17453289]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [-0.785398   -0.43633222]\n",
      " [-1.13446378  0.34906578]\n",
      " [-1.13446378 -0.26179933]\n",
      " [ 1.22173022  0.08726644]]\n",
      "prediction:\n",
      "[[-0.35543641  0.17347039]\n",
      " [ 0.723598    0.14483021]\n",
      " [-0.83622789 -0.31917369]\n",
      " [-0.160245   -0.30204439]\n",
      " [-0.48482838 -0.09021866]\n",
      " [ 0.36813879 -0.11903317]\n",
      " [-0.49136126 -0.35479257]\n",
      " [-0.91042149  0.41348854]\n",
      " [-0.90119523 -0.14000864]\n",
      " [ 0.99978882  0.11402632]]\n",
      "cost:\n",
      "0.199256\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933 -0.34906578]\n",
      " [-0.785398    0.34906578]\n",
      " [ 0.52359867 -0.17453289]\n",
      " [-1.04719733  0.17453289]\n",
      " [ 0.785398   -0.34906578]\n",
      " [-1.04719733  0.08726644]\n",
      " [-0.43633222  0.08726644]\n",
      " [-0.17453289  0.34906578]\n",
      " [ 1.04719733 -0.43633222]\n",
      " [-1.04719733 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.27409282 -0.30347949]\n",
      " [-0.67937678  0.30307207]\n",
      " [ 0.67487693 -0.15790637]\n",
      " [-0.91781205  0.14685783]\n",
      " [ 0.9779706  -0.25877014]\n",
      " [-0.91117412  0.08160961]\n",
      " [-0.45182899  0.07668982]\n",
      " [-0.17153053  0.28385144]\n",
      " [ 0.99879843 -0.32027325]\n",
      " [-0.95368344 -0.31214973]]\n",
      "cost:\n",
      "0.116136\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867  0.26179933]\n",
      " [-0.61086511  0.08726644]\n",
      " [-1.22173022 -0.08726644]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [-0.785398    0.08726644]\n",
      " [ 0.61086511  0.        ]\n",
      " [-1.04719733  0.34906578]\n",
      " [-0.43633222  0.34906578]\n",
      " [-0.43633222  0.17453289]\n",
      " [-0.17453289 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.4137277   0.16337164]\n",
      " [-0.52550721  0.01039804]\n",
      " [-0.9259795  -0.17454468]\n",
      " [ 0.99965316 -0.45797983]\n",
      " [-0.76573509  0.00392301]\n",
      " [ 0.94128311 -0.09806606]\n",
      " [-0.91983753  0.20757848]\n",
      " [-0.32209325  0.24387015]\n",
      " [-0.37848267  0.07691865]\n",
      " [-0.09440587 -0.45655689]]\n",
      "cost:\n",
      "0.167163\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511 -0.34906578]\n",
      " [-0.34906578 -0.08726644]\n",
      " [ 0.785398    0.34906578]\n",
      " [-0.87266444  0.08726644]\n",
      " [-0.61086511  0.34906578]\n",
      " [-0.26179933  0.34906578]\n",
      " [-0.61086511 -0.17453289]\n",
      " [-0.34906578  0.34906578]\n",
      " [ 0.785398   -0.26179933]\n",
      " [-0.52359867  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.80892032 -0.46522602]\n",
      " [-0.26206243 -0.18542162]\n",
      " [ 0.98754686  0.17674261]\n",
      " [-0.99733317 -0.02587483]\n",
      " [-0.74597108  0.17937332]\n",
      " [-0.16790433  0.22182372]\n",
      " [-0.73638618 -0.27435052]\n",
      " [-0.29218724  0.2071967 ]\n",
      " [ 0.99272227 -0.35717547]\n",
      " [-0.48797354 -0.01202132]]\n",
      "cost:\n",
      "0.181671\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578 -0.17453289]\n",
      " [-0.26179933  0.17453289]\n",
      " [-0.52359867  0.34906578]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [-0.34906578  0.        ]\n",
      " [ 0.69813156  0.17453289]\n",
      " [-0.61086511 -0.34906578]\n",
      " [ 0.          0.08726644]\n",
      " [-0.52359867 -0.08726644]\n",
      " [-1.22173022  0.26179933]]\n",
      "prediction:\n",
      "[[-0.25449318 -0.27493322]\n",
      " [-0.17123643  0.1326447 ]\n",
      " [-0.37289041  0.31721312]\n",
      " [ 0.99837583 -0.27370998]\n",
      " [-0.2384968  -0.04045733]\n",
      " [ 0.96221864  0.08924463]\n",
      " [-0.61942583 -0.5145359 ]\n",
      " [-0.01038396  0.04242394]\n",
      " [-0.34322643 -0.14446943]\n",
      " [-0.99770796  0.15647763]]\n",
      "cost:\n",
      "0.159562\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378  0.34906578]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [ 1.13446378  0.17453289]\n",
      " [ 0.17453289  0.08726644]\n",
      " [ 1.04719733  0.26179933]\n",
      " [-0.69813156 -0.34906578]\n",
      " [-0.43633222  0.        ]\n",
      " [-0.87266444 -0.08726644]\n",
      " [ 0.17453289  0.26179933]\n",
      " [-1.13446378  0.34906578]]\n",
      "prediction:\n",
      "[[-0.97422069  0.19231638]\n",
      " [ 0.98327285 -0.32777721]\n",
      " [ 0.97838968  0.01946013]\n",
      " [ 0.16888671  0.01042912]\n",
      " [ 0.97978586  0.14249316]\n",
      " [-0.69515038 -0.55238438]\n",
      " [-0.43729854 -0.09856137]\n",
      " [-0.92350543 -0.191431  ]\n",
      " [ 0.21320929  0.17391868]\n",
      " [-0.9742223   0.19231877]]\n",
      "cost:\n",
      "0.161152\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089  0.34906578]\n",
      " [-0.52359867 -0.26179933]\n",
      " [-0.52359867 -0.08726644]\n",
      " [-0.43633222  0.26179933]\n",
      " [ 0.785398    0.17453289]\n",
      " [ 0.17453289  0.34906578]\n",
      " [ 0.61086511  0.        ]\n",
      " [-0.34906578  0.26179933]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [-0.69813156  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.96615058  0.20693785]\n",
      " [-0.85213035 -0.55204463]\n",
      " [-0.6988349  -0.206625  ]\n",
      " [-0.55614167  0.12545912]\n",
      " [ 0.90471697  0.05279462]\n",
      " [ 0.19682012  0.17508377]\n",
      " [ 0.66016388 -0.09808945]\n",
      " [-0.41052508  0.12980393]\n",
      " [ 0.9843713  -0.36367229]\n",
      " [-0.9987222   0.04165669]]\n",
      "cost:\n",
      "0.209478\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.43633222 -0.43633222]\n",
      " [ 0.26179933  0.08726644]\n",
      " [-0.34906578 -0.17453289]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [ 0.08726644  0.17453289]\n",
      " [ 0.08726644  0.08726644]\n",
      " [-0.52359867  0.17453289]\n",
      " [-1.04719733  0.        ]\n",
      " [-1.13446378  0.17453289]\n",
      " [-0.34906578 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.23155919 -0.45877272]\n",
      " [ 0.3617923   0.06148943]\n",
      " [-0.15069647 -0.18522994]\n",
      " [ 0.99976486 -0.18523982]\n",
      " [ 0.12740998  0.16529144]\n",
      " [ 0.12883765  0.08161495]\n",
      " [-0.4613359   0.23388433]\n",
      " [-0.9467473   0.03358433]\n",
      " [-0.97948736  0.24828355]\n",
      " [-0.15439726 -0.45404258]]\n",
      "cost:\n",
      "0.119135\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.43633222 -0.43633222]\n",
      " [-1.04719733 -0.26179933]\n",
      " [ 0.69813156 -0.43633222]\n",
      " [ 0.08726644 -0.08726644]\n",
      " [-0.52359867  0.        ]\n",
      " [ 0.52359867  0.34906578]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [ 0.43633222 -0.34906578]\n",
      " [-0.87266444 -0.17453289]\n",
      " [-0.26179933  0.26179933]]\n",
      "prediction:\n",
      "[[-0.29349187 -0.32741442]\n",
      " [-0.99541479 -0.19218275]\n",
      " [ 0.93421    -0.33677909]\n",
      " [ 0.15085623 -0.0463949 ]\n",
      " [-0.60852754  0.05013164]\n",
      " [ 0.62705284  0.41061634]\n",
      " [ 0.99729532 -0.04937214]\n",
      " [ 0.55808449 -0.27774978]\n",
      " [-0.97696465 -0.11700112]\n",
      " [-0.220744    0.34058219]]\n",
      "cost:\n",
      "0.121947\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867 -0.43633222]\n",
      " [-0.17453289  0.17453289]\n",
      " [ 0.95993089  0.26179933]\n",
      " [-1.04719733 -0.26179933]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [ 1.13446378  0.17453289]\n",
      " [ 0.785398   -0.43633222]\n",
      " [-0.08726644 -0.17453289]\n",
      " [-0.61086511 -0.17453289]\n",
      " [-0.69813156 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.46583813 -0.35226718]\n",
      " [-0.13571453  0.28483355]\n",
      " [ 0.9720645   0.38112786]\n",
      " [-0.9983477  -0.16569224]\n",
      " [ 0.26417962 -0.19961205]\n",
      " [ 0.99410927  0.25077298]\n",
      " [ 0.79509091 -0.35647768]\n",
      " [-0.09363208 -0.10483318]\n",
      " [-0.69892085 -0.09242421]\n",
      " [-0.84886646 -0.17644498]]\n",
      "cost:\n",
      "0.111269\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.         -0.08726644]\n",
      " [ 0.61086511 -0.17453289]\n",
      " [ 0.34906578  0.08726644]\n",
      " [-0.34906578 -0.17453289]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [ 0.26179933  0.26179933]\n",
      " [ 1.04719733  0.34906578]\n",
      " [ 0.61086511 -0.26179933]\n",
      " [-0.95993089  0.        ]\n",
      " [ 0.61086511  0.26179933]]\n",
      "prediction:\n",
      "[[-0.104495   -0.12840331]\n",
      " [ 0.49410564 -0.26097801]\n",
      " [ 0.16477367  0.05826667]\n",
      " [-0.38096365 -0.24261864]\n",
      " [ 0.24443088 -0.28031597]\n",
      " [ 0.18271667  0.23938107]\n",
      " [ 0.99293321  0.32858276]\n",
      " [ 0.40869734 -0.40967709]\n",
      " [-0.99975616 -0.02248424]\n",
      " [ 0.55268192  0.23344833]]\n",
      "cost:\n",
      "0.123959\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644 -0.43633222]\n",
      " [-0.17453289  0.08726644]\n",
      " [-0.87266444 -0.08726644]\n",
      " [ 0.61086511  0.17453289]\n",
      " [-1.22173022  0.34906578]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [ 0.95993089 -0.26179933]\n",
      " [-0.43633222 -0.08726644]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [ 0.          0.34906578]]\n",
      "prediction:\n",
      "[[ 0.15664503 -0.41344067]\n",
      " [-0.13296701  0.08979382]\n",
      " [-0.98506111 -0.07203308]\n",
      " [ 0.8004058   0.15608233]\n",
      " [-0.99492329  0.26535591]\n",
      " [ 0.89940047 -0.26176658]\n",
      " [ 0.99720597 -0.27161518]\n",
      " [-0.44507903 -0.08490913]\n",
      " [ 0.10123872 -0.2408604 ]\n",
      " [ 0.00297457  0.3504096 ]]\n",
      "cost:\n",
      "0.0937633\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511 -0.26179933]\n",
      " [-1.04719733  0.34906578]\n",
      " [ 0.52359867 -0.43633222]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [-0.08726644  0.08726644]\n",
      " [-0.26179933 -0.43633222]\n",
      " [-0.08726644  0.26179933]\n",
      " [-1.22173022  0.08726644]\n",
      " [-1.04719733 -0.17453289]\n",
      " [-0.785398    0.26179933]]\n",
      "prediction:\n",
      "[[-0.68956375 -0.23207372]\n",
      " [-0.94013721  0.27964982]\n",
      " [ 0.94605601 -0.37408915]\n",
      " [ 0.99969429 -0.22020251]\n",
      " [-0.09690266  0.10274076]\n",
      " [-0.34735551 -0.39741135]\n",
      " [-0.09346223  0.27341837]\n",
      " [-0.55787432  0.06805874]\n",
      " [-0.86817324 -0.13665657]\n",
      " [-0.78040975  0.21790347]]\n",
      "cost:\n",
      "0.195985\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933 -0.08726644]\n",
      " [-0.34906578  0.34906578]\n",
      " [-0.17453289  0.        ]\n",
      " [-0.43633222 -0.43633222]\n",
      " [ 0.69813156  0.34906578]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [ 0.26179933 -0.43633222]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [-1.22173022 -0.34906578]\n",
      " [-1.13446378 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.19134974 -0.03260071]\n",
      " [-0.3173582   0.39825037]\n",
      " [-0.07713756  0.0361957 ]\n",
      " [-0.4129515  -0.33569539]\n",
      " [ 0.85897696  0.39735663]\n",
      " [ 0.38452142 -0.18054292]\n",
      " [ 0.28437558 -0.33339679]\n",
      " [ 0.99918872 -0.12666823]\n",
      " [-0.96503848 -0.24063611]\n",
      " [-0.99300277 -0.05552604]]\n",
      "cost:\n",
      "0.121014\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289  0.34906578]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [ 1.13446378  0.17453289]\n",
      " [-1.13446378  0.17453289]\n",
      " [-0.08726644 -0.17453289]\n",
      " [ 1.13446378  0.26179933]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [-0.785398   -0.26179933]\n",
      " [-0.87266444  0.34906578]]\n",
      "prediction:\n",
      "[[-0.04658979  0.26296535]\n",
      " [ 0.87793612 -0.21980169]\n",
      " [ 0.8538419  -0.47981912]\n",
      " [ 0.90061897  0.12280268]\n",
      " [-0.99892914  0.12954593]\n",
      " [-0.0907511  -0.20710537]\n",
      " [ 0.91586924  0.20275754]\n",
      " [ 0.89308882 -0.12432435]\n",
      " [-0.89869082 -0.31014284]\n",
      " [-0.93761033  0.26056805]]\n",
      "cost:\n",
      "0.148271\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.          0.17453289]\n",
      " [-0.69813156 -0.26179933]\n",
      " [ 0.         -0.26179933]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [ 0.52359867  0.17453289]\n",
      " [-1.22173022 -0.26179933]\n",
      " [ 0.17453289  0.        ]\n",
      " [ 0.785398   -0.26179933]\n",
      " [ 1.04719733  0.26179933]\n",
      " [-0.08726644  0.17453289]]\n",
      "prediction:\n",
      "[[-0.00373119  0.20318587]\n",
      " [-0.87281066 -0.29035726]\n",
      " [ 0.01348742 -0.30645111]\n",
      " [ 0.37836909 -0.27829197]\n",
      " [ 0.49316388  0.24661677]\n",
      " [-0.99937499 -0.29868355]\n",
      " [ 0.20554741  0.01984014]\n",
      " [ 0.85860026 -0.2695227 ]\n",
      " [ 0.99544007  0.33990106]\n",
      " [-0.07277523  0.20063387]]\n",
      "cost:\n",
      "0.0936314\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733  0.17453289]\n",
      " [-0.17453289  0.26179933]\n",
      " [-0.69813156 -0.43633222]\n",
      " [-0.52359867 -0.17453289]\n",
      " [-0.26179933  0.34906578]\n",
      " [-0.69813156 -0.26179933]\n",
      " [-0.26179933  0.17453289]\n",
      " [ 1.04719733 -0.26179933]\n",
      " [ 0.34906578  0.26179933]\n",
      " [ 0.52359867  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.99535334  0.04358795]\n",
      " [-0.18174759  0.16064903]\n",
      " [-0.97823632 -0.46824127]\n",
      " [-0.79527014 -0.24148482]\n",
      " [-0.27772766  0.24450448]\n",
      " [-0.9871158  -0.31524807]\n",
      " [-0.31713766  0.09232892]\n",
      " [ 0.98965394 -0.33540103]\n",
      " [ 0.38186187  0.18193088]\n",
      " [ 0.56689847  0.23172501]]\n",
      "cost:\n",
      "0.160755\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511 -0.34906578]\n",
      " [ 0.08726644 -0.34906578]\n",
      " [-0.08726644  0.26179933]\n",
      " [ 0.08726644 -0.43633222]\n",
      " [ 0.17453289  0.08726644]\n",
      " [ 0.52359867  0.        ]\n",
      " [-0.17453289 -0.17453289]\n",
      " [ 0.61086511 -0.17453289]\n",
      " [ 0.785398    0.34906578]\n",
      " [-1.04719733 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.73871636 -0.30558658]\n",
      " [ 0.13024935 -0.30917481]\n",
      " [-0.11504025  0.30973986]\n",
      " [ 0.12125569 -0.39246303]\n",
      " [ 0.12691441  0.12819825]\n",
      " [ 0.70452356  0.02136579]\n",
      " [-0.1554338  -0.13189949]\n",
      " [ 0.87959659 -0.14186591]\n",
      " [ 0.99375314  0.43137112]\n",
      " [-0.99954212 -0.03474994]]\n",
      "cost:\n",
      "0.116192\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222  0.08726644]\n",
      " [ 0.785398   -0.26179933]\n",
      " [-1.04719733 -0.26179933]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [ 1.04719733 -0.17453289]\n",
      " [-0.43633222 -0.34906578]\n",
      " [-0.87266444 -0.26179933]\n",
      " [ 0.         -0.43633222]\n",
      " [-1.13446378 -0.34906578]\n",
      " [ 0.95993089 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.43106836  0.59731239]\n",
      " [ 0.84901559 -0.12293396]\n",
      " [-0.98231691 -0.04777535]\n",
      " [ 0.4060021  -0.00949542]\n",
      " [ 0.99369425  0.02831912]\n",
      " [-0.46870694 -0.21683948]\n",
      " [-0.91151261 -0.0701474 ]\n",
      " [-0.01125498 -0.36572945]\n",
      " [-0.98889083 -0.10526091]\n",
      " [ 0.97195697 -0.16352956]]\n",
      "cost:\n",
      "0.205697\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378  0.34906578]\n",
      " [-0.34906578  0.08726644]\n",
      " [-1.22173022 -0.26179933]\n",
      " [-0.95993089  0.34906578]\n",
      " [ 0.         -0.17453289]\n",
      " [ 0.61086511  0.        ]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [-1.04719733 -0.08726644]\n",
      " [-0.52359867  0.26179933]\n",
      " [-0.26179933  0.        ]]\n",
      "prediction:\n",
      "[[ 0.99979234  0.27603146]\n",
      " [-0.3352353   0.06049043]\n",
      " [-0.93636632 -0.48978776]\n",
      " [-0.87844968  0.29147547]\n",
      " [ 0.02786696 -0.24250343]\n",
      " [ 0.7363736  -0.0226682 ]\n",
      " [ 0.32546461 -0.29420194]\n",
      " [-0.91606039 -0.16774377]\n",
      " [-0.46124339  0.22923549]\n",
      " [-0.2609129  -0.02366837]]\n",
      "cost:\n",
      "0.121924\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511  0.17453289]\n",
      " [ 0.08726644  0.        ]\n",
      " [ 0.87266444  0.34906578]\n",
      " [-0.61086511  0.17453289]\n",
      " [ 0.61086511  0.17453289]\n",
      " [-0.95993089  0.17453289]\n",
      " [-0.34906578  0.26179933]\n",
      " [-1.13446378  0.17453289]\n",
      " [ 0.61086511  0.26179933]\n",
      " [-1.22173022  0.34906578]]\n",
      "prediction:\n",
      "[[-0.55657405 -0.16353516]\n",
      " [ 0.1261825  -0.26181337]\n",
      " [ 0.99957633  0.39832214]\n",
      " [-0.55657405 -0.16353516]\n",
      " [ 0.80877018 -0.12882966]\n",
      " [-0.90234578 -0.14383161]\n",
      " [-0.35039508  0.29334453]\n",
      " [-0.95430958 -0.45853567]\n",
      " [ 0.82955503  0.11450917]\n",
      " [-0.91553271  0.12919472]]\n",
      "cost:\n",
      "0.310177\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867  0.26179933]\n",
      " [ 0.43633222  0.17453289]\n",
      " [-1.22173022 -0.43633222]\n",
      " [ 1.22173022 -0.34906578]\n",
      " [-1.22173022  0.        ]\n",
      " [ 0.08726644 -0.08726644]\n",
      " [ 1.04719733  0.08726644]\n",
      " [-0.95993089 -0.17453289]\n",
      " [-0.61086511 -0.26179933]\n",
      " [-0.52359867  0.        ]]\n",
      "prediction:\n",
      "[[ 0.56834555  0.37911114]\n",
      " [ 0.44776368  0.23471814]\n",
      " [-0.94414961 -0.40262097]\n",
      " [ 0.99157482 -0.36590314]\n",
      " [-0.98071516  0.02285339]\n",
      " [ 0.06414363 -0.09232076]\n",
      " [ 0.99564993  0.16496122]\n",
      " [-0.94419861 -0.14951839]\n",
      " [-0.5273425  -0.26423153]\n",
      " [-0.40258342  0.03949839]]\n",
      "cost:\n",
      "0.129662\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089  0.34906578]\n",
      " [-0.26179933 -0.08726644]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [-0.34906578 -0.08726644]\n",
      " [-0.08726644 -0.43633222]\n",
      " [-1.04719733  0.08726644]\n",
      " [-1.22173022 -0.08726644]\n",
      " [ 1.22173022  0.34906578]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [-0.26179933 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.88084805  0.34690174]\n",
      " [-0.34464329 -0.07125413]\n",
      " [ 0.88018674 -0.15740575]\n",
      " [-0.44189426 -0.07669581]\n",
      " [-0.067438   -0.43909058]\n",
      " [-0.94776171  0.11682781]\n",
      " [-0.97662836 -0.09094438]\n",
      " [ 0.99927628  0.29696015]\n",
      " [ 0.86743438 -0.06433599]\n",
      " [-0.24304482 -0.37232625]]\n",
      "cost:\n",
      "0.123787\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222  0.17453289]\n",
      " [-0.17453289 -0.08726644]\n",
      " [ 1.22173022 -0.08726644]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [-0.34906578 -0.34906578]\n",
      " [ 0.61086511  0.17453289]\n",
      " [-0.17453289 -0.17453289]\n",
      " [ 1.13446378  0.17453289]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [ 0.08726644  0.        ]]\n",
      "prediction:\n",
      "[[ 0.63766479  0.28915709]\n",
      " [-0.44175348 -0.08675089]\n",
      " [ 0.64357126 -0.15388927]\n",
      " [ 0.84461761 -0.25912914]\n",
      " [-0.99988639 -0.46980432]\n",
      " [ 0.680794    0.30942208]\n",
      " [-0.31327    -0.21731976]\n",
      " [ 0.65798712  0.23921652]\n",
      " [ 0.8452037  -0.13331582]\n",
      " [ 0.15698633  0.01289746]]\n",
      "cost:\n",
      "0.31008\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.43633222]\n",
      " [-1.04719733  0.        ]\n",
      " [ 0.52359867 -0.08726644]\n",
      " [ 0.26179933 -0.34906578]\n",
      " [ 0.43633222 -0.34906578]\n",
      " [-0.785398   -0.17453289]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [-1.04719733  0.26179933]\n",
      " [-0.17453289  0.        ]\n",
      " [ 0.17453289 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.88972646 -0.27858067]\n",
      " [-0.94412249  0.09069277]\n",
      " [ 0.65084755 -0.01278176]\n",
      " [ 0.24635896 -0.24666043]\n",
      " [ 0.46676925 -0.24281178]\n",
      " [-0.72233719 -0.08435791]\n",
      " [ 0.99973559 -0.01408636]\n",
      " [-0.93971777  0.52327853]\n",
      " [-0.24767695  0.06579922]\n",
      " [ 0.18632264 -0.30933449]]\n",
      "cost:\n",
      "0.168258\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733  0.26179933]\n",
      " [ 0.69813156  0.08726644]\n",
      " [-1.13446378  0.34906578]\n",
      " [ 1.04719733 -0.43633222]\n",
      " [ 1.22173022  0.17453289]\n",
      " [-0.785398    0.26179933]\n",
      " [-0.785398   -0.43633222]\n",
      " [ 0.         -0.26179933]\n",
      " [-0.26179933  0.26179933]\n",
      " [ 0.17453289  0.08726644]]\n",
      "prediction:\n",
      "[[-0.97956055  0.16138205]\n",
      " [ 0.80213594  0.01329368]\n",
      " [-0.97911769  0.20942494]\n",
      " [ 0.98227739 -0.44803092]\n",
      " [ 0.99715215  0.07524205]\n",
      " [-0.78851378  0.14704604]\n",
      " [-0.73543507 -0.4491761 ]\n",
      " [ 0.01807037 -0.30501056]\n",
      " [-0.28830901  0.16843817]\n",
      " [ 0.22802278  0.03546523]]\n",
      "cost:\n",
      "0.115383\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578 -0.26179933]\n",
      " [-0.52359867  0.17453289]\n",
      " [ 0.87266444  0.08726644]\n",
      " [ 0.          0.17453289]\n",
      " [-1.13446378 -0.17453289]\n",
      " [ 0.69813156  0.34906578]\n",
      " [ 0.785398   -0.17453289]\n",
      " [ 0.17453289  0.34906578]\n",
      " [-1.22173022 -0.34906578]\n",
      " [ 0.34906578  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.34335399 -0.35442543]\n",
      " [-0.62729973  0.10667589]\n",
      " [ 0.990493    0.03707818]\n",
      " [-0.03786524  0.12928782]\n",
      " [-0.99460721 -0.25021976]\n",
      " [ 0.82431698  0.29522792]\n",
      " [ 0.960917   -0.24947704]\n",
      " [ 0.1609129   0.2851221 ]\n",
      " [-0.99367487 -0.43916091]\n",
      " [ 0.34186718  0.03061208]]\n",
      "cost:\n",
      "0.125856\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733  0.08726644]\n",
      " [-0.785398    0.17453289]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [ 0.26179933  0.34906578]\n",
      " [-0.08726644  0.17453289]\n",
      " [ 0.08726644  0.08726644]\n",
      " [-0.95993089 -0.34906578]\n",
      " [ 1.22173022  0.26179933]]\n",
      "prediction:\n",
      "[[-0.98077035  0.04367477]\n",
      " [-0.87041527  0.1097187 ]\n",
      " [ 0.606058   -0.34715667]\n",
      " [ 0.32512009 -0.23256178]\n",
      " [ 0.23621307 -0.22038709]\n",
      " [ 0.17692749  0.34463483]\n",
      " [-0.1555828   0.14013532]\n",
      " [ 0.04440881  0.07687398]\n",
      " [-0.96037394 -0.47463408]\n",
      " [ 0.99962717  0.1748762 ]]\n",
      "cost:\n",
      "0.0989976\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933 -0.17453289]\n",
      " [ 0.17453289  0.34906578]\n",
      " [ 0.785398    0.26179933]\n",
      " [-0.87266444  0.26179933]\n",
      " [-0.52359867 -0.17453289]\n",
      " [-0.52359867 -0.17453289]\n",
      " [-0.95993089  0.17453289]\n",
      " [-0.87266444 -0.08726644]\n",
      " [ 0.43633222  0.        ]\n",
      " [-0.34906578 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.18411759 -0.23887269]\n",
      " [ 0.20685156  0.2917189 ]\n",
      " [ 0.99976748  0.20285095]\n",
      " [-0.90036678  0.24289805]\n",
      " [-0.44122481 -0.21882506]\n",
      " [-0.44122481 -0.21882506]\n",
      " [-0.95919544  0.14883417]\n",
      " [-0.83969057 -0.10605671]\n",
      " [ 0.8588168  -0.04382415]\n",
      " [-0.25456008 -0.49377087]]\n",
      "cost:\n",
      "0.127085\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398    0.        ]\n",
      " [ 1.22173022  0.08726644]\n",
      " [ 0.95993089  0.17453289]\n",
      " [ 0.          0.        ]\n",
      " [ 0.52359867 -0.43633222]\n",
      " [-1.13446378 -0.43633222]\n",
      " [ 0.69813156  0.26179933]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [-0.43633222  0.17453289]\n",
      " [ 0.34906578  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.50495195 -0.02306032]\n",
      " [ 0.89675784  0.0671004 ]\n",
      " [ 0.91864568  0.15592782]\n",
      " [ 0.09647115 -0.01051554]\n",
      " [ 0.33591697 -0.4406223 ]\n",
      " [-0.9998911  -0.39334229]\n",
      " [ 0.57675552  0.25500157]\n",
      " [ 0.5056026  -0.37373725]\n",
      " [-0.49619022  0.19357938]\n",
      " [ 0.24313593  0.15078905]]\n",
      "cost:\n",
      "0.156536\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398    0.17453289]\n",
      " [-0.61086511 -0.26179933]\n",
      " [ 0.785398   -0.17453289]\n",
      " [-0.17453289  0.34906578]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [ 0.69813156  0.        ]\n",
      " [ 0.61086511 -0.43633222]\n",
      " [-0.95993089  0.34906578]\n",
      " [ 0.785398    0.        ]\n",
      " [ 0.61086511  0.17453289]]\n",
      "prediction:\n",
      "[[-0.98482513  0.13982522]\n",
      " [-0.77290726 -0.30945069]\n",
      " [ 0.93641275 -0.23630528]\n",
      " [-0.18294337  0.31485683]\n",
      " [ 0.73562104 -0.13381022]\n",
      " [ 0.748492   -0.04632599]\n",
      " [ 0.74938357 -0.49948657]\n",
      " [-0.99857002  0.30049819]\n",
      " [ 0.96031791 -0.05767224]\n",
      " [ 0.66827512  0.1379115 ]]\n",
      "cost:\n",
      "0.116448\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511  0.08726644]\n",
      " [ 0.61086511  0.08726644]\n",
      " [ 0.61086511  0.08726644]\n",
      " [-0.17453289 -0.34906578]\n",
      " [ 0.52359867  0.34906578]\n",
      " [-0.26179933 -0.43633222]\n",
      " [-0.95993089  0.17453289]\n",
      " [ 0.26179933 -0.43633222]\n",
      " [-0.08726644  0.34906578]\n",
      " [-0.95993089  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.94213688  0.02353689]\n",
      " [ 0.94213688  0.02353689]\n",
      " [ 0.94213688  0.02353689]\n",
      " [-0.1575551  -0.32568148]\n",
      " [ 0.83091223  0.24925879]\n",
      " [-0.31908134 -0.41028127]\n",
      " [-0.996122    0.10437799]\n",
      " [ 0.31917822 -0.4193415 ]\n",
      " [-0.02498739  0.27896073]\n",
      " [-0.996122    0.10437799]]\n",
      "cost:\n",
      "0.173847\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398    0.08726644]\n",
      " [-0.26179933 -0.43633222]\n",
      " [-0.61086511  0.34906578]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [ 0.          0.17453289]\n",
      " [-0.08726644  0.34906578]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [-0.52359867 -0.08726644]\n",
      " [-0.69813156  0.17453289]\n",
      " [ 0.52359867  0.08726644]]\n",
      "prediction:\n",
      "[[-0.98299509  0.02461481]\n",
      " [-0.20995125 -0.4697763 ]\n",
      " [-0.6718595   0.28058618]\n",
      " [ 0.53149855 -0.28498501]\n",
      " [-0.03832691  0.12800746]\n",
      " [-0.1544459   0.29587966]\n",
      " [ 0.99975538 -0.31193763]\n",
      " [-0.53777182 -0.13428478]\n",
      " [-0.92133796  0.10088482]\n",
      " [ 0.60687864  0.0256486 ]]\n",
      "cost:\n",
      "0.106264\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511 -0.43633222]\n",
      " [ 0.34906578 -0.08726644]\n",
      " [-1.04719733 -0.17453289]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [ 0.95993089  0.        ]\n",
      " [ 1.04719733 -0.26179933]\n",
      " [-1.04719733 -0.17453289]\n",
      " [-0.43633222 -0.43633222]\n",
      " [ 0.785398    0.        ]\n",
      " [-0.34906578  0.        ]]\n",
      "prediction:\n",
      "[[ 0.57680762 -0.4409548 ]\n",
      " [ 0.3385618  -0.01479765]\n",
      " [-0.99594355  0.02010075]\n",
      " [ 0.50347883  0.0404537 ]\n",
      " [ 0.95831126  0.19200398]\n",
      " [ 0.98001188 -0.13453411]\n",
      " [-0.99594331  0.02009529]\n",
      " [-0.3979257  -0.47068772]\n",
      " [ 0.81162691  0.22944632]\n",
      " [-0.29303053  0.26260355]]\n",
      "cost:\n",
      "0.15639\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867 -0.34906578]\n",
      " [-0.26179933 -0.08726644]\n",
      " [-0.26179933 -0.17453289]\n",
      " [ 0.08726644 -0.34906578]\n",
      " [-0.08726644 -0.43633222]\n",
      " [-0.43633222 -0.26179933]\n",
      " [ 0.         -0.17453289]\n",
      " [ 1.22173022  0.17453289]\n",
      " [ 0.43633222  0.34906578]\n",
      " [ 0.26179933 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.99186343 -0.2065389 ]\n",
      " [-0.27859601  0.01556846]\n",
      " [-0.40491    -0.06663283]\n",
      " [ 0.02620533 -0.23019767]\n",
      " [-0.03959227 -0.29132828]\n",
      " [-0.92782682 -0.14136553]\n",
      " [-0.03522992 -0.06298982]\n",
      " [ 0.99973297  0.31780371]\n",
      " [ 0.44729829  0.482126  ]\n",
      " [ 0.2313474  -0.21218696]]\n",
      "cost:\n",
      "0.222014\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578 -0.17453289]\n",
      " [-0.43633222  0.17453289]\n",
      " [ 0.          0.08726644]\n",
      " [-0.17453289 -0.08726644]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [-1.22173022  0.17453289]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [ 0.95993089  0.34906578]\n",
      " [ 0.08726644 -0.34906578]\n",
      " [-1.13446378  0.        ]]\n",
      "prediction:\n",
      "[[ 0.36742067 -0.2219059 ]\n",
      " [-0.44320226  0.17216225]\n",
      " [-0.04037946  0.10637076]\n",
      " [-0.1823677  -0.08764847]\n",
      " [ 0.22165808 -0.21071044]\n",
      " [-0.99200934  0.1626963 ]\n",
      " [ 0.99636602 -0.10736195]\n",
      " [ 0.97964668  0.33876848]\n",
      " [ 0.18491891 -0.51626694]\n",
      " [-0.9917134  -0.01862757]]\n",
      "cost:\n",
      "0.0814515\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444 -0.26179933]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [-0.34906578  0.17453289]\n",
      " [-0.43633222 -0.34906578]\n",
      " [-0.87266444  0.17453289]\n",
      " [-0.43633222  0.34906578]\n",
      " [-0.34906578 -0.17453289]\n",
      " [-0.17453289  0.        ]\n",
      " [-0.785398   -0.43633222]\n",
      " [ 0.87266444 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.9957208  -0.20822242]\n",
      " [ 0.27941039 -0.15320429]\n",
      " [-0.33848584  0.21183798]\n",
      " [-0.33857638 -0.29598618]\n",
      " [-0.9962346   0.21701401]\n",
      " [-0.39822173  0.41230705]\n",
      " [-0.29413083 -0.1434278 ]\n",
      " [-0.19671866  0.01743083]\n",
      " [-0.90490729 -0.38437846]\n",
      " [ 0.99452507 -0.13075703]]\n",
      "cost:\n",
      "0.0867535\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.22173022  0.        ]\n",
      " [ 1.22173022  0.08726644]\n",
      " [ 0.08726644 -0.34906578]\n",
      " [-0.26179933  0.        ]\n",
      " [ 0.87266444  0.        ]\n",
      " [-0.08726644 -0.43633222]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [ 1.22173022 -0.08726644]\n",
      " [ 0.08726644  0.34906578]\n",
      " [-1.22173022 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.83833772  0.06918471]\n",
      " [ 0.86411625  0.17124361]\n",
      " [ 0.07463227 -0.32625005]\n",
      " [-0.43930092  0.0568802 ]\n",
      " [ 0.67995805  0.05041057]\n",
      " [-0.14919859 -0.38245377]\n",
      " [ 0.58049667 -0.23865689]\n",
      " [ 0.88617122 -0.0012131 ]\n",
      " [ 0.0931794   0.39894047]\n",
      " [-0.99989414 -0.30697659]]\n",
      "cost:\n",
      "0.202401\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511  0.34906578]\n",
      " [-0.87266444  0.26179933]\n",
      " [ 0.         -0.17453289]\n",
      " [-0.26179933  0.        ]\n",
      " [-0.52359867  0.08726644]\n",
      " [-0.785398   -0.26179933]\n",
      " [ 0.785398    0.17453289]\n",
      " [-0.69813156 -0.08726644]\n",
      " [ 1.13446378  0.08726644]\n",
      " [-0.95993089 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.55847955  0.30687052]\n",
      " [-0.89165878  0.21655639]\n",
      " [-0.09428729 -0.20706306]\n",
      " [-0.26193434 -0.0276443 ]\n",
      " [-0.43235588  0.04728484]\n",
      " [-0.7033062  -0.40990552]\n",
      " [ 0.9295789   0.11752502]\n",
      " [-0.56254852 -0.15077287]\n",
      " [ 0.99978918  0.0183761 ]\n",
      " [-0.94812274 -0.45676333]]\n",
      "cost:\n",
      "0.116403\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.26179933]\n",
      " [-0.87266444 -0.43633222]\n",
      " [-0.43633222  0.34906578]\n",
      " [ 0.95993089  0.17453289]\n",
      " [ 0.95993089  0.26179933]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [ 0.17453289  0.34906578]\n",
      " [-0.95993089 -0.34906578]\n",
      " [-0.52359867 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.98385501 -0.18626842]\n",
      " [-0.86133659 -0.35041922]\n",
      " [-0.44877669  0.28740045]\n",
      " [ 0.99648523  0.09971945]\n",
      " [ 0.99595696  0.19202089]\n",
      " [ 0.0533524  -0.15739481]\n",
      " [ 0.05336475 -0.15739988]\n",
      " [ 0.13466865  0.30391771]\n",
      " [-0.94853991 -0.27391416]\n",
      " [-0.471113   -0.36133578]]\n",
      "cost:\n",
      "0.0783608\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156 -0.17453289]\n",
      " [-0.52359867  0.17453289]\n",
      " [-0.34906578  0.        ]\n",
      " [-0.43633222 -0.34906578]\n",
      " [-1.04719733  0.        ]\n",
      " [ 1.04719733 -0.17453289]\n",
      " [-0.17453289 -0.26179933]\n",
      " [-0.61086511 -0.26179933]\n",
      " [ 1.13446378 -0.08726644]\n",
      " [ 0.52359867 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.74258292 -0.09680737]\n",
      " [-0.51232576  0.46024722]\n",
      " [-0.3133885   0.07753432]\n",
      " [-0.374816   -0.39072216]\n",
      " [-0.99803936  0.17758541]\n",
      " [ 0.99227136 -0.11400193]\n",
      " [-0.09937684 -0.25807807]\n",
      " [-0.54001248 -0.24153072]\n",
      " [ 0.99533427  0.02496481]\n",
      " [ 0.52394688 -0.25761244]]\n",
      "cost:\n",
      "0.113302\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289 -0.43633222]\n",
      " [ 0.95993089 -0.34906578]\n",
      " [-0.69813156 -0.08726644]\n",
      " [-0.17453289 -0.43633222]\n",
      " [-0.34906578  0.26179933]\n",
      " [-0.43633222 -0.26179933]\n",
      " [ 0.          0.26179933]\n",
      " [ 0.95993089 -0.43633222]\n",
      " [-0.52359867  0.34906578]\n",
      " [ 0.785398    0.34906578]]\n",
      "prediction:\n",
      "[[-0.13933936 -0.30825916]\n",
      " [ 0.98943591 -0.27558714]\n",
      " [-0.99895036 -0.09696309]\n",
      " [-0.13933267 -0.30825758]\n",
      " [-0.48897341  0.18707062]\n",
      " [-0.60017312 -0.20861588]\n",
      " [ 0.06409387  0.24110322]\n",
      " [ 0.98709279 -0.32183656]\n",
      " [-0.83297706  0.2476671 ]\n",
      " [ 0.84835947  0.23176013]]\n",
      "cost:\n",
      "0.16204\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398    0.26179933]\n",
      " [-0.61086511  0.        ]\n",
      " [-1.13446378  0.        ]\n",
      " [-0.87266444 -0.08726644]\n",
      " [-1.22173022  0.34906578]\n",
      " [-0.87266444  0.08726644]\n",
      " [ 0.08726644  0.08726644]\n",
      " [ 1.04719733  0.26179933]\n",
      " [-0.69813156  0.26179933]\n",
      " [ 1.04719733 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.8836844   0.10820637]\n",
      " [-0.67160285 -0.08281578]\n",
      " [-0.9634307  -0.12168991]\n",
      " [-0.88297236 -0.20583645]\n",
      " [-0.88521707  0.17867585]\n",
      " [-0.85603964 -0.02566349]\n",
      " [ 0.11673341 -0.02688487]\n",
      " [ 0.99676424  0.12159313]\n",
      " [-0.65190995  0.14102916]\n",
      " [ 0.99382347 -0.63379121]]\n",
      "cost:\n",
      "0.170607\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398   -0.17453289]\n",
      " [ 1.04719733  0.08726644]\n",
      " [-0.52359867  0.08726644]\n",
      " [ 0.17453289 -0.26179933]\n",
      " [-0.69813156 -0.34906578]\n",
      " [ 0.69813156  0.        ]\n",
      " [-0.34906578 -0.43633222]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [ 0.52359867  0.17453289]\n",
      " [-0.43633222  0.        ]]\n",
      "prediction:\n",
      "[[ 0.90702397 -0.1614776 ]\n",
      " [ 0.98681742  0.18322451]\n",
      " [-0.6553418   0.16519716]\n",
      " [ 0.14160201 -0.25646263]\n",
      " [-0.99971873 -0.36165941]\n",
      " [ 0.55741954  0.0541808 ]\n",
      " [-0.53873491 -0.43500203]\n",
      " [ 0.77780473 -0.13857408]\n",
      " [ 0.52733767  0.37139368]\n",
      " [-0.55540651  0.02583444]]\n",
      "cost:\n",
      "0.147059\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289  0.17453289]\n",
      " [ 0.17453289  0.34906578]\n",
      " [ 0.87266444 -0.34906578]\n",
      " [ 0.52359867 -0.43633222]\n",
      " [ 0.08726644  0.26179933]\n",
      " [ 0.785398   -0.43633222]\n",
      " [-0.08726644  0.17453289]\n",
      " [-0.87266444  0.08726644]\n",
      " [ 1.04719733  0.        ]\n",
      " [-0.69813156 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.16247705  0.14316107]\n",
      " [ 0.13072129  0.30867219]\n",
      " [ 0.94704831 -0.29611051]\n",
      " [ 0.51809388 -0.3703129 ]\n",
      " [ 0.03456496  0.22794935]\n",
      " [ 0.85319418 -0.37466925]\n",
      " [-0.08150108  0.12839951]\n",
      " [-0.99918914  0.04612901]\n",
      " [ 0.98077989 -0.0124339 ]\n",
      " [-0.98013282 -0.30753109]]\n",
      "cost:\n",
      "0.0937188\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644 -0.08726644]\n",
      " [ 1.22173022  0.08726644]\n",
      " [ 0.69813156  0.        ]\n",
      " [ 0.61086511 -0.43633222]\n",
      " [ 1.04719733  0.34906578]\n",
      " [-0.08726644 -0.43633222]\n",
      " [-0.52359867 -0.08726644]\n",
      " [ 0.61086511  0.26179933]\n",
      " [ 1.04719733 -0.34906578]\n",
      " [-0.17453289  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.10104397 -0.06068533]\n",
      " [ 0.87780923  0.06423697]\n",
      " [ 0.4272216  -0.01028835]\n",
      " [ 0.43509749 -0.41056719]\n",
      " [ 0.8481003   0.32279545]\n",
      " [-0.19497842 -0.38194463]\n",
      " [-0.9999103  -0.09980221]\n",
      " [ 0.53114736  0.25420973]\n",
      " [ 0.87357354 -0.33713561]\n",
      " [-0.32737365  0.19768101]]\n",
      "cost:\n",
      "0.203004\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511  0.26179933]\n",
      " [ 1.22173022  0.        ]\n",
      " [-0.43633222 -0.26179933]\n",
      " [-1.04719733 -0.08726644]\n",
      " [ 0.52359867 -0.08726644]\n",
      " [ 0.87266444  0.08726644]\n",
      " [-0.17453289  0.08726644]\n",
      " [-0.08726644 -0.17453289]\n",
      " [-1.13446378 -0.26179933]\n",
      " [-1.13446378  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.65145469  0.39328352]\n",
      " [ 0.99669588 -0.03844529]\n",
      " [-0.56187105 -0.38467085]\n",
      " [-0.97186828 -0.11777833]\n",
      " [ 0.66687012 -0.10811107]\n",
      " [ 0.98641819  0.16194798]\n",
      " [-0.21056581  0.12393971]\n",
      " [-0.16377768 -0.22587302]\n",
      " [-0.97933024 -0.4213787 ]\n",
      " [-0.95250869  0.17904834]]\n",
      "cost:\n",
      "0.14736\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398   -0.43633222]\n",
      " [-0.34906578 -0.26179933]\n",
      " [-0.52359867  0.08726644]\n",
      " [-0.785398   -0.26179933]\n",
      " [ 1.04719733 -0.34906578]\n",
      " [ 0.95993089 -0.43633222]\n",
      " [-0.17453289  0.08726644]\n",
      " [ 0.17453289  0.08726644]\n",
      " [ 0.08726644  0.08726644]\n",
      " [ 0.87266444 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.72717679 -0.33077544]\n",
      " [-0.31827068 -0.21225418]\n",
      " [-0.65544999  0.2991682 ]\n",
      " [-0.99983776 -0.18650043]\n",
      " [ 0.95817327 -0.24710687]\n",
      " [ 0.8683393  -0.31059474]\n",
      " [-0.05110863  0.19727094]\n",
      " [ 0.15097845  0.27514046]\n",
      " [ 0.15629543  0.23567726]\n",
      " [ 0.87107998 -0.1741657 ]]\n",
      "cost:\n",
      "0.155265\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398    0.08726644]\n",
      " [-0.52359867  0.08726644]\n",
      " [-1.13446378  0.26179933]\n",
      " [-0.61086511  0.08726644]\n",
      " [-0.34906578 -0.08726644]\n",
      " [-0.26179933  0.26179933]\n",
      " [ 0.785398   -0.17453289]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [-1.04719733  0.        ]\n",
      " [ 0.43633222 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.67088556  0.06974721]\n",
      " [-0.47693413  0.08134667]\n",
      " [-0.95930517  0.27438432]\n",
      " [-0.52192056  0.07856461]\n",
      " [-0.32256272 -0.12908176]\n",
      " [-0.21841462  0.30283439]\n",
      " [ 0.99977934 -0.24248424]\n",
      " [ 0.69342935 -0.40825588]\n",
      " [-0.95988607 -0.06527053]\n",
      " [ 0.69333446 -0.40823433]]\n",
      "cost:\n",
      "0.146267\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156  0.17453289]\n",
      " [ 0.95993089  0.26179933]\n",
      " [ 0.43633222  0.26179933]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [-0.26179933  0.34906578]\n",
      " [-0.87266444 -0.43633222]\n",
      " [ 0.08726644  0.        ]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [ 1.13446378  0.17453289]\n",
      " [-0.34906578 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.53900731  0.1003018 ]\n",
      " [ 0.82184029  0.18779822]\n",
      " [ 0.39504594  0.19007964]\n",
      " [ 0.81218946 -0.11884655]\n",
      " [-0.23482502  0.28589383]\n",
      " [-0.99991983 -0.39719152]\n",
      " [ 0.16457565 -0.0262024 ]\n",
      " [ 0.7074185  -0.42062876]\n",
      " [ 0.84092975  0.07971195]\n",
      " [-0.35634083 -0.33490548]]\n",
      "cost:\n",
      "0.142597\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578  0.34906578]\n",
      " [ 0.26179933  0.26179933]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [-0.69813156  0.08726644]\n",
      " [ 0.87266444 -0.34906578]\n",
      " [-0.61086511  0.34906578]\n",
      " [-0.87266444 -0.08726644]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [-0.87266444  0.34906578]\n",
      " [-0.43633222 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.27519402  0.24124053]\n",
      " [ 0.32498002  0.19209518]\n",
      " [ 0.73047197 -0.11498324]\n",
      " [-0.73814726  0.02574167]\n",
      " [ 0.98689586 -0.3736735 ]\n",
      " [-0.5914613   0.23897965]\n",
      " [-0.99278414 -0.14825235]\n",
      " [ 0.99692607 -0.42828825]\n",
      " [-0.96304947  0.2170174 ]\n",
      " [-0.36247742 -0.29216114]]\n",
      "cost:\n",
      "0.116194\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.          0.08726644]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [ 0.61086511  0.08726644]\n",
      " [-0.08726644 -0.34906578]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [ 0.87266444  0.17453289]\n",
      " [ 0.34906578 -0.34906578]\n",
      " [ 0.785398   -0.34906578]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [-0.61086511  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.03015352  0.14499103]\n",
      " [ 0.29632729 -0.14133811]\n",
      " [ 0.53513587  0.22314511]\n",
      " [-0.2012192  -0.34386849]\n",
      " [ 0.88740069 -0.0943916 ]\n",
      " [ 0.85137552  0.35764793]\n",
      " [ 0.26371884 -0.33035022]\n",
      " [ 0.79126507 -0.29193026]\n",
      " [ 0.24297708 -0.22794908]\n",
      " [-0.9999218   0.24715535]]\n",
      "cost:\n",
      "0.136631\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644  0.        ]\n",
      " [-0.08726644 -0.34906578]\n",
      " [ 0.95993089  0.34906578]\n",
      " [ 0.08726644 -0.08726644]\n",
      " [-0.61086511  0.        ]\n",
      " [-0.87266444 -0.26179933]\n",
      " [-0.17453289  0.08726644]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [-1.04719733 -0.08726644]\n",
      " [ 0.69813156  0.34906578]]\n",
      "prediction:\n",
      "[[-0.02795621  0.00857645]\n",
      " [-0.12406229 -0.42886248]\n",
      " [ 0.99936378  0.34480566]\n",
      " [ 0.08615614 -0.08344987]\n",
      " [-0.64265066  0.01486409]\n",
      " [-0.93668622 -0.31375954]\n",
      " [-0.21009043  0.07576273]\n",
      " [ 0.10029069 -0.29514316]\n",
      " [-0.99533212 -0.10461292]\n",
      " [ 0.91171539  0.32621858]]\n",
      "cost:\n",
      "0.0707254\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156 -0.17453289]\n",
      " [ 0.785398   -0.08726644]\n",
      " [-0.69813156 -0.34906578]\n",
      " [-0.08726644 -0.34906578]\n",
      " [-0.69813156  0.34906578]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [ 0.17453289 -0.26179933]\n",
      " [-0.87266444  0.26179933]\n",
      " [-1.13446378  0.        ]\n",
      " [ 0.785398   -0.34906578]]\n",
      "prediction:\n",
      "[[  9.02898490e-01  -8.22899491e-02]\n",
      " [  9.83277142e-01  -5.05387725e-04]\n",
      " [ -7.79650390e-01  -2.91654348e-01]\n",
      " [ -1.10728793e-01  -3.26766133e-01]\n",
      " [ -7.74285376e-01   4.19785440e-01]\n",
      " [  4.98960435e-01  -1.74878493e-01]\n",
      " [  1.99928775e-01  -1.98850214e-01]\n",
      " [ -9.73360956e-01   3.45920801e-01]\n",
      " [ -9.95781839e-01   1.05080597e-01]\n",
      " [  9.90015090e-01  -2.54117131e-01]]\n",
      "cost:\n",
      "0.136565\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.          0.26179933]\n",
      " [ 0.17453289  0.34906578]\n",
      " [-0.87266444 -0.43633222]\n",
      " [ 0.95993089  0.08726644]\n",
      " [-0.26179933 -0.08726644]\n",
      " [-0.26179933 -0.08726644]\n",
      " [ 1.13446378  0.08726644]\n",
      " [-1.04719733  0.        ]\n",
      " [ 0.         -0.17453289]\n",
      " [ 0.          0.26179933]]\n",
      "prediction:\n",
      "[[-0.06611779  0.22361639]\n",
      " [ 0.18327725  0.27003205]\n",
      " [-0.97722059 -0.556934  ]\n",
      " [ 0.98823422  0.01383148]\n",
      " [-0.32625008 -0.13019978]\n",
      " [-0.32627505 -0.13017917]\n",
      " [ 0.99680406  0.00553295]\n",
      " [-0.99546725 -0.07825048]\n",
      " [-0.07042485 -0.23742335]\n",
      " [-0.06602146  0.22363938]]\n",
      "cost:\n",
      "0.0973648\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511 -0.17453289]\n",
      " [ 0.69813156  0.34906578]\n",
      " [ 1.22173022 -0.43633222]\n",
      " [-0.26179933 -0.43633222]\n",
      " [-0.34906578  0.        ]\n",
      " [ 1.04719733 -0.26179933]\n",
      " [-0.17453289 -0.43633222]\n",
      " [-0.87266444 -0.43633222]\n",
      " [-1.22173022 -0.26179933]\n",
      " [-0.61086511 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.57883239 -0.03735032]\n",
      " [ 0.7412836   0.57483804]\n",
      " [ 0.99000329 -0.18536086]\n",
      " [-0.20567051 -0.23725548]\n",
      " [-0.28133211  0.08981966]\n",
      " [ 0.99485958 -0.0846438 ]\n",
      " [-0.07219087 -0.2462597 ]\n",
      " [-0.92878783 -0.20419545]\n",
      " [-0.99707103 -0.01570072]\n",
      " [-0.56536961 -0.16243994]]\n",
      "cost:\n",
      "0.219639\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867 -0.26179933]\n",
      " [-0.95993089  0.17453289]\n",
      " [ 0.34906578  0.26179933]\n",
      " [ 1.22173022  0.        ]\n",
      " [ 0.69813156  0.        ]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [-1.13446378 -0.26179933]\n",
      " [-0.87266444 -0.34906578]\n",
      " [-0.26179933 -0.43633222]\n",
      " [-0.95993089  0.34906578]]\n",
      "prediction:\n",
      "[[-0.38669473 -0.24066564]\n",
      " [-0.93650067  0.19296122]\n",
      " [ 0.40830117  0.27338722]\n",
      " [ 0.99935418  0.04436223]\n",
      " [ 0.96904254  0.03552405]\n",
      " [ 0.18695226 -0.1699459 ]\n",
      " [-0.96354389 -0.22909532]\n",
      " [-0.82183206 -0.31635469]\n",
      " [-0.19811006 -0.41506979]\n",
      " [-0.87305474  0.33476239]]\n",
      "cost:\n",
      "0.121813\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511  0.17453289]\n",
      " [-1.22173022  0.        ]\n",
      " [-0.08726644  0.26179933]\n",
      " [ 1.22173022 -0.34906578]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [-0.17453289 -0.08726644]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [-0.61086511  0.08726644]]\n",
      "prediction:\n",
      "[[  5.71732759e-01   2.59182513e-01]\n",
      " [ -9.99879837e-01   1.40815973e-04]\n",
      " [ -3.11429501e-02   4.11209077e-01]\n",
      " [  8.10919464e-01  -4.32621449e-01]\n",
      " [  9.08531249e-01  -3.41638476e-01]\n",
      " [  7.66977012e-01  -2.11538941e-01]\n",
      " [ -1.02149405e-01  -1.09027483e-01]\n",
      " [  5.43626189e-01  -1.01303384e-01]\n",
      " [  7.32587814e-01  -1.09642021e-01]\n",
      " [ -7.49035776e-01   9.96925384e-02]]\n",
      "cost:\n",
      "0.184147\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.26179933  0.26179933]\n",
      " [-0.785398    0.        ]\n",
      " [-0.52359867  0.        ]\n",
      " [ 0.          0.17453289]\n",
      " [-0.87266444 -0.08726644]\n",
      " [-0.08726644 -0.43633222]\n",
      " [-0.69813156  0.34906578]\n",
      " [ 0.52359867 -0.08726644]\n",
      " [-0.34906578 -0.34906578]\n",
      " [ 0.785398   -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.21417953  0.2847262 ]\n",
      " [-0.94725955 -0.00744421]\n",
      " [-0.55016172 -0.01654134]\n",
      " [-0.05695254  0.18922259]\n",
      " [-0.97656184 -0.10122985]\n",
      " [ 0.00178135 -0.41610199]\n",
      " [-0.71922076  0.32326549]\n",
      " [ 0.81919605 -0.08611268]\n",
      " [-0.31016049 -0.34667569]\n",
      " [ 0.99973023 -0.33595642]]\n",
      "cost:\n",
      "0.108378\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867 -0.17453289]\n",
      " [-1.22173022  0.26179933]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [-0.95993089  0.34906578]\n",
      " [-0.95993089 -0.34906578]\n",
      " [-0.26179933 -0.17453289]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [-0.34906578 -0.43633222]\n",
      " [-0.34906578  0.08726644]\n",
      " [ 0.17453289  0.        ]]\n",
      "prediction:\n",
      "[[-0.48722315 -0.15847309]\n",
      " [-0.93240029  0.30998552]\n",
      " [ 0.24226896 -0.13396667]\n",
      " [-0.77835715  0.40550837]\n",
      " [-0.89647335 -0.31602347]\n",
      " [-0.22947431 -0.1530564 ]\n",
      " [ 0.99988657 -0.22262074]\n",
      " [-0.35143214 -0.39255008]\n",
      " [-0.29216507  0.1159799 ]\n",
      " [ 0.32757711  0.04769997]]\n",
      "cost:\n",
      "0.12847\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289 -0.43633222]\n",
      " [ 0.08726644 -0.34906578]\n",
      " [-0.52359867  0.34906578]\n",
      " [ 0.61086511 -0.26179933]\n",
      " [ 0.          0.26179933]\n",
      " [ 0.43633222  0.26179933]\n",
      " [ 1.04719733  0.34906578]\n",
      " [-0.87266444 -0.26179933]\n",
      " [-0.08726644  0.17453289]\n",
      " [-0.26179933 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.06517915 -0.36205351]\n",
      " [-0.01953833 -0.29766047]\n",
      " [-0.72242558  0.27176446]\n",
      " [ 0.67793036 -0.23494984]\n",
      " [-0.06424089  0.19894247]\n",
      " [ 0.39927819  0.17478283]\n",
      " [ 0.99894553  0.22911994]\n",
      " [-0.99907738 -0.1832713 ]\n",
      " [-0.10795151  0.1147386 ]\n",
      " [-0.34831333 -0.35429433]]\n",
      "cost:\n",
      "0.118135\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733 -0.26179933]\n",
      " [-1.04719733  0.17453289]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [ 1.22173022  0.26179933]\n",
      " [ 0.17453289 -0.26179933]\n",
      " [-0.69813156  0.        ]\n",
      " [-0.08726644  0.08726644]\n",
      " [-1.13446378  0.34906578]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [ 1.22173022 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.95106173 -0.29124105]\n",
      " [-0.97346234  0.17619415]\n",
      " [ 0.34146255 -0.27359796]\n",
      " [ 0.99275237  0.28795388]\n",
      " [ 0.17779656 -0.26434952]\n",
      " [-0.66539431  0.02115995]\n",
      " [-0.18750027  0.11507615]\n",
      " [-0.97676408  0.35904112]\n",
      " [ 0.56854832 -0.37992084]\n",
      " [ 0.99458951 -0.19675623]]\n",
      "cost:\n",
      "0.10067\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644 -0.34906578]\n",
      " [ 0.         -0.08726644]\n",
      " [ 1.04719733 -0.43633222]\n",
      " [ 0.69813156 -0.43633222]\n",
      " [ 0.52359867  0.17453289]\n",
      " [-0.785398   -0.34906578]\n",
      " [ 1.04719733 -0.26179933]\n",
      " [ 1.13446378  0.        ]\n",
      " [-0.08726644 -0.08726644]\n",
      " [ 0.08726644 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.01513011 -0.21349195]\n",
      " [-0.01014782 -0.00357954]\n",
      " [ 0.86787838 -0.26181147]\n",
      " [ 0.50789368 -0.2861858 ]\n",
      " [ 0.46045002  0.51466918]\n",
      " [-0.99991441 -0.16129687]\n",
      " [ 0.88478947 -0.11944013]\n",
      " [ 0.83802122  0.24208315]\n",
      " [-0.18013863  0.03732428]\n",
      " [-0.03266001 -0.27815694]]\n",
      "cost:\n",
      "0.23304\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733  0.08726644]\n",
      " [-0.43633222  0.        ]\n",
      " [ 0.26179933 -0.08726644]\n",
      " [ 0.95993089 -0.26179933]\n",
      " [-1.22173022 -0.43633222]\n",
      " [-0.69813156  0.17453289]\n",
      " [ 0.61086511  0.17453289]\n",
      " [ 1.22173022  0.17453289]\n",
      " [-0.69813156 -0.17453289]\n",
      " [ 0.52359867 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.9463293   0.10277939]\n",
      " [-0.5198797   0.00919638]\n",
      " [ 0.23069811 -0.06295225]\n",
      " [ 0.94665062 -0.31626168]\n",
      " [-0.99867862 -0.47323236]\n",
      " [-0.9385522   0.25482431]\n",
      " [ 0.59643853  0.26295894]\n",
      " [ 0.97727358  0.21729998]\n",
      " [-0.91540301 -0.19061475]\n",
      " [ 0.52474523 -0.28259668]]\n",
      "cost:\n",
      "0.133766\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933 -0.08726644]\n",
      " [-0.61086511 -0.43633222]\n",
      " [-0.52359867  0.        ]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [-0.08726644  0.26179933]\n",
      " [ 1.13446378  0.34906578]\n",
      " [ 1.22173022  0.08726644]\n",
      " [-0.17453289 -0.34906578]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [-0.08726644  0.34906578]]\n",
      "prediction:\n",
      "[[-0.26173821 -0.08646729]\n",
      " [-0.99929392 -0.44087023]\n",
      " [-0.94321305 -0.00138172]\n",
      " [ 0.66822183 -0.16389586]\n",
      " [-0.07867782  0.20891146]\n",
      " [ 0.98514736  0.25875139]\n",
      " [ 0.98476261  0.04438248]\n",
      " [-0.20666452 -0.34075359]\n",
      " [ 0.43988642 -0.26232436]\n",
      " [-0.04334113  0.27104938]]\n",
      "cost:\n",
      "0.143584\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933  0.26179933]\n",
      " [-1.13446378  0.        ]\n",
      " [ 0.69813156  0.26179933]\n",
      " [-0.785398    0.26179933]\n",
      " [-0.61086511  0.08726644]\n",
      " [-0.52359867 -0.08726644]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [-0.26179933 -0.08726644]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [ 0.52359867  0.17453289]]\n",
      "prediction:\n",
      "[[-0.14555317  0.20968683]\n",
      " [-0.99910164 -0.08260656]\n",
      " [ 0.75654399  0.2049842 ]\n",
      " [-0.87536508  0.18309583]\n",
      " [-0.62223762  0.02298374]\n",
      " [-0.48818412 -0.17916416]\n",
      " [ 0.99251765 -0.56853706]\n",
      " [-0.14983657 -0.16022468]\n",
      " [ 0.98056704 -0.20651302]\n",
      " [ 0.49943954  0.130338  ]]\n",
      "cost:\n",
      "0.135428\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.22173022 -0.26179933]\n",
      " [ 1.13446378  0.34906578]\n",
      " [-1.22173022 -0.26179933]\n",
      " [-1.22173022  0.26179933]\n",
      " [-0.26179933 -0.34906578]\n",
      " [ 0.52359867 -0.17453289]\n",
      " [ 0.26179933 -0.43633222]\n",
      " [ 1.04719733  0.17453289]\n",
      " [-0.34906578 -0.26179933]\n",
      " [ 1.22173022 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.92634153 -0.14098856]\n",
      " [ 0.89667362  0.36301789]\n",
      " [-0.99702859 -0.13262685]\n",
      " [-0.99763364  0.3441827 ]\n",
      " [-0.21637432 -0.24281019]\n",
      " [ 0.56808674 -0.12386007]\n",
      " [ 0.36274257 -0.33906907]\n",
      " [ 0.95353585  0.22442164]\n",
      " [-0.3738839  -0.15392867]\n",
      " [ 0.79876012 -0.27856296]]\n",
      "cost:\n",
      "0.204669\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867 -0.34906578]\n",
      " [ 1.22173022  0.26179933]\n",
      " [-1.04719733  0.08726644]\n",
      " [-0.52359867  0.26179933]\n",
      " [ 1.13446378 -0.34906578]\n",
      " [ 1.13446378  0.08726644]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [ 0.95993089  0.34906578]\n",
      " [-0.61086511  0.26179933]\n",
      " [ 0.17453289  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.54977256 -0.44601414]\n",
      " [ 0.86548066  0.1221391 ]\n",
      " [-0.99986082 -0.02071382]\n",
      " [-0.62486649  0.13033894]\n",
      " [ 0.85136318 -0.44357303]\n",
      " [ 0.91841519 -0.01288024]\n",
      " [ 0.40619531 -0.25569502]\n",
      " [ 0.79520351  0.2267608 ]\n",
      " [-0.80483949  0.12836137]\n",
      " [ 0.18194383  0.16188774]]\n",
      "cost:\n",
      "0.194354\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511 -0.34906578]\n",
      " [ 0.08726644 -0.43633222]\n",
      " [ 0.34906578  0.17453289]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [-0.52359867  0.34906578]\n",
      " [-0.87266444 -0.34906578]\n",
      " [ 0.          0.34906578]\n",
      " [ 0.17453289 -0.43633222]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [ 0.17453289 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.77294677 -0.23195516]\n",
      " [-0.01653149 -0.31831732]\n",
      " [ 0.36158755  0.19731823]\n",
      " [ 0.79229146 -0.02646996]\n",
      " [-0.59559876  0.31770727]\n",
      " [-0.99910301 -0.23499802]\n",
      " [-0.08845921  0.35484877]\n",
      " [ 0.10421696 -0.29671383]\n",
      " [ 0.99903917 -0.12194084]\n",
      " [ 0.15836452 -0.09644214]]\n",
      "cost:\n",
      "0.137683\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.17453289]\n",
      " [ 0.17453289 -0.43633222]\n",
      " [-0.34906578 -0.43633222]\n",
      " [-0.69813156 -0.08726644]\n",
      " [-0.69813156 -0.08726644]\n",
      " [-0.08726644 -0.43633222]\n",
      " [ 1.04719733 -0.26179933]\n",
      " [ 0.95993089 -0.34906578]\n",
      " [-0.52359867  0.08726644]\n",
      " [-0.95993089  0.34906578]]\n",
      "prediction:\n",
      "[[-0.98646712 -0.0232161 ]\n",
      " [ 0.20952228 -0.26049843]\n",
      " [-0.36683536 -0.26419404]\n",
      " [-0.67696035  0.00741873]\n",
      " [-0.67696035  0.00741873]\n",
      " [-0.09303793 -0.29583749]\n",
      " [ 0.99846298 -0.10854586]\n",
      " [ 0.99428356 -0.18496503]\n",
      " [-0.52568257  0.19167121]\n",
      " [-0.93040681  0.50161839]]\n",
      "cost:\n",
      "0.148694\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444 -0.26179933]\n",
      " [-0.34906578 -0.17453289]\n",
      " [-0.785398   -0.34906578]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [-0.785398   -0.08726644]\n",
      " [-0.08726644  0.        ]\n",
      " [-0.52359867  0.08726644]\n",
      " [ 0.26179933  0.34906578]\n",
      " [ 0.52359867  0.34906578]\n",
      " [-1.04719733 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.99975276 -0.30427858]\n",
      " [-0.34497669 -0.18106174]\n",
      " [-0.83927733 -0.39124137]\n",
      " [ 0.43585473 -0.09934939]\n",
      " [-0.82827687 -0.07784975]\n",
      " [-0.09260254  0.0217043 ]\n",
      " [-0.48155788  0.09798709]\n",
      " [ 0.23806019  0.3722192 ]\n",
      " [ 0.6621381   0.34837013]\n",
      " [-0.99264389 -0.18426748]]\n",
      "cost:\n",
      "0.0558974\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444 -0.34906578]\n",
      " [-0.785398   -0.26179933]\n",
      " [ 0.785398   -0.43633222]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [-0.785398   -0.43633222]\n",
      " [ 0.87266444  0.34906578]\n",
      " [-0.52359867  0.17453289]\n",
      " [-0.785398    0.17453289]\n",
      " [ 0.95993089 -0.34906578]\n",
      " [-1.22173022  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.96121281 -0.24669586]\n",
      " [-0.8668527  -0.16872421]\n",
      " [ 0.86442977 -0.31539744]\n",
      " [ 0.11995637 -0.13512892]\n",
      " [-0.7881304  -0.30954939]\n",
      " [ 0.93862116  0.31616962]\n",
      " [-0.585302    0.18624285]\n",
      " [-0.92420053  0.18206099]\n",
      " [ 0.98996741 -0.25118327]\n",
      " [-0.99721187  0.31653526]]\n",
      "cost:\n",
      "0.118628\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444  0.08726644]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [-1.22173022 -0.43633222]\n",
      " [ 0.26179933  0.        ]\n",
      " [-1.04719733  0.        ]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [ 1.04719733  0.17453289]\n",
      " [ 0.          0.34906578]\n",
      " [-0.43633222  0.26179933]\n",
      " [ 0.785398    0.26179933]]\n",
      "prediction:\n",
      "[[-0.92971551  0.02074588]\n",
      " [ 0.08357506 -0.2216361 ]\n",
      " [-0.9722352  -0.46047026]\n",
      " [ 0.3119939  -0.04971719]\n",
      " [-0.98314637 -0.08182923]\n",
      " [ 0.48378855 -0.40669027]\n",
      " [ 0.9994477   0.13597225]\n",
      " [-0.03057146  0.24894397]\n",
      " [-0.4129326   0.1927444 ]\n",
      " [ 0.89078003  0.19560724]]\n",
      "cost:\n",
      "0.0993564\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444 -0.08726644]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [-0.61086511  0.        ]\n",
      " [-0.785398   -0.08726644]\n",
      " [ 0.785398   -0.17453289]\n",
      " [-0.95993089 -0.26179933]\n",
      " [-0.61086511 -0.17453289]\n",
      " [ 0.785398    0.        ]\n",
      " [ 0.69813156  0.17453289]\n",
      " [ 0.26179933  0.        ]]\n",
      "prediction:\n",
      "[[-0.9794277  -0.05783357]\n",
      " [ 0.99249113 -0.08099227]\n",
      " [-0.56694424  0.05884321]\n",
      " [-0.89533722 -0.06455572]\n",
      " [ 0.95226485 -0.2405486 ]\n",
      " [-0.99407113 -0.46471792]\n",
      " [-0.65147924 -0.22133057]\n",
      " [ 0.92211336  0.03138655]\n",
      " [ 0.88370144  0.49172592]\n",
      " [ 0.29332408  0.07631749]]\n",
      "cost:\n",
      "0.136711\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933  0.34906578]\n",
      " [ 0.52359867  0.08726644]\n",
      " [-0.95993089 -0.43633222]\n",
      " [ 0.95993089 -0.43633222]\n",
      " [-0.17453289  0.34906578]\n",
      " [ 0.34906578  0.34906578]\n",
      " [ 0.26179933 -0.43633222]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [ 1.22173022  0.        ]\n",
      " [ 0.87266444  0.17453289]]\n",
      "prediction:\n",
      "[[-0.34787947  0.23199311]\n",
      " [ 0.38751206  0.03480247]\n",
      " [-0.99993098 -0.36183566]\n",
      " [ 0.88128334 -0.36620519]\n",
      " [-0.26513419  0.21901689]\n",
      " [ 0.21721403  0.2257123 ]\n",
      " [ 0.28046846 -0.35965419]\n",
      " [ 0.6004709  -0.16248378]\n",
      " [ 0.85117829 -0.01684932]\n",
      " [ 0.88200933  0.09846213]]\n",
      "cost:\n",
      "0.144504\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733 -0.08726644]\n",
      " [-0.69813156 -0.43633222]\n",
      " [ 0.17453289  0.        ]\n",
      " [ 0.69813156  0.34906578]\n",
      " [-0.34906578 -0.43633222]\n",
      " [-0.61086511  0.17453289]\n",
      " [ 1.22173022 -0.08726644]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [ 0.26179933  0.        ]\n",
      " [ 0.43633222  0.34906578]]\n",
      "prediction:\n",
      "[[ -9.98118937e-01  -7.12347552e-02]\n",
      " [ -8.85020554e-01  -3.73151958e-01]\n",
      " [  1.14733413e-01  -1.01674870e-02]\n",
      " [  8.08524609e-01   3.18062872e-01]\n",
      " [ -4.65119481e-01  -3.79667163e-01]\n",
      " [ -6.20833755e-01   1.58170536e-01]\n",
      " [  9.99424636e-01  -9.63183120e-02]\n",
      " [ -3.90821248e-02  -2.31421396e-01]\n",
      " [  2.53586411e-01  -2.00897455e-04]\n",
      " [  3.80127728e-01   3.33007067e-01]]\n",
      "cost:\n",
      "0.0991648\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511  0.08726644]\n",
      " [-0.87266444  0.08726644]\n",
      " [-0.95993089 -0.26179933]\n",
      " [-0.17453289 -0.26179933]\n",
      " [ 0.95993089 -0.34906578]\n",
      " [-1.04719733  0.34906578]\n",
      " [-0.43633222  0.17453289]\n",
      " [-1.22173022 -0.08726644]\n",
      " [-0.34906578  0.26179933]\n",
      " [ 0.17453289  0.        ]]\n",
      "prediction:\n",
      "[[-0.47147539  0.07675503]\n",
      " [-0.74689722  0.05014974]\n",
      " [-0.86433887 -0.3475188 ]\n",
      " [-0.19289525 -0.31590968]\n",
      " [ 0.99993908 -0.42614537]\n",
      " [-0.83294547  0.29218107]\n",
      " [-0.42144108  0.16206665]\n",
      " [-0.72831374 -0.09816968]\n",
      " [-0.34035888  0.25818765]\n",
      " [ 0.49859712 -0.0171741 ]]\n",
      "cost:\n",
      "0.161187\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378  0.08726644]\n",
      " [ 0.43633222  0.08726644]\n",
      " [ 0.52359867  0.26179933]\n",
      " [ 0.08726644  0.        ]\n",
      " [-0.26179933  0.34906578]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [-0.95993089  0.17453289]\n",
      " [-0.87266444  0.08726644]\n",
      " [-0.52359867 -0.17453289]\n",
      " [-0.34906578 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.99968308  0.01185195]\n",
      " [ 0.31699738  0.03684348]\n",
      " [ 0.52792382  0.23526132]\n",
      " [-0.12412956 -0.05899403]\n",
      " [-0.23718439  0.35520583]\n",
      " [ 0.42778918 -0.40843853]\n",
      " [-0.99411774  0.10310917]\n",
      " [-0.96744859  0.01187272]\n",
      " [-0.37897515 -0.28890806]\n",
      " [-0.22767019 -0.39294153]]\n",
      "cost:\n",
      "0.1266\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933 -0.26179933]\n",
      " [ 1.22173022  0.        ]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [-1.22173022  0.        ]\n",
      " [ 0.61086511 -0.34906578]\n",
      " [-0.34906578 -0.34906578]\n",
      " [-0.26179933 -0.17453289]\n",
      " [ 1.22173022  0.08726644]\n",
      " [-0.26179933  0.08726644]\n",
      " [ 0.17453289  0.34906578]]\n",
      "prediction:\n",
      "[[-0.25658876 -0.22764555]\n",
      " [ 0.9684822   0.0269777 ]\n",
      " [ 0.198752   -0.15277544]\n",
      " [-0.99981129  0.05387657]\n",
      " [ 0.59298366 -0.36255389]\n",
      " [-0.38095653 -0.34504753]\n",
      " [-0.26126677 -0.14575742]\n",
      " [ 0.98499     0.16012774]\n",
      " [-0.25689569  0.153439  ]\n",
      " [ 0.22063859  0.46775362]]\n",
      "cost:\n",
      "0.110899\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156  0.08726644]\n",
      " [ 1.22173022  0.26179933]\n",
      " [-0.52359867  0.26179933]\n",
      " [-0.08726644 -0.26179933]\n",
      " [ 1.04719733 -0.34906578]\n",
      " [-0.52359867  0.34906578]\n",
      " [ 0.08726644 -0.43633222]\n",
      " [ 0.43633222  0.08726644]\n",
      " [ 0.785398   -0.08726644]\n",
      " [-0.95993089  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.64869589  0.03229874]\n",
      " [ 0.94826519  0.18268345]\n",
      " [-0.55867422  0.21566409]\n",
      " [-0.05533905 -0.26380166]\n",
      " [ 0.93409896 -0.394416  ]\n",
      " [-0.5771656   0.29135874]\n",
      " [ 0.13177955 -0.45241424]\n",
      " [ 0.40010676  0.0550369 ]\n",
      " [ 0.81707358 -0.12917881]\n",
      " [-0.999879    0.12288616]]\n",
      "cost:\n",
      "0.0862787\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398   -0.34906578]\n",
      " [-0.43633222 -0.26179933]\n",
      " [ 1.04719733 -0.43633222]\n",
      " [ 0.34906578  0.08726644]\n",
      " [ 0.         -0.26179933]\n",
      " [ 1.04719733 -0.26179933]\n",
      " [-0.17453289  0.34906578]\n",
      " [-0.61086511 -0.08726644]\n",
      " [ 0.87266444  0.08726644]\n",
      " [ 1.04719733 -0.34906578]]\n",
      "prediction:\n",
      "[[  7.64020860e-01  -2.41575524e-01]\n",
      " [ -8.65798056e-01  -1.83057219e-01]\n",
      " [  8.61869454e-01  -3.22060078e-01]\n",
      " [  2.89451629e-01   2.23414153e-01]\n",
      " [  1.06917337e-01  -2.20650956e-01]\n",
      " [  8.30796540e-01  -1.56243756e-01]\n",
      " [ -2.36835614e-01   4.72683251e-01]\n",
      " [ -9.99884784e-01   4.40984935e-04]\n",
      " [  7.17354774e-01   2.13029295e-01]\n",
      " [  8.91890049e-01  -2.44345412e-01]]\n",
      "cost:\n",
      "0.219228\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.         -0.43633222]\n",
      " [-0.26179933 -0.17453289]\n",
      " [-0.08726644 -0.34906578]\n",
      " [ 0.17453289 -0.26179933]\n",
      " [ 0.08726644  0.08726644]\n",
      " [-0.26179933 -0.08726644]\n",
      " [-0.34906578 -0.17453289]\n",
      " [-1.22173022  0.34906578]\n",
      " [-0.34906578  0.        ]\n",
      " [-1.13446378  0.        ]]\n",
      "prediction:\n",
      "[[ 0.70965767 -0.41305861]\n",
      " [-0.17125182 -0.11262444]\n",
      " [ 0.25748476 -0.31672332]\n",
      " [ 0.9979229  -0.19946505]\n",
      " [ 0.86372513  0.16783923]\n",
      " [ 0.12192385 -0.02960643]\n",
      " [-0.08096979 -0.1024962 ]\n",
      " [-0.98188061  0.46025679]\n",
      " [-0.00190362  0.05995364]\n",
      " [-0.99841875  0.07955471]]\n",
      "cost:\n",
      "0.421227\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.34906578]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [ 0.         -0.17453289]\n",
      " [ 0.17453289 -0.43633222]\n",
      " [-0.785398    0.34906578]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [-1.13446378 -0.08726644]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [-0.17453289 -0.26179933]\n",
      " [-0.08726644 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.99002099 -0.21355864]\n",
      " [ 0.96197933 -0.02264658]\n",
      " [-0.03879593 -0.05728303]\n",
      " [ 0.20511597 -0.2860817 ]\n",
      " [-0.68849456  0.54904795]\n",
      " [ 0.35267463 -0.11591514]\n",
      " [-0.98853666  0.04776307]\n",
      " [ 0.99892092  0.023728  ]\n",
      " [-0.25423485 -0.13010369]\n",
      " [-0.15036941 -0.30045035]]\n",
      "cost:\n",
      "0.181816\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089 -0.34906578]\n",
      " [-0.17453289 -0.17453289]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [-0.95993089 -0.34906578]\n",
      " [ 0.17453289  0.34906578]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [-0.26179933 -0.17453289]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [-0.69813156  0.34906578]\n",
      " [ 0.43633222  0.17453289]]\n",
      "prediction:\n",
      "[[-0.98991108 -0.32554287]\n",
      " [-0.23891315 -0.1371689 ]\n",
      " [ 0.99890798 -0.18875524]\n",
      " [-0.98991108 -0.32554287]\n",
      " [ 0.28209847  0.36845988]\n",
      " [ 0.59674597 -0.19869471]\n",
      " [-0.35889199 -0.1361336 ]\n",
      " [ 0.15737714 -0.12501271]\n",
      " [-0.72428644  0.33628795]\n",
      " [ 0.94129944  0.22867721]]\n",
      "cost:\n",
      "0.18089\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511 -0.17453289]\n",
      " [-0.87266444  0.08726644]\n",
      " [ 0.08726644 -0.43633222]\n",
      " [ 0.785398    0.34906578]\n",
      " [-1.22173022 -0.34906578]\n",
      " [-0.17453289 -0.34906578]\n",
      " [ 0.26179933  0.26179933]\n",
      " [-0.34906578 -0.08726644]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [-1.13446378 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.9717713  -0.13446422]\n",
      " [-0.91544735  0.12881745]\n",
      " [ 0.08616928 -0.38366809]\n",
      " [ 0.99908602  0.38999733]\n",
      " [-0.97303921 -0.27381092]\n",
      " [-0.18774296 -0.29042339]\n",
      " [ 0.26441008  0.32847533]\n",
      " [-0.42521384 -0.03389943]\n",
      " [ 0.29190969 -0.12461142]\n",
      " [-0.98523682 -0.05436289]]\n",
      "cost:\n",
      "0.138378\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156 -0.26179933]\n",
      " [ 1.22173022 -0.34906578]\n",
      " [-0.69813156 -0.34906578]\n",
      " [ 0.34906578 -0.34906578]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [-0.785398   -0.43633222]\n",
      " [ 0.         -0.34906578]\n",
      " [-1.04719733  0.26179933]\n",
      " [-0.69813156 -0.26179933]\n",
      " [ 0.95993089 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.69726288 -0.04787939]\n",
      " [ 0.99813175 -0.10292362]\n",
      " [-0.72999251 -0.13585748]\n",
      " [ 0.33137384 -0.14220269]\n",
      " [ 0.06906527 -0.06239999]\n",
      " [-0.84300059 -0.23969893]\n",
      " [-0.02579456 -0.18259893]\n",
      " [-0.99449539  0.61877298]\n",
      " [-0.69794321 -0.0484519 ]\n",
      " [ 0.99265575 -0.15790004]]\n",
      "cost:\n",
      "0.231137\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378  0.08726644]\n",
      " [ 0.26179933  0.34906578]\n",
      " [ 1.04719733 -0.43633222]\n",
      " [-0.95993089 -0.26179933]\n",
      " [-0.87266444  0.26179933]\n",
      " [ 1.13446378  0.08726644]\n",
      " [-1.22173022  0.        ]\n",
      " [ 1.22173022  0.34906578]\n",
      " [ 0.34906578  0.08726644]\n",
      " [ 1.22173022 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.98462373  0.05159183]\n",
      " [ 0.40845889  0.28295383]\n",
      " [ 0.90547341 -0.43731752]\n",
      " [-0.97023344 -0.292757  ]\n",
      " [-0.92892051  0.22399735]\n",
      " [ 0.9877038   0.04285091]\n",
      " [-0.98040438 -0.06265815]\n",
      " [ 0.93753147  0.25883991]\n",
      " [ 0.49601594  0.02918425]\n",
      " [ 0.9159745  -0.41477686]]\n",
      "cost:\n",
      "0.17224\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733 -0.08726644]\n",
      " [-0.785398    0.        ]\n",
      " [-0.43633222 -0.08726644]\n",
      " [-0.87266444 -0.17453289]\n",
      " [ 1.13446378  0.        ]\n",
      " [-0.08726644  0.08726644]\n",
      " [-1.04719733 -0.17453289]\n",
      " [ 1.04719733  0.        ]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [-0.43633222 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.97170991 -0.02279915]\n",
      " [-0.78783858  0.12767924]\n",
      " [-0.46654415 -0.04489388]\n",
      " [-0.89409757 -0.19640519]\n",
      " [ 0.9918099   0.21572357]\n",
      " [-0.05021213  0.40488058]\n",
      " [-0.97479773 -0.18241282]\n",
      " [ 0.9803583   0.15449734]\n",
      " [ 0.99051732 -0.31482393]\n",
      " [-0.48228908 -0.46375537]]\n",
      "cost:\n",
      "0.140615\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.          0.        ]\n",
      " [-1.04719733 -0.08726644]\n",
      " [-0.785398    0.26179933]\n",
      " [ 0.52359867 -0.08726644]\n",
      " [-1.13446378 -0.26179933]\n",
      " [-0.08726644 -0.43633222]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [ 0.17453289  0.08726644]\n",
      " [-0.43633222 -0.17453289]\n",
      " [-1.04719733 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.12962045  0.06819896]\n",
      " [-0.93277675  0.00105375]\n",
      " [-0.58350366  0.49007371]\n",
      " [ 0.76072997 -0.02435605]\n",
      " [-0.9330126  -0.15922351]\n",
      " [-0.12801787 -0.34814113]\n",
      " [ 0.99988216 -0.32292262]\n",
      " [ 0.15658808  0.22518714]\n",
      " [-0.45666337 -0.12011173]\n",
      " [-0.88273782 -0.18036765]]\n",
      "cost:\n",
      "0.171543\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.17453289]\n",
      " [ 1.22173022  0.34906578]\n",
      " [ 0.17453289  0.26179933]\n",
      " [-1.13446378  0.26179933]\n",
      " [-0.785398    0.        ]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [-0.95993089  0.17453289]\n",
      " [ 1.04719733  0.        ]\n",
      " [-0.95993089  0.17453289]\n",
      " [-0.785398   -0.17453289]]\n",
      "prediction:\n",
      "[[-0.92441022 -0.26862913]\n",
      " [ 0.99700147  0.25735128]\n",
      " [ 0.08688659  0.22634318]\n",
      " [-0.90342277  0.18517871]\n",
      " [-0.72280276 -0.03373688]\n",
      " [ 0.51648283 -0.52885866]\n",
      " [-0.858235    0.11255359]\n",
      " [ 0.99813813 -0.07574438]\n",
      " [-0.85824746  0.11254229]\n",
      " [-0.74426889 -0.25222632]]\n",
      "cost:\n",
      "0.147823\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511 -0.43633222]\n",
      " [ 1.22173022  0.17453289]\n",
      " [-0.08726644 -0.17453289]\n",
      " [-0.95993089 -0.26179933]\n",
      " [-0.17453289  0.26179933]\n",
      " [-1.04719733 -0.26179933]\n",
      " [-1.22173022  0.34906578]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [-0.08726644 -0.17453289]\n",
      " [-0.08726644 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.65844178 -0.35962775]\n",
      " [ 0.99955052  0.25868908]\n",
      " [-0.08799409 -0.14332922]\n",
      " [-0.96726322 -0.21815567]\n",
      " [-0.21576628  0.32987064]\n",
      " [-0.97642362 -0.20815259]\n",
      " [-0.95053446  0.37278283]\n",
      " [ 0.90133792 -0.18681724]\n",
      " [-0.08799388 -0.14334916]\n",
      " [-0.07314892 -0.06465518]]\n",
      "cost:\n",
      "0.111839\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156 -0.26179933]\n",
      " [-0.95993089 -0.17453289]\n",
      " [ 0.61086511  0.34906578]\n",
      " [-0.785398   -0.34906578]\n",
      " [-1.22173022 -0.43633222]\n",
      " [ 0.87266444  0.        ]\n",
      " [-0.52359867  0.17453289]\n",
      " [-0.43633222  0.        ]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [ 0.34906578  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.93094444 -0.21564205]\n",
      " [-0.99108958 -0.1081477 ]\n",
      " [ 0.74698567  0.43629074]\n",
      " [-0.84286416 -0.2766397 ]\n",
      " [-0.9844631  -0.3169246 ]\n",
      " [ 0.99870509  0.02323594]\n",
      " [-0.47672513  0.25399774]\n",
      " [-0.45972669  0.02672206]\n",
      " [ 0.57370996 -0.31064069]\n",
      " [ 0.34704369  0.11890639]]\n",
      "cost:\n",
      "0.118121\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867 -0.43633222]\n",
      " [ 0.69813156  0.34906578]\n",
      " [ 0.52359867  0.34906578]\n",
      " [-0.08726644  0.17453289]\n",
      " [ 0.17453289  0.        ]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [-0.26179933  0.26179933]\n",
      " [ 0.52359867 -0.17453289]\n",
      " [ 0.69813156  0.26179933]\n",
      " [-0.34906578  0.17453289]]\n",
      "prediction:\n",
      "[[-0.99969327 -0.56046581]\n",
      " [ 0.93204486  0.18355931]\n",
      " [ 0.38664502  0.18492275]\n",
      " [-0.13235429  0.07216974]\n",
      " [ 0.25249535 -0.05976984]\n",
      " [ 0.94006819 -0.25762871]\n",
      " [-0.68869215  0.12676516]\n",
      " [ 0.64796352 -0.25451866]\n",
      " [ 0.96539158  0.12796627]\n",
      " [-0.91309834  0.0587566 ]]\n",
      "cost:\n",
      "0.292852\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.43633222 -0.17453289]\n",
      " [-0.69813156 -0.26179933]\n",
      " [-0.95993089 -0.17453289]\n",
      " [-0.785398    0.08726644]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [-0.34906578 -0.26179933]\n",
      " [-0.34906578  0.17453289]\n",
      " [ 0.34906578 -0.34906578]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [-1.22173022 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.46628693 -0.11756328]\n",
      " [-0.57773876 -0.17714456]\n",
      " [-0.91252416 -0.03140388]\n",
      " [-0.74643415  0.30634287]\n",
      " [ 0.99977046 -0.21244912]\n",
      " [-0.39884627 -0.19958961]\n",
      " [-0.40522847  0.49593395]\n",
      " [ 0.52277696 -0.24022469]\n",
      " [ 0.93098265 -0.23440799]\n",
      " [-0.98080051 -0.07492221]]\n",
      "cost:\n",
      "0.225503\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.43633222  0.17453289]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [ 1.04719733 -0.17453289]\n",
      " [ 0.52359867  0.34906578]\n",
      " [ 1.22173022  0.26179933]\n",
      " [ 0.785398   -0.43633222]\n",
      " [ 0.         -0.17453289]\n",
      " [-0.43633222  0.34906578]\n",
      " [-0.08726644 -0.08726644]\n",
      " [ 0.26179933  0.26179933]]\n",
      "prediction:\n",
      "[[-0.99126762  0.11468751]\n",
      " [ 0.24707605 -0.22768444]\n",
      " [ 0.98281896 -0.22483878]\n",
      " [ 0.42042282  0.23376811]\n",
      " [ 0.98014772  0.15736212]\n",
      " [ 0.80618787 -0.50666928]\n",
      " [-0.17283611 -0.20867445]\n",
      " [-0.99874455  0.24576727]\n",
      " [-0.2342211  -0.12303448]\n",
      " [ 0.27258226  0.17825529]]\n",
      "cost:\n",
      "0.216974\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089  0.        ]\n",
      " [ 0.26179933  0.34906578]\n",
      " [-0.34906578 -0.08726644]\n",
      " [ 0.69813156  0.        ]\n",
      " [-0.61086511  0.17453289]\n",
      " [-0.61086511 -0.17453289]\n",
      " [-0.08726644 -0.17453289]\n",
      " [-0.95993089 -0.17453289]\n",
      " [ 0.61086511 -0.17453289]\n",
      " [ 0.         -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.99904233  0.04939509]\n",
      " [ 0.29380852  0.47071648]\n",
      " [-0.33020428 -0.05489586]\n",
      " [ 0.79481053  0.05090212]\n",
      " [-0.67062634  0.26915857]\n",
      " [-0.66603893 -0.20704949]\n",
      " [-0.08578951 -0.17372483]\n",
      " [-0.99928933 -0.242204  ]\n",
      " [ 0.6583178  -0.21714792]\n",
      " [-0.02108479 -0.32379216]]\n",
      "cost:\n",
      "0.0720709\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867 -0.08726644]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [-0.17453289  0.17453289]\n",
      " [ 0.52359867  0.        ]\n",
      " [-0.43633222  0.34906578]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [-0.43633222 -0.17453289]\n",
      " [ 0.08726644 -0.34906578]\n",
      " [ 0.61086511 -0.34906578]\n",
      " [-0.17453289 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.99180758 -0.03708193]\n",
      " [ 0.20405926 -0.10081229]\n",
      " [-0.27315256  0.28738576]\n",
      " [ 0.64528948  0.083628  ]\n",
      " [-0.96169633  0.47181445]\n",
      " [ 0.9996919  -0.1059577 ]\n",
      " [-0.82312226 -0.12823817]\n",
      " [ 0.05935545 -0.28507465]\n",
      " [ 0.7339285  -0.28064451]\n",
      " [-0.24185213 -0.28937474]]\n",
      "cost:\n",
      "0.230987\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089  0.08726644]\n",
      " [-0.17453289 -0.43633222]\n",
      " [ 1.04719733  0.08726644]\n",
      " [-0.08726644  0.34906578]\n",
      " [ 1.04719733  0.17453289]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [ 0.785398    0.34906578]\n",
      " [ 0.08726644 -0.34906578]\n",
      " [-0.26179933 -0.17453289]\n",
      " [-0.52359867  0.26179933]]\n",
      "prediction:\n",
      "[[-0.9998194  -0.01023477]\n",
      " [-0.19718242 -0.4651283 ]\n",
      " [ 0.97646064  0.01523392]\n",
      " [-0.06679688  0.28090447]\n",
      " [ 0.98334605  0.09545474]\n",
      " [ 0.21305722 -0.11162127]\n",
      " [ 0.73692703  0.27541843]\n",
      " [ 0.08158823 -0.39031371]\n",
      " [-0.24963771 -0.19450822]\n",
      " [-0.5931195   0.19425139]]\n",
      "cost:\n",
      "0.0711445\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733  0.        ]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [ 0.87266444  0.        ]\n",
      " [-0.95993089  0.        ]\n",
      " [-0.785398   -0.34906578]\n",
      " [-1.04719733  0.        ]\n",
      " [-0.43633222 -0.26179933]\n",
      " [-0.26179933  0.17453289]\n",
      " [-0.87266444 -0.34906578]\n",
      " [ 0.08726644  0.17453289]]\n",
      "prediction:\n",
      "[[-0.7976597   0.07806627]\n",
      " [ 0.17258398 -0.07612976]\n",
      " [ 0.99995625  0.04979925]\n",
      " [-0.80537766  0.06693823]\n",
      " [-0.5950036  -0.39053646]\n",
      " [-0.7976597   0.07806627]\n",
      " [-0.41645107 -0.29184142]\n",
      " [-0.30586323  0.30088958]\n",
      " [-0.67131865 -0.39718086]\n",
      " [ 0.03193176  0.31258342]]\n",
      "cost:\n",
      "0.155979\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289 -0.08726644]\n",
      " [ 0.52359867  0.26179933]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [-0.785398   -0.17453289]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [ 0.61086511  0.26179933]\n",
      " [ 0.43633222  0.        ]\n",
      " [ 0.69813156  0.08726644]\n",
      " [ 1.13446378 -0.34906578]\n",
      " [-0.61086511  0.        ]]\n",
      "prediction:\n",
      "[[-0.19215876 -0.06644543]\n",
      " [ 0.53981775  0.34784368]\n",
      " [ 0.92210001 -0.29974505]\n",
      " [-0.99985754 -0.19251491]\n",
      " [ 0.72842407 -0.2253941 ]\n",
      " [ 0.59139097  0.33561352]\n",
      " [ 0.46936753 -0.00960759]\n",
      " [ 0.56695986  0.08182057]\n",
      " [ 0.94494402 -0.42241055]\n",
      " [-0.94334692  0.02623668]]\n",
      "cost:\n",
      "0.156378\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289 -0.26179933]\n",
      " [ 0.17453289 -0.34906578]\n",
      " [ 1.04719733 -0.26179933]\n",
      " [ 0.87266444  0.17453289]\n",
      " [ 0.87266444  0.34906578]\n",
      " [-0.61086511 -0.43633222]\n",
      " [ 1.04719733  0.34906578]\n",
      " [ 1.13446378 -0.08726644]\n",
      " [ 0.          0.08726644]\n",
      " [ 0.08726644 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.24138436 -0.22619072]\n",
      " [ 0.18785556 -0.31650046]\n",
      " [ 0.73800492 -0.26070711]\n",
      " [ 0.66279197  0.16357322]\n",
      " [ 0.61768591  0.32301405]\n",
      " [-0.99995685 -0.40083861]\n",
      " [ 0.74669307  0.31970599]\n",
      " [ 0.89397877 -0.08845811]\n",
      " [-0.05175052  0.11739038]\n",
      " [ 0.07400603 -0.06026149]]\n",
      "cost:\n",
      "0.190968\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578 -0.43633222]\n",
      " [-1.22173022  0.08726644]\n",
      " [ 1.13446378  0.34906578]\n",
      " [-0.17453289  0.08726644]\n",
      " [-1.22173022  0.08726644]\n",
      " [-0.95993089 -0.43633222]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [ 0.26179933 -0.08726644]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [ 1.13446378 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.44189057 -0.34658736]\n",
      " [-0.9794566   0.1594765 ]\n",
      " [ 0.99585783  0.45687237]\n",
      " [-0.22822531  0.11236906]\n",
      " [-0.97944069  0.15952614]\n",
      " [-0.95051283 -0.34983599]\n",
      " [ 0.26993084 -0.19783252]\n",
      " [ 0.19968215 -0.03701464]\n",
      " [ 0.26993084 -0.19783252]\n",
      " [ 0.99689639 -0.17263213]]\n",
      "cost:\n",
      "0.140398\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289  0.08726644]\n",
      " [ 0.87266444  0.34906578]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [ 0.          0.34906578]\n",
      " [-0.785398   -0.43633222]\n",
      " [-0.08726644  0.08726644]\n",
      " [ 0.34906578  0.08726644]\n",
      " [-0.69813156  0.17453289]\n",
      " [ 0.785398    0.17453289]\n",
      " [-1.13446378 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.21853971  0.00743858]\n",
      " [ 0.98847657  0.22786112]\n",
      " [ 0.97216433 -0.16241913]\n",
      " [-0.00948145  0.26487604]\n",
      " [-0.89692616 -0.54347122]\n",
      " [-0.11596461  0.00736849]\n",
      " [ 0.31644908  0.00716671]\n",
      " [-0.77342463  0.0868671 ]\n",
      " [ 0.95253408  0.07928842]\n",
      " [-0.99939185 -0.35453379]]\n",
      "cost:\n",
      "0.126601\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733  0.26179933]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [-1.22173022  0.34906578]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [-0.34906578  0.17453289]\n",
      " [ 0.52359867  0.34906578]\n",
      " [-0.08726644  0.        ]\n",
      " [ 0.34906578  0.08726644]\n",
      " [ 1.22173022  0.34906578]\n",
      " [ 1.22173022 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.93624985  0.14536831]\n",
      " [ 0.42857552 -0.4854309 ]\n",
      " [-0.99993724  0.17914127]\n",
      " [ 0.07077482 -0.36258465]\n",
      " [-0.45540559  0.09995119]\n",
      " [ 0.42227829  0.22106795]\n",
      " [-0.1144575  -0.03875736]\n",
      " [ 0.27433294  0.02449532]\n",
      " [ 0.87783772  0.17105068]\n",
      " [ 0.89528543 -0.30936879]]\n",
      "cost:\n",
      "0.188707\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.43633222]\n",
      " [ 1.22173022  0.26179933]\n",
      " [ 0.52359867  0.        ]\n",
      " [-0.95993089 -0.43633222]\n",
      " [ 0.61086511  0.        ]\n",
      " [-0.69813156  0.17453289]\n",
      " [-0.34906578  0.17453289]\n",
      " [-0.69813156  0.        ]\n",
      " [ 0.34906578 -0.43633222]\n",
      " [-1.22173022  0.26179933]]\n",
      "prediction:\n",
      "[[ -8.84929538e-01  -3.58484954e-01]\n",
      " [  9.99898791e-01   2.46582180e-01]\n",
      " [  4.03135628e-01  -4.68438398e-03]\n",
      " [ -7.84582734e-01  -3.84322792e-01]\n",
      " [  5.22163272e-01   9.88363870e-04]\n",
      " [ -5.81296444e-01   1.60979003e-01]\n",
      " [ -2.61203051e-01   1.42508492e-01]\n",
      " [ -6.74298644e-01  -9.07512382e-03]\n",
      " [  4.45808738e-01  -3.93380612e-01]\n",
      " [ -9.77945149e-01   2.71090835e-01]]\n",
      "cost:\n",
      "0.146236\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444  0.17453289]\n",
      " [-0.08726644 -0.08726644]\n",
      " [-0.08726644 -0.34906578]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [-0.95993089  0.17453289]\n",
      " [ 0.43633222 -0.43633222]\n",
      " [ 0.34906578 -0.43633222]\n",
      " [-0.34906578 -0.34906578]\n",
      " [ 0.34906578  0.17453289]\n",
      " [ 0.61086511 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.97942197  0.31044239]\n",
      " [-0.0858888  -0.05428407]\n",
      " [-0.10672959 -0.26793218]\n",
      " [ 0.99954158 -0.07383118]\n",
      " [-0.99677467  0.30159223]\n",
      " [ 0.36705631 -0.27935374]\n",
      " [ 0.2791799  -0.28465143]\n",
      " [-0.40936148 -0.21476886]\n",
      " [ 0.30605209  0.34687981]\n",
      " [ 0.72728145 -0.21012469]]\n",
      "cost:\n",
      "0.137448\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.22173022  0.34906578]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [-0.95993089 -0.08726644]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [-0.52359867 -0.34906578]\n",
      " [ 0.17453289  0.        ]\n",
      " [-0.785398   -0.08726644]\n",
      " [ 1.13446378  0.08726644]\n",
      " [-1.22173022 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.84492385  0.47427881]\n",
      " [ 0.94622678 -0.04546977]\n",
      " [-0.99605602 -0.06538071]\n",
      " [ 0.94627571 -0.04545284]\n",
      " [ 0.84994054 -0.15319422]\n",
      " [-0.52644217 -0.38919589]\n",
      " [ 0.26782098  0.05402423]\n",
      " [-0.9064343  -0.04349373]\n",
      " [ 0.95306861  0.20421343]\n",
      " [-0.99516267 -0.37430906]]\n",
      "cost:\n",
      "0.140953\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089  0.17453289]\n",
      " [ 0.26179933 -0.34906578]\n",
      " [-0.69813156 -0.34906578]\n",
      " [ 0.69813156  0.26179933]\n",
      " [ 0.52359867  0.26179933]\n",
      " [-0.43633222 -0.08726644]\n",
      " [-0.69813156  0.26179933]\n",
      " [ 0.87266444  0.08726644]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [ 0.34906578  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.9576956   0.09389035]\n",
      " [ 0.29800096 -0.37252754]\n",
      " [-0.99705267 -0.34147853]\n",
      " [ 0.69304609  0.17017807]\n",
      " [ 0.54037178  0.17991613]\n",
      " [-0.56331694 -0.09311204]\n",
      " [-0.99834579  0.1942203 ]\n",
      " [ 0.91352576  0.02477401]\n",
      " [ 0.95350367 -0.41059053]\n",
      " [ 0.34937227  0.26074794]]\n",
      "cost:\n",
      "0.137879\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444 -0.34906578]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [ 0.87266444  0.        ]\n",
      " [ 0.61086511 -0.34906578]\n",
      " [-1.13446378  0.26179933]\n",
      " [ 0.69813156  0.26179933]\n",
      " [ 0.43633222 -0.34906578]\n",
      " [-0.17453289 -0.17453289]\n",
      " [-0.43633222 -0.34906578]\n",
      " [-1.13446378 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.92123085 -0.2458176 ]\n",
      " [ 0.93143356 -0.15728188]\n",
      " [ 0.99634552  0.09758651]\n",
      " [ 0.77712423 -0.24360912]\n",
      " [-0.99397892  0.38620147]\n",
      " [ 0.89868367  0.4286786 ]\n",
      " [ 0.49264866 -0.26363742]\n",
      " [-0.09176477 -0.10789397]\n",
      " [-0.51147807 -0.25350586]\n",
      " [-0.98988706 -0.04722439]]\n",
      "cost:\n",
      "0.169551\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378 -0.43633222]\n",
      " [ 1.13446378 -0.34906578]\n",
      " [-0.61086511  0.17453289]\n",
      " [ 1.13446378 -0.08726644]\n",
      " [-0.08726644 -0.43633222]\n",
      " [-0.43633222  0.08726644]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [ 0.34906578  0.17453289]\n",
      " [-0.34906578 -0.34906578]\n",
      " [-0.43633222 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.96354723 -0.25266191]\n",
      " [ 0.97375679 -0.18345301]\n",
      " [-0.99957854  0.33720943]\n",
      " [ 0.95072007  0.08249713]\n",
      " [-0.08159351 -0.33215889]\n",
      " [-0.91312706  0.20384361]\n",
      " [ 0.73765004 -0.13901554]\n",
      " [ 0.45921114  0.34863991]\n",
      " [-0.52182317 -0.23889816]\n",
      " [-0.71450627 -0.24832696]]\n",
      "cost:\n",
      "0.258413\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644  0.17453289]\n",
      " [-0.17453289 -0.17453289]\n",
      " [-1.22173022  0.17453289]\n",
      " [-1.04719733 -0.08726644]\n",
      " [-0.26179933 -0.34906578]\n",
      " [-0.34906578 -0.26179933]\n",
      " [-1.04719733  0.08726644]\n",
      " [-0.95993089 -0.26179933]\n",
      " [-0.52359867  0.17453289]\n",
      " [-0.52359867 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.99989855  0.26264957]\n",
      " [-0.11728445 -0.15048024]\n",
      " [ 0.9454329   0.24892412]\n",
      " [-0.88086361 -0.01670783]\n",
      " [-0.49465406 -0.36684924]\n",
      " [-0.66477901 -0.24276939]\n",
      " [-0.65001631  0.17004728]\n",
      " [-0.84273154 -0.2554276 ]\n",
      " [-0.40265211  0.26956117]\n",
      " [-0.87881243 -0.35081187]]\n",
      "cost:\n",
      "0.491003\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378  0.        ]\n",
      " [ 0.87266444  0.        ]\n",
      " [-0.785398    0.        ]\n",
      " [ 0.17453289  0.08726644]\n",
      " [-0.08726644  0.17453289]\n",
      " [-0.43633222 -0.08726644]\n",
      " [-0.69813156  0.17453289]\n",
      " [ 0.87266444  0.17453289]\n",
      " [-0.785398   -0.43633222]\n",
      " [ 1.13446378 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.99414378  0.01131421]\n",
      " [ 0.96538419 -0.00349145]\n",
      " [-0.99620825 -0.02064689]\n",
      " [ 0.05061638  0.10119391]\n",
      " [-0.19353396  0.18315168]\n",
      " [-0.4795759  -0.10443029]\n",
      " [-0.9188233   0.20112039]\n",
      " [ 0.90799171  0.20606726]\n",
      " [-0.98186952 -0.49706933]\n",
      " [ 0.86528254 -0.44816643]]\n",
      "cost:\n",
      "0.146795\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933  0.        ]\n",
      " [ 1.04719733  0.26179933]\n",
      " [-1.04719733 -0.08726644]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [-0.95993089 -0.26179933]\n",
      " [-0.95993089 -0.08726644]\n",
      " [-0.87266444  0.34906578]\n",
      " [ 1.04719733 -0.26179933]\n",
      " [-0.08726644  0.17453289]\n",
      " [-0.26179933  0.26179933]]\n",
      "prediction:\n",
      "[[-0.40423152 -0.03092791]\n",
      " [ 0.99236608  0.23376855]\n",
      " [-0.976511   -0.12368825]\n",
      " [ 0.98599654 -0.28563684]\n",
      " [-0.95731783 -0.35787937]\n",
      " [-0.95199782 -0.12487616]\n",
      " [-0.7850697   0.32976168]\n",
      " [ 0.99174231 -0.37630492]\n",
      " [-0.15586413  0.13655163]\n",
      " [-0.32555047  0.24376269]]\n",
      "cost:\n",
      "0.10436\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733  0.34906578]\n",
      " [ 0.26179933  0.08726644]\n",
      " [-0.87266444 -0.43633222]\n",
      " [ 0.69813156  0.17453289]\n",
      " [ 0.43633222 -0.43633222]\n",
      " [ 0.17453289  0.26179933]\n",
      " [-1.04719733 -0.43633222]\n",
      " [ 0.61086511  0.17453289]\n",
      " [-0.61086511 -0.43633222]\n",
      " [-0.52359867  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.99936533  0.31026191]\n",
      " [ 0.16113146  0.04705549]\n",
      " [-0.97037452 -0.32537338]\n",
      " [ 0.7940864   0.13158408]\n",
      " [ 0.51932341 -0.33736116]\n",
      " [ 0.10950993  0.21884832]\n",
      " [-0.99752635 -0.32271633]\n",
      " [ 0.62246442  0.13470857]\n",
      " [-0.61521786 -0.31777936]\n",
      " [-0.46211016  0.08347837]]\n",
      "cost:\n",
      "0.0975777\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398    0.17453289]\n",
      " [ 0.61086511 -0.17453289]\n",
      " [ 0.         -0.26179933]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [ 0.61086511  0.26179933]\n",
      " [-1.13446378 -0.26179933]\n",
      " [-0.08726644  0.34906578]\n",
      " [-0.08726644 -0.34906578]\n",
      " [-0.52359867  0.08726644]\n",
      " [ 1.04719733 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.91413212  0.1775758 ]\n",
      " [ 0.60081387 -0.14728172]\n",
      " [-0.01322817 -0.23617573]\n",
      " [ 0.18298845 -0.05177436]\n",
      " [ 0.55009103  0.26437357]\n",
      " [-0.99986655 -0.21958213]\n",
      " [-0.13520265  0.34092987]\n",
      " [-0.1706225  -0.3146354 ]\n",
      " [-0.58661598  0.09912375]\n",
      " [ 0.99224734 -0.39193732]]\n",
      "cost:\n",
      "0.0698604\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444  0.26179933]\n",
      " [-0.34906578  0.        ]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [-0.87266444  0.34906578]\n",
      " [-0.26179933 -0.34906578]\n",
      " [-0.43633222  0.17453289]\n",
      " [-0.61086511 -0.34906578]\n",
      " [-1.04719733 -0.17453289]\n",
      " [-0.785398    0.26179933]\n",
      " [-0.69813156  0.        ]]\n",
      "prediction:\n",
      "[[ 0.99645734  0.19452439]\n",
      " [-0.33899072  0.00226569]\n",
      " [ 0.9990778  -0.40786883]\n",
      " [-0.83434892  0.28107187]\n",
      " [-0.1561154  -0.34816381]\n",
      " [-0.35832629  0.15545245]\n",
      " [-0.54209208 -0.34057355]\n",
      " [-0.98712164 -0.20041224]\n",
      " [-0.71893311  0.20867896]\n",
      " [-0.69809735 -0.02085255]]\n",
      "cost:\n",
      "0.079425\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733 -0.26179933]\n",
      " [-0.87266444  0.08726644]\n",
      " [-0.785398   -0.34906578]\n",
      " [-1.13446378  0.        ]\n",
      " [-0.69813156 -0.17453289]\n",
      " [-0.95993089  0.08726644]\n",
      " [-1.22173022  0.26179933]\n",
      " [-0.785398   -0.08726644]\n",
      " [ 0.95993089  0.26179933]\n",
      " [ 0.17453289  0.        ]]\n",
      "prediction:\n",
      "[[ 0.99917519 -0.39891922]\n",
      " [-0.74960238  0.07896232]\n",
      " [-0.70547408 -0.48291647]\n",
      " [-0.86396188 -0.02596027]\n",
      " [-0.56752264 -0.20466337]\n",
      " [-0.82890916  0.07360051]\n",
      " [-0.92221403  0.28147501]\n",
      " [-0.64033085 -0.09551596]\n",
      " [ 0.99772304  0.29461256]\n",
      " [ 0.07106051  0.01204486]]\n",
      "cost:\n",
      "0.156173\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222 -0.34906578]\n",
      " [-0.785398   -0.26179933]\n",
      " [-0.69813156  0.08726644]\n",
      " [-1.04719733  0.        ]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [-1.04719733 -0.17453289]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [-0.08726644 -0.26179933]\n",
      " [ 0.08726644  0.        ]\n",
      " [-0.785398   -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.5001803  -0.33074805]\n",
      " [-0.74903905 -0.19327492]\n",
      " [-0.63493437  0.50350201]\n",
      " [-0.95141041  0.15543783]\n",
      " [ 0.69274771 -0.32351902]\n",
      " [-0.95316488 -0.071479  ]\n",
      " [ 0.99991179  0.01661726]\n",
      " [-0.13704035 -0.23164488]\n",
      " [ 0.08294784  0.09566922]\n",
      " [-0.71458435 -0.09903547]]\n",
      "cost:\n",
      "0.142694\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444  0.26179933]\n",
      " [ 0.34906578  0.26179933]\n",
      " [-0.52359867  0.17453289]\n",
      " [-0.785398    0.        ]\n",
      " [ 0.17453289  0.26179933]\n",
      " [-1.13446378  0.08726644]\n",
      " [-1.22173022 -0.17453289]\n",
      " [-0.17453289  0.26179933]\n",
      " [-0.87266444  0.08726644]\n",
      " [ 0.87266444  0.26179933]]\n",
      "prediction:\n",
      "[[-0.77704358  0.14571585]\n",
      " [ 0.30156964  0.12012564]\n",
      " [-0.49538058  0.04154147]\n",
      " [-0.64923048 -0.15184791]\n",
      " [ 0.12271501  0.11169189]\n",
      " [-0.86499894 -0.10753631]\n",
      " [-0.79210401 -0.62501478]\n",
      " [-0.20858681  0.12217903]\n",
      " [-0.72954494 -0.06867613]\n",
      " [ 0.99996239  0.08310537]]\n",
      "cost:\n",
      "0.232832\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.22173022 -0.34906578]\n",
      " [ 0.26179933  0.08726644]\n",
      " [-1.22173022  0.08726644]\n",
      " [ 0.785398   -0.17453289]\n",
      " [ 0.         -0.43633222]\n",
      " [-0.95993089  0.34906578]\n",
      " [ 0.26179933  0.08726644]\n",
      " [-0.95993089  0.08726644]\n",
      " [-0.26179933 -0.34906578]\n",
      " [-0.26179933  0.08726644]]\n",
      "prediction:\n",
      "[[-0.88779229 -0.30392924]\n",
      " [ 0.24075168  0.09374607]\n",
      " [-0.86579299  0.11876374]\n",
      " [ 0.99995476 -0.16722462]\n",
      " [-0.05276421 -0.40679079]\n",
      " [-0.80772376  0.37230554]\n",
      " [ 0.24077925  0.09375121]\n",
      " [-0.85158205  0.08718313]\n",
      " [-0.35010597 -0.34084368]\n",
      " [-0.31411818  0.08030484]]\n",
      "cost:\n",
      "0.141726\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644 -0.08726644]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [ 0.         -0.43633222]\n",
      " [-1.04719733 -0.08726644]\n",
      " [-0.95993089  0.17453289]\n",
      " [-0.34906578  0.08726644]\n",
      " [-0.17453289 -0.43633222]\n",
      " [ 0.87266444 -0.26179933]\n",
      " [-0.34906578 -0.43633222]\n",
      " [ 1.13446378  0.08726644]]\n",
      "prediction:\n",
      "[[-0.02326551 -0.01841912]\n",
      " [ 0.98635489 -0.0247187 ]\n",
      " [ 0.1087384  -0.34504038]\n",
      " [-0.99672556 -0.0086576 ]\n",
      " [-0.99264544  0.37658009]\n",
      " [-0.38926676  0.20053563]\n",
      " [-0.20848089 -0.32865152]\n",
      " [ 0.93151361 -0.17998222]\n",
      " [-0.40303606 -0.31499711]\n",
      " [ 0.99314749  0.26764384]]\n",
      "cost:\n",
      "0.131715\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444  0.        ]\n",
      " [-1.13446378 -0.26179933]\n",
      " [ 0.17453289  0.26179933]\n",
      " [ 0.69813156  0.17453289]\n",
      " [ 0.          0.        ]\n",
      " [ 0.08726644 -0.43633222]\n",
      " [-0.69813156  0.34906578]\n",
      " [ 1.04719733 -0.34906578]\n",
      " [ 1.04719733 -0.17453289]\n",
      " [-0.08726644 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.90144289 -0.00406987]\n",
      " [-0.99985754 -0.18793601]\n",
      " [ 0.20045659  0.30254778]\n",
      " [ 0.63754225  0.16736889]\n",
      " [ 0.02153523  0.02066941]\n",
      " [ 0.09441245 -0.35229325]\n",
      " [-0.90330112  0.37708923]\n",
      " [ 0.96466517 -0.26701346]\n",
      " [ 0.95824069 -0.13336295]\n",
      " [-0.15163156 -0.33597258]]\n",
      "cost:\n",
      "0.0946806\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222 -0.17453289]\n",
      " [-0.43633222  0.34906578]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [ 0.52359867  0.34906578]\n",
      " [-0.52359867 -0.26179933]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [ 0.95993089 -0.43633222]\n",
      " [-0.61086511 -0.26179933]\n",
      " [-0.26179933  0.17453289]\n",
      " [ 1.04719733 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.44963965 -0.14572501]\n",
      " [-0.82645822  0.3514019 ]\n",
      " [-0.11207765 -0.14753564]\n",
      " [ 0.51494086  0.35372779]\n",
      " [-0.93107456 -0.20418325]\n",
      " [ 0.07706834 -0.06270778]\n",
      " [ 0.99054557 -0.33329865]\n",
      " [-0.99854267 -0.19849938]\n",
      " [-0.38652498  0.18949226]\n",
      " [ 0.9968127  -0.33011332]]\n",
      "cost:\n",
      "0.188838\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.22173022 -0.26179933]\n",
      " [-0.08726644  0.17453289]\n",
      " [ 0.17453289  0.34906578]\n",
      " [-0.08726644  0.34906578]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [-0.61086511  0.08726644]\n",
      " [ 0.785398    0.26179933]\n",
      " [-1.04719733 -0.43633222]\n",
      " [ 0.17453289 -0.34906578]\n",
      " [-0.34906578 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.99233538 -0.24120556]\n",
      " [-0.10143172  0.12405219]\n",
      " [ 0.19869772  0.23596594]\n",
      " [-0.13281865  0.27019683]\n",
      " [ 0.99931937 -0.14108853]\n",
      " [-0.52975929  0.05477546]\n",
      " [ 0.97591192  0.18754859]\n",
      " [-0.98632991 -0.40128648]\n",
      " [ 0.18434775 -0.33753565]\n",
      " [-0.36555904 -0.30643505]]\n",
      "cost:\n",
      "0.0964082\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156 -0.17453289]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [-1.22173022 -0.43633222]\n",
      " [-0.69813156  0.08726644]\n",
      " [ 0.08726644  0.26179933]\n",
      " [ 0.61086511  0.26179933]\n",
      " [ 0.52359867  0.34906578]\n",
      " [-0.17453289 -0.34906578]\n",
      " [ 0.87266444 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.88089561 -0.12678827]\n",
      " [ 0.89746392 -0.31953979]\n",
      " [ 0.99530929 -0.18179597]\n",
      " [-0.99950522 -0.28929037]\n",
      " [-0.88091218  0.09177554]\n",
      " [ 0.10765117  0.25411612]\n",
      " [ 0.5627681   0.25720528]\n",
      " [ 0.45386985  0.3335413 ]\n",
      " [-0.17644303 -0.27847281]\n",
      " [ 0.89746392 -0.31953979]]\n",
      "cost:\n",
      "0.124966\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.22173022 -0.43633222]\n",
      " [ 1.13446378  0.34906578]\n",
      " [ 1.04719733  0.26179933]\n",
      " [-0.17453289 -0.43633222]\n",
      " [-0.785398   -0.43633222]\n",
      " [ 0.61086511  0.26179933]\n",
      " [-0.87266444 -0.34906578]\n",
      " [ 0.87266444 -0.26179933]\n",
      " [ 0.26179933  0.26179933]\n",
      " [ 0.95993089  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.88444418 -0.30043274]\n",
      " [ 0.87778544  0.20228568]\n",
      " [ 0.86243987  0.16925643]\n",
      " [-0.03366655 -0.36285403]\n",
      " [-0.98912585 -0.33779773]\n",
      " [ 0.54347992  0.17439455]\n",
      " [-0.99973726 -0.27946144]\n",
      " [ 0.81498802 -0.20554104]\n",
      " [ 0.3636944   0.17300801]\n",
      " [ 0.76549256  0.23006405]]\n",
      "cost:\n",
      "0.195008\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398   -0.08726644]\n",
      " [-0.26179933  0.17453289]\n",
      " [-0.43633222  0.17453289]\n",
      " [ 0.17453289  0.26179933]\n",
      " [-0.785398   -0.26179933]\n",
      " [ 0.52359867 -0.17453289]\n",
      " [ 0.69813156  0.26179933]\n",
      " [ 0.34906578  0.        ]\n",
      " [-1.04719733 -0.08726644]\n",
      " [ 1.22173022 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.86306071 -0.12117133]\n",
      " [-0.20591016  0.15973029]\n",
      " [-0.39382383  0.16131805]\n",
      " [ 0.18740951  0.25465757]\n",
      " [-0.88678849 -0.32359818]\n",
      " [ 0.59642041 -0.23413567]\n",
      " [ 0.88634473  0.24972889]\n",
      " [ 0.26815182 -0.03098545]\n",
      " [-0.99754041 -0.14228246]\n",
      " [ 0.9995504  -0.50511336]]\n",
      "cost:\n",
      "0.0996579\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289 -0.34906578]\n",
      " [ 0.69813156 -0.43633222]\n",
      " [-0.17453289 -0.34906578]\n",
      " [-1.04719733 -0.17453289]\n",
      " [ 1.22173022  0.        ]\n",
      " [-0.52359867 -0.08726644]\n",
      " [-0.785398    0.        ]\n",
      " [ 0.34906578 -0.08726644]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [ 0.43633222 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.16529308 -0.29873991]\n",
      " [ 0.77800018 -0.46186242]\n",
      " [-0.16528073 -0.29869312]\n",
      " [-0.9993853  -0.03996433]\n",
      " [ 0.99601096  0.42830622]\n",
      " [-0.48021072  0.02196858]\n",
      " [-0.95995814  0.17692335]\n",
      " [ 0.37564021  0.04159639]\n",
      " [ 0.95666915  0.0353801 ]\n",
      " [ 0.43440825 -0.11201786]]\n",
      "cost:\n",
      "0.152204\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378 -0.17453289]\n",
      " [-0.52359867 -0.34906578]\n",
      " [-0.785398    0.        ]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [-0.34906578 -0.08726644]\n",
      " [-0.61086511 -0.26179933]\n",
      " [-0.61086511  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.99609584 -0.06308354]\n",
      " [-0.80879295 -0.32309633]\n",
      " [-0.99871492  0.10530812]\n",
      " [ 0.9850744   0.01508971]\n",
      " [ 0.72864735 -0.33549002]\n",
      " [ 0.57954359 -0.00718829]\n",
      " [ 0.48423657 -0.19356804]\n",
      " [-0.35498592  0.00209072]\n",
      " [-0.88113475 -0.21017805]\n",
      " [-0.78602767  0.51307237]]\n",
      "cost:\n",
      "0.183063\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578 -0.08726644]\n",
      " [-0.17453289 -0.26179933]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [ 1.04719733  0.34906578]\n",
      " [-0.34906578  0.34906578]\n",
      " [-0.785398   -0.34906578]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [-0.43633222 -0.34906578]\n",
      " [ 1.13446378  0.34906578]\n",
      " [ 0.17453289  0.34906578]]\n",
      "prediction:\n",
      "[[-0.41130665 -0.07874294]\n",
      " [-0.11751298 -0.26877651]\n",
      " [ 0.45754221 -0.26523584]\n",
      " [ 0.93129706  0.23334219]\n",
      " [-0.32054526  0.25088862]\n",
      " [-0.99986899 -0.34265336]\n",
      " [ 0.96813363 -0.09658455]\n",
      " [-0.58778441 -0.34271815]\n",
      " [ 0.95976323  0.22350283]\n",
      " [ 0.24722733  0.265369  ]]\n",
      "cost:\n",
      "0.12242\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578 -0.34906578]\n",
      " [-1.13446378  0.26179933]\n",
      " [-1.04719733  0.08726644]\n",
      " [ 0.69813156  0.08726644]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [-0.34906578 -0.17453289]\n",
      " [-1.13446378 -0.26179933]\n",
      " [-0.52359867  0.26179933]\n",
      " [-0.26179933 -0.17453289]\n",
      " [ 0.61086511 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.49488297 -0.38207754]\n",
      " [-0.97597283  0.31083521]\n",
      " [-0.95554274  0.1180792 ]\n",
      " [ 0.99932551  0.14715871]\n",
      " [ 0.48291311 -0.14501001]\n",
      " [-0.35438141 -0.17517422]\n",
      " [-0.96319759 -0.29060534]\n",
      " [-0.58509398  0.34485203]\n",
      " [-0.2299272  -0.17624861]\n",
      " [ 0.98186415 -0.24404135]]\n",
      "cost:\n",
      "0.154197\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398    0.34906578]\n",
      " [ 0.17453289  0.17453289]\n",
      " [ 0.34906578  0.17453289]\n",
      " [ 0.69813156 -0.43633222]\n",
      " [ 0.34906578  0.26179933]\n",
      " [ 0.08726644  0.        ]\n",
      " [-1.13446378 -0.34906578]\n",
      " [ 0.61086511 -0.26179933]\n",
      " [ 0.34906578 -0.43633222]\n",
      " [ 0.785398   -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.85799026  0.29769877]\n",
      " [ 0.07082241  0.18150181]\n",
      " [ 0.28955558  0.16224998]\n",
      " [ 0.73292255 -0.35414621]\n",
      " [ 0.29534593  0.24775517]\n",
      " [-0.09569464  0.01213488]\n",
      " [-0.99994874 -0.18461467]\n",
      " [ 0.60263252 -0.21592656]\n",
      " [-0.06421243 -0.35080588]\n",
      " [ 0.95560247 -0.28378639]]\n",
      "cost:\n",
      "0.144516\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.         -0.17453289]\n",
      " [ 0.785398   -0.17453289]\n",
      " [ 0.17453289  0.        ]\n",
      " [-0.43633222  0.08726644]\n",
      " [-0.17453289 -0.17453289]\n",
      " [-0.26179933  0.34906578]\n",
      " [-0.43633222 -0.17453289]\n",
      " [-0.52359867 -0.34906578]\n",
      " [ 0.08726644 -0.34906578]\n",
      " [-1.22173022 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.07432021 -0.12658565]\n",
      " [ 0.99980623 -0.06961747]\n",
      " [ 0.25370911  0.06814414]\n",
      " [-0.41489235  0.19081444]\n",
      " [-0.08779687 -0.11323515]\n",
      " [-0.21405233  0.51252252]\n",
      " [-0.38917589 -0.11890484]\n",
      " [-0.38806897 -0.26604089]\n",
      " [ 0.13995902 -0.29080421]\n",
      " [-0.99824941 -0.28719747]]\n",
      "cost:\n",
      "0.139294\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398    0.        ]\n",
      " [-0.61086511  0.26179933]\n",
      " [-0.08726644 -0.08726644]\n",
      " [ 0.61086511  0.34906578]\n",
      " [ 0.52359867 -0.43633222]\n",
      " [ 0.         -0.17453289]\n",
      " [-0.08726644  0.26179933]\n",
      " [-1.22173022  0.08726644]\n",
      " [-0.26179933 -0.26179933]\n",
      " [-0.34906578  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.99930942 -0.04424432]\n",
      " [-0.61652923  0.1941971 ]\n",
      " [-0.05036598 -0.12565197]\n",
      " [ 0.64157605  0.24442591]\n",
      " [ 0.59892434 -0.49723881]\n",
      " [ 0.04029088 -0.21665898]\n",
      " [-0.04996091  0.17865093]\n",
      " [-0.99940616  0.0249685 ]\n",
      " [-0.2079398  -0.31128374]\n",
      " [-0.3540594   0.11863666]]\n",
      "cost:\n",
      "0.105502\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.26179933]\n",
      " [ 0.43633222 -0.43633222]\n",
      " [ 1.04719733  0.        ]\n",
      " [ 1.22173022  0.34906578]\n",
      " [-0.17453289 -0.43633222]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [-0.26179933 -0.26179933]\n",
      " [ 0.         -0.34906578]\n",
      " [ 0.52359867 -0.43633222]\n",
      " [-1.13446378  0.08726644]]\n",
      "prediction:\n",
      "[[-0.99629277 -0.10886957]\n",
      " [ 0.44237837 -0.27246207]\n",
      " [ 0.9929719   0.11232419]\n",
      " [ 0.90459085  0.45739546]\n",
      " [-0.19853348 -0.26031056]\n",
      " [ 0.91871166 -0.00793351]\n",
      " [-0.30362663 -0.13931918]\n",
      " [ 0.00506383 -0.21078695]\n",
      " [ 0.5353272  -0.2756561 ]\n",
      " [-0.99718249  0.25680286]]\n",
      "cost:\n",
      "0.174637\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089  0.        ]\n",
      " [ 0.17453289 -0.34906578]\n",
      " [ 0.52359867 -0.17453289]\n",
      " [ 0.87266444  0.34906578]\n",
      " [-0.69813156  0.17453289]\n",
      " [ 0.34906578 -0.43633222]\n",
      " [-0.95993089 -0.26179933]\n",
      " [-0.61086511 -0.17453289]\n",
      " [ 0.95993089 -0.43633222]\n",
      " [-1.22173022  0.34906578]]\n",
      "prediction:\n",
      "[[-0.96889001  0.04883927]\n",
      " [ 0.13440333 -0.28112435]\n",
      " [ 0.53574836 -0.11599109]\n",
      " [ 0.98974806  0.34455633]\n",
      " [-0.68925667  0.17207703]\n",
      " [ 0.35363206 -0.33246437]\n",
      " [-0.92588353 -0.19098207]\n",
      " [-0.61023664 -0.13269907]\n",
      " [ 0.99883872 -0.30888236]\n",
      " [-0.97365904  0.33342221]]\n",
      "cost:\n",
      "0.0920934\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578  0.26179933]\n",
      " [-0.785398    0.26179933]\n",
      " [ 1.04719733  0.08726644]\n",
      " [-0.26179933 -0.08726644]\n",
      " [ 0.61086511  0.34906578]\n",
      " [ 0.34906578  0.        ]\n",
      " [-0.08726644  0.08726644]\n",
      " [-0.26179933  0.08726644]\n",
      " [-1.13446378  0.26179933]\n",
      " [-0.52359867  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.28995684  0.16351046]\n",
      " [-0.86069274  0.06491362]\n",
      " [ 0.99959332 -0.35210201]\n",
      " [-0.14440817 -0.53516364]\n",
      " [ 0.71976405  0.2255158 ]\n",
      " [ 0.29026964 -0.17218189]\n",
      " [-0.07907197 -0.03096389]\n",
      " [-0.17134777 -0.0677472 ]\n",
      " [-0.99849117 -0.01051769]\n",
      " [-0.38459224  0.24718417]]\n",
      "cost:\n",
      "0.23518\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444  0.34906578]\n",
      " [ 0.785398    0.        ]\n",
      " [-0.95993089  0.17453289]\n",
      " [ 0.17453289  0.17453289]\n",
      " [ 0.08726644 -0.34906578]\n",
      " [ 0.61086511  0.        ]\n",
      " [ 0.61086511 -0.43633222]\n",
      " [ 1.04719733  0.17453289]\n",
      " [ 0.34906578 -0.43633222]\n",
      " [-0.43633222  0.17453289]]\n",
      "prediction:\n",
      "[[-0.97355545  0.27348489]\n",
      " [ 0.90400505 -0.02202566]\n",
      " [-0.99939883  0.1388061 ]\n",
      " [ 0.23475561  0.13287936]\n",
      " [ 0.14119984 -0.36696863]\n",
      " [ 0.61979687 -0.02051942]\n",
      " [ 0.62902623 -0.39683273]\n",
      " [ 0.99518067  0.14416622]\n",
      " [ 0.34326208 -0.40945679]\n",
      " [-0.42520845  0.13002305]]\n",
      "cost:\n",
      "0.0629443\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644 -0.26179933]\n",
      " [ 0.52359867  0.08726644]\n",
      " [ 0.26179933  0.17453289]\n",
      " [ 0.26179933 -0.08726644]\n",
      " [-0.43633222 -0.08726644]\n",
      " [ 1.13446378  0.34906578]\n",
      " [-0.69813156 -0.34906578]\n",
      " [ 0.08726644  0.17453289]\n",
      " [-0.08726644  0.        ]\n",
      " [-1.13446378 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.09740095 -0.31630197]\n",
      " [ 0.48998037  0.07489539]\n",
      " [ 0.23535757  0.19327922]\n",
      " [ 0.25687417 -0.10867138]\n",
      " [-0.40383148 -0.08593029]\n",
      " [ 0.99962956  0.37716615]\n",
      " [-0.81418693 -0.44595587]\n",
      " [ 0.05763136  0.20180449]\n",
      " [-0.03473179 -0.00282558]\n",
      " [-0.99869233 -0.27319548]]\n",
      "cost:\n",
      "0.0727798\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.34906578]\n",
      " [-1.22173022  0.17453289]\n",
      " [ 0.08726644  0.26179933]\n",
      " [ 0.08726644 -0.34906578]\n",
      " [-0.69813156 -0.08726644]\n",
      " [ 0.17453289  0.08726644]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [ 1.22173022 -0.08726644]\n",
      " [ 0.08726644  0.        ]\n",
      " [ 0.52359867  0.26179933]]\n",
      "prediction:\n",
      "[[-0.98584777 -0.44201142]\n",
      " [-0.98513305  0.21992934]\n",
      " [ 0.01216304  0.26183119]\n",
      " [ 0.02760889 -0.40513727]\n",
      " [-0.65474772 -0.11468816]\n",
      " [ 0.16657597  0.08072988]\n",
      " [ 0.3822234  -0.20150945]\n",
      " [ 0.99977452 -0.09951404]\n",
      " [ 0.01341013 -0.01658606]\n",
      " [ 0.53627396  0.28292397]]\n",
      "cost:\n",
      "0.100017\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289 -0.43633222]\n",
      " [ 0.785398   -0.08726644]\n",
      " [-0.26179933 -0.26179933]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [ 0.17453289 -0.34906578]\n",
      " [-1.04719733  0.08726644]\n",
      " [-0.43633222  0.        ]\n",
      " [ 0.          0.        ]\n",
      " [-0.87266444  0.        ]\n",
      " [ 0.          0.17453289]]\n",
      "prediction:\n",
      "[[-0.16987942 -0.45582777]\n",
      " [ 0.99983495 -0.03714604]\n",
      " [-0.23352973 -0.2317273 ]\n",
      " [ 0.48906371 -0.12540781]\n",
      " [ 0.23175514 -0.34875867]\n",
      " [-0.99273431  0.25332376]\n",
      " [-0.40007755  0.05274653]\n",
      " [ 0.00291901  0.03108343]\n",
      " [-0.95010155  0.02652467]\n",
      " [ 0.03705643  0.36724451]]\n",
      "cost:\n",
      "0.10352\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444  0.        ]\n",
      " [ 0.61086511 -0.26179933]\n",
      " [-0.61086511  0.        ]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [-0.95993089  0.        ]\n",
      " [ 0.26179933  0.34906578]\n",
      " [ 0.87266444  0.26179933]\n",
      " [-0.61086511 -0.26179933]\n",
      " [-0.87266444  0.        ]\n",
      " [-0.785398   -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.99616396  0.00265273]\n",
      " [ 0.69919837 -0.24766156]\n",
      " [-0.63866425  0.03774533]\n",
      " [ 0.35919586 -0.25030038]\n",
      " [-0.99176747  0.02867229]\n",
      " [ 0.24449179  0.35176456]\n",
      " [ 0.99467009  0.27493486]\n",
      " [-0.62507176 -0.24675491]\n",
      " [-0.95807397  0.02992455]\n",
      " [-0.87932724 -0.45928344]]\n",
      "cost:\n",
      "0.0666144\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089 -0.43633222]\n",
      " [-1.22173022 -0.08726644]\n",
      " [ 0.34906578 -0.34906578]\n",
      " [ 0.61086511 -0.17453289]\n",
      " [-0.52359867  0.26179933]\n",
      " [ 0.          0.        ]\n",
      " [-0.08726644  0.08726644]\n",
      " [ 0.          0.17453289]\n",
      " [ 0.17453289 -0.34906578]\n",
      " [ 0.785398   -0.43633222]]\n",
      "prediction:\n",
      "[[-0.97521049 -0.34834468]\n",
      " [-0.99626666  0.02558796]\n",
      " [ 0.35116884 -0.24638063]\n",
      " [ 0.93304139 -0.10384063]\n",
      " [-0.51038361  0.38786131]\n",
      " [-0.06454825  0.0295438 ]\n",
      " [-0.13312516  0.15455729]\n",
      " [-0.03438075  0.26689839]\n",
      " [ 0.17462568 -0.26957461]\n",
      " [ 0.99925983 -0.33147645]]\n",
      "cost:\n",
      "0.146939\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733 -0.08726644]\n",
      " [-1.13446378 -0.26179933]\n",
      " [-0.17453289  0.26179933]\n",
      " [-1.22173022  0.08726644]\n",
      " [-0.95993089  0.17453289]\n",
      " [-0.34906578  0.08726644]\n",
      " [-0.34906578  0.26179933]\n",
      " [-0.52359867 -0.17453289]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [ 0.52359867 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.83033717 -0.08786085]\n",
      " [-0.8656528  -0.27861899]\n",
      " [-0.21705478  0.27788097]\n",
      " [-0.78470945  0.08772854]\n",
      " [-0.82294434  0.17894453]\n",
      " [-0.38544613  0.07885185]\n",
      " [-0.39710453  0.27507815]\n",
      " [-0.57707912 -0.20860994]\n",
      " [ 0.99990827 -0.26568767]\n",
      " [ 0.90392756 -0.47123885]]\n",
      "cost:\n",
      "0.194006\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444  0.        ]\n",
      " [ 0.69813156  0.17453289]\n",
      " [-0.785398    0.26179933]\n",
      " [-1.22173022 -0.26179933]\n",
      " [ 0.61086511  0.34906578]\n",
      " [ 0.43633222  0.26179933]\n",
      " [-0.95993089  0.17453289]\n",
      " [-1.04719733 -0.26179933]\n",
      " [-0.95993089  0.08726644]\n",
      " [-1.13446378  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.99955291 -0.11794244]\n",
      " [ 0.95340335  0.02443304]\n",
      " [-0.6897549   0.12632246]\n",
      " [-0.89187372 -0.4738225 ]\n",
      " [ 0.85922229  0.20806485]\n",
      " [ 0.48012614  0.12892939]\n",
      " [-0.90440571  0.03464304]\n",
      " [-0.8618964  -0.48608941]\n",
      " [-0.8795048  -0.04910641]\n",
      " [-0.88263327  0.20419419]]\n",
      "cost:\n",
      "0.234311\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289  0.17453289]\n",
      " [ 1.04719733 -0.34906578]\n",
      " [ 0.785398    0.34906578]\n",
      " [-0.95993089  0.17453289]\n",
      " [-0.52359867  0.17453289]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [-0.17453289  0.34906578]\n",
      " [ 0.17453289  0.17453289]\n",
      " [ 0.61086511 -0.43633222]\n",
      " [-0.17453289  0.08726644]]\n",
      "prediction:\n",
      "[[-0.16878283  0.08992738]\n",
      " [ 0.9948985  -0.3804839 ]\n",
      " [ 0.83377206  0.22751601]\n",
      " [-0.99981403  0.07067317]\n",
      " [-0.64718962  0.07272047]\n",
      " [ 0.71851885 -0.36895183]\n",
      " [-0.13685976  0.26029855]\n",
      " [ 0.20375587  0.08528499]\n",
      " [ 0.55124158 -0.43812957]\n",
      " [-0.16957411  0.0141245 ]]\n",
      "cost:\n",
      "0.0899795\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733  0.17453289]\n",
      " [-0.95993089  0.34906578]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [-0.17453289 -0.08726644]\n",
      " [ 0.52359867  0.08726644]\n",
      " [ 0.26179933 -0.34906578]\n",
      " [ 0.17453289  0.08726644]\n",
      " [-1.04719733 -0.17453289]\n",
      " [ 0.43633222 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.99926037  0.20740913]\n",
      " [-0.98515576  0.42459422]\n",
      " [ 0.55144095 -0.09480859]\n",
      " [ 0.27511823 -0.3262234 ]\n",
      " [-0.18577547 -0.08073466]\n",
      " [ 0.44455111  0.08769308]\n",
      " [ 0.17509054 -0.45818287]\n",
      " [ 0.11903191  0.11509477]\n",
      " [-0.99775589 -0.17958313]\n",
      " [ 0.37599534 -0.09379596]]\n",
      "cost:\n",
      "0.0699632\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933 -0.26179933]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [ 0.61086511  0.08726644]\n",
      " [-0.87266444  0.26179933]\n",
      " [-0.34906578  0.17453289]\n",
      " [ 0.17453289  0.17453289]\n",
      " [ 0.43633222  0.        ]\n",
      " [-0.08726644  0.08726644]\n",
      " [-0.52359867 -0.08726644]\n",
      " [-0.61086511 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.26056543 -0.56375861]\n",
      " [ 0.99671304 -0.19601671]\n",
      " [ 0.96134198  0.04616817]\n",
      " [-0.99959284  0.29728714]\n",
      " [-0.3066254   0.16514905]\n",
      " [ 0.18858421  0.18047684]\n",
      " [ 0.6873275  -0.06721946]\n",
      " [-0.0601788   0.05775594]\n",
      " [-0.45136383 -0.15253504]\n",
      " [-0.67991412 -0.1608071 ]]\n",
      "cost:\n",
      "0.166126\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289 -0.17453289]\n",
      " [-1.04719733 -0.34906578]\n",
      " [-0.52359867  0.08726644]\n",
      " [-0.17453289  0.17453289]\n",
      " [ 0.61086511  0.        ]\n",
      " [ 0.87266444  0.08726644]\n",
      " [ 0.95993089 -0.34906578]\n",
      " [-0.26179933  0.17453289]\n",
      " [-0.52359867 -0.34906578]\n",
      " [-1.13446378 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.18068767 -0.16310094]\n",
      " [-0.99023533 -0.28414211]\n",
      " [-0.54514229  0.14742047]\n",
      " [-0.19959481  0.3014549 ]\n",
      " [ 0.80731976  0.01263235]\n",
      " [ 0.99485934  0.18078867]\n",
      " [ 0.9951753  -0.30341563]\n",
      " [-0.30276608  0.28230354]\n",
      " [-0.49541229 -0.28022584]\n",
      " [-0.98961353 -0.34887359]]\n",
      "cost:\n",
      "0.105992\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156 -0.17453289]\n",
      " [ 0.17453289 -0.26179933]\n",
      " [-0.34906578 -0.08726644]\n",
      " [-1.22173022  0.26179933]\n",
      " [ 0.785398    0.26179933]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [-0.69813156 -0.43633222]\n",
      " [-0.61086511  0.        ]\n",
      " [ 0.785398    0.26179933]\n",
      " [-0.08726644 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.84566993 -0.12780418]\n",
      " [ 0.23868982 -0.22556935]\n",
      " [-0.31518915 -0.07060164]\n",
      " [-0.99976236  0.2757585 ]\n",
      " [ 0.96088535  0.2815966 ]\n",
      " [ 0.89346743 -0.31375909]\n",
      " [-0.85317034 -0.42922986]\n",
      " [-0.62874585  0.00900542]\n",
      " [ 0.96090496  0.28158164]\n",
      " [-0.05316094 -0.15850736]]\n",
      "cost:\n",
      "0.125323\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156  0.26179933]\n",
      " [ 0.26179933  0.26179933]\n",
      " [ 0.785398    0.08726644]\n",
      " [ 0.785398   -0.26179933]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [-0.26179933  0.08726644]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [-0.17453289 -0.26179933]\n",
      " [-0.69813156 -0.08726644]\n",
      " [-1.13446378  0.        ]]\n",
      "prediction:\n",
      "[[  7.47383118e-01   3.17157805e-01]\n",
      " [  3.06302279e-01   3.03759843e-01]\n",
      " [  8.44476581e-01   1.03320368e-01]\n",
      " [  8.28913629e-01  -2.51988292e-01]\n",
      " [  9.80024278e-01  -4.28206891e-01]\n",
      " [ -2.23440886e-01   8.75633955e-02]\n",
      " [  2.90357679e-01  -2.61471063e-01]\n",
      " [ -1.36700913e-01  -2.65639931e-01]\n",
      " [ -8.11157048e-01  -8.26617032e-02]\n",
      " [ -9.99873817e-01  -8.79883533e-04]]\n",
      "cost:\n",
      "0.0748402\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933  0.        ]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [-0.17453289  0.34906578]\n",
      " [ 0.08726644  0.08726644]\n",
      " [ 0.69813156  0.34906578]\n",
      " [-0.95993089  0.08726644]\n",
      " [-0.69813156 -0.43633222]\n",
      " [ 0.34906578  0.17453289]\n",
      " [-0.61086511  0.26179933]\n",
      " [-0.17453289 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.20219649 -0.0516715 ]\n",
      " [ 0.99030751 -0.16890842]\n",
      " [-0.1246749   0.22253513]\n",
      " [ 0.17141128  0.02037479]\n",
      " [ 0.99614394  0.20864889]\n",
      " [-0.99878079 -0.01716639]\n",
      " [-0.91161549 -0.5678423 ]\n",
      " [ 0.48733461  0.05795961]\n",
      " [-0.68773723  0.15045106]\n",
      " [-0.11646028 -0.2587491 ]]\n",
      "cost:\n",
      "0.17358\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089  0.34906578]\n",
      " [-0.17453289 -0.08726644]\n",
      " [ 0.08726644 -0.34906578]\n",
      " [ 1.22173022  0.26179933]\n",
      " [ 0.         -0.26179933]\n",
      " [-0.43633222 -0.34906578]\n",
      " [-0.61086511  0.17453289]\n",
      " [-0.785398    0.17453289]\n",
      " [ 0.52359867  0.        ]\n",
      " [-0.17453289 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.98779285  0.33390591]\n",
      " [-0.22898342 -0.05811335]\n",
      " [ 0.09981282 -0.36713848]\n",
      " [ 0.99526083  0.21051659]\n",
      " [-0.00718712 -0.26032409]\n",
      " [-0.40055823 -0.38429019]\n",
      " [-0.83840692  0.16300304]\n",
      " [-0.99939996  0.15349247]\n",
      " [ 0.31761083  0.0155841 ]\n",
      " [-0.14463708 -0.25651148]]\n",
      "cost:\n",
      "0.108503\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444 -0.34906578]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [ 0.26179933  0.08726644]\n",
      " [-0.52359867  0.34906578]\n",
      " [ 0.34906578  0.        ]\n",
      " [-0.26179933 -0.43633222]\n",
      " [ 0.95993089  0.08726644]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [ 0.         -0.08726644]\n",
      " [ 0.87266444 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.74076521 -0.28241447]\n",
      " [ 0.78245091 -0.14427014]\n",
      " [ 0.34054786  0.14382546]\n",
      " [-0.99986833  0.4652499 ]\n",
      " [ 0.53650308  0.04746013]\n",
      " [-0.94438612 -0.35564625]\n",
      " [ 0.96034712  0.1564558 ]\n",
      " [ 0.33187383 -0.12799472]\n",
      " [ 0.25340253 -0.05245245]\n",
      " [ 0.74073243 -0.28240386]]\n",
      "cost:\n",
      "0.226773\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398   -0.34906578]\n",
      " [-1.22173022  0.        ]\n",
      " [ 0.08726644  0.08726644]\n",
      " [ 0.95993089  0.        ]\n",
      " [ 0.61086511 -0.26179933]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [ 0.          0.08726644]\n",
      " [-0.95993089 -0.26179933]\n",
      " [ 0.26179933  0.26179933]\n",
      " [-0.43633222 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.93567199 -0.31562465]\n",
      " [-0.99843848  0.08972042]\n",
      " [ 0.05444133  0.14487438]\n",
      " [ 0.99800098  0.04463158]\n",
      " [ 0.6219126  -0.23546401]\n",
      " [ 0.10677652 -0.05616975]\n",
      " [-0.04656111  0.12816797]\n",
      " [-0.97907799 -0.2454219 ]\n",
      " [ 0.18890652  0.43878466]\n",
      " [-0.43462855 -0.40337414]]\n",
      "cost:\n",
      "0.093425\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398    0.34906578]\n",
      " [-0.95993089 -0.17453289]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [ 0.69813156  0.34906578]\n",
      " [ 0.         -0.17453289]\n",
      " [-1.22173022  0.34906578]\n",
      " [-0.69813156 -0.08726644]\n",
      " [-0.43633222 -0.17453289]\n",
      " [ 0.          0.08726644]\n",
      " [-0.34906578 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.91558182  0.29471293]\n",
      " [-0.98973262 -0.25890234]\n",
      " [ 0.9991827  -0.40140837]\n",
      " [ 0.83454251  0.30172691]\n",
      " [ 0.03660966 -0.23642491]\n",
      " [-0.98731166  0.28802997]\n",
      " [-0.68326885 -0.12431316]\n",
      " [-0.45843029 -0.26609471]\n",
      " [ 0.08474483  0.05368143]\n",
      " [-0.37395063 -0.11629444]]\n",
      "cost:\n",
      "0.127039\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398   -0.34906578]\n",
      " [-0.26179933 -0.08726644]\n",
      " [-0.95993089 -0.43633222]\n",
      " [ 0.17453289  0.26179933]\n",
      " [-0.34906578  0.        ]\n",
      " [ 0.785398    0.26179933]\n",
      " [ 0.08726644  0.08726644]\n",
      " [-0.95993089 -0.26179933]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [-0.17453289  0.08726644]]\n",
      "prediction:\n",
      "[[-0.86188984 -0.27991149]\n",
      " [-0.26181948 -0.08491917]\n",
      " [-0.97200572 -0.3615244 ]\n",
      " [ 0.1984825   0.31141403]\n",
      " [-0.36092475  0.00222113]\n",
      " [ 0.9907344   0.31818777]\n",
      " [ 0.07404449  0.08922166]\n",
      " [-0.98672557 -0.2172707 ]\n",
      " [ 0.99869239 -0.36636996]\n",
      " [-0.18476278  0.09787945]]\n",
      "cost:\n",
      "0.0685558\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511 -0.08726644]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [-0.17453289  0.        ]\n",
      " [ 1.13446378 -0.34906578]\n",
      " [-1.04719733  0.17453289]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [ 0.17453289  0.        ]\n",
      " [ 0.69813156 -0.43633222]\n",
      " [-0.34906578  0.17453289]]\n",
      "prediction:\n",
      "[[-0.75169855 -0.01744254]\n",
      " [ 0.97725368 -0.14760581]\n",
      " [ 0.61767262 -0.28856   ]\n",
      " [-0.17412974  0.04044144]\n",
      " [ 0.9625482  -0.25874978]\n",
      " [-0.99984652  0.37067091]\n",
      " [ 0.36776558 -0.22478841]\n",
      " [ 0.17194095  0.03190507]\n",
      " [ 0.58423895 -0.36177647]\n",
      " [-0.35988152  0.34842604]]\n",
      "cost:\n",
      "0.134794\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156 -0.08726644]\n",
      " [ 0.95993089 -0.43633222]\n",
      " [ 1.22173022 -0.08726644]\n",
      " [-0.69813156  0.17453289]\n",
      " [-0.43633222  0.08726644]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [-0.87266444  0.26179933]\n",
      " [-0.95993089 -0.34906578]\n",
      " [ 0.87266444  0.        ]\n",
      " [ 0.87266444  0.26179933]]\n",
      "prediction:\n",
      "[[-0.82914066 -0.10005623]\n",
      " [ 0.8569653  -0.43692502]\n",
      " [ 0.9790135  -0.08759634]\n",
      " [-0.84121984  0.16970831]\n",
      " [-0.427304    0.07590985]\n",
      " [ 0.97596633 -0.25376251]\n",
      " [-0.98808604  0.28181174]\n",
      " [-0.99509013 -0.37667367]\n",
      " [ 0.87872511 -0.00374458]\n",
      " [ 0.8297106   0.27287224]]\n",
      "cost:\n",
      "0.109422\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156 -0.34906578]\n",
      " [-0.43633222 -0.17453289]\n",
      " [-1.13446378 -0.26179933]\n",
      " [ 1.22173022  0.17453289]\n",
      " [-0.34906578  0.        ]\n",
      " [ 0.87266444 -0.26179933]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [ 1.13446378  0.17453289]\n",
      " [-0.69813156 -0.08726644]\n",
      " [-0.785398    0.08726644]]\n",
      "prediction:\n",
      "[[-0.75240195 -0.32552183]\n",
      " [-0.43088937 -0.15298063]\n",
      " [-0.99873972 -0.19803794]\n",
      " [ 0.98382926  0.31769833]\n",
      " [-0.35622305  0.06708654]\n",
      " [ 0.8918891  -0.20981872]\n",
      " [ 0.94122696 -0.37901774]\n",
      " [ 0.97660118  0.28857788]\n",
      " [-0.74517894 -0.04760443]\n",
      " [-0.89737433  0.17511284]]\n",
      "cost:\n",
      "0.123205\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156  0.        ]\n",
      " [-0.52359867 -0.08726644]\n",
      " [ 0.785398    0.        ]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [-0.61086511 -0.43633222]\n",
      " [-0.87266444  0.08726644]\n",
      " [-0.61086511  0.17453289]\n",
      " [ 0.         -0.26179933]\n",
      " [-0.87266444  0.34906578]\n",
      " [-0.785398    0.08726644]]\n",
      "prediction:\n",
      "[[-0.73772001 -0.01445255]\n",
      " [-0.49651176 -0.09144726]\n",
      " [ 0.99012542 -0.02417573]\n",
      " [ 0.99964809 -0.10925711]\n",
      " [-0.53278947 -0.53476721]\n",
      " [-0.93256712  0.06308957]\n",
      " [-0.57299584  0.17422909]\n",
      " [-0.09551782 -0.30439791]\n",
      " [-0.8849858   0.35362941]\n",
      " [-0.82399833  0.07212862]]\n",
      "cost:\n",
      "0.0708396\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444 -0.08726644]\n",
      " [-0.61086511  0.17453289]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [ 0.08726644  0.08726644]\n",
      " [-0.87266444 -0.08726644]\n",
      " [ 0.34906578  0.26179933]\n",
      " [-0.87266444  0.        ]\n",
      " [ 1.13446378  0.08726644]\n",
      " [ 1.04719733 -0.43633222]\n",
      " [ 0.87266444 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.97567773 -0.07785348]\n",
      " [-0.65425909  0.21472849]\n",
      " [ 0.21776062 -0.2559481 ]\n",
      " [-0.02518421  0.11238186]\n",
      " [-0.97567397 -0.07784236]\n",
      " [ 0.30542696  0.34290424]\n",
      " [-0.98473561  0.01151585]\n",
      " [ 0.99538505  0.14644149]\n",
      " [ 0.98269695 -0.40762183]\n",
      " [ 0.92389512 -0.42226461]]\n",
      "cost:\n",
      "0.0905313\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578 -0.17453289]\n",
      " [ 0.43633222  0.17453289]\n",
      " [-1.22173022 -0.08726644]\n",
      " [ 0.52359867 -0.17453289]\n",
      " [-0.87266444 -0.26179933]\n",
      " [ 0.43633222  0.08726644]\n",
      " [ 0.17453289 -0.34906578]\n",
      " [-0.52359867  0.08726644]\n",
      " [-0.785398    0.17453289]\n",
      " [ 1.04719733  0.34906578]]\n",
      "prediction:\n",
      "[[-0.35682774 -0.19507378]\n",
      " [ 0.39762613  0.19085489]\n",
      " [-0.99383831 -0.17315452]\n",
      " [ 0.59405816 -0.20174569]\n",
      " [-0.88871431 -0.32071865]\n",
      " [ 0.40257043  0.09751011]\n",
      " [ 0.13098605 -0.43573043]\n",
      " [-0.47984239  0.09688829]\n",
      " [-0.8057189   0.18135238]\n",
      " [ 0.99979746  0.33122125]]\n",
      "cost:\n",
      "0.0693259\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933  0.26179933]\n",
      " [-1.22173022 -0.34906578]\n",
      " [ 0.87266444 -0.34906578]\n",
      " [ 1.04719733 -0.43633222]\n",
      " [-0.69813156  0.17453289]\n",
      " [ 1.22173022  0.26179933]\n",
      " [-0.34906578 -0.17453289]\n",
      " [ 1.04719733  0.        ]\n",
      " [ 0.17453289 -0.26179933]\n",
      " [ 1.04719733  0.34906578]]\n",
      "prediction:\n",
      "[[-0.24958342  0.2362178 ]\n",
      " [-0.99987084 -0.30568916]\n",
      " [ 0.74492198 -0.30353865]\n",
      " [ 0.84501088 -0.36653408]\n",
      " [-0.8731395   0.14601678]\n",
      " [ 0.91029686  0.2165972 ]\n",
      " [-0.36542252 -0.15455134]\n",
      " [ 0.88515294  0.02118339]\n",
      " [ 0.27845067 -0.23164234]\n",
      " [ 0.87633193  0.28790569]]\n",
      "cost:\n",
      "0.157486\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.22173022 -0.26179933]\n",
      " [ 0.87266444  0.08726644]\n",
      " [-1.13446378  0.        ]\n",
      " [ 0.08726644 -0.08726644]\n",
      " [-1.04719733 -0.08726644]\n",
      " [ 0.69813156  0.34906578]\n",
      " [ 0.          0.26179933]\n",
      " [-0.26179933 -0.17453289]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [-0.785398   -0.17453289]]\n",
      "prediction:\n",
      "[[ -9.72728372e-01  -4.61273044e-01]\n",
      " [  9.99121845e-01   7.29428604e-02]\n",
      " [ -9.66429770e-01   9.80168232e-04]\n",
      " [  1.03276737e-01  -9.37283337e-02]\n",
      " [ -9.61842477e-01  -1.08838439e-01]\n",
      " [  9.62829471e-01   3.87280822e-01]\n",
      " [  3.72597575e-02   3.11447322e-01]\n",
      " [ -2.25797042e-01  -2.36904487e-01]\n",
      " [  8.47735465e-01  -1.14242949e-01]\n",
      " [ -7.12358356e-01  -2.46639952e-01]]\n",
      "cost:\n",
      "0.137584\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.22173022 -0.43633222]\n",
      " [-0.69813156 -0.26179933]\n",
      " [ 0.69813156  0.        ]\n",
      " [-0.69813156  0.08726644]\n",
      " [-0.52359867  0.        ]\n",
      " [ 0.26179933  0.17453289]\n",
      " [ 1.22173022  0.08726644]\n",
      " [ 0.34906578  0.17453289]\n",
      " [-0.17453289 -0.43633222]\n",
      " [ 0.52359867 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.99852574 -0.34083211]\n",
      " [-0.76563406 -0.23089053]\n",
      " [ 0.79437947  0.01393735]\n",
      " [-0.76546896  0.1290848 ]\n",
      " [-0.5372777  -0.00421632]\n",
      " [ 0.19420268  0.25892919]\n",
      " [ 0.9994579   0.22157156]\n",
      " [ 0.3023681   0.25816983]\n",
      " [-0.18916442 -0.36626887]\n",
      " [ 0.58012938 -0.38123876]]\n",
      "cost:\n",
      "0.112198\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933 -0.17453289]\n",
      " [-1.22173022  0.        ]\n",
      " [-0.52359867  0.08726644]\n",
      " [ 0.17453289 -0.26179933]\n",
      " [-0.52359867 -0.34906578]\n",
      " [ 0.69813156  0.34906578]\n",
      " [-0.17453289  0.17453289]\n",
      " [ 0.34906578  0.34906578]\n",
      " [-0.26179933  0.        ]\n",
      " [ 1.04719733 -0.17453289]]\n",
      "prediction:\n",
      "[[ -2.32706502e-01  -2.02508226e-01]\n",
      " [ -9.99401808e-01  -7.13594630e-02]\n",
      " [ -5.03015220e-01   7.21315518e-02]\n",
      " [  1.66895136e-01  -3.15068007e-01]\n",
      " [ -5.04879177e-01  -4.74922389e-01]\n",
      " [  8.58636796e-01   3.13506782e-01]\n",
      " [ -1.54857531e-01   1.70810059e-01]\n",
      " [  3.59323800e-01   3.21554631e-01]\n",
      " [ -2.42799416e-01  -9.30547423e-04]\n",
      " [  9.99143541e-01  -2.33478680e-01]]\n",
      "cost:\n",
      "0.0789321\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733  0.17453289]\n",
      " [ 1.04719733  0.17453289]\n",
      " [-0.08726644  0.08726644]\n",
      " [-1.04719733 -0.43633222]\n",
      " [-0.08726644  0.        ]\n",
      " [-0.43633222  0.34906578]\n",
      " [-1.13446378 -0.17453289]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [ 0.52359867  0.17453289]\n",
      " [-0.34906578  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.98485482  0.10422836]\n",
      " [ 0.98485482  0.10422836]\n",
      " [-0.05423467  0.00453082]\n",
      " [-0.98784858 -0.58541965]\n",
      " [-0.07208792 -0.07253102]\n",
      " [-0.50354213  0.27502561]\n",
      " [-0.998272   -0.31496203]\n",
      " [ 0.92903197 -0.14177562]\n",
      " [ 0.51671112  0.0884821 ]\n",
      " [-0.39829922  0.18090954]]\n",
      "cost:\n",
      "0.106664\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398    0.34906578]\n",
      " [-0.95993089  0.34906578]\n",
      " [-0.52359867 -0.08726644]\n",
      " [-0.87266444 -0.34906578]\n",
      " [-0.69813156 -0.17453289]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [-1.22173022 -0.17453289]\n",
      " [-1.04719733 -0.17453289]\n",
      " [-1.04719733 -0.26179933]\n",
      " [-0.52359867  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.95275754  0.36435461]\n",
      " [-0.6763798   0.36228287]\n",
      " [-0.54708743 -0.08557785]\n",
      " [-0.73334599 -0.39726549]\n",
      " [-0.6360817  -0.1814017 ]\n",
      " [ 0.99990857 -0.04229688]\n",
      " [-0.82603812 -0.20482418]\n",
      " [-0.79384005 -0.1669593 ]\n",
      " [-0.73671734 -0.30149081]\n",
      " [-0.52503562  0.19060087]]\n",
      "cost:\n",
      "0.173003\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733 -0.43633222]\n",
      " [-0.08726644 -0.26179933]\n",
      " [-1.22173022 -0.17453289]\n",
      " [-1.04719733 -0.34906578]\n",
      " [-0.26179933 -0.26179933]\n",
      " [-1.04719733  0.08726644]\n",
      " [-0.43633222 -0.34906578]\n",
      " [-1.04719733 -0.34906578]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [-0.34906578 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.76119888 -0.27538365]\n",
      " [-0.05037991 -0.15509382]\n",
      " [-0.63805962  0.18517673]\n",
      " [-0.72687173 -0.16763869]\n",
      " [-0.26400274 -0.10602039]\n",
      " [-0.63472432  0.53098559]\n",
      " [-0.47015104 -0.19821703]\n",
      " [-0.72683823 -0.16765252]\n",
      " [ 0.99996805  0.07627776]\n",
      " [-0.37637606 -0.28326923]]\n",
      "cost:\n",
      "0.314192\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156  0.        ]\n",
      " [-0.26179933 -0.26179933]\n",
      " [-0.87266444 -0.08726644]\n",
      " [-0.34906578 -0.43633222]\n",
      " [ 0.34906578  0.26179933]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [ 0.34906578 -0.34906578]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [-0.69813156  0.        ]\n",
      " [-1.13446378  0.08726644]]\n",
      "prediction:\n",
      "[[-0.69207668  0.02469529]\n",
      " [-0.22927788 -0.23188415]\n",
      " [-0.90482724 -0.06844848]\n",
      " [-0.33400884 -0.4331584 ]\n",
      " [ 0.36037612  0.46276566]\n",
      " [ 0.37219456 -0.13085076]\n",
      " [ 0.38223773 -0.3292115 ]\n",
      " [ 0.99990433 -0.05910503]\n",
      " [-0.69207668  0.02469529]\n",
      " [-0.98445415  0.21134058]]\n",
      "cost:\n",
      "0.0762055\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289  0.        ]\n",
      " [ 0.61086511  0.26179933]\n",
      " [-0.69813156  0.17453289]\n",
      " [-0.17453289  0.        ]\n",
      " [ 0.26179933 -0.08726644]\n",
      " [-0.87266444  0.08726644]\n",
      " [ 0.785398    0.        ]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [ 1.04719733  0.        ]\n",
      " [ 1.13446378 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.14800325 -0.02142173]\n",
      " [ 0.54106051  0.3623333 ]\n",
      " [-0.96760774  0.23518969]\n",
      " [-0.14223795  0.00349812]\n",
      " [ 0.21707426 -0.13136445]\n",
      " [-0.99978483  0.07326529]\n",
      " [ 0.8243044  -0.03540784]\n",
      " [ 0.57230949 -0.30861482]\n",
      " [ 0.9623791  -0.04765138]\n",
      " [ 0.95520568 -0.54892457]]\n",
      "cost:\n",
      "0.132815\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511  0.08726644]\n",
      " [ 0.61086511 -0.17453289]\n",
      " [-0.61086511  0.        ]\n",
      " [-0.43633222  0.26179933]\n",
      " [ 0.26179933 -0.08726644]\n",
      " [-0.08726644  0.17453289]\n",
      " [-0.69813156 -0.17453289]\n",
      " [ 0.34906578 -0.34906578]\n",
      " [ 0.785398    0.        ]\n",
      " [ 0.785398   -0.26179933]]\n",
      "prediction:\n",
      "[[-0.90380281  0.12576143]\n",
      " [ 0.73548532 -0.20168334]\n",
      " [-0.94196582  0.01017914]\n",
      " [-0.55700362  0.42950767]\n",
      " [ 0.17353621 -0.10180266]\n",
      " [-0.21558009  0.22886115]\n",
      " [-0.99669003 -0.21464829]\n",
      " [ 0.26184562 -0.43337867]\n",
      " [ 0.99855793  0.00446337]\n",
      " [ 0.97668988 -0.29184484]]\n",
      "cost:\n",
      "0.201905\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156  0.        ]\n",
      " [ 0.785398   -0.34906578]\n",
      " [-0.95993089 -0.43633222]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [ 0.26179933  0.08726644]\n",
      " [ 1.04719733 -0.17453289]\n",
      " [-0.26179933 -0.34906578]\n",
      " [-0.08726644  0.26179933]\n",
      " [ 0.          0.34906578]\n",
      " [ 0.         -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.57524091  0.08193605]\n",
      " [ 0.72030437 -0.19927469]\n",
      " [-0.99993831 -0.27092245]\n",
      " [ 0.91847712 -0.26095539]\n",
      " [ 0.27537367  0.13189426]\n",
      " [ 0.96639049 -0.06823129]\n",
      " [-0.28323808 -0.27194577]\n",
      " [-0.05472106  0.29250899]\n",
      " [ 0.0387493   0.39873698]\n",
      " [-0.01953869 -0.31146479]]\n",
      "cost:\n",
      "0.125378\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.         -0.17453289]\n",
      " [-0.95993089 -0.17453289]\n",
      " [ 0.87266444  0.26179933]\n",
      " [-0.43633222  0.34906578]\n",
      " [ 0.26179933 -0.34906578]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [ 0.         -0.17453289]\n",
      " [-1.04719733 -0.26179933]\n",
      " [ 1.22173022 -0.34906578]\n",
      " [-0.95993089  0.34906578]]\n",
      "prediction:\n",
      "[[-0.12896426 -0.11835903]\n",
      " [-0.97399205 -0.12381455]\n",
      " [ 0.98287308  0.25748858]\n",
      " [-0.51992702  0.34488538]\n",
      " [ 0.23751627 -0.32590047]\n",
      " [-0.02930086 -0.22483757]\n",
      " [-0.12896426 -0.11835903]\n",
      " [-0.96504408 -0.23218365]\n",
      " [ 0.99944264 -0.29920009]\n",
      " [-0.9455592   0.3330107 ]]\n",
      "cost:\n",
      "0.102049\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.43633222]\n",
      " [-0.87266444 -0.43633222]\n",
      " [-0.87266444 -0.34906578]\n",
      " [ 0.34906578 -0.43633222]\n",
      " [-1.04719733  0.34906578]\n",
      " [ 1.22173022  0.26179933]\n",
      " [ 1.22173022  0.34906578]\n",
      " [ 0.         -0.08726644]\n",
      " [ 0.26179933  0.26179933]\n",
      " [-0.95993089  0.34906578]]\n",
      "prediction:\n",
      "[[-0.91863233 -0.32261863]\n",
      " [-0.84252113 -0.35110608]\n",
      " [-0.85588896 -0.28985843]\n",
      " [ 0.3534286  -0.35303077]\n",
      " [-0.94630426  0.22145019]\n",
      " [ 0.99869245  0.15568274]\n",
      " [ 0.99629682  0.18956032]\n",
      " [-0.08944546 -0.08871123]\n",
      " [ 0.2480443   0.18595544]\n",
      " [-0.91400141  0.2266756 ]]\n",
      "cost:\n",
      "0.14624\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156 -0.43633222]\n",
      " [ 0.          0.26179933]\n",
      " [ 1.22173022 -0.08726644]\n",
      " [ 0.95993089 -0.43633222]\n",
      " [-0.52359867  0.08726644]\n",
      " [ 0.17453289  0.08726644]\n",
      " [-1.04719733  0.17453289]\n",
      " [ 0.26179933 -0.08726644]\n",
      " [-0.17453289  0.34906578]\n",
      " [-1.04719733  0.        ]]\n",
      "prediction:\n",
      "[[ 0.74814141 -0.44156098]\n",
      " [-0.05362958  0.20550133]\n",
      " [ 0.99703115 -0.14230943]\n",
      " [ 0.97128707 -0.45564345]\n",
      " [-0.51733983  0.05889013]\n",
      " [ 0.18616976  0.04970962]\n",
      " [-0.99189693  0.1325008 ]\n",
      " [ 0.27329934 -0.10471373]\n",
      " [-0.25913122  0.28256646]\n",
      " [-0.99717093 -0.00788234]]\n",
      "cost:\n",
      "0.0698765\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289  0.        ]\n",
      " [ 1.22173022  0.34906578]\n",
      " [-0.26179933 -0.26179933]\n",
      " [ 0.61086511  0.        ]\n",
      " [-0.785398    0.26179933]\n",
      " [-0.69813156 -0.43633222]\n",
      " [-0.52359867 -0.17453289]\n",
      " [-1.04719733 -0.43633222]\n",
      " [-0.17453289  0.        ]\n",
      " [ 1.22173022  0.08726644]]\n",
      "prediction:\n",
      "[[-0.09528842  0.00975465]\n",
      " [ 0.98243433  0.32997534]\n",
      " [-0.25144795 -0.2462046 ]\n",
      " [ 0.72106433  0.00652057]\n",
      " [-0.94608879  0.29401618]\n",
      " [-0.69265723 -0.39132744]\n",
      " [-0.51222223 -0.15852289]\n",
      " [-0.99731863 -0.39068821]\n",
      " [-0.09528842  0.00975465]\n",
      " [ 0.99845612  0.10588358]]\n",
      "cost:\n",
      "0.104938\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289 -0.34906578]\n",
      " [ 0.43633222 -0.34906578]\n",
      " [-0.43633222  0.        ]\n",
      " [-0.34906578 -0.17453289]\n",
      " [ 0.69813156 -0.43633222]\n",
      " [ 0.69813156  0.26179933]\n",
      " [-1.22173022  0.34906578]\n",
      " [ 1.22173022  0.34906578]\n",
      " [ 0.43633222  0.08726644]\n",
      " [-0.69813156 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.178258   -0.27403998]\n",
      " [ 0.44690534 -0.27009574]\n",
      " [-0.46484369  0.02914482]\n",
      " [-0.39837202 -0.15151872]\n",
      " [ 0.84993631 -0.33613878]\n",
      " [ 0.84798527  0.25475669]\n",
      " [-0.99967837  0.26357284]\n",
      " [ 0.99563158  0.25212282]\n",
      " [ 0.41349745  0.11097641]\n",
      " [-0.89922011 -0.34753764]]\n",
      "cost:\n",
      "0.131857\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378  0.        ]\n",
      " [-0.34906578 -0.08726644]\n",
      " [-0.17453289  0.        ]\n",
      " [-0.34906578  0.34906578]\n",
      " [ 0.69813156  0.08726644]\n",
      " [-0.785398    0.        ]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [-0.69813156 -0.43633222]\n",
      " [ 0.         -0.08726644]\n",
      " [-0.52359867  0.34906578]]\n",
      "prediction:\n",
      "[[-0.99410027 -0.0546042 ]\n",
      " [-0.27280173 -0.12215864]\n",
      " [-0.16088235 -0.01951843]\n",
      " [-0.30099615  0.30601773]\n",
      " [ 0.88588184  0.05408033]\n",
      " [-0.85975921 -0.03469171]\n",
      " [ 0.99981326 -0.22401878]\n",
      " [-0.69635999 -0.5361445 ]\n",
      " [ 0.07053983 -0.11922059]\n",
      " [-0.37194863  0.31765807]]\n",
      "cost:\n",
      "0.107113\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867  0.26179933]\n",
      " [-1.13446378 -0.17453289]\n",
      " [-0.52359867 -0.34906578]\n",
      " [-1.22173022  0.34906578]\n",
      " [-0.34906578  0.26179933]\n",
      " [-0.26179933  0.17453289]\n",
      " [-0.34906578  0.        ]\n",
      " [-1.13446378  0.17453289]\n",
      " [-0.95993089  0.17453289]\n",
      " [-0.785398    0.34906578]]\n",
      "prediction:\n",
      "[[-0.79590893  0.10716121]\n",
      " [ 0.999883   -0.35958225]\n",
      " [-0.87189871 -0.56557953]\n",
      " [ 0.93669224  0.15429686]\n",
      " [-0.53938127  0.11770618]\n",
      " [-0.02042275  0.05947732]\n",
      " [-0.68555975 -0.11061575]\n",
      " [-0.32189476  0.04967733]\n",
      " [-0.95744401  0.0467861 ]\n",
      " [-0.52120793  0.17063352]]\n",
      "cost:\n",
      "0.716181\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444  0.08726644]\n",
      " [ 0.26179933 -0.34906578]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [ 0.08726644  0.17453289]\n",
      " [ 1.04719733 -0.26179933]\n",
      " [-0.69813156  0.26179933]\n",
      " [ 1.04719733  0.        ]\n",
      " [ 0.26179933  0.34906578]\n",
      " [-0.52359867  0.08726644]\n",
      " [ 0.26179933  0.        ]]\n",
      "prediction:\n",
      "[[ 0.83156669  0.05123839]\n",
      " [ 0.3930108  -0.52104092]\n",
      " [ 0.59890854 -0.14854737]\n",
      " [ 0.10272808  0.11286789]\n",
      " [ 0.90705675 -0.38432032]\n",
      " [-0.99984992  0.21011311]\n",
      " [ 0.97067827 -0.04839548]\n",
      " [ 0.24838848  0.3223514 ]\n",
      " [-0.94604671  0.02384711]\n",
      " [ 0.1580493  -0.04157238]]\n",
      "cost:\n",
      "0.154862\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378 -0.26179933]\n",
      " [-0.34906578 -0.43633222]\n",
      " [ 0.785398    0.34906578]\n",
      " [-0.61086511  0.26179933]\n",
      " [ 1.04719733  0.26179933]\n",
      " [ 0.26179933  0.34906578]\n",
      " [-0.61086511  0.34906578]\n",
      " [-0.61086511  0.34906578]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [-0.08726644  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.99567986 -0.32078549]\n",
      " [-0.64055097 -0.53134596]\n",
      " [ 0.78840816  0.16339852]\n",
      " [-0.98428065  0.06291506]\n",
      " [ 0.9910112   0.11080082]\n",
      " [ 0.26017103  0.20420301]\n",
      " [-0.97716206  0.13829826]\n",
      " [-0.97715712  0.13828334]\n",
      " [ 0.56530023 -0.34985656]\n",
      " [-0.26131377  0.01166872]]\n",
      "cost:\n",
      "0.250454\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578 -0.34906578]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [-0.61086511 -0.17453289]\n",
      " [ 0.         -0.43633222]\n",
      " [ 1.13446378  0.17453289]\n",
      " [ 0.61086511  0.26179933]\n",
      " [-0.95993089 -0.34906578]\n",
      " [-0.26179933  0.34906578]\n",
      " [ 0.          0.        ]\n",
      " [ 0.52359867 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.30056629 -0.29045811]\n",
      " [ 0.07547182 -0.2071203 ]\n",
      " [-0.69467878 -0.14127962]\n",
      " [-0.00263835 -0.36046398]\n",
      " [ 0.99929065  0.21063988]\n",
      " [ 0.65173781  0.28550357]\n",
      " [-0.99949312 -0.32509309]\n",
      " [-0.26380834  0.37831464]\n",
      " [-0.04166403  0.02411032]\n",
      " [ 0.5191406  -0.04704329]]\n",
      "cost:\n",
      "0.0649437\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156  0.34906578]\n",
      " [ 0.         -0.08726644]\n",
      " [-0.43633222 -0.43633222]\n",
      " [-1.13446378 -0.34906578]\n",
      " [-0.08726644  0.17453289]\n",
      " [-0.34906578  0.08726644]\n",
      " [ 0.95993089 -0.34906578]\n",
      " [-1.22173022  0.        ]\n",
      " [-0.43633222  0.17453289]\n",
      " [ 0.69813156 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.71130347  0.41075242]\n",
      " [-0.10326485 -0.11054323]\n",
      " [-0.46502438 -0.39307708]\n",
      " [-0.97626668 -0.29371375]\n",
      " [-0.14453281  0.16795295]\n",
      " [-0.40582255  0.08079714]\n",
      " [ 0.99979925 -0.31284642]\n",
      " [-0.95993495  0.00954951]\n",
      " [-0.46779105  0.19922601]\n",
      " [ 0.95525575 -0.22970936]]\n",
      "cost:\n",
      "0.111815\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.         -0.26179933]\n",
      " [-1.13446378  0.34906578]\n",
      " [-0.87266444 -0.34906578]\n",
      " [ 0.          0.34906578]\n",
      " [ 0.08726644  0.        ]\n",
      " [ 0.26179933 -0.08726644]\n",
      " [-0.61086511  0.34906578]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [ 0.87266444  0.        ]]\n",
      "prediction:\n",
      "[[-0.03257238 -0.27753207]\n",
      " [-0.99866617  0.25955522]\n",
      " [-0.97433466 -0.42899144]\n",
      " [-0.04254898  0.32917571]\n",
      " [ 0.09151665  0.01841525]\n",
      " [ 0.24808687 -0.06407522]\n",
      " [-0.62744606  0.27556005]\n",
      " [ 0.99215335 -0.21135788]\n",
      " [ 0.36854205 -0.2832807 ]\n",
      " [ 0.99434048 -0.01856888]]\n",
      "cost:\n",
      "0.077342\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867 -0.26179933]\n",
      " [-1.04719733  0.26179933]\n",
      " [-0.26179933  0.        ]\n",
      " [-1.13446378  0.        ]\n",
      " [ 0.34906578  0.08726644]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [-1.04719733  0.34906578]\n",
      " [ 0.17453289  0.26179933]\n",
      " [-0.95993089  0.        ]\n",
      " [-0.43633222 -0.43633222]]\n",
      "prediction:\n",
      "[[ -6.79845691e-01  -3.16314071e-01]\n",
      " [ -9.21765506e-01   2.21592873e-01]\n",
      " [ -3.68099630e-01   1.62124634e-05]\n",
      " [ -8.13965023e-01  -4.49023619e-02]\n",
      " [  9.98054326e-01   6.64007589e-02]\n",
      " [  9.98138726e-01  -2.42128119e-01]\n",
      " [ -9.05270815e-01   2.88845807e-01]\n",
      " [  6.27182066e-01   2.44070560e-01]\n",
      " [ -9.42479730e-01  -2.10352801e-02]\n",
      " [ -5.95761180e-01  -5.26412189e-01]]\n",
      "cost:\n",
      "0.284666\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156 -0.17453289]\n",
      " [-0.26179933 -0.34906578]\n",
      " [ 0.08726644  0.26179933]\n",
      " [-0.61086511  0.26179933]\n",
      " [-1.22173022 -0.08726644]\n",
      " [ 0.61086511 -0.17453289]\n",
      " [ 0.61086511 -0.26179933]\n",
      " [-0.52359867 -0.26179933]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [-0.34906578  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.98816776 -0.13616608]\n",
      " [-0.17589878 -0.41204187]\n",
      " [ 0.08695628  0.3565205 ]\n",
      " [-0.64237702  0.35399944]\n",
      " [-0.99985027 -0.00963762]\n",
      " [ 0.9007265  -0.14870434]\n",
      " [ 0.93974727 -0.25700086]\n",
      " [-0.43862471 -0.27484348]\n",
      " [ 0.43075988 -0.06495562]\n",
      " [-0.34546658  0.20634623]]\n",
      "cost:\n",
      "0.158721\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511 -0.08726644]\n",
      " [ 0.         -0.08726644]\n",
      " [-0.69813156 -0.34906578]\n",
      " [-0.34906578  0.34906578]\n",
      " [-0.26179933  0.        ]\n",
      " [ 0.08726644  0.34906578]\n",
      " [-0.26179933  0.34906578]\n",
      " [ 0.08726644 -0.08726644]\n",
      " [ 0.785398   -0.17453289]\n",
      " [-1.13446378  0.08726644]]\n",
      "prediction:\n",
      "[[-0.50562131 -0.12098766]\n",
      " [ 0.03729304 -0.09330113]\n",
      " [-0.77079564 -0.54916602]\n",
      " [-0.28032604  0.24679455]\n",
      " [-0.19027682 -0.01330095]\n",
      " [ 0.13608995  0.27998093]\n",
      " [-0.18843725  0.26109713]\n",
      " [ 0.12522747 -0.10522662]\n",
      " [ 0.99989188 -0.26736894]\n",
      " [-0.99620861  0.01130038]]\n",
      "cost:\n",
      "0.118976\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156  0.26179933]\n",
      " [-1.13446378 -0.08726644]\n",
      " [ 0.         -0.43633222]\n",
      " [-0.08726644  0.26179933]\n",
      " [ 0.17453289  0.26179933]\n",
      " [-0.43633222 -0.17453289]\n",
      " [ 0.         -0.17453289]\n",
      " [-0.08726644  0.08726644]\n",
      " [ 0.52359867  0.26179933]\n",
      " [-0.08726644 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.99900413  0.23701715]\n",
      " [-0.99968851 -0.1165247 ]\n",
      " [-0.0205235  -0.50009435]\n",
      " [-0.11334775  0.2309597 ]\n",
      " [ 0.20552364  0.23638226]\n",
      " [-0.511446   -0.19798125]\n",
      " [-0.02184916 -0.18269743]\n",
      " [-0.07948512  0.06879392]\n",
      " [ 0.82928002  0.23191696]\n",
      " [-0.15522496 -0.28813487]]\n",
      "cost:\n",
      "0.108934\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398   -0.43633222]\n",
      " [-0.95993089  0.34906578]\n",
      " [ 0.         -0.17453289]\n",
      " [ 0.43633222 -0.43633222]\n",
      " [ 1.13446378  0.17453289]\n",
      " [ 1.04719733 -0.34906578]\n",
      " [-0.43633222  0.17453289]\n",
      " [-0.43633222  0.08726644]\n",
      " [ 0.34906578 -0.43633222]\n",
      " [-1.13446378  0.26179933]]\n",
      "prediction:\n",
      "[[-0.78035951 -0.34004924]\n",
      " [-0.97044581  0.35299695]\n",
      " [-0.04234108 -0.15109903]\n",
      " [ 0.40851766 -0.3276422 ]\n",
      " [ 0.99653804  0.20059714]\n",
      " [ 0.99486798 -0.21711199]\n",
      " [-0.35156661  0.19018617]\n",
      " [-0.30461249  0.09466129]\n",
      " [ 0.34015957 -0.32707921]\n",
      " [-0.99660641  0.24537301]]\n",
      "cost:\n",
      "0.101712\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.08726644]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [-1.22173022 -0.43633222]\n",
      " [ 0.87266444  0.08726644]\n",
      " [ 0.785398    0.26179933]\n",
      " [-0.17453289  0.        ]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [ 0.87266444  0.26179933]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [-0.52359867 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.99916977 -0.0397291 ]\n",
      " [ 0.96063995 -0.17171422]\n",
      " [-0.99495512 -0.32376051]\n",
      " [ 0.83761984  0.13132071]\n",
      " [ 0.73962641  0.36530966]\n",
      " [-0.16217561  0.02736559]\n",
      " [ 0.54096067 -0.32052732]\n",
      " [ 0.84380275  0.38588437]\n",
      " [ 0.92019939 -0.11487366]\n",
      " [-0.57728612 -0.28737766]]\n",
      "cost:\n",
      "0.142223\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.26179933 -0.26179933]\n",
      " [-0.08726644  0.26179933]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [ 0.52359867 -0.08726644]\n",
      " [-0.34906578  0.34906578]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [-0.17453289 -0.43633222]\n",
      " [ 0.61086511  0.34906578]\n",
      " [ 1.13446378 -0.34906578]\n",
      " [ 0.61086511 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.22215375 -0.18631409]\n",
      " [-0.25233999  0.26648301]\n",
      " [ 0.66667926 -0.2184654 ]\n",
      " [ 0.41895598 -0.03401892]\n",
      " [-0.9999162   0.34953228]\n",
      " [-0.0300641  -0.1274889 ]\n",
      " [-0.29222679 -0.31526652]\n",
      " [ 0.53649992  0.36297044]\n",
      " [ 0.99268389 -0.18343617]\n",
      " [ 0.55387557 -0.28996807]]\n",
      "cost:\n",
      "0.198253\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578 -0.34906578]\n",
      " [-0.43633222  0.34906578]\n",
      " [-0.95993089  0.        ]\n",
      " [ 0.69813156  0.34906578]\n",
      " [-0.87266444  0.34906578]\n",
      " [-0.26179933 -0.17453289]\n",
      " [-0.87266444  0.        ]\n",
      " [-0.08726644  0.17453289]\n",
      " [-1.13446378 -0.34906578]\n",
      " [-0.26179933  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.54799825 -0.47508481]\n",
      " [-0.49532863  0.19362418]\n",
      " [-0.81151015 -0.04769044]\n",
      " [ 0.99995106  0.17135753]\n",
      " [-0.82989192  0.20328684]\n",
      " [-0.33163249 -0.23876892]\n",
      " [-0.65211403 -0.04639221]\n",
      " [-0.10323626  0.07377921]\n",
      " [-0.93122733 -0.43996918]\n",
      " [-0.2650882   0.20888145]]\n",
      "cost:\n",
      "0.184495\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511 -0.34906578]\n",
      " [-1.04719733  0.26179933]\n",
      " [-0.26179933  0.08726644]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [ 0.95993089 -0.26179933]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [ 0.          0.17453289]\n",
      " [ 0.61086511 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.43766573 -0.34701237]\n",
      " [-0.99996299  0.47157967]\n",
      " [-0.23940648  0.13603434]\n",
      " [ 0.75257379 -0.05124493]\n",
      " [ 0.28115433 -0.25584802]\n",
      " [ 0.79088658 -0.25531074]\n",
      " [ 0.81721032 -0.15450898]\n",
      " [ 0.82249141 -0.0462923 ]\n",
      " [ 0.01888127  0.25409317]\n",
      " [ 0.43766573 -0.34701237]]\n",
      "cost:\n",
      "0.134714\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089 -0.34906578]\n",
      " [-0.87266444 -0.17453289]\n",
      " [-0.69813156 -0.17453289]\n",
      " [ 0.         -0.34906578]\n",
      " [ 0.26179933 -0.34906578]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [-0.52359867 -0.26179933]\n",
      " [-1.04719733 -0.26179933]\n",
      " [ 0.61086511 -0.34906578]\n",
      " [-0.52359867  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.99509442 -0.26109552]\n",
      " [-0.97245365 -0.04420238]\n",
      " [-0.77465689 -0.03277117]\n",
      " [-0.0523038  -0.24017605]\n",
      " [ 0.22408703 -0.26146221]\n",
      " [ 0.99747324  0.11375319]\n",
      " [-0.55711389 -0.1345482 ]\n",
      " [-0.99318486 -0.11934794]\n",
      " [ 0.63910651 -0.23776257]\n",
      " [-0.57363027  0.5812996 ]]\n",
      "cost:\n",
      "0.173598\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444  0.26179933]\n",
      " [ 1.13446378  0.26179933]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [-0.34906578  0.26179933]\n",
      " [-1.22173022 -0.26179933]\n",
      " [ 1.22173022 -0.43633222]\n",
      " [-1.22173022 -0.34906578]\n",
      " [-0.95993089 -0.43633222]\n",
      " [-0.87266444  0.34906578]\n",
      " [ 0.34906578  0.        ]]\n",
      "prediction:\n",
      "[[ 0.9581185   0.20765634]\n",
      " [ 0.99664801  0.21876138]\n",
      " [ 0.45869657 -0.09866897]\n",
      " [-0.37940672  0.19982906]\n",
      " [-0.99165231 -0.24768566]\n",
      " [ 0.9688893  -0.35816291]\n",
      " [-0.97349793 -0.30820647]\n",
      " [-0.91804254 -0.40107447]\n",
      " [-0.86177599  0.27116543]\n",
      " [ 0.44063559 -0.01465987]]\n",
      "cost:\n",
      "0.131252\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733 -0.26179933]\n",
      " [ 0.43633222 -0.34906578]\n",
      " [ 1.22173022  0.08726644]\n",
      " [-1.04719733 -0.34906578]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [-0.61086511  0.34906578]\n",
      " [-0.69813156 -0.26179933]\n",
      " [ 0.52359867 -0.08726644]\n",
      " [ 1.13446378  0.        ]\n",
      " [-0.17453289  0.34906578]]\n",
      "prediction:\n",
      "[[-0.99064404 -0.25184673]\n",
      " [ 0.42338398 -0.35064131]\n",
      " [ 0.99574232  0.11497975]\n",
      " [-0.99081522 -0.33537349]\n",
      " [ 0.12945414 -0.15377854]\n",
      " [-0.62361246  0.34925333]\n",
      " [-0.73278624 -0.25206226]\n",
      " [ 0.50871176 -0.05481381]\n",
      " [ 0.99559027  0.0255471 ]\n",
      " [-0.25126389  0.34779993]]\n",
      "cost:\n",
      "0.070819\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444  0.17453289]\n",
      " [-0.43633222 -0.34906578]\n",
      " [ 0.61086511 -0.26179933]\n",
      " [ 0.34906578  0.        ]\n",
      " [-0.87266444 -0.08726644]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [ 0.08726644  0.        ]\n",
      " [ 0.34906578  0.08726644]\n",
      " [ 1.22173022  0.        ]\n",
      " [-1.04719733  0.17453289]]\n",
      "prediction:\n",
      "[[-0.94555122  0.27381673]\n",
      " [-0.45464045 -0.51360792]\n",
      " [ 0.71453249 -0.38196379]\n",
      " [ 0.33586439 -0.01582131]\n",
      " [-0.93568349 -0.09506312]\n",
      " [ 0.43773735 -0.12140001]\n",
      " [ 0.04490203 -0.02062165]\n",
      " [ 0.35917312  0.11146077]\n",
      " [ 0.99975681  0.02396986]\n",
      " [-0.99121833  0.24867044]]\n",
      "cost:\n",
      "0.0955192\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378 -0.08726644]\n",
      " [ 0.95993089  0.08726644]\n",
      " [-0.87266444  0.17453289]\n",
      " [ 1.04719733  0.26179933]\n",
      " [-1.13446378 -0.26179933]\n",
      " [-0.61086511  0.        ]\n",
      " [-0.17453289 -0.26179933]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [ 0.17453289 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.95938456 -0.07584231]\n",
      " [ 0.88798177  0.15960391]\n",
      " [-0.97926247  0.25051895]\n",
      " [ 0.93950438  0.39195928]\n",
      " [-0.99959797 -0.33441833]\n",
      " [-0.63914734  0.02855791]\n",
      " [-0.14322598 -0.30405575]\n",
      " [ 0.58509099 -0.16778956]\n",
      " [ 0.88403422 -0.17770515]\n",
      " [ 0.2204252  -0.30336562]]\n",
      "cost:\n",
      "0.10744\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.17453289]\n",
      " [ 0.         -0.26179933]\n",
      " [ 1.04719733 -0.17453289]\n",
      " [ 0.61086511 -0.17453289]\n",
      " [ 1.04719733 -0.17453289]\n",
      " [-1.13446378 -0.43633222]\n",
      " [-0.61086511 -0.43633222]\n",
      " [-1.22173022 -0.34906578]\n",
      " [-1.04719733  0.26179933]\n",
      " [-0.87266444  0.26179933]]\n",
      "prediction:\n",
      "[[-0.89833105 -0.04342851]\n",
      " [-0.1286806  -0.20935284]\n",
      " [ 0.99816769 -0.0754488 ]\n",
      " [ 0.60623872 -0.09110946]\n",
      " [ 0.99816769 -0.0754488 ]\n",
      " [-0.89693177 -0.28775737]\n",
      " [-0.56860614 -0.31319773]\n",
      " [-0.87462378 -0.19721057]\n",
      " [-0.92031091  0.39593837]\n",
      " [-0.8126089   0.38398179]]\n",
      "cost:\n",
      "0.182371\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444  0.34906578]\n",
      " [ 0.69813156  0.08726644]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [ 0.785398    0.34906578]\n",
      " [-0.17453289 -0.17453289]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [-0.34906578  0.08726644]\n",
      " [ 0.43633222  0.        ]\n",
      " [ 0.95993089 -0.26179933]\n",
      " [ 0.52359867 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.89082527  0.32699659]\n",
      " [ 0.76987147  0.07703423]\n",
      " [ 0.03842562 -0.31921503]\n",
      " [ 0.74369359  0.32830828]\n",
      " [-0.59130925 -0.19104822]\n",
      " [ 0.22218554 -0.1969232 ]\n",
      " [-0.99995452  0.10423458]\n",
      " [ 0.38944504 -0.00433606]\n",
      " [ 0.85541117 -0.37343732]\n",
      " [ 0.54224491 -0.20114657]]\n",
      "cost:\n",
      "0.157639\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511  0.17453289]\n",
      " [-0.95993089  0.        ]\n",
      " [-0.61086511  0.26179933]\n",
      " [-0.52359867  0.34906578]\n",
      " [ 0.87266444  0.34906578]\n",
      " [-0.95993089 -0.08726644]\n",
      " [ 1.22173022 -0.34906578]\n",
      " [-0.34906578  0.17453289]\n",
      " [-0.26179933  0.34906578]\n",
      " [ 0.43633222 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.5891816   0.0312447 ]\n",
      " [-0.98426014 -0.07237525]\n",
      " [-0.59319162  0.10769316]\n",
      " [-0.51675618  0.19600408]\n",
      " [ 0.9838717   0.17746857]\n",
      " [-0.97359902 -0.16826616]\n",
      " [ 0.99954432 -0.39104831]\n",
      " [-0.30943927  0.05418848]\n",
      " [-0.21172111  0.2103056 ]\n",
      " [ 0.36912081 -0.50363189]]\n",
      "cost:\n",
      "0.141168\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644  0.17453289]\n",
      " [ 1.13446378 -0.08726644]\n",
      " [ 0.61086511  0.        ]\n",
      " [ 0.34906578 -0.08726644]\n",
      " [-0.785398    0.17453289]\n",
      " [ 1.22173022  0.08726644]\n",
      " [ 1.22173022 -0.43633222]\n",
      " [-0.87266444  0.26179933]\n",
      " [ 0.69813156  0.17453289]\n",
      " [ 0.52359867 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.11820459  0.17469162]\n",
      " [ 0.93790615 -0.16116937]\n",
      " [ 0.56112528 -0.03437413]\n",
      " [ 0.36100349 -0.11217779]\n",
      " [-0.99500054  0.15567288]\n",
      " [ 0.95691627  0.05455422]\n",
      " [ 0.81528026 -0.46130309]\n",
      " [-0.99946517  0.28976581]\n",
      " [ 0.64485991  0.17809999]\n",
      " [ 0.53907841 -0.41653892]]\n",
      "cost:\n",
      "0.146597\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933 -0.17453289]\n",
      " [-1.22173022 -0.08726644]\n",
      " [ 0.52359867 -0.43633222]\n",
      " [-0.26179933 -0.34906578]\n",
      " [-0.17453289 -0.26179933]\n",
      " [-0.61086511 -0.17453289]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [ 1.13446378  0.34906578]\n",
      " [-1.22173022  0.08726644]\n",
      " [-1.22173022  0.17453289]]\n",
      "prediction:\n",
      "[[-0.27378953 -0.1249783 ]\n",
      " [-0.90686327  0.00796826]\n",
      " [ 0.45336661 -0.40663064]\n",
      " [-0.28253901 -0.32466719]\n",
      " [-0.20264558 -0.23051313]\n",
      " [-0.55071139 -0.12063054]\n",
      " [ 0.7811799  -0.02456013]\n",
      " [ 0.99989575  0.40434808]\n",
      " [-0.92745662  0.18138793]\n",
      " [-0.96117365  0.26113337]]\n",
      "cost:\n",
      "0.152155\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378  0.34906578]\n",
      " [ 1.04719733 -0.43633222]\n",
      " [ 0.08726644 -0.43633222]\n",
      " [-0.26179933 -0.08726644]\n",
      " [-1.22173022  0.34906578]\n",
      " [-1.13446378  0.34906578]\n",
      " [-0.52359867 -0.34906578]\n",
      " [-0.43633222  0.        ]\n",
      " [-0.17453289  0.08726644]\n",
      " [ 0.26179933  0.        ]]\n",
      "prediction:\n",
      "[[ 0.99783486  0.23344149]\n",
      " [ 0.99272996 -0.38623759]\n",
      " [ 0.12971853 -0.41282219]\n",
      " [-0.26272935 -0.08181022]\n",
      " [-0.98975766  0.24815986]\n",
      " [-0.99324614  0.27217323]\n",
      " [-0.42801729 -0.32642016]\n",
      " [-0.38190433  0.00774925]\n",
      " [-0.15107913  0.07355299]\n",
      " [ 0.39732608 -0.01149708]]\n",
      "cost:\n",
      "0.10372\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933  0.26179933]\n",
      " [ 0.785398    0.08726644]\n",
      " [ 0.34906578  0.        ]\n",
      " [-0.87266444  0.08726644]\n",
      " [ 0.43633222  0.08726644]\n",
      " [ 0.87266444 -0.34906578]\n",
      " [ 1.04719733  0.08726644]\n",
      " [ 0.61086511  0.        ]\n",
      " [-0.87266444 -0.08726644]\n",
      " [ 0.43633222 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.30077291  0.30880702]\n",
      " [ 0.87205821  0.10064124]\n",
      " [ 0.32463324 -0.02189359]\n",
      " [-0.99781287  0.0843629 ]\n",
      " [ 0.40453321  0.07473069]\n",
      " [ 0.90909743 -0.43210411]\n",
      " [ 0.98901701  0.10882995]\n",
      " [ 0.57555807 -0.03049931]\n",
      " [-0.99802142 -0.11889706]\n",
      " [ 0.28398946 -0.50653398]]\n",
      "cost:\n",
      "0.0837327\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867  0.        ]\n",
      " [-0.95993089 -0.26179933]\n",
      " [-1.04719733 -0.08726644]\n",
      " [ 1.04719733  0.        ]\n",
      " [-0.95993089  0.34906578]\n",
      " [ 0.43633222  0.17453289]\n",
      " [-1.22173022  0.26179933]\n",
      " [-0.08726644 -0.34906578]\n",
      " [-0.785398    0.34906578]\n",
      " [-0.61086511 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.44081044 -0.01377817]\n",
      " [-0.7393707  -0.32375556]\n",
      " [-0.80991769 -0.11522744]\n",
      " [ 0.99996221 -0.07817869]\n",
      " [-0.66917479  0.28454095]\n",
      " [ 0.48539218  0.14550909]\n",
      " [-0.87825334  0.20039311]\n",
      " [-0.11408527 -0.37623703]\n",
      " [-0.53600615  0.28058451]\n",
      " [-0.47283646 -0.38589111]]\n",
      "cost:\n",
      "0.17867\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156 -0.34906578]\n",
      " [-1.22173022 -0.34906578]\n",
      " [ 0.69813156  0.17453289]\n",
      " [-0.08726644  0.08726644]\n",
      " [ 0.785398    0.26179933]\n",
      " [-0.26179933 -0.43633222]\n",
      " [ 0.52359867  0.17453289]\n",
      " [ 0.95993089  0.26179933]\n",
      " [-1.04719733  0.34906578]\n",
      " [ 0.87266444 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.6809746  -0.34299791]\n",
      " [-0.99460399 -0.31572074]\n",
      " [ 0.73696673  0.1179075 ]\n",
      " [-0.00870553  0.06650869]\n",
      " [ 0.870848    0.18892173]\n",
      " [-0.24645177 -0.42041263]\n",
      " [ 0.50061238  0.13629161]\n",
      " [ 0.99164373  0.22753252]\n",
      " [-0.99784523  0.25940457]\n",
      " [ 0.9539969  -0.25420442]]\n",
      "cost:\n",
      "0.0807439\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.22173022 -0.17453289]\n",
      " [ 0.52359867 -0.43633222]\n",
      " [ 0.34906578  0.26179933]\n",
      " [-0.61086511  0.34906578]\n",
      " [-0.95993089 -0.08726644]\n",
      " [ 0.87266444  0.34906578]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [ 0.785398    0.17453289]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [ 0.26179933  0.08726644]]\n",
      "prediction:\n",
      "[[-0.99877441 -0.25928554]\n",
      " [ 0.52083302 -0.46387154]\n",
      " [ 0.3676188   0.22593281]\n",
      " [-0.59554172  0.30074799]\n",
      " [-0.99532121 -0.12744179]\n",
      " [ 0.89466256  0.291677  ]\n",
      " [ 0.98825783 -0.23809214]\n",
      " [ 0.87043458  0.14200422]\n",
      " [ 0.67696667 -0.20556149]\n",
      " [ 0.28696397  0.05630902]]\n",
      "cost:\n",
      "0.088274\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644 -0.43633222]\n",
      " [ 0.785398    0.17453289]\n",
      " [-1.22173022 -0.43633222]\n",
      " [-0.08726644  0.26179933]\n",
      " [ 0.43633222  0.08726644]\n",
      " [ 0.87266444 -0.34906578]\n",
      " [-1.22173022  0.34906578]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [ 1.04719733 -0.34906578]\n",
      " [-0.95993089 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.17590997 -0.34665453]\n",
      " [ 0.84623688  0.23628864]\n",
      " [-0.98993307 -0.26294157]\n",
      " [-0.09620088  0.29394689]\n",
      " [ 0.51811838  0.11669558]\n",
      " [ 0.88670206 -0.23239708]\n",
      " [-0.9934181   0.384534  ]\n",
      " [ 0.98357362 -0.12158179]\n",
      " [ 0.97458589 -0.21660808]\n",
      " [-0.98131919 -0.23185882]]\n",
      "cost:\n",
      "0.151767\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156 -0.43633222]\n",
      " [ 0.95993089  0.17453289]\n",
      " [-0.43633222 -0.43633222]\n",
      " [ 0.26179933  0.34906578]\n",
      " [ 0.43633222  0.26179933]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [-0.26179933 -0.34906578]\n",
      " [-0.34906578 -0.43633222]\n",
      " [-0.34906578  0.34906578]\n",
      " [-1.13446378 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.79873586 -0.26001722]\n",
      " [ 0.99954087  0.18046996]\n",
      " [-0.3682141  -0.26950419]\n",
      " [ 0.22210157  0.34121862]\n",
      " [ 0.43857348  0.24424948]\n",
      " [ 0.81654203 -0.21031024]\n",
      " [-0.17180644 -0.23345585]\n",
      " [-0.26997676 -0.26878843]\n",
      " [-0.30407116  0.32179475]\n",
      " [-0.99890792 -0.22262558]]\n",
      "cost:\n",
      "0.130129\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644 -0.08726644]\n",
      " [ 0.34906578  0.26179933]\n",
      " [-0.26179933 -0.08726644]\n",
      " [-0.43633222 -0.34906578]\n",
      " [-0.87266444 -0.26179933]\n",
      " [-0.17453289 -0.43633222]\n",
      " [ 0.43633222 -0.43633222]\n",
      " [-0.95993089  0.34906578]\n",
      " [ 0.69813156  0.17453289]\n",
      " [ 0.26179933 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.12379473 -0.04581276]\n",
      " [ 0.46403867  0.3319042 ]\n",
      " [-0.29727045 -0.02230267]\n",
      " [-0.36706474 -0.2080036 ]\n",
      " [-0.97367746 -0.13452965]\n",
      " [-0.12221102 -0.30131447]\n",
      " [ 0.68920845 -0.27613223]\n",
      " [-0.99507886  0.41267309]\n",
      " [ 0.99973744  0.19617508]\n",
      " [ 0.31038374 -0.30556944]]\n",
      "cost:\n",
      "0.154227\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378  0.34906578]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [ 0.61086511  0.34906578]\n",
      " [ 0.34906578  0.08726644]\n",
      " [ 0.08726644  0.26179933]\n",
      " [-0.43633222 -0.17453289]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [-0.08726644  0.08726644]\n",
      " [ 0.34906578 -0.08726644]\n",
      " [-0.08726644  0.34906578]]\n",
      "prediction:\n",
      "[[-0.99982488  0.21688366]\n",
      " [ 0.5696274  -0.21113324]\n",
      " [ 0.5585826   0.25157848]\n",
      " [ 0.27118513  0.01480835]\n",
      " [ 0.07100856  0.17335297]\n",
      " [-0.48519987 -0.47308168]\n",
      " [ 0.99798059 -0.33354542]\n",
      " [-0.027116    0.01783688]\n",
      " [ 0.26835248 -0.20197065]\n",
      " [-0.06678315  0.23329751]]\n",
      "cost:\n",
      "0.152951\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156 -0.08726644]\n",
      " [ 0.26179933  0.17453289]\n",
      " [ 0.52359867  0.        ]\n",
      " [-0.26179933 -0.34906578]\n",
      " [-0.26179933  0.        ]\n",
      " [-0.95993089 -0.34906578]\n",
      " [-0.69813156 -0.43633222]\n",
      " [ 0.17453289  0.17453289]\n",
      " [-0.61086511  0.26179933]\n",
      " [ 1.13446378  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.79505539 -0.1003899 ]\n",
      " [ 0.24789134  0.18324624]\n",
      " [ 0.49004316 -0.00627191]\n",
      " [-0.23514709 -0.35182512]\n",
      " [-0.24768484  0.01861181]\n",
      " [-0.99877411 -0.35150337]\n",
      " [-0.85004866 -0.41335657]\n",
      " [ 0.157877    0.19213088]\n",
      " [-0.63128555  0.30336845]\n",
      " [ 0.99952972  0.16684355]]\n",
      "cost:\n",
      "0.0596772\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578 -0.43633222]\n",
      " [-0.785398   -0.34906578]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [-0.17453289 -0.08726644]\n",
      " [ 1.22173022 -0.34906578]\n",
      " [ 0.08726644  0.17453289]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [-0.34906578  0.34906578]\n",
      " [-0.08726644  0.08726644]\n",
      " [ 0.43633222  0.        ]]\n",
      "prediction:\n",
      "[[ 0.37501916 -0.33394608]\n",
      " [-0.9999187  -0.25765941]\n",
      " [ 0.86494011 -0.05425052]\n",
      " [-0.17130035 -0.10220437]\n",
      " [ 0.95447874 -0.21820959]\n",
      " [ 0.08490849  0.20603088]\n",
      " [ 0.95386207 -0.2933366 ]\n",
      " [-0.56387317  0.47975761]\n",
      " [-0.04615564  0.07278373]\n",
      " [ 0.39241278  0.00445823]]\n",
      "cost:\n",
      "0.128668\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.         -0.08726644]\n",
      " [-0.87266444 -0.34906578]\n",
      " [-0.34906578  0.17453289]\n",
      " [ 1.13446378  0.34906578]\n",
      " [ 0.08726644 -0.43633222]\n",
      " [-0.17453289  0.26179933]\n",
      " [ 0.34906578 -0.08726644]\n",
      " [-0.785398   -0.34906578]\n",
      " [-1.13446378  0.26179933]\n",
      " [ 0.95993089 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.017506   -0.07466453]\n",
      " [-0.9459247  -0.30575567]\n",
      " [-0.38805142  0.16467984]\n",
      " [ 0.99755597  0.28564188]\n",
      " [ 0.1130361  -0.39293864]\n",
      " [-0.17066956  0.25284308]\n",
      " [ 0.37548068 -0.06327297]\n",
      " [-0.86335611 -0.30282483]\n",
      " [-0.99637002  0.238471  ]\n",
      " [ 0.99478239 -0.25231844]]\n",
      "cost:\n",
      "0.0660488\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511  0.26179933]\n",
      " [ 0.43633222 -0.34906578]\n",
      " [ 0.26179933  0.26179933]\n",
      " [-0.87266444  0.08726644]\n",
      " [-0.52359867  0.        ]\n",
      " [ 0.43633222 -0.43633222]\n",
      " [ 0.34906578  0.34906578]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [ 0.785398    0.17453289]\n",
      " [-0.785398   -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.64664799  0.2048046 ]\n",
      " [ 0.39649129 -0.32432115]\n",
      " [ 0.23585984  0.21221106]\n",
      " [-0.99870884  0.05035317]\n",
      " [-0.58130705 -0.01297972]\n",
      " [ 0.39638147 -0.39365354]\n",
      " [ 0.34575227  0.27998102]\n",
      " [ 0.99713176 -0.15037516]\n",
      " [ 0.90715373  0.13416459]\n",
      " [-0.98981345 -0.41281667]]\n",
      "cost:\n",
      "0.10482\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222  0.        ]\n",
      " [ 0.17453289  0.        ]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [ 0.785398    0.        ]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [ 0.43633222 -0.34906578]\n",
      " [-1.04719733 -0.08726644]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [-0.52359867 -0.34906578]\n",
      " [ 0.26179933 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.41366592  0.31814089]\n",
      " [ 0.14397509  0.07543994]\n",
      " [ 0.94602078 -0.03021527]\n",
      " [ 0.86006629  0.33816427]\n",
      " [ 0.38181242 -0.12950864]\n",
      " [ 0.34534422 -0.33421761]\n",
      " [-0.99993896  0.10032411]\n",
      " [ 0.87073129 -0.40709943]\n",
      " [-0.66792357 -0.3260234 ]\n",
      " [ 0.21214934  0.00801546]]\n",
      "cost:\n",
      "0.176693\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398   -0.26179933]\n",
      " [-0.43633222  0.08726644]\n",
      " [-0.95993089  0.26179933]\n",
      " [ 1.13446378 -0.08726644]\n",
      " [ 0.34906578  0.34906578]\n",
      " [-0.69813156  0.17453289]\n",
      " [-0.34906578  0.08726644]\n",
      " [ 0.43633222 -0.34906578]\n",
      " [ 1.22173022  0.26179933]\n",
      " [ 0.43633222 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.92444897 -0.36047113]\n",
      " [-0.44528469  0.03635138]\n",
      " [-0.99797446  0.23344748]\n",
      " [ 0.99348962 -0.19296849]\n",
      " [ 0.32777309  0.2731573 ]\n",
      " [-0.85110235  0.09765755]\n",
      " [-0.40421355  0.04010705]\n",
      " [ 0.44955641 -0.5119313 ]\n",
      " [ 0.99637818  0.13188007]\n",
      " [ 0.349226   -0.16589135]]\n",
      "cost:\n",
      "0.130931\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511  0.34906578]\n",
      " [ 0.          0.08726644]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [ 0.         -0.17453289]\n",
      " [-0.17453289 -0.26179933]\n",
      " [ 0.785398    0.17453289]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [-0.785398   -0.43633222]\n",
      " [-1.04719733  0.17453289]\n",
      " [ 1.22173022  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.55882877  0.33949739]\n",
      " [ 0.06971988  0.08946198]\n",
      " [ 0.88922828 -0.16152009]\n",
      " [ 0.03530366 -0.14571318]\n",
      " [-0.21481651 -0.25075427]\n",
      " [ 0.73099875  0.1675396 ]\n",
      " [ 0.90470904 -0.39761144]\n",
      " [-0.94458318 -0.40273842]\n",
      " [-0.99983811  0.15135768]\n",
      " [ 0.96958232  0.17671745]]\n",
      "cost:\n",
      "0.103731\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933 -0.26179933]\n",
      " [ 0.26179933 -0.34906578]\n",
      " [ 0.87266444  0.34906578]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [-0.34906578  0.26179933]\n",
      " [ 0.95993089  0.34906578]\n",
      " [ 0.61086511 -0.43633222]\n",
      " [ 0.43633222  0.26179933]\n",
      " [-0.95993089  0.        ]\n",
      " [-0.95993089  0.08726644]]\n",
      "prediction:\n",
      "[[-0.26252645 -0.24491468]\n",
      " [ 0.22053553 -0.34318322]\n",
      " [ 0.97642237  0.22849812]\n",
      " [ 0.35079309 -0.26122355]\n",
      " [-0.33653238  0.20954445]\n",
      " [ 0.9949826   0.23303534]\n",
      " [ 0.62976348 -0.42175883]\n",
      " [ 0.41845006  0.2010694 ]\n",
      " [-0.99720842 -0.04724152]\n",
      " [-0.99610877  0.03628481]]\n",
      "cost:\n",
      "0.060428\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378 -0.26179933]\n",
      " [-0.87266444 -0.08726644]\n",
      " [ 0.52359867  0.17453289]\n",
      " [-0.26179933  0.34906578]\n",
      " [-0.43633222 -0.43633222]\n",
      " [ 0.34906578  0.08726644]\n",
      " [-0.87266444  0.34906578]\n",
      " [-1.04719733  0.34906578]\n",
      " [ 1.04719733  0.        ]\n",
      " [ 0.26179933 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.99835563 -0.30021447]\n",
      " [-0.9702006  -0.07955625]\n",
      " [ 0.60932279  0.11859594]\n",
      " [-0.27938402  0.22193198]\n",
      " [-0.43161356 -0.4614042 ]\n",
      " [ 0.36730725  0.06064908]\n",
      " [-0.93716061  0.21837938]\n",
      " [-0.99427223  0.21924001]\n",
      " [ 0.98476774 -0.02106745]\n",
      " [ 0.30952036 -0.38210163]]\n",
      "cost:\n",
      "0.0937613\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398   -0.34906578]\n",
      " [-0.95993089 -0.26179933]\n",
      " [-0.87266444 -0.17453289]\n",
      " [ 0.52359867  0.26179933]\n",
      " [ 0.         -0.26179933]\n",
      " [-0.69813156 -0.17453289]\n",
      " [-0.95993089 -0.43633222]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [ 0.52359867  0.34906578]\n",
      " [-0.61086511  0.26179933]]\n",
      "prediction:\n",
      "[[-0.73746091 -0.23205572]\n",
      " [-0.94075936 -0.18042345]\n",
      " [-0.88020301 -0.10035467]\n",
      " [ 0.75073439  0.29168457]\n",
      " [-0.08756699 -0.20487341]\n",
      " [-0.62464738 -0.1023229 ]\n",
      " [-0.91536438 -0.30123478]\n",
      " [ 0.99989653 -0.3020862 ]\n",
      " [ 0.76471603  0.36451548]\n",
      " [-0.5220381   0.27964041]]\n",
      "cost:\n",
      "0.138061\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.43633222]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [ 0.69813156  0.34906578]\n",
      " [ 0.785398   -0.43633222]\n",
      " [-0.785398    0.        ]\n",
      " [-1.04719733 -0.17453289]\n",
      " [-0.52359867 -0.08726644]\n",
      " [-1.22173022  0.        ]\n",
      " [ 1.13446378 -0.08726644]\n",
      " [-0.17453289  0.        ]]\n",
      "prediction:\n",
      "[[-0.86735719 -0.38079575]\n",
      " [ 0.19258355 -0.06293895]\n",
      " [ 0.76052707  0.50837147]\n",
      " [ 0.88475126 -0.415232  ]\n",
      " [-0.78250706  0.01930079]\n",
      " [-0.94999105 -0.1383407 ]\n",
      " [-0.51678169 -0.07610122]\n",
      " [-0.97888434  0.07124952]\n",
      " [ 0.99978215 -0.04902142]\n",
      " [-0.23284306  0.00804791]]\n",
      "cost:\n",
      "0.116405\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378  0.34906578]\n",
      " [ 0.785398    0.17453289]\n",
      " [-0.69813156  0.        ]\n",
      " [ 0.26179933 -0.43633222]\n",
      " [ 1.04719733  0.17453289]\n",
      " [ 0.95993089 -0.26179933]\n",
      " [ 0.26179933  0.        ]\n",
      " [-0.61086511 -0.43633222]\n",
      " [ 0.08726644  0.08726644]\n",
      " [ 0.43633222  0.17453289]]\n",
      "prediction:\n",
      "[[-0.99968582  0.29047394]\n",
      " [ 0.83495533  0.13773078]\n",
      " [-0.92718351 -0.04908203]\n",
      " [ 0.23780952 -0.46512687]\n",
      " [ 0.98555011  0.12784165]\n",
      " [ 0.97896367 -0.29828298]\n",
      " [ 0.17420803 -0.03026187]\n",
      " [-0.7204597  -0.44386184]\n",
      " [ 0.02039805  0.06435886]\n",
      " [ 0.37796822  0.1353092 ]]\n",
      "cost:\n",
      "0.0942432\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644  0.        ]\n",
      " [ 0.95993089 -0.43633222]\n",
      " [ 0.         -0.26179933]\n",
      " [-0.785398    0.17453289]\n",
      " [ 0.61086511  0.        ]\n",
      " [-1.04719733  0.34906578]\n",
      " [ 1.13446378 -0.34906578]\n",
      " [-1.13446378 -0.43633222]\n",
      " [ 1.22173022 -0.08726644]\n",
      " [ 0.26179933  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.08129546  0.01455332]\n",
      " [ 0.93668175 -0.37888765]\n",
      " [-0.01478493 -0.25074908]\n",
      " [-0.91140324  0.18439785]\n",
      " [ 0.62358844  0.00188538]\n",
      " [-0.99513417  0.35517722]\n",
      " [ 0.98173362 -0.31736061]\n",
      " [-0.99583703 -0.35638767]\n",
      " [ 0.97926801 -0.07315496]\n",
      " [ 0.34426174  0.27810484]]\n",
      "cost:\n",
      "0.0930778\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156  0.26179933]\n",
      " [-0.69813156  0.08726644]\n",
      " [ 0.785398   -0.34906578]\n",
      " [-0.17453289  0.08726644]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [ 0.69813156  0.        ]\n",
      " [ 1.13446378  0.34906578]\n",
      " [-0.08726644  0.34906578]\n",
      " [ 0.08726644  0.17453289]\n",
      " [-0.34906578 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.59611458  0.14074309]\n",
      " [-0.99994373 -0.01140025]\n",
      " [ 0.70689023 -0.54298341]\n",
      " [-0.10087124  0.02446125]\n",
      " [ 0.92707473 -0.31540823]\n",
      " [ 0.63826942 -0.08381855]\n",
      " [ 0.93333292  0.21471484]\n",
      " [-0.07985579  0.25681013]\n",
      " [ 0.13364139  0.08058214]\n",
      " [-0.4517763  -0.28034812]]\n",
      "cost:\n",
      "0.161617\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.43633222]\n",
      " [-0.52359867 -0.34906578]\n",
      " [-0.61086511 -0.43633222]\n",
      " [-0.785398   -0.08726644]\n",
      " [-0.34906578 -0.17453289]\n",
      " [-0.785398    0.34906578]\n",
      " [ 1.22173022  0.34906578]\n",
      " [ 0.52359867 -0.08726644]\n",
      " [-0.17453289  0.08726644]\n",
      " [-1.04719733  0.17453289]]\n",
      "prediction:\n",
      "[[-0.9087922  -0.36535528]\n",
      " [-0.41022897 -0.30475029]\n",
      " [-0.41115937 -0.3826544 ]\n",
      " [-0.69761682 -0.06670626]\n",
      " [-0.25839037 -0.15681623]\n",
      " [-0.59994888  0.31310043]\n",
      " [ 0.99994433  0.30022761]\n",
      " [ 0.65529668 -0.08261693]\n",
      " [-0.11877336  0.07855701]\n",
      " [-0.9480148   0.15325524]]\n",
      "cost:\n",
      "0.145329\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867  0.08726644]\n",
      " [ 0.52359867  0.17453289]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [-0.26179933  0.17453289]\n",
      " [ 0.785398    0.34906578]\n",
      " [-0.08726644 -0.26179933]\n",
      " [ 0.43633222 -0.43633222]\n",
      " [-0.61086511 -0.26179933]\n",
      " [ 0.         -0.08726644]\n",
      " [ 1.13446378  0.        ]]\n",
      "prediction:\n",
      "[[-0.98270047  0.08995615]\n",
      " [ 0.51232404  0.17852972]\n",
      " [ 0.41990998 -0.0842587 ]\n",
      " [-0.39999253  0.17286302]\n",
      " [ 0.90822095  0.34475049]\n",
      " [-0.1835397  -0.28237796]\n",
      " [ 0.44827089 -0.50704396]\n",
      " [-0.99877483 -0.29532585]\n",
      " [-0.05705438 -0.08581187]\n",
      " [ 0.99843061 -0.02862832]]\n",
      "cost:\n",
      "0.150447\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089  0.34906578]\n",
      " [ 1.04719733  0.        ]\n",
      " [ 0.43633222  0.26179933]\n",
      " [-0.785398   -0.34906578]\n",
      " [-0.34906578  0.26179933]\n",
      " [ 0.08726644  0.        ]\n",
      " [-1.22173022 -0.17453289]\n",
      " [-0.785398   -0.43633222]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [ 0.87266444  0.26179933]]\n",
      "prediction:\n",
      "[[-0.96390855  0.2519131 ]\n",
      " [ 0.99867201 -0.02608828]\n",
      " [ 0.39336354  0.1866795 ]\n",
      " [-0.81647533 -0.35395172]\n",
      " [-0.42311114  0.18419632]\n",
      " [ 0.05074555  0.01657036]\n",
      " [-0.99265522 -0.20674406]\n",
      " [-0.77101064 -0.44763047]\n",
      " [ 0.42780986 -0.26606297]\n",
      " [ 0.99059868  0.17286395]]\n",
      "cost:\n",
      "0.0824553\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867  0.        ]\n",
      " [-0.08726644  0.26179933]\n",
      " [-0.34906578 -0.26179933]\n",
      " [-0.34906578  0.17453289]\n",
      " [ 0.785398   -0.26179933]\n",
      " [ 0.          0.        ]\n",
      " [-0.17453289  0.        ]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [ 0.61086511  0.26179933]\n",
      " [ 0.52359867 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.9996019  -0.02542501]\n",
      " [-0.14297111  0.28431082]\n",
      " [-0.73355752 -0.3082031 ]\n",
      " [-0.6357429   0.17885692]\n",
      " [ 0.99848193 -0.27329877]\n",
      " [-0.04745753 -0.00767664]\n",
      " [-0.16055612 -0.01815194]\n",
      " [ 0.39088926 -0.18638937]\n",
      " [ 0.83940005  0.33652624]\n",
      " [ 0.71603155 -0.4314321 ]]\n",
      "cost:\n",
      "0.198837\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089 -0.34906578]\n",
      " [ 0.17453289  0.08726644]\n",
      " [-0.08726644 -0.34906578]\n",
      " [-0.17453289  0.08726644]\n",
      " [-0.17453289 -0.08726644]\n",
      " [-0.95993089  0.        ]\n",
      " [ 0.08726644 -0.43633222]\n",
      " [-1.13446378 -0.17453289]\n",
      " [ 0.26179933 -0.34906578]\n",
      " [ 0.34906578  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.99975228 -0.27445081]\n",
      " [ 0.19074678  0.15022211]\n",
      " [-0.07323206 -0.26372546]\n",
      " [-0.14874735  0.12998766]\n",
      " [-0.1342977  -0.04179662]\n",
      " [-0.98191005  0.04164158]\n",
      " [ 0.13671879 -0.33489013]\n",
      " [-0.99482381 -0.10595199]\n",
      " [ 0.29038402 -0.2647751 ]\n",
      " [ 0.39477304  0.46177745]]\n",
      "cost:\n",
      "0.0872833\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644 -0.17453289]\n",
      " [ 0.43633222  0.26179933]\n",
      " [ 0.34906578 -0.08726644]\n",
      " [-0.26179933  0.34906578]\n",
      " [-0.43633222 -0.26179933]\n",
      " [ 0.785398    0.17453289]\n",
      " [ 1.04719733 -0.43633222]\n",
      " [-1.22173022 -0.08726644]\n",
      " [-0.34906578 -0.08726644]\n",
      " [-0.26179933 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.02108761 -0.15482248]\n",
      " [ 0.42764726  0.27643701]\n",
      " [ 0.29599679 -0.07337388]\n",
      " [-0.23948966  0.3667784 ]\n",
      " [-0.39371645 -0.26736253]\n",
      " [ 0.95113909  0.17795506]\n",
      " [ 0.99610615 -0.48540875]\n",
      " [-0.99980336 -0.12170742]\n",
      " [-0.32377717 -0.06609427]\n",
      " [-0.21273758 -0.05978671]]\n",
      "cost:\n",
      "0.0762811\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089 -0.43633222]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [-0.69813156 -0.08726644]\n",
      " [-0.61086511 -0.26179933]\n",
      " [-1.22173022  0.08726644]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [ 1.22173022  0.26179933]\n",
      " [ 0.          0.17453289]]\n",
      "prediction:\n",
      "[[-0.96723676 -0.41349849]\n",
      " [ 0.77387619 -0.33959326]\n",
      " [ 0.9750998  -0.058477  ]\n",
      " [-0.69855255 -0.06574846]\n",
      " [-0.55947763 -0.23853673]\n",
      " [-0.99896067  0.18569633]\n",
      " [ 0.15828826 -0.15678604]\n",
      " [ 0.70167243 -0.05332091]\n",
      " [ 0.99483728  0.4162147 ]\n",
      " [-0.00891041  0.27413699]]\n",
      "cost:\n",
      "0.0960832\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.         -0.08726644]\n",
      " [-1.04719733 -0.17453289]\n",
      " [-0.52359867  0.17453289]\n",
      " [ 0.         -0.34906578]\n",
      " [ 0.52359867 -0.08726644]\n",
      " [ 0.95993089  0.08726644]\n",
      " [-0.17453289 -0.34906578]\n",
      " [-1.04719733 -0.26179933]\n",
      " [ 0.43633222 -0.43633222]\n",
      " [-1.13446378 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.04376196 -0.02874225]\n",
      " [-0.96497691 -0.01664787]\n",
      " [-0.45354035  0.47272298]\n",
      " [-0.02424969 -0.26337746]\n",
      " [ 0.54558277 -0.01727901]\n",
      " [ 0.99990237  0.32371095]\n",
      " [-0.26167926 -0.2517724 ]\n",
      " [-0.94407439 -0.13241459]\n",
      " [ 0.40732965 -0.3162851 ]\n",
      " [-0.90983248 -0.26353481]]\n",
      "cost:\n",
      "0.166258\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511 -0.17453289]\n",
      " [-1.13446378 -0.34906578]\n",
      " [-0.34906578 -0.43633222]\n",
      " [-0.95993089 -0.26179933]\n",
      " [ 1.04719733 -0.34906578]\n",
      " [ 0.08726644 -0.08726644]\n",
      " [-0.52359867 -0.08726644]\n",
      " [-0.785398   -0.34906578]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [ 0.08726644 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.60081542 -0.06557165]\n",
      " [-0.99306828  0.23529287]\n",
      " [-0.37725389 -0.47163779]\n",
      " [-0.97686094 -0.03979386]\n",
      " [ 0.9973492  -0.2441773 ]\n",
      " [ 0.07753722  0.12250943]\n",
      " [-0.53066826  0.30535612]\n",
      " [-0.83091134 -0.2976703 ]\n",
      " [ 0.99427527  0.20231058]\n",
      " [ 0.10165814 -0.23633097]]\n",
      "cost:\n",
      "0.21736\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444 -0.17453289]\n",
      " [-0.95993089  0.        ]\n",
      " [-0.17453289 -0.08726644]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [-0.17453289 -0.43633222]\n",
      " [ 1.22173022  0.34906578]\n",
      " [-0.34906578  0.26179933]\n",
      " [-0.785398   -0.43633222]\n",
      " [-0.43633222 -0.26179933]\n",
      " [ 0.61086511 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.98314446 -0.07051762]\n",
      " [-0.99880773  0.05930255]\n",
      " [-0.06869585 -0.03987423]\n",
      " [ 0.336164   -0.17295957]\n",
      " [-0.09015463 -0.32834002]\n",
      " [ 0.99648929  0.41519743]\n",
      " [-0.29319638  0.35046571]\n",
      " [-0.97263259 -0.29164177]\n",
      " [-0.3962287  -0.17047739]\n",
      " [ 0.66119522 -0.29418305]]\n",
      "cost:\n",
      "0.141823\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378 -0.08726644]\n",
      " [-0.26179933  0.08726644]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [ 0.785398   -0.26179933]\n",
      " [ 0.          0.        ]\n",
      " [ 0.17453289  0.34906578]\n",
      " [ 0.785398   -0.43633222]\n",
      " [-0.95993089 -0.34906578]\n",
      " [-0.87266444 -0.08726644]\n",
      " [ 1.04719733 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.93034977 -0.00385794]\n",
      " [-0.17809632  0.11488401]\n",
      " [ 0.94679821 -0.16723558]\n",
      " [ 0.71476758 -0.17745481]\n",
      " [ 0.06092024  0.00183008]\n",
      " [ 0.31495276  0.53711903]\n",
      " [ 0.71589172 -0.33259901]\n",
      " [-0.99917263 -0.24299447]\n",
      " [-0.9962858  -0.04227482]\n",
      " [ 0.9109447  -0.32106644]]\n",
      "cost:\n",
      "0.147243\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.22173022  0.34906578]\n",
      " [-0.08726644 -0.34906578]\n",
      " [-0.08726644 -0.26179933]\n",
      " [-0.87266444 -0.34906578]\n",
      " [ 1.04719733 -0.26179933]\n",
      " [ 0.785398   -0.26179933]\n",
      " [ 0.87266444 -0.26179933]\n",
      " [-1.22173022  0.        ]\n",
      " [-0.08726644 -0.17453289]\n",
      " [-0.52359867 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.97272015  0.56622517]\n",
      " [-0.03727793 -0.27616683]\n",
      " [-0.02112128 -0.18692869]\n",
      " [-0.98499793 -0.28036416]\n",
      " [ 0.97719079 -0.16749625]\n",
      " [ 0.80034697 -0.15233083]\n",
      " [ 0.9111914  -0.16035944]\n",
      " [-0.99929333  0.16799797]\n",
      " [-0.03407064 -0.07635105]\n",
      " [-0.52127683 -0.08440437]]\n",
      "cost:\n",
      "0.146739\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398   -0.34906578]\n",
      " [-0.69813156 -0.34906578]\n",
      " [ 0.26179933 -0.43633222]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [ 0.52359867 -0.17453289]\n",
      " [-0.95993089 -0.26179933]\n",
      " [ 1.13446378  0.        ]\n",
      " [-0.08726644 -0.08726644]\n",
      " [-0.52359867 -0.17453289]\n",
      " [-0.69813156  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.91283834 -0.25371596]\n",
      " [-0.84256345 -0.26180622]\n",
      " [ 0.17987733 -0.38765997]\n",
      " [ 0.08503234 -0.00844582]\n",
      " [ 0.50433552 -0.11118051]\n",
      " [-0.99855232 -0.19158693]\n",
      " [ 0.99941999  0.35399252]\n",
      " [-0.13026652 -0.01472949]\n",
      " [-0.53275263 -0.09280897]\n",
      " [-0.76620001  0.44779477]]\n",
      "cost:\n",
      "0.160114\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444 -0.26179933]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [-0.95993089 -0.26179933]\n",
      " [ 0.61086511  0.17453289]\n",
      " [-0.34906578  0.26179933]\n",
      " [-0.87266444 -0.34906578]\n",
      " [-0.61086511  0.08726644]\n",
      " [ 0.95993089  0.08726644]\n",
      " [ 0.26179933  0.34906578]\n",
      " [-0.95993089 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.8982513  -0.28417385]\n",
      " [ 0.99851972 -0.27687168]\n",
      " [-0.95660663 -0.30255449]\n",
      " [ 0.67810762  0.15895481]\n",
      " [-0.38485777  0.27209622]\n",
      " [-0.89573467 -0.38419122]\n",
      " [-0.62204361  0.07713531]\n",
      " [ 0.99519378  0.06473363]\n",
      " [ 0.30371967  0.37026244]\n",
      " [-0.96277094 -0.09942818]]\n",
      "cost:\n",
      "0.0585122\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733 -0.08726644]\n",
      " [-1.22173022  0.17453289]\n",
      " [-0.95993089 -0.17453289]\n",
      " [-1.04719733  0.34906578]\n",
      " [ 0.52359867  0.17453289]\n",
      " [-0.26179933  0.26179933]\n",
      " [-0.52359867  0.17453289]\n",
      " [-0.61086511  0.26179933]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [-1.13446378  0.08726644]]\n",
      "prediction:\n",
      "[[-0.8372978  -0.16054779]\n",
      " [-0.66833788  0.03562361]\n",
      " [-0.78914481 -0.25968033]\n",
      " [-0.71882296  0.22705764]\n",
      " [ 0.72695398  0.08705435]\n",
      " [-0.25432146  0.16565502]\n",
      " [-0.51800859  0.08826783]\n",
      " [-0.54566294  0.16073447]\n",
      " [ 0.99995583 -0.58984035]\n",
      " [-0.77190983 -0.02249819]]\n",
      "cost:\n",
      "0.243678\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156  0.17453289]\n",
      " [ 1.04719733  0.26179933]\n",
      " [-0.08726644  0.08726644]\n",
      " [ 0.52359867  0.34906578]\n",
      " [-1.22173022 -0.43633222]\n",
      " [-0.26179933 -0.34906578]\n",
      " [-0.26179933  0.26179933]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [ 1.04719733  0.26179933]\n",
      " [-0.95993089 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.82455063  0.09970819]\n",
      " [ 0.99440634  0.19173664]\n",
      " [-0.09080687  0.07719585]\n",
      " [ 0.51252973  0.24731655]\n",
      " [-0.99630624 -0.34534639]\n",
      " [-0.29483938 -0.32545   ]\n",
      " [-0.30454165  0.19038884]\n",
      " [ 0.69776714 -0.30167308]\n",
      " [ 0.99440634  0.19173664]\n",
      " [-0.98489243 -0.35276771]]\n",
      "cost:\n",
      "0.0936915\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289 -0.43633222]\n",
      " [ 1.04719733  0.        ]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [-0.61086511 -0.08726644]\n",
      " [ 0.69813156  0.08726644]\n",
      " [-0.08726644  0.        ]\n",
      " [ 0.785398   -0.17453289]\n",
      " [-0.08726644  0.17453289]\n",
      " [ 0.34906578 -0.08726644]\n",
      " [ 0.87266444  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.20189404 -0.49957919]\n",
      " [ 0.94567358  0.02754166]\n",
      " [ 0.05984913 -0.27997157]\n",
      " [-0.9999615  -0.06324619]\n",
      " [ 0.63601959  0.11156132]\n",
      " [-0.03065847  0.00729591]\n",
      " [ 0.70769805 -0.17441811]\n",
      " [ 0.00191338  0.22520126]\n",
      " [ 0.36144823 -0.0736456 ]\n",
      " [ 0.85978007  0.3907004 ]]\n",
      "cost:\n",
      "0.104883\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398    0.08726644]\n",
      " [-0.69813156  0.26179933]\n",
      " [ 1.04719733  0.        ]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [ 1.13446378  0.34906578]\n",
      " [-0.61086511  0.08726644]\n",
      " [-0.34906578 -0.26179933]\n",
      " [-1.13446378 -0.43633222]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [ 1.22173022 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.75070733  0.09703632]\n",
      " [-0.9254871   0.27768663]\n",
      " [ 0.96229553  0.05175724]\n",
      " [ 0.11722253 -0.15893808]\n",
      " [ 0.9650982   0.37063876]\n",
      " [-0.65215331  0.10017072]\n",
      " [-0.36343545 -0.24986261]\n",
      " [-0.99976838 -0.37757665]\n",
      " [ 0.452869   -0.16748634]\n",
      " [ 0.93149257 -0.36079007]]\n",
      "cost:\n",
      "0.109466\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733  0.26179933]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [-0.43633222 -0.17453289]\n",
      " [-0.61086511 -0.34906578]\n",
      " [-0.17453289 -0.26179933]\n",
      " [-1.04719733  0.08726644]\n",
      " [ 0.87266444 -0.34906578]\n",
      " [-0.26179933 -0.43633222]\n",
      " [ 0.785398    0.        ]\n",
      " [-0.34906578  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.95934802  0.35664696]\n",
      " [ 0.97520387 -0.11187916]\n",
      " [-0.39291993 -0.13886964]\n",
      " [-0.69143021 -0.27106938]\n",
      " [-0.08594619 -0.22890411]\n",
      " [-0.99987012  0.14599118]\n",
      " [ 0.8005625  -0.27668473]\n",
      " [-0.21729393 -0.36602488]\n",
      " [ 0.88822371  0.05521265]\n",
      " [-0.28549507  0.36282334]]\n",
      "cost:\n",
      "0.106011\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511  0.08726644]\n",
      " [-0.34906578 -0.17453289]\n",
      " [-1.22173022 -0.26179933]\n",
      " [ 0.26179933  0.26179933]\n",
      " [ 0.87266444  0.08726644]\n",
      " [ 0.95993089  0.17453289]\n",
      " [ 1.04719733 -0.34906578]\n",
      " [ 0.43633222  0.17453289]\n",
      " [-0.87266444  0.34906578]\n",
      " [ 1.22173022  0.        ]]\n",
      "prediction:\n",
      "[[ 0.58367562  0.03632282]\n",
      " [-0.23458727 -0.25395858]\n",
      " [-0.99980491 -0.39107803]\n",
      " [ 0.27722248  0.18826124]\n",
      " [ 0.80706882  0.02097898]\n",
      " [ 0.89334583  0.09265374]\n",
      " [ 0.91137558 -0.49241671]\n",
      " [ 0.46538013  0.11618159]\n",
      " [-0.98081911  0.27355608]\n",
      " [ 0.92010754 -0.05392947]]\n",
      "cost:\n",
      "0.142881\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289 -0.17453289]\n",
      " [-0.95993089 -0.43633222]\n",
      " [-0.52359867 -0.08726644]\n",
      " [ 1.04719733 -0.43633222]\n",
      " [ 0.          0.        ]\n",
      " [-0.34906578 -0.17453289]\n",
      " [ 1.13446378 -0.34906578]\n",
      " [-0.52359867 -0.26179933]\n",
      " [-0.26179933  0.34906578]\n",
      " [-1.04719733  0.26179933]]\n",
      "prediction:\n",
      "[[-0.25974604 -0.13595171]\n",
      " [-0.93561572 -0.31892732]\n",
      " [-0.57380605 -0.05245831]\n",
      " [ 0.9958989  -0.30001977]\n",
      " [-0.10008999  0.00625669]\n",
      " [-0.40976396 -0.13060537]\n",
      " [ 0.99879819 -0.21836494]\n",
      " [-0.51515198 -0.19731218]\n",
      " [-0.19850415  0.41453335]\n",
      " [-0.99404818  0.35144678]]\n",
      "cost:\n",
      "0.104409\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.43633222  0.26179933]\n",
      " [-0.34906578 -0.34906578]\n",
      " [-0.69813156  0.        ]\n",
      " [-0.43633222  0.        ]\n",
      " [ 0.52359867 -0.17453289]\n",
      " [-0.34906578 -0.34906578]\n",
      " [-0.61086511  0.08726644]\n",
      " [-1.22173022  0.        ]\n",
      " [ 0.43633222  0.08726644]\n",
      " [-1.04719733 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.34479487  0.39872742]\n",
      " [-0.28255129 -0.34821248]\n",
      " [-0.45167443  0.01784415]\n",
      " [-0.33435467  0.02902202]\n",
      " [ 0.99984038 -0.18493024]\n",
      " [-0.28255129 -0.34821248]\n",
      " [-0.48817614  0.13389534]\n",
      " [-0.9853428  -0.0013541 ]\n",
      " [ 0.94579929  0.12697043]\n",
      " [-0.94561267 -0.36649996]]\n",
      "cost:\n",
      "0.210896\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578  0.26179933]\n",
      " [-0.43633222  0.17453289]\n",
      " [ 1.04719733 -0.34906578]\n",
      " [-0.61086511 -0.34906578]\n",
      " [ 0.26179933  0.26179933]\n",
      " [-0.43633222 -0.43633222]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [-0.08726644  0.        ]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [ 0.          0.34906578]]\n",
      "prediction:\n",
      "[[-0.60799277  0.21772546]\n",
      " [-0.90711176  0.1312544 ]\n",
      " [ 0.99860948 -0.32096684]\n",
      " [-0.99664223 -0.30467761]\n",
      " [ 0.25296998  0.21477452]\n",
      " [-0.83383709 -0.38939053]\n",
      " [ 0.99162078 -0.1578307 ]\n",
      " [-0.44175667 -0.01906997]\n",
      " [ 0.45885104 -0.19939676]\n",
      " [-0.083932    0.32821232]]\n",
      "cost:\n",
      "0.224683\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733 -0.17453289]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [-0.08726644  0.34906578]\n",
      " [-0.52359867 -0.08726644]\n",
      " [ 0.          0.08726644]\n",
      " [-0.52359867  0.        ]\n",
      " [ 1.22173022  0.17453289]\n",
      " [ 0.          0.34906578]\n",
      " [-0.34906578 -0.08726644]\n",
      " [-1.13446378  0.26179933]]\n",
      "prediction:\n",
      "[[-0.97179019 -0.4739573 ]\n",
      " [ 0.86899656 -0.37393856]\n",
      " [-0.06811603  0.26641953]\n",
      " [-0.50569713 -0.17688701]\n",
      " [ 0.00150091  0.01756477]\n",
      " [-0.50851178 -0.07148689]\n",
      " [ 0.99985033  0.07528526]\n",
      " [ 0.01020328  0.27563626]\n",
      " [-0.31225073 -0.1725724 ]\n",
      " [-0.98627228  0.15009068]]\n",
      "cost:\n",
      "0.148607\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511 -0.08726644]\n",
      " [-1.13446378 -0.08726644]\n",
      " [ 0.87266444 -0.34906578]\n",
      " [-0.08726644  0.34906578]\n",
      " [ 0.34906578  0.17453289]\n",
      " [ 0.17453289  0.26179933]\n",
      " [-0.87266444 -0.26179933]\n",
      " [-0.08726644  0.26179933]\n",
      " [ 0.61086511 -0.34906578]\n",
      " [-0.26179933  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.64992779 -0.12530273]\n",
      " [-0.99938315 -0.18478201]\n",
      " [ 0.99906039 -0.39245695]\n",
      " [ 0.04889404  0.25289696]\n",
      " [ 0.26755285  0.07712284]\n",
      " [ 0.16418646  0.16454545]\n",
      " [-0.94430947 -0.32183009]\n",
      " [ 0.00596646  0.18493822]\n",
      " [ 0.7018038  -0.37450829]\n",
      " [-0.19245325  0.24030478]]\n",
      "cost:\n",
      "0.1184\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578  0.26179933]\n",
      " [-0.52359867  0.17453289]\n",
      " [ 0.43633222  0.34906578]\n",
      " [ 0.69813156  0.17453289]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [-0.87266444  0.        ]\n",
      " [-0.52359867  0.34906578]\n",
      " [-1.22173022 -0.17453289]\n",
      " [-0.785398    0.26179933]\n",
      " [-0.69813156 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.39621019  0.13151586]\n",
      " [-0.5266825   0.07507531]\n",
      " [ 0.60851038  0.20950046]\n",
      " [ 0.99691176  0.05253766]\n",
      " [ 0.99700677 -0.32750732]\n",
      " [-0.95010751 -0.06293599]\n",
      " [-0.54568601  0.23738492]\n",
      " [-0.99362892 -0.41810885]\n",
      " [-0.75991523  0.12793663]\n",
      " [-0.66053677 -0.46371496]]\n",
      "cost:\n",
      "0.200716\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644  0.        ]\n",
      " [-1.04719733 -0.34906578]\n",
      " [-1.13446378  0.17453289]\n",
      " [ 0.43633222  0.26179933]\n",
      " [ 0.34906578  0.17453289]\n",
      " [ 0.08726644 -0.34906578]\n",
      " [-0.785398   -0.34906578]\n",
      " [-0.52359867 -0.26179933]\n",
      " [-1.04719733 -0.34906578]\n",
      " [ 0.785398    0.08726644]]\n",
      "prediction:\n",
      "[[ 0.00854868  0.00582487]\n",
      " [-0.91386569 -0.29282701]\n",
      " [-0.94394964  0.26352003]\n",
      " [ 0.50144124  0.34464258]\n",
      " [ 0.36919403  0.20735705]\n",
      " [ 0.07981551 -0.34242859]\n",
      " [-0.67361343 -0.28146401]\n",
      " [-0.51233423 -0.22013156]\n",
      " [-0.91386569 -0.29282701]\n",
      " [ 0.99993026  0.1259378 ]]\n",
      "cost:\n",
      "0.112426\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644  0.        ]\n",
      " [ 0.43633222 -0.34906578]\n",
      " [ 0.26179933  0.17453289]\n",
      " [-0.61086511  0.26179933]\n",
      " [ 0.08726644  0.08726644]\n",
      " [ 0.26179933  0.08726644]\n",
      " [-0.43633222  0.        ]\n",
      " [ 0.08726644 -0.34906578]\n",
      " [-0.61086511  0.08726644]\n",
      " [ 0.43633222  0.34906578]]\n",
      "prediction:\n",
      "[[-0.19829634 -0.04366823]\n",
      " [ 0.99766457 -0.50077653]\n",
      " [ 0.3894569   0.12481993]\n",
      " [-0.99578214  0.18522483]\n",
      " [ 0.05336711  0.03600588]\n",
      " [ 0.36915204  0.02490871]\n",
      " [-0.53969204 -0.04952839]\n",
      " [ 0.38431591 -0.48157105]\n",
      " [-0.99544531  0.01857834]\n",
      " [ 0.97514999  0.28261572]]\n",
      "cost:\n",
      "0.278928\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398    0.17453289]\n",
      " [-0.26179933  0.08726644]\n",
      " [-0.43633222  0.26179933]\n",
      " [ 0.785398   -0.43633222]\n",
      " [-0.26179933  0.17453289]\n",
      " [-0.08726644 -0.34906578]\n",
      " [-0.26179933  0.        ]\n",
      " [ 1.22173022 -0.08726644]\n",
      " [-0.34906578 -0.17453289]\n",
      " [ 0.34906578  0.26179933]]\n",
      "prediction:\n",
      "[[-0.99972576  0.15261257]\n",
      " [-0.14423925  0.06092846]\n",
      " [-0.43278286  0.2468967 ]\n",
      " [ 0.94539404 -0.50529218]\n",
      " [-0.15331584  0.14038061]\n",
      " [ 0.01978905 -0.40095589]\n",
      " [-0.20635405 -0.01278612]\n",
      " [ 0.99828863 -0.09123542]\n",
      " [-0.24387032 -0.20987239]\n",
      " [ 0.22835736  0.23464325]]\n",
      "cost:\n",
      "0.127324\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578 -0.08726644]\n",
      " [-0.34906578  0.26179933]\n",
      " [-0.34906578  0.34906578]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [-1.13446378  0.26179933]\n",
      " [-0.69813156 -0.26179933]\n",
      " [ 0.17453289  0.34906578]\n",
      " [ 0.61086511 -0.43633222]\n",
      " [-0.26179933  0.        ]\n",
      " [-1.22173022 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.37859663 -0.11528881]\n",
      " [-0.31086865  0.19764836]\n",
      " [-0.33699915  0.27654022]\n",
      " [ 0.99981517 -0.11236251]\n",
      " [-0.98439384  0.18231428]\n",
      " [-0.55611527 -0.30226424]\n",
      " [ 0.21723637  0.26319245]\n",
      " [ 0.8242923  -0.47563693]\n",
      " [-0.2603958  -0.03166744]\n",
      " [-0.98767447 -0.30662635]]\n",
      "cost:\n",
      "0.113644\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867 -0.08726644]\n",
      " [ 0.34906578  0.        ]\n",
      " [ 1.04719733 -0.43633222]\n",
      " [-1.04719733 -0.26179933]\n",
      " [-0.43633222 -0.17453289]\n",
      " [-1.22173022 -0.17453289]\n",
      " [ 0.08726644  0.        ]\n",
      " [ 0.08726644  0.34906578]\n",
      " [-0.52359867 -0.26179933]\n",
      " [ 1.22173022 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.50146216 -0.04315209]\n",
      " [ 0.35356715  0.03857563]\n",
      " [ 0.98738933 -0.37727344]\n",
      " [-0.98177862 -0.2286628 ]\n",
      " [-0.41602716 -0.12862638]\n",
      " [-0.99524373 -0.11283148]\n",
      " [ 0.11788583  0.02696954]\n",
      " [ 0.00411508  0.55823851]\n",
      " [-0.48935542 -0.21044359]\n",
      " [ 0.99889153 -0.12227104]]\n",
      "cost:\n",
      "0.108702\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089 -0.43633222]\n",
      " [ 1.13446378  0.17453289]\n",
      " [-0.785398    0.17453289]\n",
      " [ 0.52359867 -0.17453289]\n",
      " [ 0.87266444  0.17453289]\n",
      " [-0.34906578  0.17453289]\n",
      " [ 0.52359867 -0.43633222]\n",
      " [ 1.04719733 -0.26179933]\n",
      " [-0.17453289 -0.17453289]\n",
      " [ 1.22173022  0.08726644]]\n",
      "prediction:\n",
      "[[-0.99961609 -0.4325538 ]\n",
      " [ 0.93511277  0.19436306]\n",
      " [-0.9911148   0.1681349 ]\n",
      " [ 0.56179917 -0.1544721 ]\n",
      " [ 0.84820455  0.1911547 ]\n",
      " [-0.37877908  0.19844159]\n",
      " [ 0.53943026 -0.42462474]\n",
      " [ 0.90753025 -0.24998307]\n",
      " [-0.14201261 -0.15576328]\n",
      " [ 0.93573171  0.12041661]]\n",
      "cost:\n",
      "0.104219\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511 -0.43633222]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [ 0.34906578  0.26179933]\n",
      " [-0.69813156 -0.34906578]\n",
      " [ 1.13446378  0.26179933]\n",
      " [-1.13446378  0.17453289]\n",
      " [-0.17453289 -0.08726644]\n",
      " [-1.22173022  0.26179933]\n",
      " [ 0.61086511  0.34906578]\n",
      " [ 0.95993089  0.26179933]]\n",
      "prediction:\n",
      "[[-0.57676733 -0.53127223]\n",
      " [ 0.39843386 -0.1263005 ]\n",
      " [ 0.31622645  0.14765227]\n",
      " [-0.67566562 -0.42406213]\n",
      " [ 0.99730086  0.12252749]\n",
      " [-0.99426055  0.04835688]\n",
      " [-0.21843454 -0.11610536]\n",
      " [-0.99353421  0.09508216]\n",
      " [ 0.59240592  0.19676109]\n",
      " [ 0.9891789   0.15225042]]\n",
      "cost:\n",
      "0.133838\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733 -0.34906578]\n",
      " [ 0.52359867  0.08726644]\n",
      " [-0.95993089 -0.17453289]\n",
      " [ 0.69813156  0.08726644]\n",
      " [ 1.04719733  0.26179933]\n",
      " [ 0.43633222  0.17453289]\n",
      " [ 0.87266444  0.        ]\n",
      " [-0.34906578  0.17453289]\n",
      " [-0.17453289 -0.34906578]\n",
      " [ 0.785398    0.34906578]]\n",
      "prediction:\n",
      "[[ 0.87670088 -0.46427888]\n",
      " [ 0.38508514  0.03123776]\n",
      " [-0.99996579 -0.22196217]\n",
      " [ 0.49564159  0.02584682]\n",
      " [ 0.90683722  0.20637551]\n",
      " [ 0.32376054  0.13220321]\n",
      " [ 0.79004729 -0.06864237]\n",
      " [-0.35788357  0.12992151]\n",
      " [-0.13061854 -0.42749122]\n",
      " [ 0.54561722  0.29131359]]\n",
      "cost:\n",
      "0.138944\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733  0.17453289]\n",
      " [ 0.         -0.43633222]\n",
      " [-0.95993089 -0.26179933]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [-0.52359867  0.08726644]\n",
      " [-1.13446378 -0.43633222]\n",
      " [-0.95993089 -0.34906578]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [ 0.69813156  0.        ]]\n",
      "prediction:\n",
      "[[-0.97610009  0.4524326 ]\n",
      " [ 0.05596711 -0.31037283]\n",
      " [-0.9393537  -0.16291828]\n",
      " [ 0.88831061 -0.2154184 ]\n",
      " [-0.59215587  0.30293027]\n",
      " [-0.96818119 -0.2776725 ]\n",
      " [-0.94307774 -0.22041959]\n",
      " [ 0.8973524  -0.05749868]\n",
      " [ 0.99892962 -0.06279053]\n",
      " [ 0.92664593  0.17149302]]\n",
      "cost:\n",
      "0.202937\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644 -0.43633222]\n",
      " [ 0.61086511 -0.34906578]\n",
      " [-0.52359867  0.34906578]\n",
      " [-0.95993089 -0.34906578]\n",
      " [-0.08726644  0.        ]\n",
      " [ 0.785398   -0.17453289]\n",
      " [ 0.785398   -0.08726644]\n",
      " [ 0.17453289  0.        ]\n",
      " [-0.52359867  0.34906578]\n",
      " [-0.52359867 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.11423642 -0.35690817]\n",
      " [ 0.71084368 -0.27783424]\n",
      " [-0.56463033  0.37665194]\n",
      " [-0.99978369 -0.27601683]\n",
      " [-0.0575494   0.02241211]\n",
      " [ 0.9862777  -0.14705808]\n",
      " [ 0.99187279 -0.05392563]\n",
      " [ 0.20704344  0.00347284]\n",
      " [-0.56463033  0.37665194]\n",
      " [-0.58037949 -0.13566251]]\n",
      "cost:\n",
      "0.0939362\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.26179933  0.        ]\n",
      " [-0.26179933 -0.26179933]\n",
      " [ 1.22173022 -0.43633222]\n",
      " [-0.69813156 -0.08726644]\n",
      " [-0.52359867 -0.17453289]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [ 0.52359867  0.17453289]\n",
      " [-0.43633222  0.08726644]\n",
      " [-1.22173022  0.08726644]\n",
      " [ 0.          0.26179933]]\n",
      "prediction:\n",
      "[[ 0.22394437  0.00297128]\n",
      " [-0.26827037 -0.2986002 ]\n",
      " [ 0.99519819 -0.50075805]\n",
      " [-0.76742363 -0.09605312]\n",
      " [-0.54327101 -0.18811081]\n",
      " [ 0.99101329 -0.08852404]\n",
      " [ 0.52909523  0.24003635]\n",
      " [-0.39669216  0.1033847 ]\n",
      " [-0.99962825  0.10530232]\n",
      " [-0.03526802  0.31942406]]\n",
      "cost:\n",
      "0.0921877\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867  0.        ]\n",
      " [-0.87266444 -0.26179933]\n",
      " [ 0.26179933 -0.34906578]\n",
      " [ 0.87266444 -0.34906578]\n",
      " [ 1.13446378  0.26179933]\n",
      " [-0.69813156 -0.17453289]\n",
      " [ 0.26179933 -0.43633222]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [ 0.87266444  0.08726644]\n",
      " [-1.04719733 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.55299711  0.09791848]\n",
      " [-0.97918957 -0.14866379]\n",
      " [ 0.23886281 -0.24243611]\n",
      " [ 0.93015593 -0.22405241]\n",
      " [ 0.99573064  0.47967345]\n",
      " [-0.75759965 -0.07456445]\n",
      " [ 0.25094295 -0.3271732 ]\n",
      " [ 0.55454743  0.00443749]\n",
      " [ 0.94206697  0.24458964]\n",
      " [-0.99903446 -0.20908216]]\n",
      "cost:\n",
      "0.141622\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933 -0.34906578]\n",
      " [ 0.61086511  0.08726644]\n",
      " [ 1.04719733 -0.34906578]\n",
      " [ 0.87266444  0.08726644]\n",
      " [-0.87266444  0.26179933]\n",
      " [ 1.04719733  0.17453289]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [ 0.08726644 -0.34906578]\n",
      " [-1.22173022 -0.43633222]\n",
      " [ 0.52359867 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.25233287 -0.27506503]\n",
      " [ 0.60324335  0.1275557 ]\n",
      " [ 0.96251106 -0.27057415]\n",
      " [ 0.87832582  0.13345839]\n",
      " [-0.99336326  0.39704943]\n",
      " [ 0.97346294  0.27423614]\n",
      " [ 0.18719004 -0.20796107]\n",
      " [ 0.20485334 -0.28914884]\n",
      " [-0.99952817 -0.28760231]\n",
      " [ 0.53837347 -0.06763568]]\n",
      "cost:\n",
      "0.112032\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511  0.17453289]\n",
      " [ 0.34906578  0.17453289]\n",
      " [-0.785398   -0.34906578]\n",
      " [ 1.13446378  0.26179933]\n",
      " [-0.52359867  0.        ]\n",
      " [-0.08726644 -0.43633222]\n",
      " [ 0.69813156  0.17453289]\n",
      " [ 0.69813156 -0.43633222]\n",
      " [ 0.785398   -0.34906578]\n",
      " [-0.95993089 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.54257059  0.18424742]\n",
      " [ 0.34968704  0.18605793]\n",
      " [-0.97146255 -0.26340842]\n",
      " [ 0.99697268  0.32754657]\n",
      " [-0.57760942  0.01839473]\n",
      " [-0.07366046 -0.36549297]\n",
      " [ 0.63775015  0.1853791 ]\n",
      " [ 0.69147962 -0.34023857]\n",
      " [ 0.83796191 -0.26439363]\n",
      " [-0.99963641 -0.21508296]]\n",
      "cost:\n",
      "0.0885595\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289  0.08726644]\n",
      " [-0.87266444  0.08726644]\n",
      " [ 0.785398    0.17453289]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [ 0.34906578 -0.43633222]\n",
      " [ 0.95993089 -0.43633222]\n",
      " [-1.22173022  0.17453289]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [-0.08726644  0.26179933]\n",
      " [ 1.13446378  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.21590164  0.07779191]\n",
      " [-0.97257119  0.06569809]\n",
      " [ 0.868572    0.17354919]\n",
      " [ 0.08930467 -0.17686062]\n",
      " [ 0.33459294 -0.45627818]\n",
      " [ 0.94466311 -0.45139503]\n",
      " [-0.99976003  0.14806953]\n",
      " [ 0.17830166 -0.17816953]\n",
      " [-0.07777094  0.2465276 ]\n",
      " [ 0.99080718  0.0791369 ]]\n",
      "cost:\n",
      "0.0667662\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.43633222  0.        ]\n",
      " [-1.13446378 -0.17453289]\n",
      " [-0.87266444 -0.26179933]\n",
      " [ 0.95993089 -0.34906578]\n",
      " [-0.87266444  0.08726644]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [-0.95993089 -0.17453289]\n",
      " [ 0.785398    0.34906578]\n",
      " [-0.17453289  0.26179933]\n",
      " [-0.08726644 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.48511457  0.03015258]\n",
      " [-0.98675495 -0.13618568]\n",
      " [-0.89340448 -0.2203982 ]\n",
      " [ 0.99898529 -0.32237452]\n",
      " [-0.84522575  0.11210866]\n",
      " [ 0.98790568 -0.3988727 ]\n",
      " [-0.96253049 -0.13537112]\n",
      " [ 0.91012114  0.38592219]\n",
      " [-0.20401664  0.30843398]\n",
      " [-0.0645318  -0.07251345]]\n",
      "cost:\n",
      "0.0713332\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289  0.26179933]\n",
      " [-0.08726644  0.08726644]\n",
      " [-1.22173022 -0.17453289]\n",
      " [ 0.52359867 -0.17453289]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [ 1.04719733 -0.34906578]\n",
      " [-0.95993089  0.        ]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [-0.95993089  0.08726644]\n",
      " [ 0.52359867  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.21447314  0.34972313]\n",
      " [-0.0936088   0.11708136]\n",
      " [-0.99650443 -0.16554104]\n",
      " [ 0.55137777 -0.20379007]\n",
      " [ 0.13814245 -0.21129721]\n",
      " [ 0.99403447 -0.42388704]\n",
      " [-0.97115737  0.0013344 ]\n",
      " [ 0.99518025 -0.29585421]\n",
      " [-0.97446281  0.09727722]\n",
      " [ 0.50104916  0.32651079]]\n",
      "cost:\n",
      "0.0788222\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511  0.        ]\n",
      " [-1.04719733  0.26179933]\n",
      " [-0.87266444  0.26179933]\n",
      " [-1.13446378 -0.34906578]\n",
      " [ 0.785398   -0.43633222]\n",
      " [-0.95993089  0.08726644]\n",
      " [-0.785398    0.        ]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [ 0.43633222 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.84083527  0.00658751]\n",
      " [-0.95395672  0.33600548]\n",
      " [-0.84809661  0.35091624]\n",
      " [-0.95174277 -0.33786699]\n",
      " [ 0.99989033 -0.44463173]\n",
      " [-0.89236546  0.10627253]\n",
      " [-0.78527975  0.00593231]\n",
      " [ 0.27238545 -0.14629526]\n",
      " [ 0.44403157 -0.22803894]\n",
      " [ 0.40648943 -0.06199388]]\n",
      "cost:\n",
      "0.108556\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089 -0.08726644]\n",
      " [-1.04719733 -0.34906578]\n",
      " [ 0.87266444  0.17453289]\n",
      " [-0.17453289 -0.34906578]\n",
      " [-0.61086511  0.08726644]\n",
      " [-0.61086511  0.34906578]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [ 0.69813156  0.17453289]\n",
      " [ 0.69813156 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.98267573 -0.08745118]\n",
      " [-0.99990827 -0.36508331]\n",
      " [ 0.96100765  0.2023112 ]\n",
      " [-0.1809973  -0.35444742]\n",
      " [-0.71018344  0.09120364]\n",
      " [-0.75039285  0.37251204]\n",
      " [ 0.59966463 -0.07081982]\n",
      " [ 0.42775995 -0.35344896]\n",
      " [ 0.62479961  0.2046044 ]\n",
      " [ 0.59966463 -0.07081982]]\n",
      "cost:\n",
      "0.0789432\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398    0.34906578]\n",
      " [ 1.04719733 -0.26179933]\n",
      " [ 0.26179933  0.34906578]\n",
      " [ 0.69813156 -0.43633222]\n",
      " [-0.17453289  0.34906578]\n",
      " [ 0.26179933  0.        ]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [-0.26179933 -0.43633222]\n",
      " [ 1.22173022  0.17453289]\n",
      " [-0.61086511  0.        ]]\n",
      "prediction:\n",
      "[[-0.47574285  0.22751355]\n",
      " [ 0.93666977 -0.27289334]\n",
      " [ 0.07961033  0.23981613]\n",
      " [ 0.67838806 -0.41117117]\n",
      " [-0.43211123  0.22796653]\n",
      " [ 0.4641183  -0.02374958]\n",
      " [ 0.9680301  -0.17712229]\n",
      " [-0.37414423 -0.4200193 ]\n",
      " [ 0.85820198  0.14207047]\n",
      " [-0.99994546 -0.01745001]]\n",
      "cost:\n",
      "0.298729\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378  0.17453289]\n",
      " [ 1.22173022  0.        ]\n",
      " [ 0.34906578 -0.34906578]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [ 1.22173022 -0.08726644]\n",
      " [ 0.17453289 -0.43633222]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [-0.52359867  0.26179933]\n",
      " [ 1.13446378  0.        ]\n",
      " [ 0.43633222 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.99996567  0.32061753]\n",
      " [ 0.8893683   0.03614171]\n",
      " [ 0.34756899 -0.3114419 ]\n",
      " [ 0.27933389 -0.12930904]\n",
      " [ 0.92241585 -0.02881961]\n",
      " [ 0.15432979 -0.4207474 ]\n",
      " [ 0.27933389 -0.12930904]\n",
      " [-0.6256085   0.39946386]\n",
      " [ 0.89803731  0.05385666]\n",
      " [ 0.45249406 -0.22380933]]\n",
      "cost:\n",
      "0.145315\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222  0.26179933]\n",
      " [-0.26179933  0.17453289]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [ 0.34906578  0.34906578]\n",
      " [-0.26179933  0.34906578]\n",
      " [-0.95993089  0.17453289]\n",
      " [ 0.          0.17453289]\n",
      " [ 0.52359867  0.08726644]\n",
      " [-0.43633222 -0.26179933]\n",
      " [-1.13446378 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.942963    0.15393254]\n",
      " [-0.18860459  0.07370564]\n",
      " [ 0.39077148 -0.30033356]\n",
      " [ 0.67721885  0.23780578]\n",
      " [-0.08449131  0.24365091]\n",
      " [-0.99522734  0.02378998]\n",
      " [ 0.09763362  0.09037067]\n",
      " [ 0.99895346 -0.02107162]\n",
      " [-0.52587169 -0.43947625]\n",
      " [-0.99654758 -0.42122152]]\n",
      "cost:\n",
      "0.262838\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578 -0.26179933]\n",
      " [ 0.69813156  0.26179933]\n",
      " [-0.61086511 -0.17453289]\n",
      " [-0.95993089 -0.08726644]\n",
      " [ 0.95993089 -0.26179933]\n",
      " [-0.87266444  0.34906578]\n",
      " [ 0.          0.26179933]\n",
      " [-0.34906578  0.26179933]\n",
      " [ 1.04719733 -0.17453289]\n",
      " [ 0.17453289 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.35634604 -0.31252277]\n",
      " [ 0.76511163  0.2273297 ]\n",
      " [-0.60422271 -0.20907792]\n",
      " [-0.99756801 -0.0921789 ]\n",
      " [ 0.98892552 -0.36829928]\n",
      " [-0.98829889  0.30646208]\n",
      " [ 0.0188573   0.23575191]\n",
      " [-0.3275682   0.23202191]\n",
      " [ 0.99771506 -0.22313939]\n",
      " [ 0.15485165 -0.21341076]]\n",
      "cost:\n",
      "0.0615137\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398    0.26179933]\n",
      " [-0.61086511 -0.08726644]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [ 1.22173022  0.        ]\n",
      " [-0.52359867 -0.08726644]\n",
      " [ 0.61086511 -0.43633222]\n",
      " [ 0.          0.        ]\n",
      " [ 0.26179933  0.08726644]\n",
      " [-1.13446378  0.08726644]\n",
      " [ 0.785398    0.26179933]]\n",
      "prediction:\n",
      "[[ 0.83367026  0.2503446 ]\n",
      " [-0.75388038 -0.10207708]\n",
      " [ 0.2748774  -0.21732931]\n",
      " [ 0.99527782 -0.0169142 ]\n",
      " [-0.63448799 -0.10344641]\n",
      " [ 0.533795   -0.58145964]\n",
      " [-0.07570672 -0.00242058]\n",
      " [ 0.26978639  0.06060063]\n",
      " [-0.99989152  0.10979648]\n",
      " [ 0.8336702   0.25034535]]\n",
      "cost:\n",
      "0.103125\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578  0.17453289]\n",
      " [ 0.61086511 -0.43633222]\n",
      " [-0.785398   -0.08726644]\n",
      " [-0.61086511 -0.43633222]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [-0.08726644  0.17453289]\n",
      " [ 0.08726644  0.34906578]\n",
      " [ 1.04719733  0.17453289]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [-0.69813156  0.26179933]]\n",
      "prediction:\n",
      "[[-0.42391121  0.14510426]\n",
      " [ 0.6521945  -0.36103532]\n",
      " [-0.997949   -0.07846166]\n",
      " [-0.75337565 -0.35364524]\n",
      " [ 0.95708311 -0.3686747 ]\n",
      " [-0.18502973  0.14633586]\n",
      " [ 0.00418801  0.29817674]\n",
      " [ 0.99890035  0.11616668]\n",
      " [ 0.72141892 -0.16774258]\n",
      " [-0.9839682   0.21968119]]\n",
      "cost:\n",
      "0.124011\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.22173022 -0.34906578]\n",
      " [-0.785398    0.34906578]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [ 0.52359867  0.        ]\n",
      " [-0.17453289 -0.43633222]\n",
      " [ 1.22173022  0.17453289]\n",
      " [-0.17453289  0.17453289]\n",
      " [-0.26179933  0.        ]\n",
      " [-0.69813156  0.17453289]\n",
      " [ 1.13446378  0.17453289]]\n",
      "prediction:\n",
      "[[-0.99944252 -0.41065937]\n",
      " [-0.92906141  0.26903528]\n",
      " [ 0.92134672 -0.22117171]\n",
      " [ 0.60667908 -0.02626809]\n",
      " [-0.17312521 -0.48557559]\n",
      " [ 0.99064577  0.10533377]\n",
      " [-0.17929916  0.15498899]\n",
      " [-0.26561972 -0.00755101]\n",
      " [-0.85274452  0.13122925]\n",
      " [ 0.98800224  0.10539489]]\n",
      "cost:\n",
      "0.119125\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578  0.08726644]\n",
      " [ 0.52359867  0.08726644]\n",
      " [ 1.04719733  0.26179933]\n",
      " [ 0.95993089 -0.34906578]\n",
      " [ 0.34906578 -0.08726644]\n",
      " [-0.61086511  0.        ]\n",
      " [ 1.04719733 -0.43633222]\n",
      " [ 0.785398   -0.26179933]\n",
      " [-0.34906578 -0.17453289]\n",
      " [-1.04719733  0.26179933]]\n",
      "prediction:\n",
      "[[-0.33406463  0.10712507]\n",
      " [ 0.43765444  0.10981001]\n",
      " [ 0.97441435  0.31088832]\n",
      " [ 0.88137394 -0.34974015]\n",
      " [ 0.27661964 -0.08432736]\n",
      " [-0.67719465  0.03941311]\n",
      " [ 0.90617037 -0.41460213]\n",
      " [ 0.67370248 -0.25031078]\n",
      " [-0.3368426  -0.19012293]\n",
      " [-0.99993932  0.29853523]]\n",
      "cost:\n",
      "0.0764394\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289 -0.17453289]\n",
      " [ 0.         -0.08726644]\n",
      " [-0.43633222  0.26179933]\n",
      " [ 0.785398   -0.26179933]\n",
      " [ 0.785398    0.34906578]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [-0.43633222 -0.26179933]\n",
      " [ 1.13446378 -0.34906578]\n",
      " [ 0.17453289  0.08726644]\n",
      " [-1.04719733  0.        ]]\n",
      "prediction:\n",
      "[[ 0.21463345 -0.15955618]\n",
      " [ 0.02603008 -0.07898359]\n",
      " [-0.55154836  0.32326099]\n",
      " [ 0.8494013  -0.25341752]\n",
      " [ 0.7707541   0.39132094]\n",
      " [ 0.73568833 -0.26860273]\n",
      " [-0.46964711 -0.24252203]\n",
      " [ 0.98930991 -0.33052289]\n",
      " [ 0.21198139  0.11511653]\n",
      " [-0.99993908  0.04214258]]\n",
      "cost:\n",
      "0.0642957\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733 -0.34906578]\n",
      " [-1.22173022 -0.26179933]\n",
      " [-0.87266444  0.17453289]\n",
      " [ 0.52359867 -0.08726644]\n",
      " [-0.34906578  0.17453289]\n",
      " [ 0.52359867  0.17453289]\n",
      " [ 0.34906578  0.        ]\n",
      " [-0.17453289 -0.17453289]\n",
      " [ 0.785398   -0.26179933]\n",
      " [ 0.785398   -0.08726644]]\n",
      "prediction:\n",
      "[[ -9.80015159e-01  -4.03600931e-01]\n",
      " [ -9.95119452e-01  -2.88659036e-01]\n",
      " [ -9.59528863e-01   3.00630271e-01]\n",
      " [  5.97895026e-01  -1.04979880e-01]\n",
      " [ -3.88944894e-01   2.75084436e-01]\n",
      " [  5.42090416e-01   2.82281160e-01]\n",
      " [  3.34053457e-01   6.08861446e-05]\n",
      " [ -1.53319195e-01  -1.85209513e-01]\n",
      " [  9.95110750e-01  -2.79463500e-01]\n",
      " [  9.96407032e-01  -8.39100480e-02]]\n",
      "cost:\n",
      "0.122197\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.          0.08726644]\n",
      " [ 0.08726644  0.26179933]\n",
      " [-1.04719733  0.17453289]\n",
      " [-1.04719733 -0.34906578]\n",
      " [ 1.04719733 -0.17453289]\n",
      " [-0.61086511 -0.26179933]\n",
      " [-0.26179933  0.17453289]\n",
      " [ 0.69813156  0.34906578]\n",
      " [-0.785398   -0.08726644]\n",
      " [-0.87266444  0.08726644]]\n",
      "prediction:\n",
      "[[-0.05035006  0.04273403]\n",
      " [ 0.08811986  0.20383251]\n",
      " [-0.96629483  0.11505216]\n",
      " [-0.92316395 -0.5094285 ]\n",
      " [ 0.99994862 -0.26274288]\n",
      " [-0.49548388 -0.34497991]\n",
      " [-0.22238532  0.11585183]\n",
      " [ 0.8026278   0.29228094]\n",
      " [-0.70969081 -0.12822348]\n",
      " [-0.81187117  0.03780854]]\n",
      "cost:\n",
      "0.102471\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156  0.17453289]\n",
      " [-0.87266444 -0.43633222]\n",
      " [ 0.34906578  0.26179933]\n",
      " [-0.95993089 -0.34906578]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [-1.13446378  0.34906578]\n",
      " [ 0.95993089  0.        ]\n",
      " [ 0.34906578 -0.43633222]\n",
      " [-0.69813156 -0.08726644]\n",
      " [-0.61086511  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.74618018  0.18230528]\n",
      " [-0.9185937  -0.35417888]\n",
      " [ 0.36014622  0.24306215]\n",
      " [-0.97766864 -0.29831645]\n",
      " [ 0.99804473 -0.23398803]\n",
      " [-0.98516214  0.34967533]\n",
      " [ 0.99604142  0.00588033]\n",
      " [ 0.26932299 -0.38450509]\n",
      " [-0.79862392 -0.06640761]\n",
      " [-0.68151993  0.11486119]]\n",
      "cost:\n",
      "0.090321\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156 -0.43633222]\n",
      " [-0.52359867  0.17453289]\n",
      " [-0.17453289 -0.43633222]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [ 1.13446378  0.34906578]\n",
      " [-0.43633222  0.08726644]\n",
      " [-1.04719733  0.17453289]\n",
      " [ 0.          0.17453289]\n",
      " [ 1.04719733  0.        ]\n",
      " [ 0.17453289  0.34906578]]\n",
      "prediction:\n",
      "[[-0.86065638 -0.48434848]\n",
      " [-0.58388942  0.09263487]\n",
      " [-0.22753233 -0.48596302]\n",
      " [ 0.98266172 -0.13595816]\n",
      " [ 0.94446534  0.21575905]\n",
      " [-0.45115116  0.01732538]\n",
      " [-0.99968791  0.07506654]\n",
      " [-0.04089037  0.10130022]\n",
      " [ 0.99209356 -0.05707677]\n",
      " [ 0.20340998  0.22794209]]\n",
      "cost:\n",
      "0.109906\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.26179933 -0.08726644]\n",
      " [ 0.61086511  0.08726644]\n",
      " [-1.13446378  0.26179933]\n",
      " [ 1.22173022  0.26179933]\n",
      " [-0.34906578  0.34906578]\n",
      " [ 0.17453289 -0.34906578]\n",
      " [ 0.69813156  0.26179933]\n",
      " [-0.26179933 -0.34906578]\n",
      " [-0.52359867 -0.08726644]\n",
      " [ 0.          0.34906578]]\n",
      "prediction:\n",
      "[[ 0.21888956 -0.11922218]\n",
      " [ 0.57449841  0.00939117]\n",
      " [-0.99983329  0.09693247]\n",
      " [ 0.9987995   0.11312763]\n",
      " [-0.29410627  0.18902841]\n",
      " [ 0.23222628 -0.468887  ]\n",
      " [ 0.77183115  0.12058052]\n",
      " [-0.18645763 -0.48644012]\n",
      " [-0.55085731 -0.13490438]\n",
      " [-0.00430335  0.22654688]]\n",
      "cost:\n",
      "0.141591\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.22173022 -0.08726644]\n",
      " [-1.22173022  0.26179933]\n",
      " [-0.61086511  0.        ]\n",
      " [-0.87266444 -0.26179933]\n",
      " [-0.17453289 -0.17453289]\n",
      " [ 0.785398   -0.26179933]\n",
      " [ 0.34906578 -0.08726644]\n",
      " [-0.95993089 -0.08726644]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [-0.17453289  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.99986094 -0.08781483]\n",
      " [-0.98403645  0.31783071]\n",
      " [-0.58254451  0.02013039]\n",
      " [-0.91425335 -0.36366645]\n",
      " [-0.25456002 -0.16032913]\n",
      " [ 0.93982959 -0.33243349]\n",
      " [ 0.35235572 -0.05560707]\n",
      " [-0.94347417 -0.08202711]\n",
      " [ 0.05858268 -0.17905429]\n",
      " [-0.26017413  0.45215416]]\n",
      "cost:\n",
      "0.107411\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378 -0.34906578]\n",
      " [-0.61086511  0.17453289]\n",
      " [-1.22173022  0.34906578]\n",
      " [-0.69813156 -0.26179933]\n",
      " [-0.26179933 -0.34906578]\n",
      " [ 0.08726644  0.        ]\n",
      " [ 0.61086511  0.34906578]\n",
      " [ 0.17453289  0.17453289]\n",
      " [ 1.22173022  0.17453289]\n",
      " [ 0.26179933  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.99118888 -0.40409103]\n",
      " [-0.74634862  0.05087136]\n",
      " [-0.99950552  0.14227355]\n",
      " [-0.90342957 -0.34334162]\n",
      " [-0.33840528 -0.43781981]\n",
      " [ 0.04847563 -0.05704303]\n",
      " [ 0.58274591  0.22607562]\n",
      " [ 0.16533507  0.11101442]\n",
      " [ 0.99593055  0.02662926]\n",
      " [ 0.26306522  0.24999799]]\n",
      "cost:\n",
      "0.160694\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444  0.34906578]\n",
      " [-0.43633222 -0.08726644]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [-0.95993089 -0.34906578]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [-0.95993089 -0.34906578]\n",
      " [ 0.95993089  0.34906578]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [-0.785398    0.        ]\n",
      " [ 1.04719733  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.93555033  0.28735024]\n",
      " [-0.43708199 -0.08659985]\n",
      " [ 0.7308805  -0.07583091]\n",
      " [-0.99433923 -0.3935976 ]\n",
      " [ 0.0972878  -0.2037009 ]\n",
      " [-0.99433923 -0.39359763]\n",
      " [ 0.98148882  0.29842645]\n",
      " [ 0.0972878  -0.2037009 ]\n",
      " [-0.93689299 -0.00520724]\n",
      " [ 0.99380076  0.28961849]]\n",
      "cost:\n",
      "0.0584566\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398   -0.17453289]\n",
      " [ 0.95993089  0.        ]\n",
      " [ 0.34906578  0.34906578]\n",
      " [ 0.08726644 -0.08726644]\n",
      " [ 0.26179933 -0.08726644]\n",
      " [ 0.95993089 -0.43633222]\n",
      " [-0.87266444 -0.17453289]\n",
      " [ 0.95993089  0.        ]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [-1.13446378  0.34906578]]\n",
      "prediction:\n",
      "[[-0.9442414  -0.16242538]\n",
      " [ 0.98445529 -0.01121221]\n",
      " [ 0.26905295  0.35816562]\n",
      " [ 0.09007714 -0.07168701]\n",
      " [ 0.21046205 -0.07090436]\n",
      " [ 0.94616938 -0.53016043]\n",
      " [-0.98618907 -0.16076596]\n",
      " [ 0.98445529 -0.01121221]\n",
      " [ 0.59668887 -0.07653075]\n",
      " [-0.99856174  0.34646302]]\n",
      "cost:\n",
      "0.0726375\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733 -0.08726644]\n",
      " [ 0.69813156  0.        ]\n",
      " [-0.95993089 -0.26179933]\n",
      " [-1.22173022 -0.34906578]\n",
      " [-0.69813156  0.17453289]\n",
      " [-0.61086511 -0.34906578]\n",
      " [-0.26179933  0.17453289]\n",
      " [-0.61086511  0.08726644]\n",
      " [ 0.95993089 -0.34906578]\n",
      " [-0.785398    0.26179933]]\n",
      "prediction:\n",
      "[[ 0.99915576 -0.06748751]\n",
      " [ 0.79994237  0.03908417]\n",
      " [-0.97108626 -0.26812822]\n",
      " [-0.98651934 -0.31497505]\n",
      " [-0.65186775  0.2193978 ]\n",
      " [-0.57395732 -0.33008519]\n",
      " [-0.24725169  0.21471563]\n",
      " [-0.55827975  0.12410253]\n",
      " [ 0.99438632 -0.34260091]\n",
      " [-0.74342531  0.33960649]]\n",
      "cost:\n",
      "0.0747853\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089 -0.17453289]\n",
      " [-0.785398    0.34906578]\n",
      " [-0.87266444  0.        ]\n",
      " [-0.43633222 -0.34906578]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [-1.04719733 -0.43633222]\n",
      " [ 1.04719733  0.34906578]\n",
      " [-1.04719733 -0.17453289]\n",
      " [-1.13446378  0.34906578]\n",
      " [-0.17453289 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.82897234 -0.13815677]\n",
      " [-0.64031094  0.3060348 ]\n",
      " [-0.69900441  0.0198573 ]\n",
      " [-0.46290302 -0.27791819]\n",
      " [ 0.9996776  -0.08925623]\n",
      " [-0.84911728 -0.35594451]\n",
      " [ 0.99704415  0.3011626 ]\n",
      " [-0.88124365 -0.13768028]\n",
      " [-0.86110425  0.30427635]\n",
      " [-0.27160457 -0.35802841]]\n",
      "cost:\n",
      "0.144039\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.22173022 -0.43633222]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [-0.52359867 -0.34906578]\n",
      " [ 0.          0.26179933]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [-0.43633222  0.34906578]\n",
      " [-0.08726644 -0.08726644]\n",
      " [-0.95993089  0.17453289]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [ 0.785398   -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.96777076 -0.32253936]\n",
      " [ 0.11810231 -0.15583941]\n",
      " [-0.5662834  -0.29738313]\n",
      " [-0.02908408  0.30185151]\n",
      " [ 0.99140644 -0.18967845]\n",
      " [-0.4296824   0.41880706]\n",
      " [-0.11302901 -0.076027  ]\n",
      " [-0.99990004  0.22547783]\n",
      " [ 0.38613692 -0.14867719]\n",
      " [ 0.75792903 -0.27150902]]\n",
      "cost:\n",
      "0.091613\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378 -0.08726644]\n",
      " [-0.785398   -0.43633222]\n",
      " [-0.61086511 -0.26179933]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [-0.95993089  0.        ]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [-0.785398   -0.26179933]\n",
      " [ 0.         -0.43633222]\n",
      " [-0.69813156 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.99994045  0.36221209]\n",
      " [-0.78069234 -0.38245246]\n",
      " [-0.53865391 -0.14749658]\n",
      " [ 0.19743946 -0.02104487]\n",
      " [ 0.54937506 -0.22564816]\n",
      " [-0.98880637  0.33412421]\n",
      " [ 0.38341054 -0.04287016]\n",
      " [-0.84272182 -0.11061177]\n",
      " [-0.07146119 -0.37505916]\n",
      " [-0.65579593  0.09820911]]\n",
      "cost:\n",
      "0.187432\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644 -0.43633222]\n",
      " [-0.08726644  0.        ]\n",
      " [-0.69813156  0.26179933]\n",
      " [-1.22173022  0.08726644]\n",
      " [-1.22173022 -0.26179933]\n",
      " [-0.95993089  0.        ]\n",
      " [-0.08726644  0.08726644]\n",
      " [-1.13446378 -0.43633222]\n",
      " [ 0.         -0.43633222]\n",
      " [-0.52359867 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.00565749 -0.3445383 ]\n",
      " [ 0.45100623  0.0056583 ]\n",
      " [-0.73964095  0.40978664]\n",
      " [-0.63110322  0.21047249]\n",
      " [ 0.04412014 -0.16165353]\n",
      " [ 0.99993956  0.04126002]\n",
      " [-0.31040663  0.10753243]\n",
      " [-0.98507392 -0.32002527]\n",
      " [ 0.45797578 -0.35741904]\n",
      " [-0.93235302 -0.13038439]]\n",
      "cost:\n",
      "0.594531\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089  0.34906578]\n",
      " [-0.95993089 -0.43633222]\n",
      " [-1.22173022  0.        ]\n",
      " [ 1.22173022 -0.43633222]\n",
      " [-1.22173022  0.26179933]\n",
      " [-0.69813156 -0.34906578]\n",
      " [ 0.52359867 -0.43633222]\n",
      " [-0.69813156  0.34906578]\n",
      " [-0.785398   -0.34906578]\n",
      " [-0.52359867 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.5427866   0.30903062]\n",
      " [-0.73540151 -0.30629653]\n",
      " [-0.89961785  0.08372331]\n",
      " [ 0.9999764  -0.25383565]\n",
      " [-0.78835249  0.2570633 ]\n",
      " [-0.51508468 -0.23814219]\n",
      " [ 0.54264379 -0.2860626 ]\n",
      " [-0.41713586  0.3118206 ]\n",
      " [-0.57611024 -0.23784338]\n",
      " [-0.39328307 -0.19651535]]\n",
      "cost:\n",
      "0.276366\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867  0.08726644]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [ 0.69813156 -0.43633222]\n",
      " [-0.08726644  0.17453289]\n",
      " [ 0.08726644 -0.08726644]\n",
      " [ 0.08726644  0.17453289]\n",
      " [-0.95993089 -0.43633222]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [ 0.52359867  0.34906578]\n",
      " [ 0.69813156  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.44215864  0.06147326]\n",
      " [ 0.98830682 -0.180733  ]\n",
      " [ 0.62344509 -0.43124345]\n",
      " [-0.04702251  0.14822063]\n",
      " [ 0.10600407 -0.09320751]\n",
      " [ 0.06353115  0.1472721 ]\n",
      " [-0.99996561 -0.41645584]\n",
      " [ 0.3493655  -0.19618852]\n",
      " [ 0.38773909  0.30254093]\n",
      " [ 0.7240321   0.22293286]]\n",
      "cost:\n",
      "0.0617848\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867  0.17453289]\n",
      " [-0.43633222  0.26179933]\n",
      " [-1.22173022 -0.34906578]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [ 0.69813156  0.26179933]\n",
      " [-0.52359867  0.26179933]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [-0.87266444  0.34906578]\n",
      " [-1.22173022 -0.43633222]\n",
      " [ 0.17453289 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.55724752  0.13424593]\n",
      " [-0.40406495  0.20856445]\n",
      " [-0.97806495 -0.33549938]\n",
      " [ 0.03409211 -0.2037732 ]\n",
      " [ 0.8719722   0.21047769]\n",
      " [-0.43465927  0.20339079]\n",
      " [ 0.99987346 -0.10607959]\n",
      " [-0.83381182  0.26351795]\n",
      " [-0.98635352 -0.40062559]\n",
      " [ 0.08124598 -0.3653217 ]]\n",
      "cost:\n",
      "0.118478\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156  0.34906578]\n",
      " [-0.69813156  0.26179933]\n",
      " [-1.22173022  0.34906578]\n",
      " [-0.26179933 -0.08726644]\n",
      " [-0.87266444 -0.17453289]\n",
      " [-0.34906578  0.26179933]\n",
      " [-0.87266444 -0.34906578]\n",
      " [-0.26179933 -0.34906578]\n",
      " [ 0.52359867  0.        ]\n",
      " [-0.785398    0.34906578]]\n",
      "prediction:\n",
      "[[ 0.99987775  0.22054596]\n",
      " [-0.69417572  0.16263391]\n",
      " [-0.94657832  0.19115417]\n",
      " [-0.35742271 -0.13278528]\n",
      " [-0.89734435 -0.22698322]\n",
      " [-0.44861338  0.17232938]\n",
      " [-0.85475534 -0.43905023]\n",
      " [-0.19720992 -0.46733844]\n",
      " [ 0.98747164 -0.06786264]\n",
      " [-0.68338114  0.22724608]]\n",
      "cost:\n",
      "0.18964\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.         -0.43633222]\n",
      " [-0.95993089  0.        ]\n",
      " [-0.43633222 -0.17453289]\n",
      " [-0.17453289  0.        ]\n",
      " [-0.17453289 -0.34906578]\n",
      " [-1.22173022  0.17453289]\n",
      " [-1.13446378 -0.17453289]\n",
      " [ 1.22173022 -0.08726644]\n",
      " [-0.26179933  0.17453289]\n",
      " [-0.26179933 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.05401252 -0.45510367]\n",
      " [-0.80807465  0.06280988]\n",
      " [-0.41087699 -0.1486275 ]\n",
      " [-0.17809808  0.056233  ]\n",
      " [-0.21547481 -0.35157198]\n",
      " [-0.89973468  0.40064773]\n",
      " [-0.91705328 -0.15000978]\n",
      " [ 0.99997693 -0.02849177]\n",
      " [-0.25153852  0.31554624]\n",
      " [-0.27867165 -0.12491964]]\n",
      "cost:\n",
      "0.139064\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933 -0.26179933]\n",
      " [ 0.26179933  0.34906578]\n",
      " [ 0.785398   -0.43633222]\n",
      " [-0.17453289 -0.43633222]\n",
      " [ 0.26179933 -0.43633222]\n",
      " [-0.08726644  0.26179933]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [-0.26179933 -0.08726644]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [ 0.95993089  0.34906578]]\n",
      "prediction:\n",
      "[[-0.99796349 -0.20024545]\n",
      " [ 0.12757537  0.35940877]\n",
      " [ 0.91918212 -0.30265757]\n",
      " [-0.94718176 -0.31622154]\n",
      " [ 0.08313183 -0.30743596]\n",
      " [-0.35794556  0.26070338]\n",
      " [ 0.11415612 -0.13896833]\n",
      " [-0.96324652 -0.06484403]\n",
      " [ 0.9969669  -0.09236868]\n",
      " [ 0.98744559  0.3627452 ]]\n",
      "cost:\n",
      "0.329818\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867  0.08726644]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [ 0.26179933  0.        ]\n",
      " [ 1.13446378  0.34906578]\n",
      " [-0.08726644  0.        ]\n",
      " [ 0.26179933  0.26179933]\n",
      " [ 1.22173022 -0.43633222]\n",
      " [ 1.04719733  0.        ]\n",
      " [-0.52359867 -0.43633222]\n",
      " [-0.69813156 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.59370172  0.09522865]\n",
      " [ 0.89870131 -0.17205441]\n",
      " [ 0.26036096 -0.00368877]\n",
      " [ 0.90424901  0.39027414]\n",
      " [-0.20286064 -0.00179618]\n",
      " [ 0.28371248  0.31677625]\n",
      " [ 0.90569597 -0.37555987]\n",
      " [ 0.85183287 -0.00953008]\n",
      " [-0.9029302  -0.43187523]\n",
      " [-0.99994153 -0.16690093]]\n",
      "cost:\n",
      "0.20049\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.43633222  0.        ]\n",
      " [-0.17453289 -0.17453289]\n",
      " [-0.95993089 -0.34906578]\n",
      " [-1.13446378 -0.34906578]\n",
      " [ 0.17453289  0.34906578]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [ 1.22173022  0.17453289]\n",
      " [-0.17453289  0.08726644]\n",
      " [-1.13446378  0.34906578]\n",
      " [ 0.87266444 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.41470838  0.00433436]\n",
      " [-0.18439291 -0.18879656]\n",
      " [-0.97150123 -0.3942298 ]\n",
      " [-0.98988312 -0.4013806 ]\n",
      " [ 0.17860764  0.31162304]\n",
      " [ 0.99108094 -0.08282266]\n",
      " [ 0.99773473  0.13646214]\n",
      " [-0.16154376  0.07207502]\n",
      " [-0.9790858   0.32694426]\n",
      " [ 0.92161185 -0.16550118]]\n",
      "cost:\n",
      "0.078764\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867  0.26179933]\n",
      " [-1.04719733  0.17453289]\n",
      " [ 0.785398    0.26179933]\n",
      " [ 0.61086511  0.34906578]\n",
      " [-0.785398    0.26179933]\n",
      " [-0.95993089  0.08726644]\n",
      " [-0.95993089 -0.43633222]\n",
      " [-0.61086511 -0.08726644]\n",
      " [-0.34906578  0.17453289]\n",
      " [-0.69813156 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.75165033  0.13920495]\n",
      " [-0.94254071  0.04617067]\n",
      " [ 0.99990094  0.11753924]\n",
      " [ 0.93070352  0.19954561]\n",
      " [-0.72066361  0.13604304]\n",
      " [-0.90387452 -0.00954706]\n",
      " [-0.92160976 -0.60257864]\n",
      " [-0.58587444 -0.15130442]\n",
      " [-0.32895163  0.07879874]\n",
      " [-0.66019779 -0.27351549]]\n",
      "cost:\n",
      "0.173258\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378  0.17453289]\n",
      " [-1.22173022 -0.43633222]\n",
      " [ 0.785398    0.34906578]\n",
      " [ 0.61086511  0.34906578]\n",
      " [ 0.17453289 -0.43633222]\n",
      " [ 0.43633222 -0.43633222]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [-0.17453289 -0.43633222]\n",
      " [ 1.04719733 -0.43633222]\n",
      " [ 0.52359867 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.92777586  0.19948317]\n",
      " [-0.99997526 -0.20014694]\n",
      " [ 0.61715943  0.39949822]\n",
      " [ 0.48000476  0.40344793]\n",
      " [ 0.13282579 -0.24211632]\n",
      " [ 0.33307579 -0.22401202]\n",
      " [ 0.58605254 -0.06942025]\n",
      " [-0.24151966 -0.24303555]\n",
      " [ 0.89678538 -0.21495166]\n",
      " [ 0.40821436 -0.17289436]]\n",
      "cost:\n",
      "0.227234\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.43633222  0.        ]\n",
      " [-1.04719733  0.        ]\n",
      " [-0.69813156 -0.08726644]\n",
      " [-0.61086511 -0.34906578]\n",
      " [-0.08726644 -0.17453289]\n",
      " [-0.87266444 -0.43633222]\n",
      " [ 0.785398   -0.08726644]\n",
      " [ 1.04719733 -0.43633222]\n",
      " [ 0.26179933 -0.34906578]\n",
      " [ 0.52359867 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.35682061  0.37412301]\n",
      " [-0.99683344  0.39276892]\n",
      " [-0.7196306   0.04469706]\n",
      " [-0.65073228 -0.25397769]\n",
      " [-0.04164283 -0.06247627]\n",
      " [-0.97190976 -0.36140451]\n",
      " [ 0.99364674  0.08270048]\n",
      " [ 0.99854261 -0.31106153]\n",
      " [ 0.30910152 -0.25066167]\n",
      " [ 0.59107971 -0.071085  ]]\n",
      "cost:\n",
      "0.18965\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.22173022 -0.17453289]\n",
      " [-0.61086511 -0.26179933]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [ 0.785398    0.08726644]\n",
      " [-0.69813156  0.        ]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [ 0.52359867 -0.43633222]\n",
      " [-0.43633222 -0.43633222]\n",
      " [-1.13446378  0.34906578]\n",
      " [ 0.52359867 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.99067545 -0.05619005]\n",
      " [-0.54096687 -0.1802606 ]\n",
      " [ 0.33061916 -0.16351916]\n",
      " [ 0.99982357  0.19945168]\n",
      " [-0.73398393  0.06936841]\n",
      " [ 0.09802248 -0.10465898]\n",
      " [ 0.77613425 -0.31354558]\n",
      " [-0.30401912 -0.33473805]\n",
      " [-0.98500198  0.52641439]\n",
      " [ 0.72030818 -0.14504962]]\n",
      "cost:\n",
      "0.178606\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867  0.08726644]\n",
      " [ 0.785398    0.17453289]\n",
      " [-1.13446378 -0.34906578]\n",
      " [-0.43633222  0.34906578]\n",
      " [-1.04719733 -0.34906578]\n",
      " [ 0.26179933  0.34906578]\n",
      " [ 0.08726644  0.17453289]\n",
      " [ 0.          0.17453289]\n",
      " [ 0.17453289  0.26179933]\n",
      " [-0.17453289 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.80376697 -0.02071125]\n",
      " [ 0.99979752  0.04351264]\n",
      " [-0.99372607 -0.38240492]\n",
      " [-0.42524898  0.23143083]\n",
      " [-0.99091345 -0.37612191]\n",
      " [ 0.29548225  0.24365421]\n",
      " [ 0.09463071  0.08092452]\n",
      " [-0.04159248  0.07833532]\n",
      " [ 0.20707959  0.15516055]\n",
      " [-0.2233393  -0.44914228]]\n",
      "cost:\n",
      "0.134808\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867 -0.34906578]\n",
      " [-1.13446378 -0.34906578]\n",
      " [ 1.04719733 -0.17453289]\n",
      " [ 0.08726644  0.34906578]\n",
      " [-0.785398    0.34906578]\n",
      " [-0.69813156  0.17453289]\n",
      " [-1.13446378  0.17453289]\n",
      " [-0.95993089  0.        ]\n",
      " [-0.61086511  0.34906578]\n",
      " [ 0.95993089 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.48369637 -0.43729457]\n",
      " [-0.91195363 -0.45832253]\n",
      " [ 0.99962783 -0.21117634]\n",
      " [-0.02409491  0.23532046]\n",
      " [-0.67855549  0.21580906]\n",
      " [-0.64548492  0.09079604]\n",
      " [-0.95669883  0.09824102]\n",
      " [-0.85810369 -0.04604324]\n",
      " [-0.56278074  0.22810635]\n",
      " [ 0.99678838 -0.12219221]]\n",
      "cost:\n",
      "0.13198\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.22173022 -0.26179933]\n",
      " [-0.87266444  0.26179933]\n",
      " [-0.87266444  0.26179933]\n",
      " [-0.08726644 -0.08726644]\n",
      " [-0.95993089 -0.43633222]\n",
      " [-0.95993089  0.        ]\n",
      " [ 0.61086511 -0.43633222]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [-0.26179933  0.26179933]\n",
      " [ 0.61086511  0.26179933]]\n",
      "prediction:\n",
      "[[-0.9352501  -0.28025669]\n",
      " [-0.89569449  0.23148054]\n",
      " [-0.89564073  0.23150976]\n",
      " [-0.11970627 -0.10994485]\n",
      " [-0.9428854  -0.42755884]\n",
      " [-0.79766864 -0.01443587]\n",
      " [ 0.99883395 -0.41402137]\n",
      " [ 0.6157949  -0.09579506]\n",
      " [-0.4135778   0.21925013]\n",
      " [ 0.99833721  0.21188895]]\n",
      "cost:\n",
      "0.17014\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289  0.26179933]\n",
      " [-0.87266444 -0.26179933]\n",
      " [ 0.95993089  0.17453289]\n",
      " [-1.04719733  0.26179933]\n",
      " [-0.08726644  0.34906578]\n",
      " [ 0.34906578  0.17453289]\n",
      " [ 0.785398    0.        ]\n",
      " [-0.26179933  0.17453289]\n",
      " [ 0.          0.26179933]\n",
      " [-0.87266444  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.14623247  0.10205928]\n",
      " [-0.951078   -0.63627756]\n",
      " [ 0.99962217 -0.02070167]\n",
      " [-0.99326026  0.07274149]\n",
      " [-0.14597017  0.19212368]\n",
      " [ 0.32709059 -0.00379336]\n",
      " [ 0.97904414 -0.22465047]\n",
      " [-0.31151658  0.00467632]\n",
      " [-0.0380271   0.10026567]\n",
      " [-0.95286906  0.09591978]]\n",
      "cost:\n",
      "0.211167\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867  0.26179933]\n",
      " [-0.17453289 -0.43633222]\n",
      " [ 1.13446378  0.17453289]\n",
      " [ 0.87266444 -0.26179933]\n",
      " [-0.52359867 -0.26179933]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [-0.52359867 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.97324669  0.47783095]\n",
      " [-0.25636062 -0.30175817]\n",
      " [ 0.99943161  0.37291002]\n",
      " [ 0.98001885 -0.11043289]\n",
      " [-0.98287225 -0.13307887]\n",
      " [ 0.34063843 -0.1384007 ]\n",
      " [ 0.09149782 -0.08394075]\n",
      " [ 0.45233211  0.01002484]\n",
      " [-0.08317682 -0.18235922]\n",
      " [-0.98561168 -0.28742057]]\n",
      "cost:\n",
      "0.25775\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289 -0.08726644]\n",
      " [-0.08726644  0.26179933]\n",
      " [-0.61086511  0.        ]\n",
      " [-0.52359867 -0.08726644]\n",
      " [ 0.95993089  0.34906578]\n",
      " [-0.785398   -0.17453289]\n",
      " [ 0.08726644  0.        ]\n",
      " [ 0.69813156  0.        ]\n",
      " [-0.34906578 -0.34906578]\n",
      " [-0.87266444  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.30179694 -0.10168373]\n",
      " [-0.09412979  0.24837452]\n",
      " [-0.58175772 -0.01618421]\n",
      " [-0.52298665 -0.10684682]\n",
      " [ 0.99948812  0.34017092]\n",
      " [-0.96864527 -0.24395224]\n",
      " [ 0.21465714 -0.01263137]\n",
      " [ 0.98384291 -0.03054306]\n",
      " [-0.40637666 -0.54254758]\n",
      " [-0.9970243   0.16959427]]\n",
      "cost:\n",
      "0.117415\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933  0.34906578]\n",
      " [-0.26179933 -0.26179933]\n",
      " [-0.26179933  0.17453289]\n",
      " [-0.08726644 -0.26179933]\n",
      " [-0.52359867 -0.17453289]\n",
      " [-0.69813156 -0.26179933]\n",
      " [ 0.08726644 -0.08726644]\n",
      " [-0.08726644 -0.26179933]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [-0.08726644 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.12370935  0.53126204]\n",
      " [-0.24370047 -0.16427958]\n",
      " [-0.20145509  0.28561869]\n",
      " [ 0.09979402 -0.18408197]\n",
      " [-0.84203076 -0.05986777]\n",
      " [-0.99840409 -0.11061157]\n",
      " [ 0.06447595 -0.02818318]\n",
      " [ 0.09979309 -0.1840822 ]\n",
      " [ 0.9999001  -0.21640295]\n",
      " [ 0.06092136 -0.33677548]]\n",
      "cost:\n",
      "0.210547\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511 -0.34906578]\n",
      " [ 0.26179933 -0.34906578]\n",
      " [-0.61086511  0.26179933]\n",
      " [-0.52359867 -0.26179933]\n",
      " [ 1.22173022 -0.34906578]\n",
      " [-1.22173022  0.        ]\n",
      " [-0.87266444  0.34906578]\n",
      " [ 0.785398   -0.08726644]\n",
      " [ 0.34906578  0.17453289]\n",
      " [-0.95993089 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.55651474 -0.3136709 ]\n",
      " [ 0.26259115 -0.31253886]\n",
      " [-0.53079915  0.3022179 ]\n",
      " [-0.47094572 -0.23667902]\n",
      " [ 0.99969971 -0.31621334]\n",
      " [-0.99119741  0.04025415]\n",
      " [-0.82153952  0.36955953]\n",
      " [ 0.98465967 -0.05435458]\n",
      " [ 0.3722637   0.20344968]\n",
      " [-0.96139711 -0.13537678]]\n",
      "cost:\n",
      "0.104119\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289  0.        ]\n",
      " [ 1.04719733 -0.34906578]\n",
      " [-1.22173022  0.34906578]\n",
      " [ 0.52359867  0.26179933]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [-0.17453289  0.08726644]\n",
      " [-0.34906578  0.34906578]\n",
      " [-0.17453289 -0.17453289]\n",
      " [-0.69813156  0.26179933]\n",
      " [ 1.13446378 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.11906762 -0.03398301]\n",
      " [ 0.99159014 -0.50057203]\n",
      " [-0.99969566  0.2038517 ]\n",
      " [ 0.52712417  0.19460164]\n",
      " [ 0.06177924 -0.24240333]\n",
      " [-0.21391053  0.05513775]\n",
      " [-0.40484422  0.27206928]\n",
      " [-0.21463045 -0.23493399]\n",
      " [-0.90040421  0.18425246]\n",
      " [ 0.99612546 -0.29444844]]\n",
      "cost:\n",
      "0.124963\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933 -0.17453289]\n",
      " [-0.08726644  0.        ]\n",
      " [-0.95993089 -0.08726644]\n",
      " [ 1.22173022 -0.34906578]\n",
      " [ 0.         -0.26179933]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [-0.87266444  0.34906578]\n",
      " [-1.04719733  0.08726644]\n",
      " [ 0.34906578 -0.34906578]\n",
      " [-0.08726644  0.26179933]]\n",
      "prediction:\n",
      "[[-0.35457259 -0.15505779]\n",
      " [-0.15255284  0.01639556]\n",
      " [-0.9723534  -0.05215262]\n",
      " [ 0.99989891 -0.33916286]\n",
      " [-0.03514037 -0.24594341]\n",
      " [ 0.87307709 -0.25093186]\n",
      " [-0.90289152  0.41945502]\n",
      " [-0.98627776  0.16355179]\n",
      " [ 0.31357887 -0.33752862]\n",
      " [-0.12488565  0.30881047]]\n",
      "cost:\n",
      "0.0906998\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644  0.17453289]\n",
      " [-1.22173022  0.26179933]\n",
      " [-0.34906578 -0.08726644]\n",
      " [-0.87266444  0.08726644]\n",
      " [-1.22173022 -0.17453289]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [-0.61086511  0.08726644]\n",
      " [-1.22173022 -0.34906578]\n",
      " [ 0.52359867  0.17453289]\n",
      " [ 0.785398   -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.00238677  0.20595413]\n",
      " [-0.95276421  0.30157596]\n",
      " [-0.38777956 -0.11388571]\n",
      " [-0.78624928  0.07001526]\n",
      " [-0.87256432 -0.29014507]\n",
      " [ 0.2864376  -0.20286538]\n",
      " [-0.55601358  0.08427056]\n",
      " [-0.91695815 -0.49880433]\n",
      " [ 0.78389287  0.22244897]\n",
      " [ 0.99995804 -0.23716085]]\n",
      "cost:\n",
      "0.178554\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089 -0.17453289]\n",
      " [ 0.17453289 -0.26179933]\n",
      " [ 0.26179933  0.        ]\n",
      " [ 1.22173022 -0.08726644]\n",
      " [-0.95993089 -0.08726644]\n",
      " [ 0.43633222  0.08726644]\n",
      " [ 0.785398    0.        ]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [-0.43633222  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.90350509 -0.21515277]\n",
      " [ 0.11371073 -0.3772561 ]\n",
      " [ 0.15576293  0.03493937]\n",
      " [ 0.96353865 -0.02940281]\n",
      " [-0.99997455 -0.05191787]\n",
      " [ 0.36100763  0.34462795]\n",
      " [ 0.67892218  0.09392941]\n",
      " [ 0.54351699 -0.20039316]\n",
      " [ 0.41990155 -0.40030652]\n",
      " [-0.51697314  0.37986478]]\n",
      "cost:\n",
      "0.167311\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867 -0.08726644]\n",
      " [-0.17453289  0.        ]\n",
      " [ 0.87266444  0.34906578]\n",
      " [-1.13446378  0.34906578]\n",
      " [-0.785398   -0.43633222]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [ 0.785398   -0.17453289]\n",
      " [-0.52359867  0.26179933]\n",
      " [-0.95993089  0.34906578]\n",
      " [-1.13446378 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.5483253  -0.09435896]\n",
      " [-0.15498553 -0.02568612]\n",
      " [ 0.99944991  0.25519434]\n",
      " [-0.96340209  0.23779754]\n",
      " [-0.72511369 -0.4757351 ]\n",
      " [ 0.49001145 -0.28238541]\n",
      " [ 0.99654788 -0.19013081]\n",
      " [-0.51224077  0.18683116]\n",
      " [-0.88585287  0.25604743]\n",
      " [-0.97972739 -0.28110597]]\n",
      "cost:\n",
      "0.111173\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289 -0.17453289]\n",
      " [-0.43633222  0.        ]\n",
      " [ 0.69813156  0.34906578]\n",
      " [-1.04719733  0.08726644]\n",
      " [ 0.34906578 -0.08726644]\n",
      " [-1.13446378  0.26179933]\n",
      " [ 0.         -0.34906578]\n",
      " [-1.04719733 -0.43633222]\n",
      " [-0.52359867  0.        ]\n",
      " [-0.26179933 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.21521062 -0.13664137]\n",
      " [-0.33312774  0.02341156]\n",
      " [ 0.99996251  0.37540027]\n",
      " [-0.80973005  0.0883425 ]\n",
      " [ 0.40083134 -0.0525172 ]\n",
      " [-0.94435817  0.24862847]\n",
      " [ 0.09250695 -0.33427781]\n",
      " [-0.98224431 -0.4735468 ]\n",
      " [-0.36927912  0.01646215]\n",
      " [-0.25011858 -0.24244641]]\n",
      "cost:\n",
      "0.130111\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733 -0.26179933]\n",
      " [-0.34906578 -0.26179933]\n",
      " [-1.13446378 -0.17453289]\n",
      " [ 1.13446378  0.17453289]\n",
      " [-1.04719733 -0.43633222]\n",
      " [-1.13446378  0.08726644]\n",
      " [ 0.785398   -0.08726644]\n",
      " [ 0.95993089  0.34906578]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [-0.785398    0.08726644]]\n",
      "prediction:\n",
      "[[ 0.98409551 -0.2815392 ]\n",
      " [-0.29430485 -0.2453772 ]\n",
      " [-0.98841828 -0.17371517]\n",
      " [ 0.9834668   0.21895632]\n",
      " [-0.98487586 -0.4302977 ]\n",
      " [-0.99245137  0.13333912]\n",
      " [ 0.79412729 -0.07464215]\n",
      " [ 0.94517702  0.42145884]\n",
      " [ 0.91023582 -0.16782394]\n",
      " [-0.80655843  0.11192949]]\n",
      "cost:\n",
      "0.0798535\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289 -0.08726644]\n",
      " [ 0.61086511  0.26179933]\n",
      " [-0.95993089  0.26179933]\n",
      " [-0.61086511 -0.34906578]\n",
      " [-0.95993089 -0.26179933]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [-0.43633222  0.26179933]\n",
      " [-0.95993089  0.17453289]\n",
      " [-0.08726644  0.26179933]\n",
      " [-0.87266444  0.26179933]]\n",
      "prediction:\n",
      "[[-0.16995965 -0.11879196]\n",
      " [ 0.99996209  0.12099691]\n",
      " [-0.89417493  0.17505462]\n",
      " [-0.56599855 -0.4479399 ]\n",
      " [-0.89966881 -0.36543411]\n",
      " [ 0.87594008 -0.36033982]\n",
      " [-0.43908855  0.16261289]\n",
      " [-0.89406782  0.0975765 ]\n",
      " [ 0.02817273  0.16983943]\n",
      " [-0.85103035  0.16024151]]\n",
      "cost:\n",
      "0.168542\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644  0.        ]\n",
      " [ 0.785398    0.26179933]\n",
      " [ 0.26179933  0.08726644]\n",
      " [-1.13446378  0.08726644]\n",
      " [-0.34906578  0.34906578]\n",
      " [-0.34906578 -0.08726644]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [ 0.52359867  0.17453289]\n",
      " [-1.22173022 -0.34906578]\n",
      " [ 1.04719733  0.        ]]\n",
      "prediction:\n",
      "[[ 0.08764295 -0.03503602]\n",
      " [ 0.89798057  0.21114184]\n",
      " [ 0.27964145  0.03144899]\n",
      " [-0.99779701  0.06552884]\n",
      " [-0.32167929  0.28767824]\n",
      " [-0.31824386 -0.14782102]\n",
      " [ 0.30614811 -0.36778218]\n",
      " [ 0.51708698  0.13825677]\n",
      " [-0.99368697 -0.50190151]\n",
      " [ 0.99945951 -0.08884819]]\n",
      "cost:\n",
      "0.101777\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578  0.08726644]\n",
      " [ 1.22173022 -0.08726644]\n",
      " [ 0.          0.        ]\n",
      " [-0.61086511 -0.08726644]\n",
      " [-1.04719733 -0.26179933]\n",
      " [ 1.04719733  0.34906578]\n",
      " [ 0.08726644 -0.43633222]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [ 1.04719733  0.08726644]\n",
      " [ 0.87266444  0.08726644]]\n",
      "prediction:\n",
      "[[-0.3170566   0.09408851]\n",
      " [ 0.93785775 -0.08374951]\n",
      " [ 0.01727621  0.01633481]\n",
      " [-0.71369743 -0.09607989]\n",
      " [-0.99995893 -0.30831724]\n",
      " [ 0.87046671  0.42864808]\n",
      " [ 0.18359952 -0.4794361 ]\n",
      " [ 0.32524738 -0.17336531]\n",
      " [ 0.92904657  0.10131644]\n",
      " [ 0.86061835  0.09640735]]\n",
      "cost:\n",
      "0.100683\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444 -0.34906578]\n",
      " [ 0.         -0.43633222]\n",
      " [ 0.17453289  0.17453289]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [-0.95993089 -0.26179933]\n",
      " [-0.69813156 -0.08726644]\n",
      " [ 0.69813156  0.17453289]\n",
      " [-0.69813156 -0.34906578]\n",
      " [ 0.785398    0.08726644]\n",
      " [-1.04719733 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.98004597 -0.23676266]\n",
      " [ 0.03496854 -0.35248721]\n",
      " [ 0.21413867  0.31639996]\n",
      " [ 0.99031186 -0.01663741]\n",
      " [-0.99497622 -0.18833449]\n",
      " [-0.75010049 -0.02982174]\n",
      " [ 0.78880882  0.34098387]\n",
      " [-0.7185955  -0.26153824]\n",
      " [ 0.95687079  0.23154609]\n",
      " [-0.99770069 -0.24047504]]\n",
      "cost:\n",
      "0.131247\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867  0.17453289]\n",
      " [-1.22173022  0.08726644]\n",
      " [ 0.785398   -0.43633222]\n",
      " [ 0.17453289 -0.26179933]\n",
      " [-0.43633222 -0.08726644]\n",
      " [-0.95993089 -0.08726644]\n",
      " [ 0.17453289 -0.43633222]\n",
      " [ 1.04719733 -0.17453289]\n",
      " [ 1.22173022 -0.34906578]\n",
      " [ 0.61086511 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.49015504  0.403429  ]\n",
      " [-0.99946696  0.35850388]\n",
      " [ 0.76226044 -0.34219611]\n",
      " [ 0.20276719 -0.18708114]\n",
      " [-0.46319869  0.00694294]\n",
      " [-0.99422175  0.00414279]\n",
      " [ 0.21299413 -0.33277589]\n",
      " [ 0.98859519 -0.05556524]\n",
      " [ 0.97922981 -0.1974712 ]\n",
      " [ 0.56231028 -0.10547041]]\n",
      "cost:\n",
      "0.15679\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089 -0.08726644]\n",
      " [-0.43633222  0.17453289]\n",
      " [-0.785398    0.17453289]\n",
      " [-0.08726644 -0.08726644]\n",
      " [-0.43633222  0.17453289]\n",
      " [ 0.17453289 -0.26179933]\n",
      " [-0.08726644  0.34906578]\n",
      " [-0.61086511  0.34906578]\n",
      " [-0.785398    0.34906578]\n",
      " [ 1.13446378  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.99622321 -0.28207085]\n",
      " [-0.51861393  0.05016086]\n",
      " [-0.99386358  0.00982821]\n",
      " [-0.11990463 -0.17456615]\n",
      " [-0.51861185  0.0501615 ]\n",
      " [ 0.22937164 -0.5903064 ]\n",
      " [-0.09631903  0.21267027]\n",
      " [-0.73114264  0.18856509]\n",
      " [-0.97131252  0.16463083]\n",
      " [ 0.99920708 -0.02036648]]\n",
      "cost:\n",
      "0.202472\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511 -0.43633222]\n",
      " [-0.87266444 -0.26179933]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [-1.13446378  0.17453289]\n",
      " [-0.69813156 -0.43633222]\n",
      " [-0.785398   -0.26179933]\n",
      " [ 0.43633222  0.17453289]\n",
      " [ 0.61086511  0.        ]\n",
      " [-0.17453289  0.08726644]\n",
      " [-0.26179933 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.52409154 -0.29737264]\n",
      " [-0.90533805 -0.15207112]\n",
      " [ 0.99989593 -0.27692413]\n",
      " [-0.99149811  0.38277104]\n",
      " [-0.64075196 -0.29703426]\n",
      " [-0.80483687 -0.14989802]\n",
      " [ 0.42407078  0.31668019]\n",
      " [ 0.93102545  0.06333357]\n",
      " [-0.1482051   0.16772105]\n",
      " [-0.21947838 -0.29065752]]\n",
      "cost:\n",
      "0.170914\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222  0.26179933]\n",
      " [-1.04719733  0.26179933]\n",
      " [ 0.26179933 -0.34906578]\n",
      " [ 1.22173022  0.        ]\n",
      " [ 1.04719733 -0.17453289]\n",
      " [-1.22173022  0.        ]\n",
      " [-1.13446378 -0.26179933]\n",
      " [-0.87266444  0.34906578]\n",
      " [-0.785398    0.08726644]\n",
      " [-1.04719733  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.37260818  0.20729791]\n",
      " [-0.88394052  0.21541257]\n",
      " [ 0.19117716 -0.49614239]\n",
      " [ 0.99914682 -0.07470627]\n",
      " [ 0.99832016 -0.24485223]\n",
      " [-0.90842265 -0.05803663]\n",
      " [-0.93989944 -0.3879149 ]\n",
      " [-0.71095413  0.28895283]\n",
      " [-0.71963739  0.03539901]\n",
      " [-0.92368889  0.02589875]]\n",
      "cost:\n",
      "0.168184\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444  0.17453289]\n",
      " [-0.52359867 -0.34906578]\n",
      " [-0.08726644  0.17453289]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [ 0.17453289 -0.26179933]\n",
      " [-0.61086511 -0.17453289]\n",
      " [ 0.         -0.43633222]\n",
      " [ 1.22173022  0.08726644]\n",
      " [-0.26179933 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.94655663  0.3344861 ]\n",
      " [-0.99418426 -0.3213599 ]\n",
      " [-0.15196101  0.32758719]\n",
      " [ 0.98267055 -0.13475557]\n",
      " [ 0.2565358  -0.03808976]\n",
      " [ 0.25947505 -0.23410837]\n",
      " [-0.99910921 -0.11068486]\n",
      " [-0.10892774 -0.42496961]\n",
      " [ 0.9890402   0.23138206]\n",
      " [-0.30834579 -0.11892685]]\n",
      "cost:\n",
      "0.200484\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933  0.34906578]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [ 0.52359867 -0.08726644]\n",
      " [-0.52359867  0.26179933]\n",
      " [ 0.61086511  0.26179933]\n",
      " [-0.17453289  0.        ]\n",
      " [-0.08726644  0.34906578]\n",
      " [ 0.52359867 -0.08726644]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [-0.43633222  0.34906578]]\n",
      "prediction:\n",
      "[[-0.16869165  0.19356483]\n",
      " [ 0.3954297  -0.59148306]\n",
      " [ 0.84390277 -0.18501069]\n",
      " [-0.99971956  0.10355522]\n",
      " [ 0.99831682  0.11386021]\n",
      " [-0.1766489  -0.04881395]\n",
      " [-0.08644786  0.19298276]\n",
      " [ 0.84390277 -0.18501069]\n",
      " [ 0.26854774 -0.14490382]\n",
      " [-0.95767677  0.16683079]]\n",
      "cost:\n",
      "0.299071\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.43633222  0.08726644]\n",
      " [-1.04719733 -0.26179933]\n",
      " [ 0.69813156  0.26179933]\n",
      " [ 0.26179933  0.        ]\n",
      " [-0.17453289  0.08726644]\n",
      " [ 0.69813156  0.34906578]\n",
      " [ 1.04719733  0.26179933]\n",
      " [-0.17453289  0.34906578]\n",
      " [-0.95993089 -0.26179933]\n",
      " [-0.61086511 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.40789449  0.01817341]\n",
      " [-0.99463701 -0.34411216]\n",
      " [ 0.85933012  0.14353271]\n",
      " [ 0.27430317 -0.06772906]\n",
      " [-0.16976607  0.04043408]\n",
      " [ 0.81192303  0.21456207]\n",
      " [ 0.99968874  0.15865251]\n",
      " [-0.15826817  0.24563746]\n",
      " [-0.99223089 -0.35160124]\n",
      " [-0.57073206 -0.49511781]]\n",
      "cost:\n",
      "0.104931\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.22173022 -0.17453289]\n",
      " [ 0.26179933 -0.43633222]\n",
      " [-0.43633222  0.08726644]\n",
      " [ 0.         -0.17453289]\n",
      " [-0.87266444 -0.34906578]\n",
      " [-0.26179933  0.34906578]\n",
      " [ 0.26179933  0.26179933]\n",
      " [-1.22173022  0.08726644]\n",
      " [ 1.04719733  0.34906578]\n",
      " [-1.04719733  0.08726644]]\n",
      "prediction:\n",
      "[[-0.88056517 -0.23890021]\n",
      " [ 0.22596027 -0.45731038]\n",
      " [-0.43568751  0.02009001]\n",
      " [-0.03661086 -0.20010728]\n",
      " [-0.7951923  -0.38696131]\n",
      " [-0.31814927  0.28604847]\n",
      " [ 0.2370327   0.21248382]\n",
      " [-0.90246606  0.01666651]\n",
      " [ 0.99997449  0.25962204]\n",
      " [-0.87550598  0.02500232]]\n",
      "cost:\n",
      "0.133727\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398   -0.17453289]\n",
      " [-0.69813156 -0.08726644]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [-1.13446378  0.34906578]\n",
      " [ 0.69813156  0.08726644]\n",
      " [-1.13446378  0.34906578]\n",
      " [-0.61086511  0.26179933]\n",
      " [ 0.52359867  0.08726644]\n",
      " [-0.52359867  0.08726644]\n",
      " [-0.61086511 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.79622281 -0.43250114]\n",
      " [-0.69437504 -0.25408846]\n",
      " [ 0.558438   -0.3602353 ]\n",
      " [-0.9506169   0.28043827]\n",
      " [ 0.99993169  0.0011789 ]\n",
      " [-0.95060921  0.28043523]\n",
      " [-0.52446985  0.22109038]\n",
      " [ 0.93035555  0.02211731]\n",
      " [-0.5079658   0.0449013 ]\n",
      " [-0.59696388 -0.22525333]]\n",
      "cost:\n",
      "0.210253\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444 -0.34906578]\n",
      " [ 0.         -0.34906578]\n",
      " [-1.13446378  0.34906578]\n",
      " [-0.69813156  0.08726644]\n",
      " [ 0.26179933  0.17453289]\n",
      " [ 0.34906578 -0.08726644]\n",
      " [ 0.69813156  0.26179933]\n",
      " [ 0.17453289  0.        ]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [ 0.43633222 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.9848187  -0.39588273]\n",
      " [-0.05014133 -0.3832041 ]\n",
      " [-0.99744344  0.32845643]\n",
      " [-0.89509588  0.08985575]\n",
      " [ 0.34984502  0.17093873]\n",
      " [ 0.42062852 -0.08912349]\n",
      " [ 0.99942863  0.25042641]\n",
      " [ 0.10625042  0.00681854]\n",
      " [ 0.93195003 -0.08709016]\n",
      " [ 0.50215697 -0.28043461]]\n",
      "cost:\n",
      "0.143707\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.22173022  0.08726644]\n",
      " [-1.04719733 -0.34906578]\n",
      " [-0.87266444 -0.26179933]\n",
      " [ 0.17453289 -0.34906578]\n",
      " [-0.69813156 -0.43633222]\n",
      " [-1.22173022  0.17453289]\n",
      " [ 0.17453289  0.17453289]\n",
      " [ 1.22173022 -0.43633222]\n",
      " [-0.69813156 -0.17453289]\n",
      " [ 0.17453289 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.84532142  0.29431751]\n",
      " [-0.86057472 -0.19389452]\n",
      " [-0.75683647 -0.13376479]\n",
      " [ 0.08209593 -0.26387501]\n",
      " [-0.57287061 -0.30420798]\n",
      " [-0.82739222  0.38287133]\n",
      " [ 0.08981765  0.28522781]\n",
      " [ 0.99997884 -0.27482969]\n",
      " [-0.54973674 -0.07126811]\n",
      " [ 0.07620747 -0.12150979]]\n",
      "cost:\n",
      "0.230494\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156 -0.34906578]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [-1.22173022  0.26179933]\n",
      " [ 0.87266444  0.26179933]\n",
      " [ 0.34906578 -0.43633222]\n",
      " [ 0.08726644  0.26179933]\n",
      " [-1.04719733  0.17453289]\n",
      " [ 0.26179933  0.17453289]\n",
      " [-0.61086511 -0.17453289]\n",
      " [ 0.         -0.17453289]]\n",
      "prediction:\n",
      "[[-0.65703368 -0.35864934]\n",
      " [ 0.2474255  -0.17145871]\n",
      " [-0.9841336   0.2121418 ]\n",
      " [ 0.99993944  0.20725217]\n",
      " [ 0.38615704 -0.4496294 ]\n",
      " [-0.02397004  0.24764934]\n",
      " [-0.97867423  0.13430327]\n",
      " [ 0.22690995  0.17468975]\n",
      " [-0.54017425 -0.16801016]\n",
      " [-0.05570766 -0.15529916]]\n",
      "cost:\n",
      "0.0833912\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289  0.26179933]\n",
      " [ 1.04719733  0.34906578]\n",
      " [ 0.95993089  0.17453289]\n",
      " [ 0.         -0.17453289]\n",
      " [-0.61086511  0.17453289]\n",
      " [ 0.26179933  0.08726644]\n",
      " [-1.04719733  0.26179933]\n",
      " [ 0.34906578 -0.34906578]\n",
      " [-0.52359867  0.        ]\n",
      " [ 0.43633222  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.13864824  0.14763492]\n",
      " [ 0.98950714  0.16608341]\n",
      " [ 0.99156958  0.02720838]\n",
      " [-0.04220368 -0.27067125]\n",
      " [-0.70677722  0.04686945]\n",
      " [ 0.2369231   0.00396739]\n",
      " [-0.99986911  0.10251167]\n",
      " [ 0.27214769 -0.61497772]\n",
      " [-0.61070234 -0.09759914]\n",
      " [ 0.36125225  0.2086339 ]]\n",
      "cost:\n",
      "0.154686\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222 -0.34906578]\n",
      " [-0.785398    0.26179933]\n",
      " [-0.785398   -0.26179933]\n",
      " [ 1.22173022 -0.43633222]\n",
      " [ 0.43633222  0.34906578]\n",
      " [ 0.61086511 -0.17453289]\n",
      " [ 0.785398    0.26179933]\n",
      " [-1.04719733 -0.08726644]\n",
      " [ 0.61086511  0.        ]\n",
      " [-0.43633222  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.47351009 -0.35938272]\n",
      " [-0.89349222  0.24329481]\n",
      " [-0.92824638 -0.27709809]\n",
      " [ 0.99825251 -0.4165892 ]\n",
      " [ 0.41397935  0.37012339]\n",
      " [ 0.63616884 -0.17008719]\n",
      " [ 0.91100991  0.25565389]\n",
      " [-0.9995333  -0.10662498]\n",
      " [ 0.70574629  0.00674854]\n",
      " [-0.43074664  0.06888973]]\n",
      "cost:\n",
      "0.0864199\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289 -0.34906578]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [-0.26179933 -0.17453289]\n",
      " [-1.22173022  0.26179933]\n",
      " [ 0.95993089  0.        ]\n",
      " [-1.22173022 -0.08726644]\n",
      " [ 0.43633222  0.34906578]\n",
      " [ 1.22173022  0.08726644]\n",
      " [ 0.34906578 -0.43633222]\n",
      " [-0.17453289  0.34906578]]\n",
      "prediction:\n",
      "[[-0.24378996 -0.34230232]\n",
      " [ 0.18887852 -0.25869444]\n",
      " [-0.32829991 -0.15559541]\n",
      " [-0.98703527  0.23159514]\n",
      " [ 0.99299675 -0.01606253]\n",
      " [-0.99877137 -0.13475847]\n",
      " [ 0.3830227   0.29110703]\n",
      " [ 0.99697185  0.08899432]\n",
      " [ 0.30424544 -0.45723546]\n",
      " [-0.25744885  0.29063112]]\n",
      "cost:\n",
      "0.116748\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398   -0.08726644]\n",
      " [ 0.          0.26179933]\n",
      " [-0.08726644 -0.43633222]\n",
      " [-0.785398   -0.08726644]\n",
      " [-0.87266444 -0.43633222]\n",
      " [ 0.52359867 -0.08726644]\n",
      " [-0.43633222  0.34906578]\n",
      " [ 0.08726644  0.34906578]\n",
      " [-0.43633222  0.        ]\n",
      " [ 0.17453289  0.08726644]]\n",
      "prediction:\n",
      "[[-0.95344049 -0.10663576]\n",
      " [-0.01108619  0.20165876]\n",
      " [-0.03761239 -0.47146714]\n",
      " [-0.95344049 -0.10663576]\n",
      " [-0.9070347  -0.45485437]\n",
      " [ 0.99996102 -0.1059874 ]\n",
      " [-0.11631965  0.26380572]\n",
      " [ 0.10994143  0.29759079]\n",
      " [-0.4841173  -0.02846368]\n",
      " [ 0.2905359   0.06082849]]\n",
      "cost:\n",
      "0.153809\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222  0.        ]\n",
      " [-1.22173022  0.08726644]\n",
      " [ 0.08726644  0.26179933]\n",
      " [-0.69813156  0.17453289]\n",
      " [-0.69813156 -0.08726644]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [-0.34906578  0.34906578]\n",
      " [-1.13446378  0.17453289]\n",
      " [ 0.785398    0.34906578]\n",
      " [ 1.22173022 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.44703278 -0.05762056]\n",
      " [-0.99107611 -0.0452491 ]\n",
      " [ 0.05849251  0.17731547]\n",
      " [-0.66963065  0.07316723]\n",
      " [-0.67133701 -0.16051552]\n",
      " [ 0.34652752 -0.24793012]\n",
      " [-0.38184208  0.23932952]\n",
      " [-0.98566073  0.05440443]\n",
      " [ 0.92669785  0.20804882]\n",
      " [ 0.99979293 -0.60253859]]\n",
      "cost:\n",
      "0.145327\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867  0.34906578]\n",
      " [ 0.26179933  0.        ]\n",
      " [-0.26179933  0.34906578]\n",
      " [-0.87266444 -0.43633222]\n",
      " [-0.52359867 -0.43633222]\n",
      " [ 0.69813156  0.26179933]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [-0.52359867  0.26179933]\n",
      " [ 0.61086511 -0.34906578]\n",
      " [ 0.26179933 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.60041517  0.27026737]\n",
      " [ 0.32639539 -0.0171083 ]\n",
      " [-0.16869736  0.28629243]\n",
      " [-0.99984366 -0.38780758]\n",
      " [-0.70727158 -0.38608888]\n",
      " [ 0.98904413  0.1721158 ]\n",
      " [ 0.98719555 -0.15699045]\n",
      " [-0.54275036  0.19689916]\n",
      " [ 0.8251304  -0.31265184]\n",
      " [ 0.33285493 -0.09457441]]\n",
      "cost:\n",
      "0.156615\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222  0.17453289]\n",
      " [ 0.87266444  0.08726644]\n",
      " [-0.08726644 -0.17453289]\n",
      " [ 0.          0.26179933]\n",
      " [-1.22173022 -0.08726644]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [-0.785398    0.08726644]\n",
      " [ 0.          0.17453289]\n",
      " [-0.95993089  0.34906578]\n",
      " [-0.26179933 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.49225345  0.14971571]\n",
      " [ 0.99992412  0.00644436]\n",
      " [-0.09314079 -0.28126568]\n",
      " [ 0.00341313  0.21238533]\n",
      " [-0.98826313 -0.31456646]\n",
      " [ 0.47727159 -0.47067162]\n",
      " [-0.87097991 -0.00645973]\n",
      " [-0.00126564  0.13153018]\n",
      " [-0.96084285  0.33413556]\n",
      " [-0.26743338 -0.15187426]]\n",
      "cost:\n",
      "0.11568\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.          0.17453289]\n",
      " [ 0.95993089  0.08726644]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [-0.69813156  0.        ]\n",
      " [ 0.52359867 -0.08726644]\n",
      " [ 0.785398   -0.34906578]\n",
      " [-0.785398   -0.43633222]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [ 0.87266444 -0.26179933]\n",
      " [-0.69813156  0.34906578]]\n",
      "prediction:\n",
      "[[-0.11455137  0.24053755]\n",
      " [ 0.89060658  0.11064857]\n",
      " [ 0.96578407 -0.14130168]\n",
      " [-0.9948234   0.01031728]\n",
      " [ 0.44561064 -0.05519776]\n",
      " [ 0.78302884 -0.30082485]\n",
      " [-0.99860156 -0.38934618]\n",
      " [ 0.96578407 -0.14130168]\n",
      " [ 0.88638556 -0.22807683]\n",
      " [-0.94835716  0.45743364]]\n",
      "cost:\n",
      "0.150612\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867  0.17453289]\n",
      " [ 0.34906578 -0.43633222]\n",
      " [ 0.34906578  0.17453289]\n",
      " [ 1.22173022  0.08726644]\n",
      " [-0.34906578 -0.08726644]\n",
      " [-0.87266444  0.08726644]\n",
      " [-0.95993089  0.34906578]\n",
      " [ 0.61086511  0.        ]\n",
      " [ 0.52359867  0.34906578]\n",
      " [ 0.69813156  0.34906578]]\n",
      "prediction:\n",
      "[[-0.57359087  0.0524669 ]\n",
      " [ 0.27533525 -0.62819517]\n",
      " [ 0.33288538  0.03240469]\n",
      " [ 0.99953353 -0.04811716]\n",
      " [-0.37788731 -0.15167141]\n",
      " [-0.99686396 -0.02567651]\n",
      " [-0.99401468  0.1764722 ]\n",
      " [ 0.69684291 -0.08151123]\n",
      " [ 0.48702759  0.1621823 ]\n",
      " [ 0.69120461  0.15159427]]\n",
      "cost:\n",
      "0.166154\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156  0.26179933]\n",
      " [-0.61086511  0.34906578]\n",
      " [-0.87266444  0.        ]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [-0.34906578  0.26179933]\n",
      " [-1.22173022  0.08726644]\n",
      " [ 0.26179933 -0.08726644]\n",
      " [-0.26179933  0.17453289]\n",
      " [ 0.95993089  0.34906578]\n",
      " [ 1.22173022  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.67955685  0.15279239]\n",
      " [-0.58417296  0.23004322]\n",
      " [-0.97116202 -0.13362607]\n",
      " [ 0.31875423 -0.53524804]\n",
      " [-0.30442551  0.1508821 ]\n",
      " [-0.99922532 -0.28503355]\n",
      " [ 0.26518574 -0.22290428]\n",
      " [-0.21300867  0.06521873]\n",
      " [ 0.95932031  0.2403598 ]\n",
      " [ 0.99879801 -0.03837424]]\n",
      "cost:\n",
      "0.19862\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444 -0.17453289]\n",
      " [ 0.         -0.43633222]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [-0.52359867  0.34906578]\n",
      " [-0.95993089  0.08726644]\n",
      " [-0.34906578 -0.26179933]\n",
      " [-0.61086511  0.34906578]\n",
      " [-1.04719733 -0.43633222]\n",
      " [ 1.13446378  0.26179933]\n",
      " [-0.95993089  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.93247831 -0.15096031]\n",
      " [-0.07752095 -0.38861498]\n",
      " [ 0.99749172 -0.14557332]\n",
      " [-0.56381577  0.29881096]\n",
      " [-0.97907734  0.05965803]\n",
      " [-0.41913241 -0.22738008]\n",
      " [-0.62503159  0.28826764]\n",
      " [-0.95163316 -0.38562953]\n",
      " [ 0.99611789  0.22267307]\n",
      " [-0.98101318  0.12974346]]\n",
      "cost:\n",
      "0.0835233\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644 -0.43633222]\n",
      " [-0.95993089 -0.26179933]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [-0.95993089 -0.43633222]\n",
      " [-0.95993089  0.26179933]\n",
      " [ 0.69813156  0.08726644]\n",
      " [ 0.17453289 -0.43633222]\n",
      " [-1.04719733  0.        ]\n",
      " [ 0.26179933  0.34906578]\n",
      " [-1.13446378 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.14655939 -0.28952891]\n",
      " [-0.8166827  -0.16837914]\n",
      " [ 0.2703588  -0.12062101]\n",
      " [-0.78252345 -0.27367684]\n",
      " [-0.85767823  0.34163982]\n",
      " [ 0.99996597  0.14111565]\n",
      " [ 0.24011846 -0.27885199]\n",
      " [-0.91472352  0.06718132]\n",
      " [ 0.33079737  0.41876066]\n",
      " [-0.88006443 -0.20014533]]\n",
      "cost:\n",
      "0.177293\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378 -0.08726644]\n",
      " [-0.34906578 -0.17453289]\n",
      " [ 0.95993089  0.26179933]\n",
      " [-0.69813156  0.        ]\n",
      " [ 1.04719733  0.26179933]\n",
      " [ 0.87266444  0.17453289]\n",
      " [-1.13446378 -0.08726644]\n",
      " [-0.34906578  0.34906578]\n",
      " [ 0.08726644 -0.34906578]\n",
      " [-0.34906578  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.97671932 -0.23186971]\n",
      " [-0.3135162  -0.22742857]\n",
      " [ 0.92085665  0.21419215]\n",
      " [-0.87118697 -0.05552517]\n",
      " [ 0.95206511  0.20354001]\n",
      " [ 0.85184616  0.09143261]\n",
      " [-0.9998945  -0.21377251]\n",
      " [-0.36362949  0.30505577]\n",
      " [ 0.14604373 -0.49886245]\n",
      " [-0.32546097  0.05390501]]\n",
      "cost:\n",
      "0.115112\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444 -0.26179933]\n",
      " [ 0.         -0.08726644]\n",
      " [-0.17453289  0.34906578]\n",
      " [-0.61086511 -0.43633222]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [ 0.34906578  0.26179933]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [ 0.34906578 -0.34906578]\n",
      " [ 0.43633222  0.08726644]]\n",
      "prediction:\n",
      "[[-0.99971825 -0.22048487]\n",
      " [-0.00948374 -0.05712414]\n",
      " [-0.21129473  0.41268489]\n",
      " [-0.90911335 -0.35778275]\n",
      " [ 0.99934518 -0.16653976]\n",
      " [ 0.26490772  0.33677965]\n",
      " [ 0.4772737  -0.194417  ]\n",
      " [ 0.42333829 -0.04407246]\n",
      " [ 0.25059119 -0.27493224]\n",
      " [ 0.39705676  0.14225757]]\n",
      "cost:\n",
      "0.114285\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156 -0.43633222]\n",
      " [-0.87266444 -0.43633222]\n",
      " [-0.95993089  0.26179933]\n",
      " [-1.04719733 -0.43633222]\n",
      " [-0.08726644  0.17453289]\n",
      " [ 0.785398   -0.26179933]\n",
      " [-0.69813156 -0.43633222]\n",
      " [ 0.52359867  0.34906578]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [ 1.04719733  0.17453289]]\n",
      "prediction:\n",
      "[[-0.68596792 -0.30336866]\n",
      " [-0.9050312  -0.2959798 ]\n",
      " [-0.97521776  0.29312944]\n",
      " [-0.98586518 -0.28434172]\n",
      " [-0.13665685  0.15101714]\n",
      " [ 0.91951591 -0.17216285]\n",
      " [-0.68596792 -0.30336866]\n",
      " [ 0.53595114  0.34774017]\n",
      " [ 0.77424467 -0.05401486]\n",
      " [ 0.99975753  0.19151062]]\n",
      "cost:\n",
      "0.0971719\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444  0.34906578]\n",
      " [-1.22173022 -0.43633222]\n",
      " [-1.22173022 -0.17453289]\n",
      " [-0.34906578  0.26179933]\n",
      " [ 0.785398    0.17453289]\n",
      " [ 1.04719733 -0.17453289]\n",
      " [ 0.785398   -0.17453289]\n",
      " [-0.34906578  0.08726644]\n",
      " [-1.04719733 -0.43633222]\n",
      " [-0.87266444 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.78820437  0.36664858]\n",
      " [-0.91148257 -0.37404487]\n",
      " [-0.96261817 -0.18311588]\n",
      " [-0.39782998  0.28161773]\n",
      " [ 0.93668193  0.17768697]\n",
      " [ 0.99981856 -0.15326421]\n",
      " [ 0.91871989 -0.17628787]\n",
      " [-0.43289134  0.10196643]\n",
      " [-0.9043501  -0.40278986]\n",
      " [-0.84725076 -0.07265202]]\n",
      "cost:\n",
      "0.131234\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644  0.        ]\n",
      " [-0.61086511 -0.17453289]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [ 0.26179933  0.        ]\n",
      " [-0.43633222 -0.08726644]\n",
      " [-0.61086511  0.08726644]\n",
      " [ 1.13446378  0.08726644]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [ 0.785398   -0.17453289]]\n",
      "prediction:\n",
      "[[-0.01360535  0.03866057]\n",
      " [-0.9917407  -0.18087205]\n",
      " [ 0.95455265 -0.11536066]\n",
      " [ 0.29734978 -0.15894908]\n",
      " [ 0.35611826  0.06389376]\n",
      " [-0.77763027 -0.08660841]\n",
      " [-0.99946004  0.2786603 ]\n",
      " [ 0.97838801  0.41395161]\n",
      " [ 0.93987817 -0.51107609]\n",
      " [ 0.79460979 -0.14479183]]\n",
      "cost:\n",
      "0.220719\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644  0.17453289]\n",
      " [ 0.61086511  0.        ]\n",
      " [ 0.87266444  0.17453289]\n",
      " [ 1.22173022  0.26179933]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [-0.61086511  0.34906578]\n",
      " [-0.785398    0.26179933]\n",
      " [-0.26179933  0.08726644]\n",
      " [-0.26179933 -0.08726644]\n",
      " [-0.52359867 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.13694756  0.1121297 ]\n",
      " [ 0.57424283 -0.09549277]\n",
      " [ 0.89397591  0.07087742]\n",
      " [ 0.98184758  0.13787138]\n",
      " [ 0.98628575 -0.51069236]\n",
      " [-0.87492967  0.2813437 ]\n",
      " [-0.99980938  0.17273475]\n",
      " [-0.25579181  0.02816847]\n",
      " [-0.23018189 -0.17383879]\n",
      " [-0.69343156 -0.43124062]]\n",
      "cost:\n",
      "0.179673\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089 -0.17453289]\n",
      " [ 0.17453289  0.26179933]\n",
      " [-0.87266444 -0.17453289]\n",
      " [-0.785398   -0.26179933]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [-0.61086511 -0.34906578]\n",
      " [-0.95993089  0.        ]\n",
      " [-0.52359867 -0.26179933]\n",
      " [ 0.95993089  0.        ]]\n",
      "prediction:\n",
      "[[ 0.98598492 -0.14930274]\n",
      " [ 0.25363511  0.57821453]\n",
      " [-0.97669053 -0.1316902 ]\n",
      " [-0.89349437 -0.21616675]\n",
      " [ 0.98598492 -0.14930274]\n",
      " [ 0.25945398 -0.0343245 ]\n",
      " [-0.59203565 -0.33062917]\n",
      " [-0.99782109  0.09072508]\n",
      " [-0.47885388 -0.2170721 ]\n",
      " [ 0.98739266  0.05927875]]\n",
      "cost:\n",
      "0.0981867\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733  0.        ]\n",
      " [-1.22173022  0.08726644]\n",
      " [-0.34906578 -0.34906578]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [ 0.95993089 -0.26179933]\n",
      " [-0.08726644  0.17453289]\n",
      " [ 0.87266444  0.26179933]\n",
      " [-0.87266444 -0.17453289]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [-0.08726644  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.92336106  0.01762013]\n",
      " [-0.99982309  0.08184658]\n",
      " [-0.28636006 -0.41746151]\n",
      " [ 0.97055948 -0.20529102]\n",
      " [ 0.91216958 -0.30203241]\n",
      " [-0.04326102  0.17343281]\n",
      " [ 0.83737743  0.30896398]\n",
      " [-0.97947234 -0.18764138]\n",
      " [ 0.55366355 -0.2921654 ]\n",
      " [-0.05869214  0.36183497]]\n",
      "cost:\n",
      "0.10399\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867  0.        ]\n",
      " [-0.69813156 -0.34906578]\n",
      " [ 0.61086511 -0.34906578]\n",
      " [ 0.          0.34906578]\n",
      " [-0.69813156  0.26179933]\n",
      " [-0.08726644  0.        ]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [ 0.52359867  0.26179933]\n",
      " [ 0.52359867  0.08726644]\n",
      " [ 0.34906578  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.471596   -0.04703098]\n",
      " [-0.99398261 -0.47091514]\n",
      " [ 0.75491261 -0.4762131 ]\n",
      " [-0.09098978  0.2195386 ]\n",
      " [-0.99907273  0.14466907]\n",
      " [-0.12475989 -0.04606117]\n",
      " [ 0.99855429 -0.12675339]\n",
      " [ 0.58371806  0.16551796]\n",
      " [ 0.48748174  0.02109803]\n",
      " [ 0.36279517  0.21807624]]\n",
      "cost:\n",
      "0.157537\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644 -0.17453289]\n",
      " [ 0.34906578  0.26179933]\n",
      " [-0.95993089  0.17453289]\n",
      " [-0.87266444 -0.17453289]\n",
      " [-0.43633222  0.26179933]\n",
      " [ 0.61086511  0.        ]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [-0.17453289 -0.26179933]\n",
      " [ 0.34906578  0.        ]\n",
      " [ 1.22173022 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.07530008 -0.1703651 ]\n",
      " [ 0.36753467  0.33903137]\n",
      " [-0.99889302  0.20265073]\n",
      " [-0.98247248 -0.22890584]\n",
      " [-0.44103584  0.31732666]\n",
      " [ 0.63008058  0.00124669]\n",
      " [ 0.73167312 -0.2067863 ]\n",
      " [-0.16109522 -0.28838658]\n",
      " [ 0.36551744  0.01383619]\n",
      " [ 0.99947494 -0.39438465]]\n",
      "cost:\n",
      "0.0694261\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511  0.26179933]\n",
      " [-0.34906578  0.        ]\n",
      " [-0.52359867  0.34906578]\n",
      " [ 0.17453289  0.26179933]\n",
      " [ 1.04719733  0.17453289]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [-0.87266444 -0.17453289]\n",
      " [-0.69813156  0.34906578]\n",
      " [-0.26179933 -0.17453289]\n",
      " [ 0.61086511 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.67289889  0.17104132]\n",
      " [-0.31196988 -0.03992362]\n",
      " [-0.55913955  0.25594962]\n",
      " [ 0.14169084  0.18065335]\n",
      " [ 0.99455398  0.078949  ]\n",
      " [ 0.99746215 -0.40095928]\n",
      " [-0.99919587 -0.24937941]\n",
      " [-0.8729946   0.24177086]\n",
      " [-0.2656782  -0.25073346]\n",
      " [ 0.56739342 -0.35078773]]\n",
      "cost:\n",
      "0.12522\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089  0.26179933]\n",
      " [ 0.17453289 -0.34906578]\n",
      " [ 1.04719733 -0.43633222]\n",
      " [ 0.785398    0.34906578]\n",
      " [ 0.69813156  0.17453289]\n",
      " [ 0.785398   -0.08726644]\n",
      " [ 1.13446378  0.17453289]\n",
      " [ 0.         -0.34906578]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [-0.52359867 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.65571809  0.27932805]\n",
      " [ 0.203798   -0.31999198]\n",
      " [ 0.80545706 -0.34807882]\n",
      " [ 0.66870755  0.33313355]\n",
      " [ 0.67085111  0.16249064]\n",
      " [ 0.62788892 -0.04877081]\n",
      " [ 0.54331118  0.17161021]\n",
      " [-0.00853089 -0.31879613]\n",
      " [ 0.52987587 -0.12581334]\n",
      " [-0.99998331 -0.20865501]]\n",
      "cost:\n",
      "0.236124\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222 -0.08726644]\n",
      " [ 0.17453289  0.        ]\n",
      " [ 0.52359867 -0.43633222]\n",
      " [ 0.26179933 -0.34906578]\n",
      " [ 1.22173022 -0.34906578]\n",
      " [-0.43633222 -0.26179933]\n",
      " [-1.22173022  0.26179933]\n",
      " [-0.95993089 -0.34906578]\n",
      " [ 0.95993089  0.08726644]\n",
      " [ 1.22173022  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.49125555 -0.04557408]\n",
      " [ 0.24036416  0.0352558 ]\n",
      " [ 0.55749178 -0.32838261]\n",
      " [ 0.27273959 -0.29233482]\n",
      " [ 0.96304005 -0.24959973]\n",
      " [-0.38982591 -0.18737614]\n",
      " [-0.9996317   0.37343052]\n",
      " [-0.99359584 -0.23784257]\n",
      " [ 0.91778862  0.14621034]\n",
      " [ 0.97201723  0.33452952]]\n",
      "cost:\n",
      "0.13768\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578  0.26179933]\n",
      " [ 0.17453289  0.34906578]\n",
      " [ 0.61086511  0.        ]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [-0.34906578  0.        ]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [-1.13446378  0.08726644]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [ 0.52359867  0.        ]\n",
      " [-0.17453289  0.        ]]\n",
      "prediction:\n",
      "[[  2.72146642e-01   2.78120965e-01]\n",
      " [  1.16758704e-01   3.61325115e-01]\n",
      " [  5.93919992e-01  -2.04515774e-02]\n",
      " [  5.39448500e-01  -1.36854708e-01]\n",
      " [ -3.86380166e-01  -2.61686966e-02]\n",
      " [  1.28265589e-01  -2.89506882e-01]\n",
      " [ -9.99934733e-01   8.03701405e-04]\n",
      " [  9.97064471e-01  -5.30274928e-01]\n",
      " [  4.67729419e-01  -1.53354788e-02]\n",
      " [ -2.13680580e-01  -1.15004033e-02]]\n",
      "cost:\n",
      "0.106072\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378  0.34906578]\n",
      " [-1.13446378 -0.34906578]\n",
      " [ 0.87266444  0.17453289]\n",
      " [-0.34906578 -0.34906578]\n",
      " [-0.61086511 -0.43633222]\n",
      " [ 0.08726644  0.        ]\n",
      " [ 0.43633222  0.34906578]\n",
      " [-0.69813156  0.        ]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [-1.04719733  0.26179933]]\n",
      "prediction:\n",
      "[[-0.90909445  0.26346472]\n",
      " [-0.93814331 -0.36191884]\n",
      " [ 0.99996418  0.12541823]\n",
      " [-0.34508944 -0.32945815]\n",
      " [-0.50373864 -0.41078788]\n",
      " [ 0.0368495   0.00615988]\n",
      " [ 0.45061052  0.2878024 ]\n",
      " [-0.61514384 -0.01716073]\n",
      " [ 0.1807272  -0.16780397]\n",
      " [-0.91088212  0.20787928]]\n",
      "cost:\n",
      "0.113079\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289 -0.34906578]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [-1.13446378  0.26179933]\n",
      " [-0.52359867  0.17453289]\n",
      " [ 0.69813156 -0.43633222]\n",
      " [-1.22173022 -0.08726644]\n",
      " [ 1.04719733  0.26179933]\n",
      " [-0.61086511  0.34906578]\n",
      " [-0.95993089 -0.34906578]\n",
      " [-1.04719733  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.10484472 -0.39054888]\n",
      " [ 0.08210111 -0.11156338]\n",
      " [-0.92938805  0.16779637]\n",
      " [-0.46849304  0.12944123]\n",
      " [ 0.86948216 -0.42089397]\n",
      " [-0.89536405 -0.0739492 ]\n",
      " [ 0.99994385  0.19682129]\n",
      " [-0.51726758  0.25861046]\n",
      " [-0.85892838 -0.35294718]\n",
      " [-0.91189301  0.18380201]]\n",
      "cost:\n",
      "0.143991\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156  0.08726644]\n",
      " [ 1.22173022  0.08726644]\n",
      " [-0.52359867 -0.43633222]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [ 0.69813156  0.        ]\n",
      " [-0.34906578  0.34906578]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [ 0.43633222  0.08726644]\n",
      " [-0.43633222  0.        ]\n",
      " [ 0.61086511  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.76499027  0.05377535]\n",
      " [ 0.99908519  0.07485264]\n",
      " [-0.99861425 -0.55381578]\n",
      " [ 0.23812932 -0.3040517 ]\n",
      " [ 0.70670521 -0.02239474]\n",
      " [-0.82684189  0.38273665]\n",
      " [-0.11335687 -0.19012928]\n",
      " [ 0.44602761  0.06314666]\n",
      " [-0.98914677 -0.01103312]\n",
      " [ 0.66456711  0.0618374 ]]\n",
      "cost:\n",
      "0.217804\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733  0.08726644]\n",
      " [ 0.17453289  0.26179933]\n",
      " [ 0.87266444  0.34906578]\n",
      " [-1.22173022  0.        ]\n",
      " [ 0.61086511  0.26179933]\n",
      " [ 0.61086511 -0.43633222]\n",
      " [-0.87266444 -0.17453289]\n",
      " [ 0.52359867  0.08726644]\n",
      " [-1.13446378  0.17453289]\n",
      " [ 0.34906578  0.        ]]\n",
      "prediction:\n",
      "[[ 0.99798065 -0.02227592]\n",
      " [ 0.20945071  0.16156062]\n",
      " [ 0.92081958  0.18663928]\n",
      " [-0.99764007 -0.04072148]\n",
      " [ 0.63792521  0.13363637]\n",
      " [ 0.60545743 -0.62207639]\n",
      " [-0.91454297 -0.25423881]\n",
      " [ 0.54556441 -0.00516989]\n",
      " [-0.99507165  0.07713591]\n",
      " [ 0.35639772 -0.0577375 ]]\n",
      "cost:\n",
      "0.135352\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398    0.17453289]\n",
      " [-0.785398    0.34906578]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [ 0.52359867  0.08726644]\n",
      " [ 0.87266444  0.26179933]\n",
      " [-0.34906578  0.        ]\n",
      " [ 0.785398    0.34906578]\n",
      " [-0.69813156 -0.43633222]\n",
      " [-1.04719733 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.93016249  0.09568299]\n",
      " [-0.90721905  0.20724702]\n",
      " [ 0.3028439  -0.346154  ]\n",
      " [ 0.69839936 -0.11390238]\n",
      " [ 0.51679552  0.02782726]\n",
      " [ 0.99137467  0.16254798]\n",
      " [-0.3145605  -0.02120736]\n",
      " [ 0.87016588  0.21655479]\n",
      " [-0.82900792 -0.55204594]\n",
      " [-0.99982691 -0.12660176]]\n",
      "cost:\n",
      "0.112326\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733 -0.43633222]\n",
      " [-1.13446378 -0.43633222]\n",
      " [-0.08726644  0.17453289]\n",
      " [-1.22173022 -0.26179933]\n",
      " [ 1.04719733  0.08726644]\n",
      " [ 0.95993089  0.17453289]\n",
      " [-0.08726644 -0.43633222]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [-1.13446378 -0.34906578]\n",
      " [-0.785398    0.17453289]]\n",
      "prediction:\n",
      "[[ 0.97787941 -0.26822391]\n",
      " [-0.97595918 -0.25224209]\n",
      " [-0.09395155  0.28715792]\n",
      " [-0.99031901 -0.13308685]\n",
      " [ 0.98770142  0.14511074]\n",
      " [ 0.98056763  0.27495292]\n",
      " [-0.10954665 -0.32087713]\n",
      " [ 0.88593107 -0.28174877]\n",
      " [-0.98764014 -0.20549592]\n",
      " [-0.81455553  0.29293525]]\n",
      "cost:\n",
      "0.158791\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089 -0.43633222]\n",
      " [ 0.69813156  0.34906578]\n",
      " [-0.17453289  0.        ]\n",
      " [ 1.22173022  0.34906578]\n",
      " [ 0.95993089  0.08726644]\n",
      " [ 0.52359867 -0.17453289]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [ 0.785398   -0.08726644]\n",
      " [ 0.95993089  0.17453289]\n",
      " [ 0.95993089  0.34906578]]\n",
      "prediction:\n",
      "[[ -9.99984264e-01  -5.45165300e-01]\n",
      " [  5.75138927e-01   2.16653973e-01]\n",
      " [ -6.86525777e-02   5.63379319e-04]\n",
      " [  7.48311639e-01   1.90828994e-01]\n",
      " [  6.27558529e-01   5.78728542e-02]\n",
      " [  4.41273123e-01  -1.98816523e-01]\n",
      " [  5.33590496e-01  -3.27653319e-01]\n",
      " [  5.85743785e-01  -1.03153504e-01]\n",
      " [  6.32782578e-01   1.05690010e-01]\n",
      " [  6.97511792e-01   2.18208000e-01]]\n",
      "cost:\n",
      "0.23263\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733  0.17453289]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [-0.08726644 -0.08726644]\n",
      " [ 0.08726644  0.        ]\n",
      " [-0.52359867  0.26179933]\n",
      " [-0.95993089  0.17453289]\n",
      " [-0.34906578  0.08726644]\n",
      " [-0.17453289 -0.43633222]\n",
      " [-0.87266444  0.26179933]\n",
      " [ 0.34906578  0.34906578]]\n",
      "prediction:\n",
      "[[-0.91708243  0.04584542]\n",
      " [ 0.18447915 -0.14044285]\n",
      " [-0.05494162 -0.14008662]\n",
      " [ 0.13506362 -0.03374835]\n",
      " [-0.29641527  0.13871914]\n",
      " [-0.95668858  0.06310517]\n",
      " [-0.36784303  0.02966453]\n",
      " [-0.13936494 -0.64538723]\n",
      " [-0.93132752  0.12830546]\n",
      " [ 0.99996495  0.19166322]]\n",
      "cost:\n",
      "0.181545\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867 -0.43633222]\n",
      " [ 0.08726644  0.34906578]\n",
      " [ 0.         -0.34906578]\n",
      " [-0.17453289 -0.17453289]\n",
      " [-0.08726644 -0.08726644]\n",
      " [ 0.87266444  0.        ]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [ 0.785398    0.08726644]\n",
      " [ 0.08726644  0.26179933]\n",
      " [-1.04719733  0.26179933]]\n",
      "prediction:\n",
      "[[-0.49473339 -0.44760939]\n",
      " [ 0.02480031  0.29596594]\n",
      " [-0.01930578 -0.35182425]\n",
      " [-0.20100455 -0.15706269]\n",
      " [-0.11223522 -0.07448602]\n",
      " [ 0.99686962  0.00685474]\n",
      " [ 0.36867532 -0.27026752]\n",
      " [ 0.95463401  0.08108146]\n",
      " [ 0.04679394  0.21330573]\n",
      " [-0.99989927  0.26318654]]\n",
      "cost:\n",
      "0.0664654\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733 -0.17453289]\n",
      " [ 0.69813156  0.26179933]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [ 0.61086511  0.26179933]\n",
      " [ 0.08726644 -0.43633222]\n",
      " [-0.87266444  0.08726644]\n",
      " [-0.87266444  0.34906578]\n",
      " [ 1.22173022 -0.34906578]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [ 1.22173022  0.        ]]\n",
      "prediction:\n",
      "[[-0.99915797 -0.1739326 ]\n",
      " [ 0.76090384  0.27410266]\n",
      " [ 0.24334346 -0.24785502]\n",
      " [ 0.63630778  0.2655358 ]\n",
      " [ 0.02757427 -0.42501736]\n",
      " [-0.97618037  0.07201807]\n",
      " [-0.9365319   0.3220686 ]\n",
      " [ 0.97892481 -0.31416085]\n",
      " [ 0.23692445 -0.1535431 ]\n",
      " [ 0.99539018 -0.03186323]]\n",
      "cost:\n",
      "0.0902005\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933 -0.26179933]\n",
      " [ 0.         -0.08726644]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [ 0.69813156  0.34906578]\n",
      " [ 0.26179933  0.26179933]\n",
      " [-1.22173022  0.17453289]\n",
      " [-0.08726644  0.17453289]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [-1.13446378 -0.34906578]\n",
      " [ 0.61086511  0.08726644]]\n",
      "prediction:\n",
      "[[-0.26037002 -0.34342849]\n",
      " [ 0.11468748 -0.10563309]\n",
      " [ 0.5738095  -0.11713613]\n",
      " [ 0.98763067  0.29961434]\n",
      " [ 0.38934779  0.23094486]\n",
      " [-0.99812049  0.11392028]\n",
      " [-0.00868522  0.16264434]\n",
      " [ 0.9713949  -0.2311884 ]\n",
      " [-0.99866641 -0.48955235]\n",
      " [ 0.87597513  0.06301609]]\n",
      "cost:\n",
      "0.181523\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.43633222 -0.43633222]\n",
      " [-1.04719733 -0.08726644]\n",
      " [-0.43633222 -0.43633222]\n",
      " [-0.26179933 -0.34906578]\n",
      " [ 0.52359867 -0.43633222]\n",
      " [-1.22173022  0.        ]\n",
      " [ 0.785398   -0.17453289]\n",
      " [ 0.          0.26179933]\n",
      " [ 0.08726644 -0.08726644]\n",
      " [-0.785398   -0.17453289]]\n",
      "prediction:\n",
      "[[-0.44492793 -0.2928164 ]\n",
      " [-0.97815019  0.02877526]\n",
      " [-0.44492793 -0.2928164 ]\n",
      " [-0.26010457 -0.23356184]\n",
      " [ 0.80457157 -0.29087892]\n",
      " [-0.97005558  0.23199223]\n",
      " [ 0.99993211 -0.07989265]\n",
      " [ 0.03509174  0.50291014]\n",
      " [ 0.08053837 -0.02981821]\n",
      " [-0.77255172 -0.07014272]]\n",
      "cost:\n",
      "0.183792\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378  0.34906578]\n",
      " [ 0.         -0.43633222]\n",
      " [-0.43633222  0.26179933]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [ 1.04719733  0.26179933]\n",
      " [-0.52359867 -0.34906578]\n",
      " [ 0.87266444  0.26179933]\n",
      " [ 0.43633222 -0.43633222]\n",
      " [-1.22173022  0.17453289]\n",
      " [ 0.34906578 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.95517033  0.23325843]\n",
      " [-0.00112009 -0.39947093]\n",
      " [-0.39841771  0.2210695 ]\n",
      " [ 0.41149372 -0.08976135]\n",
      " [ 0.95764804  0.19321585]\n",
      " [-0.49476236 -0.3344695 ]\n",
      " [ 0.81884706  0.20665468]\n",
      " [ 0.41878521 -0.41062167]\n",
      " [-0.99996001  0.10242162]\n",
      " [ 0.33078474 -0.18939659]]\n",
      "cost:\n",
      "0.0840987\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511  0.26179933]\n",
      " [-1.13446378  0.17453289]\n",
      " [ 0.61086511  0.17453289]\n",
      " [-1.22173022  0.        ]\n",
      " [-0.43633222  0.34906578]\n",
      " [-0.87266444  0.26179933]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [ 0.52359867 -0.17453289]\n",
      " [-0.87266444 -0.43633222]\n",
      " [-0.69813156  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.98990983  0.13372467]\n",
      " [-0.98030365  0.03256022]\n",
      " [ 0.99458694  0.0800237 ]\n",
      " [-0.97093785 -0.09872366]\n",
      " [-0.44638348  0.19421695]\n",
      " [-0.91989392  0.13789603]\n",
      " [ 0.96587425 -0.11855415]\n",
      " [ 0.90005273 -0.23414835]\n",
      " [-0.95519209 -0.62915814]\n",
      " [-0.70082688  0.12506799]]\n",
      "cost:\n",
      "0.264619\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156 -0.26179933]\n",
      " [-0.17453289  0.26179933]\n",
      " [ 0.95993089  0.08726644]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [ 0.43633222  0.26179933]\n",
      " [ 1.13446378  0.        ]\n",
      " [ 1.22173022  0.        ]\n",
      " [ 0.43633222  0.        ]\n",
      " [-0.52359867  0.34906578]\n",
      " [-1.13446378 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.83787209 -0.35633016]\n",
      " [-0.10338077  0.21673013]\n",
      " [ 0.8890934   0.06306203]\n",
      " [ 0.93708521 -0.35668188]\n",
      " [ 0.43322107  0.23079659]\n",
      " [ 0.92281723 -0.02410041]\n",
      " [ 0.85692245 -0.04514581]\n",
      " [ 0.40457702 -0.02624595]\n",
      " [-0.47471258  0.3190285 ]\n",
      " [-0.99994206 -0.40722615]]\n",
      "cost:\n",
      "0.153628\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867  0.08726644]\n",
      " [-0.52359867  0.26179933]\n",
      " [ 0.         -0.26179933]\n",
      " [ 1.13446378 -0.34906578]\n",
      " [-0.785398    0.34906578]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [ 0.26179933  0.26179933]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [-0.69813156  0.17453289]\n",
      " [-0.52359867 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.45877668  0.05017626]\n",
      " [-0.62359107  0.2198934 ]\n",
      " [-0.10696686 -0.30063805]\n",
      " [ 0.99992085 -0.44477546]\n",
      " [-0.99027681  0.31251416]\n",
      " [ 0.11718354 -0.19324256]\n",
      " [ 0.17738946  0.22473128]\n",
      " [ 0.30381343 -0.21171105]\n",
      " [-0.96901381  0.1314813 ]\n",
      " [-0.62696505 -0.12128288]]\n",
      "cost:\n",
      "0.126431\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222 -0.17453289]\n",
      " [-1.22173022  0.08726644]\n",
      " [-0.785398   -0.43633222]\n",
      " [-1.22173022 -0.43633222]\n",
      " [ 1.04719733  0.17453289]\n",
      " [ 1.22173022  0.26179933]\n",
      " [-0.26179933 -0.43633222]\n",
      " [ 0.52359867  0.34906578]\n",
      " [-1.13446378  0.        ]\n",
      " [ 0.43633222 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.37319717 -0.14455697]\n",
      " [-0.99008596  0.11125961]\n",
      " [-0.73367894 -0.35230929]\n",
      " [-0.94837844 -0.2974205 ]\n",
      " [ 0.99666655  0.19654594]\n",
      " [ 0.99756134  0.27846256]\n",
      " [-0.33800468 -0.3389473 ]\n",
      " [ 0.48827347  0.34729978]\n",
      " [-0.97815859  0.03588111]\n",
      " [ 0.38904321 -0.2082731 ]]\n",
      "cost:\n",
      "0.137879\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398    0.17453289]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [-0.43633222 -0.43633222]\n",
      " [-0.34906578  0.08726644]\n",
      " [-1.22173022  0.08726644]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [-0.26179933  0.17453289]\n",
      " [-1.22173022  0.26179933]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [-0.61086511 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.99144143  0.21617205]\n",
      " [ 0.47585732 -0.14923273]\n",
      " [-0.41577017 -0.41342798]\n",
      " [-0.35595205  0.12536088]\n",
      " [-0.99585772  0.13641575]\n",
      " [ 0.40284327 -0.23812981]\n",
      " [-0.23302077  0.19922952]\n",
      " [-0.99006748  0.30879736]\n",
      " [ 0.99870956 -0.15098363]\n",
      " [-0.56721222 -0.42006168]]\n",
      "cost:\n",
      "0.106566\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378  0.        ]\n",
      " [-0.34906578 -0.26179933]\n",
      " [ 1.04719733 -0.43633222]\n",
      " [-0.17453289 -0.43633222]\n",
      " [-0.34906578 -0.26179933]\n",
      " [ 0.08726644  0.34906578]\n",
      " [-0.95993089 -0.17453289]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [-1.04719733  0.08726644]\n",
      " [-0.43633222  0.26179933]]\n",
      "prediction:\n",
      "[[-0.96229094  0.07092142]\n",
      " [-0.42700097 -0.18661398]\n",
      " [ 0.9981364  -0.33357424]\n",
      " [-0.21561955 -0.31290111]\n",
      " [-0.42700097 -0.18661398]\n",
      " [ 0.04799547  0.41271201]\n",
      " [-0.9401083  -0.09826791]\n",
      " [ 0.99908125 -0.31416178]\n",
      " [-0.96705437  0.14306423]\n",
      " [-0.52653188  0.31819022]]\n",
      "cost:\n",
      "0.118672\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289 -0.17453289]\n",
      " [ 0.87266444  0.        ]\n",
      " [ 0.87266444  0.        ]\n",
      " [ 0.26179933 -0.08726644]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [ 0.95993089  0.08726644]\n",
      " [-0.785398    0.34906578]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [ 0.61086511  0.26179933]\n",
      " [-0.95993089 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.14032499 -0.17610651]\n",
      " [ 0.88962334 -0.00980152]\n",
      " [ 0.88962334 -0.00980152]\n",
      " [ 0.21752778 -0.08331673]\n",
      " [ 0.8278017  -0.22008716]\n",
      " [ 0.94246638  0.07944002]\n",
      " [-0.9743222   0.35487095]\n",
      " [ 0.51613438 -0.54931408]\n",
      " [ 0.5649761   0.27809912]\n",
      " [-0.99990499 -0.10857576]]\n",
      "cost:\n",
      "0.0684339\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644  0.08726644]\n",
      " [-0.52359867  0.08726644]\n",
      " [-0.26179933 -0.08726644]\n",
      " [ 0.87266444  0.26179933]\n",
      " [-0.26179933  0.26179933]\n",
      " [ 0.17453289  0.34906578]\n",
      " [ 0.785398   -0.43633222]\n",
      " [ 0.52359867  0.        ]\n",
      " [ 0.26179933  0.34906578]\n",
      " [-0.52359867 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.17496862  0.02249347]\n",
      " [-0.99688256  0.01003618]\n",
      " [-0.29435962 -0.12191599]\n",
      " [ 0.99883729  0.0909248 ]\n",
      " [-0.29874495  0.12486689]\n",
      " [ 0.11235347  0.191075  ]\n",
      " [ 0.98294443 -0.60060787]\n",
      " [ 0.41975132 -0.06761023]\n",
      " [ 0.17652853  0.18471022]\n",
      " [-0.99365717 -0.23869498]]\n",
      "cost:\n",
      "0.220056\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578  0.08726644]\n",
      " [ 0.26179933  0.        ]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [ 0.08726644  0.34906578]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [-0.87266444  0.17453289]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [ 0.785398   -0.34906578]\n",
      " [-0.95993089 -0.08726644]\n",
      " [-0.69813156  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.31179494  0.08914378]\n",
      " [ 0.24650587 -0.00944454]\n",
      " [ 0.78147936 -0.2110613 ]\n",
      " [ 0.02752833  0.35004511]\n",
      " [ 0.99569887 -0.23832709]\n",
      " [-0.99035281  0.14023137]\n",
      " [ 0.40388229 -0.08945818]\n",
      " [ 0.98359042 -0.539222  ]\n",
      " [-0.9987728  -0.11739025]\n",
      " [-0.84701079  0.22029658]]\n",
      "cost:\n",
      "0.0978112\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733 -0.08726644]\n",
      " [-1.04719733  0.34906578]\n",
      " [-1.22173022  0.17453289]\n",
      " [-1.04719733  0.34906578]\n",
      " [-0.17453289 -0.08726644]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [-1.04719733 -0.08726644]\n",
      " [ 0.         -0.17453289]\n",
      " [ 0.08726644 -0.34906578]\n",
      " [ 0.26179933 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.99740136 -0.09039578]\n",
      " [-0.93944508  0.34064433]\n",
      " [-0.94995093  0.16889341]\n",
      " [-0.93944508  0.34064433]\n",
      " [-0.24976742 -0.04657715]\n",
      " [ 0.99903131 -0.34836721]\n",
      " [-0.96437103 -0.07203075]\n",
      " [-0.03554908 -0.16972111]\n",
      " [ 0.10350661 -0.47040722]\n",
      " [ 0.2830011  -0.08027321]]\n",
      "cost:\n",
      "0.11272\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444  0.        ]\n",
      " [ 0.26179933 -0.43633222]\n",
      " [ 0.785398    0.34906578]\n",
      " [-0.43633222 -0.17453289]\n",
      " [-1.04719733  0.34906578]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [ 0.785398   -0.43633222]\n",
      " [ 0.87266444  0.26179933]\n",
      " [ 0.08726644  0.08726644]\n",
      " [ 0.61086511  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.89092731 -0.03596228]\n",
      " [ 0.27400035 -0.44213793]\n",
      " [ 0.7047767   0.23588631]\n",
      " [-0.47090483 -0.1992404 ]\n",
      " [-0.99997699  0.20742472]\n",
      " [ 0.3682496  -0.19373192]\n",
      " [ 0.73253775 -0.41377324]\n",
      " [ 0.91738504  0.18038222]\n",
      " [ 0.07964893  0.05999315]\n",
      " [ 0.51532912  0.18599872]]\n",
      "cost:\n",
      "0.0712378\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398    0.17453289]\n",
      " [-0.69813156  0.26179933]\n",
      " [-1.04719733 -0.34906578]\n",
      " [ 0.785398    0.08726644]\n",
      " [-0.61086511 -0.34906578]\n",
      " [-0.26179933 -0.34906578]\n",
      " [-0.26179933 -0.43633222]\n",
      " [-0.95993089  0.        ]\n",
      " [-1.13446378  0.34906578]\n",
      " [-0.95993089 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.99911767  0.18773644]\n",
      " [-0.63113177  0.2627674 ]\n",
      " [-0.90380192 -0.26273021]\n",
      " [ 0.99905664  0.10532525]\n",
      " [-0.60713071 -0.2679489 ]\n",
      " [-0.25928581 -0.27497602]\n",
      " [-0.26585469 -0.34000835]\n",
      " [-0.85191023  0.02192153]\n",
      " [-0.93037426  0.34018973]\n",
      " [-0.87973171 -0.20946155]]\n",
      "cost:\n",
      "0.132495\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644 -0.43633222]\n",
      " [ 0.34906578 -0.34906578]\n",
      " [ 0.69813156  0.        ]\n",
      " [-0.52359867  0.        ]\n",
      " [-0.26179933  0.17453289]\n",
      " [-0.52359867  0.08726644]\n",
      " [ 0.87266444  0.17453289]\n",
      " [-0.69813156 -0.43633222]\n",
      " [ 0.26179933 -0.34906578]\n",
      " [ 0.43633222 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.12052588 -0.30927357]\n",
      " [ 0.35120612 -0.24498041]\n",
      " [ 0.90045607  0.0381838 ]\n",
      " [-0.90479642  0.06480918]\n",
      " [-0.29426533  0.29383078]\n",
      " [-0.84809756  0.19235779]\n",
      " [ 0.99963272  0.30123171]\n",
      " [-0.99893266 -0.27918026]\n",
      " [ 0.21890627 -0.24831299]\n",
      " [ 0.46264172 -0.30499566]]\n",
      "cost:\n",
      "0.205494\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.          0.08726644]\n",
      " [ 0.95993089  0.17453289]\n",
      " [ 0.785398    0.08726644]\n",
      " [-1.22173022 -0.08726644]\n",
      " [-1.04719733 -0.43633222]\n",
      " [-0.69813156 -0.34906578]\n",
      " [ 0.87266444  0.26179933]\n",
      " [ 1.22173022  0.34906578]\n",
      " [-0.69813156  0.17453289]\n",
      " [-1.04719733 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.01445932  0.06644791]\n",
      " [ 0.99110317  0.10589692]\n",
      " [ 0.87066752  0.04955423]\n",
      " [-0.989914   -0.10602127]\n",
      " [-0.97471642 -0.4372268 ]\n",
      " [-0.71256649 -0.35716236]\n",
      " [ 0.95721549  0.20627727]\n",
      " [ 0.9929837   0.22512586]\n",
      " [-0.70595205  0.11883876]\n",
      " [-0.98053014 -0.35481262]]\n",
      "cost:\n",
      "0.100005\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511 -0.17453289]\n",
      " [ 0.34906578  0.34906578]\n",
      " [ 0.43633222  0.        ]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [-0.95993089  0.08726644]\n",
      " [ 0.61086511 -0.34906578]\n",
      " [ 0.34906578  0.17453289]\n",
      " [ 0.17453289 -0.26179933]\n",
      " [-1.22173022 -0.34906578]\n",
      " [ 0.26179933 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.73924112 -0.14887546]\n",
      " [ 0.31742808  0.44982174]\n",
      " [ 0.49526322  0.0317583 ]\n",
      " [ 0.9992041  -0.22271869]\n",
      " [-0.9907676   0.11334372]\n",
      " [ 0.91777855 -0.29489419]\n",
      " [ 0.3710694   0.23790987]\n",
      " [ 0.10406024 -0.23365469]\n",
      " [-0.99834716 -0.29451069]\n",
      " [ 0.23230062 -0.14912438]]\n",
      "cost:\n",
      "0.137096\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222  0.26179933]\n",
      " [-0.61086511 -0.34906578]\n",
      " [-0.52359867  0.34906578]\n",
      " [-0.87266444 -0.26179933]\n",
      " [-0.785398   -0.34906578]\n",
      " [-0.785398    0.17453289]\n",
      " [-0.87266444 -0.34906578]\n",
      " [-0.785398   -0.34906578]\n",
      " [-0.785398   -0.26179933]\n",
      " [-0.52359867 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.9999854   0.30452475]\n",
      " [-0.61176109 -0.23693538]\n",
      " [-0.50952578  0.38980758]\n",
      " [-0.54139423 -0.15804261]\n",
      " [-0.61661792 -0.22510946]\n",
      " [-0.66976446  0.24698699]\n",
      " [-0.70485449 -0.22988875]\n",
      " [-0.61661792 -0.22510946]\n",
      " [-0.4165574  -0.16161859]\n",
      " [-0.50013381 -0.19356298]]\n",
      "cost:\n",
      "0.228311\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867 -0.17453289]\n",
      " [ 0.52359867  0.        ]\n",
      " [-0.17453289  0.17453289]\n",
      " [ 1.04719733  0.08726644]\n",
      " [-0.69813156  0.17453289]\n",
      " [-0.95993089 -0.43633222]\n",
      " [ 0.52359867  0.        ]\n",
      " [ 1.04719733  0.17453289]\n",
      " [-0.52359867  0.17453289]\n",
      " [ 0.52359867 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.42797989 -0.20886776]\n",
      " [ 0.44303617 -0.02201266]\n",
      " [-0.21941827  0.16767046]\n",
      " [ 0.99026126  0.05230818]\n",
      " [-0.95082009  0.16635431]\n",
      " [-0.99973369 -0.5864411 ]\n",
      " [ 0.44303617 -0.02201266]\n",
      " [ 0.99117839  0.14713474]\n",
      " [-0.6586839   0.16933393]\n",
      " [ 0.42798048 -0.20888801]]\n",
      "cost:\n",
      "0.108811\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.22173022 -0.43633222]\n",
      " [ 0.26179933  0.17453289]\n",
      " [-1.13446378 -0.34906578]\n",
      " [-0.61086511  0.34906578]\n",
      " [-0.08726644 -0.26179933]\n",
      " [ 0.          0.34906578]\n",
      " [ 1.22173022  0.34906578]\n",
      " [ 0.34906578  0.        ]\n",
      " [ 0.26179933 -0.34906578]\n",
      " [ 1.22173022  0.17453289]]\n",
      "prediction:\n",
      "[[-0.99422199 -0.36719954]\n",
      " [ 0.25455859  0.13479654]\n",
      " [-0.99649715 -0.34139201]\n",
      " [-0.62138987  0.2351492 ]\n",
      " [-0.22461554 -0.26852259]\n",
      " [-0.07159296  0.2847712 ]\n",
      " [ 0.99568325  0.18421151]\n",
      " [ 0.28914186 -0.0202976 ]\n",
      " [ 0.15003324 -0.33273742]\n",
      " [ 0.99711847  0.08544187]]\n",
      "cost:\n",
      "0.146212\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867  0.        ]\n",
      " [-0.43633222 -0.08726644]\n",
      " [-0.17453289 -0.17453289]\n",
      " [ 1.13446378  0.        ]\n",
      " [ 0.52359867 -0.17453289]\n",
      " [ 0.34906578 -0.34906578]\n",
      " [-0.52359867  0.26179933]\n",
      " [-0.17453289  0.08726644]\n",
      " [ 0.95993089 -0.43633222]\n",
      " [ 0.52359867 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.4718574   0.0588893 ]\n",
      " [-0.99254262 -0.05023643]\n",
      " [-0.41069412 -0.13486777]\n",
      " [ 0.98824936  0.11114895]\n",
      " [ 0.50086725 -0.11461855]\n",
      " [ 0.34423247 -0.3096301 ]\n",
      " [-0.99915498  0.47640023]\n",
      " [-0.42469275  0.16367267]\n",
      " [ 0.99437886 -0.42136467]\n",
      " [ 0.54499352 -0.20736481]]\n",
      "cost:\n",
      "0.204213\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733  0.17453289]\n",
      " [-0.61086511  0.08726644]\n",
      " [-0.52359867  0.17453289]\n",
      " [ 0.87266444  0.26179933]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [-0.17453289 -0.17453289]\n",
      " [-0.61086511  0.        ]\n",
      " [-0.61086511  0.34906578]\n",
      " [-0.43633222 -0.34906578]\n",
      " [ 0.95993089 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.99968976  0.09522808]\n",
      " [-0.59942114  0.07141037]\n",
      " [-0.51263213  0.14235184]\n",
      " [ 0.96517003  0.22206569]\n",
      " [ 0.99457854 -0.24630247]\n",
      " [-0.16165452 -0.18413836]\n",
      " [-0.56484312 -0.01365744]\n",
      " [-0.58528996  0.29999936]\n",
      " [-0.34648839 -0.3671442 ]\n",
      " [ 0.98389113 -0.46607807]]\n",
      "cost:\n",
      "0.0636661\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089  0.26179933]\n",
      " [ 0.17453289  0.34906578]\n",
      " [ 0.         -0.34906578]\n",
      " [ 0.69813156  0.26179933]\n",
      " [-0.34906578 -0.26179933]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [-0.43633222  0.34906578]\n",
      " [-0.43633222 -0.26179933]\n",
      " [-1.04719733 -0.26179933]\n",
      " [ 0.17453289 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.99238622  0.22161056]\n",
      " [ 0.20128712  0.29714149]\n",
      " [-0.00645639 -0.34539178]\n",
      " [ 0.73369777  0.20324372]\n",
      " [-0.35236701 -0.24622275]\n",
      " [ 0.9722454  -0.17216362]\n",
      " [-0.4557195   0.29706302]\n",
      " [-0.43688262 -0.25008887]\n",
      " [-0.99991995 -0.22214845]\n",
      " [ 0.19544514 -0.26966858]]\n",
      "cost:\n",
      "0.0365741\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644 -0.08726644]\n",
      " [ 0.26179933 -0.34906578]\n",
      " [-0.26179933 -0.26179933]\n",
      " [ 0.08726644 -0.34906578]\n",
      " [ 1.13446378  0.17453289]\n",
      " [-1.13446378 -0.34906578]\n",
      " [-1.13446378  0.        ]\n",
      " [-0.95993089 -0.26179933]\n",
      " [-0.26179933 -0.26179933]\n",
      " [-0.17453289  0.17453289]]\n",
      "prediction:\n",
      "[[-0.07102554 -0.04146569]\n",
      " [ 0.27729931 -0.28248116]\n",
      " [-0.33725265 -0.20530941]\n",
      " [ 0.12918356 -0.29609269]\n",
      " [ 0.99996448  0.41460264]\n",
      " [-0.96685386 -0.22980914]\n",
      " [-0.91447127  0.19318867]\n",
      " [-0.90151143 -0.17161265]\n",
      " [-0.33725265 -0.20530941]\n",
      " [-0.17537451  0.31577605]]\n",
      "cost:\n",
      "0.139539\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578 -0.34906578]\n",
      " [ 1.22173022  0.34906578]\n",
      " [-0.61086511 -0.17453289]\n",
      " [-0.08726644 -0.26179933]\n",
      " [ 0.08726644  0.08726644]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [ 0.61086511  0.34906578]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [ 0.87266444  0.        ]\n",
      " [ 0.43633222  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.31656757 -0.37808025]\n",
      " [ 0.98048198  0.26906252]\n",
      " [-0.99997211 -0.21413115]\n",
      " [-0.06865289 -0.26687455]\n",
      " [ 0.10891908  0.09440305]\n",
      " [ 0.56432277 -0.38184527]\n",
      " [ 0.45501035  0.27916032]\n",
      " [ 0.22124018 -0.16780159]\n",
      " [ 0.79742759 -0.01368034]\n",
      " [ 0.29890323  0.2908712 ]]\n",
      "cost:\n",
      "0.131242\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289  0.        ]\n",
      " [ 1.22173022  0.34906578]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [-0.26179933  0.08726644]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [ 0.61086511  0.08726644]\n",
      " [-0.08726644  0.        ]\n",
      " [-0.52359867  0.08726644]\n",
      " [-1.22173022 -0.43633222]\n",
      " [-0.26179933 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.1190609  -0.00947868]\n",
      " [ 0.99495292  0.410633  ]\n",
      " [ 0.55097091 -0.09636362]\n",
      " [-0.23781244  0.09476477]\n",
      " [ 0.94849259 -0.4147028 ]\n",
      " [ 0.57479006  0.09491143]\n",
      " [ 0.01520372 -0.00225357]\n",
      " [-0.57356632  0.12964983]\n",
      " [-0.99991173 -0.39588642]\n",
      " [-0.21236725 -0.33672723]]\n",
      "cost:\n",
      "0.0937145\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644  0.26179933]\n",
      " [ 0.61086511  0.08726644]\n",
      " [ 1.13446378  0.34906578]\n",
      " [ 0.17453289 -0.43633222]\n",
      " [ 0.          0.08726644]\n",
      " [-0.69813156 -0.43633222]\n",
      " [-0.785398   -0.34906578]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [-0.34906578  0.34906578]\n",
      " [-0.43633222  0.        ]]\n",
      "prediction:\n",
      "[[ 0.03457738  0.18189198]\n",
      " [ 0.61101842  0.04866107]\n",
      " [ 0.99975049  0.23901871]\n",
      " [ 0.15689924 -0.42511868]\n",
      " [-0.05900758  0.06667089]\n",
      " [-0.95814008 -0.41723743]\n",
      " [-0.99858165 -0.34665173]\n",
      " [ 0.73376375 -0.10365672]\n",
      " [-0.34317043  0.25970286]\n",
      " [-0.47436935 -0.02529712]]\n",
      "cost:\n",
      "0.104003\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398    0.34906578]\n",
      " [ 0.69813156  0.08726644]\n",
      " [ 0.17453289  0.        ]\n",
      " [ 0.17453289  0.08726644]\n",
      " [ 0.95993089  0.        ]\n",
      " [ 0.69813156 -0.43633222]\n",
      " [-1.22173022 -0.43633222]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [-0.95993089 -0.26179933]\n",
      " [ 0.34906578 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.8759169   0.46893406]\n",
      " [ 0.75159311  0.1229538 ]\n",
      " [ 0.23973493  0.01072658]\n",
      " [ 0.22742812  0.11789107]\n",
      " [ 0.98940104  0.0087341 ]\n",
      " [ 0.79270256 -0.38765302]\n",
      " [-0.99923223 -0.35918114]\n",
      " [ 0.37763432 -0.15526426]\n",
      " [-0.99805695 -0.24517584]\n",
      " [ 0.37763432 -0.15526426]]\n",
      "cost:\n",
      "0.0824792\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578 -0.43633222]\n",
      " [-0.26179933 -0.26179933]\n",
      " [-1.04719733  0.08726644]\n",
      " [ 0.69813156  0.26179933]\n",
      " [-1.13446378  0.34906578]\n",
      " [ 0.26179933  0.        ]\n",
      " [-0.69813156  0.34906578]\n",
      " [ 0.26179933  0.26179933]\n",
      " [-1.22173022  0.26179933]\n",
      " [ 1.22173022 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.40354118 -0.48155636]\n",
      " [-0.28592181 -0.32007685]\n",
      " [-0.90984654  0.01331164]\n",
      " [ 0.90759498  0.12493275]\n",
      " [-0.95603162  0.17044774]\n",
      " [ 0.2172761  -0.03627555]\n",
      " [-0.64447784  0.17663947]\n",
      " [ 0.26441374  0.15031451]\n",
      " [-0.97411573  0.10562702]\n",
      " [ 0.99990427 -0.40476793]]\n",
      "cost:\n",
      "0.166355\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733 -0.26179933]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [-0.69813156 -0.43633222]\n",
      " [ 0.08726644 -0.43633222]\n",
      " [-0.17453289  0.26179933]\n",
      " [-0.26179933 -0.08726644]\n",
      " [-0.69813156 -0.17453289]\n",
      " [ 1.13446378  0.        ]\n",
      " [-0.08726644 -0.17453289]\n",
      " [-0.785398   -0.08726644]]\n",
      "prediction:\n",
      "[[-0.99328941 -0.19707988]\n",
      " [ 0.66943908 -0.0562288 ]\n",
      " [-0.6892733  -0.36115113]\n",
      " [ 0.08557652 -0.35982174]\n",
      " [-0.17265038  0.50194633]\n",
      " [-0.27090061 -0.0353816 ]\n",
      " [-0.64458084 -0.10588931]\n",
      " [ 0.99993974  0.1269308 ]\n",
      " [-0.07062187 -0.11409181]\n",
      " [-0.83707345 -0.01775159]]\n",
      "cost:\n",
      "0.101691\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644 -0.08726644]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [-0.52359867 -0.08726644]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [ 0.95993089  0.17453289]\n",
      " [-0.08726644 -0.26179933]\n",
      " [ 0.08726644  0.34906578]\n",
      " [-0.08726644 -0.34906578]\n",
      " [-0.87266444  0.26179933]\n",
      " [ 0.61086511  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.02176665 -0.09885559]\n",
      " [ 0.93577808 -0.29353258]\n",
      " [-0.56337661 -0.1060003 ]\n",
      " [ 0.9508664  -0.1174426 ]\n",
      " [ 0.92431772  0.12692691]\n",
      " [-0.00461727 -0.3051191 ]\n",
      " [ 0.18050383  0.3239319 ]\n",
      " [-0.0076746  -0.44073275]\n",
      " [-0.99995935  0.22490679]\n",
      " [ 0.55436003  0.20194623]]\n",
      "cost:\n",
      "0.114986\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.34906578]\n",
      " [-0.08726644 -0.43633222]\n",
      " [ 0.          0.26179933]\n",
      " [ 0.17453289  0.26179933]\n",
      " [ 0.785398    0.34906578]\n",
      " [ 0.26179933  0.08726644]\n",
      " [-0.17453289  0.08726644]\n",
      " [-0.34906578  0.34906578]\n",
      " [ 0.34906578  0.08726644]\n",
      " [-0.08726644  0.        ]]\n",
      "prediction:\n",
      "[[ -9.99697626e-01  -4.64617521e-01]\n",
      " [ -9.30761471e-02  -5.16439855e-01]\n",
      " [ -8.41304194e-03   1.47221923e-01]\n",
      " [  1.25317380e-01   1.44103736e-01]\n",
      " [  9.99693573e-01   1.71320066e-01]\n",
      " [  2.09024757e-01  -4.12426860e-04]\n",
      " [ -2.08491266e-01   9.51459631e-03]\n",
      " [ -2.74840921e-01   1.94313765e-01]\n",
      " [  2.99194664e-01   2.29034922e-03]\n",
      " [ -1.00556254e-01  -7.22285286e-02]]\n",
      "cost:\n",
      "0.13095\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.43633222  0.        ]\n",
      " [ 0.43633222  0.08726644]\n",
      " [ 1.04719733  0.08726644]\n",
      " [-1.22173022  0.26179933]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [ 0.52359867  0.17453289]\n",
      " [ 0.52359867  0.        ]\n",
      " [ 0.95993089 -0.34906578]\n",
      " [-0.95993089 -0.26179933]\n",
      " [ 1.04719733 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.41053036 -0.01366663]\n",
      " [ 0.43762746  0.09535272]\n",
      " [ 0.93776143  0.12470929]\n",
      " [-0.99968719  0.37280861]\n",
      " [ 0.70534903 -0.31483123]\n",
      " [ 0.57208145  0.22401635]\n",
      " [ 0.53569889 -0.01099127]\n",
      " [ 0.89727867 -0.4430089 ]\n",
      " [-0.99464071 -0.34655756]\n",
      " [ 0.96194226 -0.11658885]]\n",
      "cost:\n",
      "0.0835107\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511  0.08726644]\n",
      " [-0.785398    0.34906578]\n",
      " [ 0.          0.26179933]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [-1.13446378  0.08726644]\n",
      " [-0.17453289  0.34906578]\n",
      " [ 0.26179933  0.        ]\n",
      " [-1.04719733  0.        ]\n",
      " [ 0.43633222 -0.34906578]\n",
      " [-0.26179933 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.55570412  0.03749822]\n",
      " [-0.76528418  0.22308034]\n",
      " [ 0.12023654  0.19241427]\n",
      " [ 0.99982291 -0.12067597]\n",
      " [-0.98900551  0.00807477]\n",
      " [-0.14850682  0.24066006]\n",
      " [ 0.39798349 -0.01779958]\n",
      " [-0.98358375 -0.0672055 ]\n",
      " [ 0.93381965 -0.58319926]\n",
      " [-0.17093755 -0.25728464]]\n",
      "cost:\n",
      "0.19108\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.22173022  0.26179933]\n",
      " [ 0.87266444 -0.34906578]\n",
      " [-0.34906578 -0.34906578]\n",
      " [-0.08726644  0.34906578]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [-0.69813156  0.26179933]\n",
      " [ 0.08726644  0.17453289]\n",
      " [ 0.87266444  0.08726644]\n",
      " [ 0.          0.34906578]\n",
      " [ 0.61086511  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.9666633   0.14800842]\n",
      " [ 0.91185635 -0.44296488]\n",
      " [-0.34822538 -0.43622848]\n",
      " [-0.14228867  0.20274754]\n",
      " [ 0.12117937 -0.30640787]\n",
      " [-0.99996358  0.10742372]\n",
      " [ 0.10350213  0.08578169]\n",
      " [ 0.85502344  0.02597768]\n",
      " [-0.02542886  0.2141991 ]\n",
      " [ 0.69466341  0.08011208]]\n",
      "cost:\n",
      "0.143708\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289 -0.43633222]\n",
      " [-0.34906578  0.17453289]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [-1.13446378  0.17453289]\n",
      " [-0.43633222 -0.43633222]\n",
      " [-1.13446378 -0.43633222]\n",
      " [-0.61086511 -0.43633222]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [ 0.52359867  0.08726644]\n",
      " [-0.43633222 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.13318832 -0.26696071]\n",
      " [-0.23483275  0.36373782]\n",
      " [ 0.99994117  0.00450908]\n",
      " [-0.98752701  0.38988215]\n",
      " [-0.36042422 -0.26204702]\n",
      " [-0.95858407 -0.2404623 ]\n",
      " [-0.52189577 -0.255018  ]\n",
      " [ 0.26908651 -0.17307013]\n",
      " [ 0.58923346  0.16978878]\n",
      " [-0.3382535  -0.20239729]]\n",
      "cost:\n",
      "0.181283\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.26179933 -0.34906578]\n",
      " [-0.87266444 -0.08726644]\n",
      " [ 0.87266444  0.34906578]\n",
      " [ 0.52359867  0.        ]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [-0.08726644  0.17453289]\n",
      " [ 0.43633222  0.26179933]\n",
      " [-0.52359867 -0.43633222]\n",
      " [-0.52359867 -0.34906578]\n",
      " [ 0.26179933 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.20498635 -0.30391747]\n",
      " [-0.99982995 -0.05819447]\n",
      " [ 0.93221092  0.38448539]\n",
      " [ 0.44720522  0.02197593]\n",
      " [ 0.99809843 -0.22741108]\n",
      " [-0.13671182  0.21592841]\n",
      " [ 0.37690488  0.3155874 ]\n",
      " [-0.67090225 -0.36799979]\n",
      " [-0.64594775 -0.28101426]\n",
      " [ 0.20885172 -0.13115159]]\n",
      "cost:\n",
      "0.10079\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578  0.26179933]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [ 0.34906578 -0.08726644]\n",
      " [-1.13446378 -0.34906578]\n",
      " [ 0.08726644 -0.08726644]\n",
      " [-0.69813156 -0.43633222]\n",
      " [-0.95993089 -0.08726644]\n",
      " [-0.52359867  0.08726644]\n",
      " [ 0.26179933 -0.08726644]\n",
      " [ 0.87266444 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.29693213  0.50971067]\n",
      " [ 0.46413818 -0.22748837]\n",
      " [ 0.40525663 -0.03545949]\n",
      " [-0.99198073 -0.32518792]\n",
      " [ 0.02258188 -0.03696121]\n",
      " [-0.73184657 -0.39422524]\n",
      " [-0.97479606 -0.03004517]\n",
      " [-0.50101674  0.22819199]\n",
      " [ 0.24685207 -0.03882881]\n",
      " [ 0.99989599 -0.01368102]]\n",
      "cost:\n",
      "0.107828\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.43633222 -0.08726644]\n",
      " [-1.22173022  0.34906578]\n",
      " [ 0.08726644  0.08726644]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [ 0.34906578  0.        ]\n",
      " [ 0.17453289  0.26179933]\n",
      " [-0.87266444  0.        ]\n",
      " [-0.43633222  0.        ]\n",
      " [ 0.61086511 -0.34906578]\n",
      " [ 0.43633222  0.        ]]\n",
      "prediction:\n",
      "[[-0.43328837 -0.11323982]\n",
      " [-0.99892551  0.3357203 ]\n",
      " [ 0.09874751  0.07123667]\n",
      " [ 0.79113281 -0.36774936]\n",
      " [ 0.58315563 -0.01899957]\n",
      " [ 0.23951495  0.31498712]\n",
      " [-0.98812652 -0.00869525]\n",
      " [-0.39617246 -0.02518613]\n",
      " [ 0.99872822 -0.51767075]\n",
      " [ 0.89246607 -0.01096614]]\n",
      "cost:\n",
      "0.200057\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644  0.26179933]\n",
      " [ 0.95993089  0.        ]\n",
      " [-1.13446378  0.34906578]\n",
      " [-0.69813156  0.34906578]\n",
      " [ 0.95993089  0.34906578]\n",
      " [-1.13446378 -0.34906578]\n",
      " [ 0.26179933 -0.43633222]\n",
      " [-0.08726644 -0.08726644]\n",
      " [ 0.87266444  0.17453289]\n",
      " [-0.95993089 -0.34906578]]\n",
      "prediction:\n",
      "[[ -3.90112400e-05   1.99640185e-01]\n",
      " [  9.94931102e-01  -7.67827332e-02]\n",
      " [ -9.85198021e-01   2.26665929e-01]\n",
      " [ -6.40143991e-01   2.26691887e-01]\n",
      " [  9.82421637e-01   2.29591176e-01]\n",
      " [ -9.90598142e-01  -3.48011345e-01]\n",
      " [  2.12119818e-01  -4.20608193e-01]\n",
      " [ -1.64917678e-01  -1.14083558e-01]\n",
      " [  9.84327674e-01   6.72753751e-02]\n",
      " [ -9.63519752e-01  -3.42198610e-01]]\n",
      "cost:\n",
      "0.108229\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444 -0.17453289]\n",
      " [-0.34906578  0.26179933]\n",
      " [-1.04719733  0.        ]\n",
      " [ 1.04719733 -0.26179933]\n",
      " [-0.17453289 -0.34906578]\n",
      " [-0.34906578  0.34906578]\n",
      " [ 0.52359867  0.26179933]\n",
      " [ 0.43633222  0.17453289]\n",
      " [ 0.26179933 -0.34906578]\n",
      " [ 1.04719733 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.82704186 -0.16813806]\n",
      " [-0.32741517  0.23404376]\n",
      " [-0.99995416 -0.01494398]\n",
      " [ 0.94330299 -0.26579526]\n",
      " [-0.16659999 -0.35838822]\n",
      " [-0.35542384  0.31968275]\n",
      " [ 0.46992391  0.24005865]\n",
      " [ 0.40632218  0.15532602]\n",
      " [ 0.20884995 -0.37984991]\n",
      " [ 0.96950459 -0.15628457]]\n",
      "cost:\n",
      "0.0511691\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222  0.08726644]\n",
      " [ 0.785398   -0.43633222]\n",
      " [-0.95993089  0.34906578]\n",
      " [-0.34906578  0.        ]\n",
      " [ 0.95993089  0.17453289]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [-0.08726644  0.26179933]\n",
      " [ 0.69813156 -0.43633222]\n",
      " [ 0.785398    0.26179933]\n",
      " [-1.13446378  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.41030237  0.03376764]\n",
      " [ 0.74385607 -0.44798419]\n",
      " [-0.98935181  0.24210794]\n",
      " [-0.37029564 -0.02090114]\n",
      " [ 0.95934165  0.10751241]\n",
      " [ 0.98234409 -0.27080503]\n",
      " [-0.05350573  0.20777513]\n",
      " [ 0.65696454 -0.43624622]\n",
      " [ 0.72480494  0.17839122]\n",
      " [-0.99967891  0.02464176]]\n",
      "cost:\n",
      "0.0906531\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222 -0.26179933]\n",
      " [-0.61086511  0.08726644]\n",
      " [ 0.69813156  0.26179933]\n",
      " [-1.04719733  0.34906578]\n",
      " [-1.13446378 -0.34906578]\n",
      " [-0.785398   -0.34906578]\n",
      " [-0.26179933  0.17453289]\n",
      " [-0.69813156 -0.26179933]\n",
      " [ 0.17453289 -0.43633222]\n",
      " [-1.04719733  0.        ]]\n",
      "prediction:\n",
      "[[ 0.62072837 -0.22958255]\n",
      " [-0.58231908  0.07365219]\n",
      " [ 0.99996793  0.29718572]\n",
      " [-0.87734008  0.36308309]\n",
      " [-0.89007378 -0.26895609]\n",
      " [-0.62505662 -0.28560749]\n",
      " [-0.26922008  0.18584979]\n",
      " [-0.57526827 -0.23011383]\n",
      " [ 0.17235149 -0.36624461]\n",
      " [-0.86299515 -0.00662721]]\n",
      "cost:\n",
      "0.151764\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933 -0.17453289]\n",
      " [ 0.          0.        ]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [ 0.785398    0.26179933]\n",
      " [ 0.17453289 -0.26179933]\n",
      " [ 0.95993089  0.        ]\n",
      " [-0.34906578  0.        ]\n",
      " [ 0.52359867  0.26179933]\n",
      " [-0.61086511 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.3573854  -0.14107636]\n",
      " [-0.02844818  0.01756759]\n",
      " [ 0.96645898 -0.4068369 ]\n",
      " [ 0.56945103 -0.25409999]\n",
      " [ 0.77817512  0.37952459]\n",
      " [ 0.18483479 -0.26162273]\n",
      " [ 0.95155311  0.06801467]\n",
      " [-0.54194987  0.03624088]\n",
      " [ 0.52223587  0.36922055]\n",
      " [-0.99994993 -0.23149581]]\n",
      "cost:\n",
      "0.132492\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378  0.34906578]\n",
      " [ 0.         -0.43633222]\n",
      " [ 0.87266444  0.34906578]\n",
      " [-0.87266444 -0.34906578]\n",
      " [-0.34906578  0.08726644]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [ 0.          0.08726644]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [ 0.785398    0.17453289]\n",
      " [-1.13446378  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.97381413  0.25518462]\n",
      " [ 0.07839797 -0.40832892]\n",
      " [ 0.8370297   0.26716647]\n",
      " [-0.98318124 -0.34140739]\n",
      " [-0.27852303  0.04211794]\n",
      " [ 0.96210957 -0.34744167]\n",
      " [ 0.08399881  0.07253204]\n",
      " [ 0.65054518 -0.25360742]\n",
      " [ 0.76059687  0.12214889]\n",
      " [-0.99977356  0.20546949]]\n",
      "cost:\n",
      "0.11355\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733 -0.26179933]\n",
      " [-0.08726644 -0.26179933]\n",
      " [ 1.13446378  0.17453289]\n",
      " [-0.785398    0.08726644]\n",
      " [-0.08726644 -0.26179933]\n",
      " [-0.87266444 -0.08726644]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [ 0.08726644  0.        ]\n",
      " [ 0.69813156  0.08726644]\n",
      " [-0.61086511  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.9922744  -0.39708561]\n",
      " [-0.18884732 -0.27995455]\n",
      " [ 0.99625438  0.36893651]\n",
      " [-0.97826862  0.18729249]\n",
      " [-0.18884732 -0.27995455]\n",
      " [-0.9987632  -0.04811184]\n",
      " [ 0.44916198 -0.34611964]\n",
      " [ 0.04645653  0.02531198]\n",
      " [ 0.69250458  0.16901579]\n",
      " [-0.72827208  0.17398828]]\n",
      "cost:\n",
      "0.130144\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222 -0.26179933]\n",
      " [-1.04719733  0.17453289]\n",
      " [-0.26179933  0.17453289]\n",
      " [-1.13446378  0.08726644]\n",
      " [ 0.          0.08726644]\n",
      " [ 0.43633222 -0.43633222]\n",
      " [ 0.87266444  0.        ]\n",
      " [-1.13446378 -0.26179933]\n",
      " [ 0.17453289 -0.34906578]\n",
      " [ 1.04719733 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.4270311  -0.22945797]\n",
      " [-0.97421753  0.27883682]\n",
      " [-0.29352823  0.2813817 ]\n",
      " [-0.98615402  0.20635165]\n",
      " [ 0.01075238  0.13272013]\n",
      " [ 0.47163826 -0.39509025]\n",
      " [ 0.97977805  0.03576352]\n",
      " [-0.98311204 -0.18343425]\n",
      " [ 0.20433018 -0.30092078]\n",
      " [ 0.99927384 -0.30244356]]\n",
      "cost:\n",
      "0.0970456\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444 -0.43633222]\n",
      " [-0.26179933  0.08726644]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [ 1.13446378  0.17453289]\n",
      " [-1.13446378 -0.34906578]\n",
      " [-1.13446378  0.08726644]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [-0.08726644  0.        ]\n",
      " [ 0.17453289  0.17453289]\n",
      " [ 0.          0.17453289]]\n",
      "prediction:\n",
      "[[-0.90987241 -0.48409653]\n",
      " [-0.31630737  0.0572248 ]\n",
      " [ 0.98801547 -0.19576402]\n",
      " [ 0.9853338   0.22888649]\n",
      " [-0.98942977 -0.38908017]\n",
      " [-0.99580324  0.13137792]\n",
      " [ 0.98777372 -0.20362841]\n",
      " [-0.08197457 -0.03367118]\n",
      " [ 0.19369265  0.21108638]\n",
      " [-0.02297227  0.19406793]]\n",
      "cost:\n",
      "0.106721\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644 -0.17453289]\n",
      " [-0.08726644 -0.08726644]\n",
      " [ 0.26179933  0.26179933]\n",
      " [ 0.87266444 -0.26179933]\n",
      " [ 0.17453289  0.08726644]\n",
      " [ 1.22173022  0.        ]\n",
      " [-0.34906578  0.34906578]\n",
      " [-0.52359867  0.        ]\n",
      " [-0.785398   -0.08726644]\n",
      " [ 0.43633222  0.17453289]]\n",
      "prediction:\n",
      "[[-0.13227849 -0.27414423]\n",
      " [-0.08572317 -0.14642932]\n",
      " [ 0.27578786  0.23698768]\n",
      " [ 0.93411827 -0.52793121]\n",
      " [ 0.14650585  0.04541897]\n",
      " [ 0.99870306 -0.12156471]\n",
      " [-0.36715809  0.33844438]\n",
      " [-0.79395741 -0.03463864]\n",
      " [-0.99974245 -0.15034889]\n",
      " [ 0.42180592  0.13953985]]\n",
      "cost:\n",
      "0.132935\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511  0.17453289]\n",
      " [-1.22173022  0.        ]\n",
      " [ 1.22173022 -0.08726644]\n",
      " [ 1.13446378  0.26179933]\n",
      " [-0.43633222 -0.08726644]\n",
      " [-0.69813156 -0.08726644]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [-0.08726644 -0.26179933]\n",
      " [-0.34906578 -0.26179933]\n",
      " [ 1.13446378  0.26179933]]\n",
      "prediction:\n",
      "[[-0.64913481  0.23822333]\n",
      " [-0.99981207  0.03173948]\n",
      " [ 0.97839242 -0.13976754]\n",
      " [ 0.93780923  0.3161253 ]\n",
      " [-0.43242478 -0.07199924]\n",
      " [-0.78757459 -0.0665376 ]\n",
      " [ 0.9532817  -0.2784577 ]\n",
      " [-0.10835652 -0.36483753]\n",
      " [-0.3937636  -0.39799285]\n",
      " [ 0.93780923  0.3161253 ]]\n",
      "cost:\n",
      "0.159941\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644 -0.34906578]\n",
      " [ 0.08726644  0.34906578]\n",
      " [-0.26179933  0.        ]\n",
      " [-0.785398   -0.43633222]\n",
      " [ 0.17453289  0.08726644]\n",
      " [-1.22173022  0.08726644]\n",
      " [-1.13446378  0.26179933]\n",
      " [-0.34906578  0.08726644]\n",
      " [-1.22173022 -0.43633222]\n",
      " [ 0.08726644  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.15500347 -0.34595463]\n",
      " [ 0.99787819  0.34331113]\n",
      " [-0.30971164 -0.02665988]\n",
      " [-0.84241408 -0.4294447 ]\n",
      " [ 0.99837673  0.08046596]\n",
      " [-0.96311629  0.06439146]\n",
      " [-0.98444325  0.22473219]\n",
      " [-0.67526478  0.05943886]\n",
      " [-0.77196157 -0.38284731]\n",
      " [ 0.68791544  0.07820819]]\n",
      "cost:\n",
      "0.388425\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578 -0.08726644]\n",
      " [-0.785398   -0.34906578]\n",
      " [ 0.785398   -0.34906578]\n",
      " [-1.04719733 -0.08726644]\n",
      " [-0.34906578  0.26179933]\n",
      " [-1.22173022  0.34906578]\n",
      " [-0.69813156 -0.08726644]\n",
      " [ 0.34906578  0.08726644]\n",
      " [-0.87266444 -0.17453289]\n",
      " [-0.08726644 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.43534958 -0.08060344]\n",
      " [-0.71028328 -0.35639843]\n",
      " [ 0.99996889 -0.36252928]\n",
      " [-0.93092614 -0.0562203 ]\n",
      " [-0.38280088  0.36380243]\n",
      " [-0.88686466  0.4321208 ]\n",
      " [-0.61658585 -0.06078229]\n",
      " [ 0.38932917  0.11702152]\n",
      " [-0.76806557 -0.15263498]\n",
      " [-0.16649342 -0.18127298]]\n",
      "cost:\n",
      "0.127198\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444 -0.34906578]\n",
      " [ 0.17453289 -0.26179933]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [ 0.43633222  0.        ]\n",
      " [ 0.26179933  0.34906578]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [-0.08726644  0.08726644]\n",
      " [-0.61086511  0.34906578]\n",
      " [ 0.34906578 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.99992275 -0.3408173 ]\n",
      " [ 0.17096041 -0.24869205]\n",
      " [ 0.9143852  -0.05725532]\n",
      " [ 0.39022332  0.01621374]\n",
      " [ 0.22223656  0.380647  ]\n",
      " [ 0.99339098 -0.22912686]\n",
      " [ 0.68754798 -0.23700133]\n",
      " [-0.08128443  0.10807423]\n",
      " [-0.78858465  0.3833625 ]\n",
      " [ 0.3372288  -0.15249822]]\n",
      "cost:\n",
      "0.0691434\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644  0.08726644]\n",
      " [ 0.08726644  0.        ]\n",
      " [-0.69813156 -0.34906578]\n",
      " [ 0.         -0.17453289]\n",
      " [-1.04719733  0.        ]\n",
      " [-0.43633222 -0.26179933]\n",
      " [-0.61086511  0.26179933]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [-0.95993089 -0.34906578]\n",
      " [-0.785398    0.08726644]]\n",
      "prediction:\n",
      "[[-0.05923831  0.14751458]\n",
      " [ 0.3264578   0.02947615]\n",
      " [-0.63150907 -0.33581969]\n",
      " [ 0.0437986  -0.14887702]\n",
      " [-0.91925621  0.06506193]\n",
      " [-0.45587575 -0.22985882]\n",
      " [-0.66790295  0.44909492]\n",
      " [ 0.9999764  -0.21418846]\n",
      " [-0.88999939 -0.34643298]\n",
      " [-0.65722466  0.18990211]]\n",
      "cost:\n",
      "0.160274\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289  0.34906578]\n",
      " [ 0.34906578 -0.08726644]\n",
      " [ 0.61086511 -0.34906578]\n",
      " [-0.52359867  0.08726644]\n",
      " [-0.61086511  0.17453289]\n",
      " [-1.22173022  0.34906578]\n",
      " [-0.95993089  0.        ]\n",
      " [ 1.13446378  0.        ]\n",
      " [-1.13446378 -0.08726644]\n",
      " [-0.95993089 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.25515148  0.31066561]\n",
      " [ 0.31436831 -0.14504705]\n",
      " [ 0.65756851 -0.50071287]\n",
      " [-0.50266016  0.05664317]\n",
      " [-0.56256986  0.14406979]\n",
      " [-0.8002193   0.27559307]\n",
      " [-0.82307774 -0.06980632]\n",
      " [ 0.99997139 -0.04979515]\n",
      " [-0.91750884 -0.21969722]\n",
      " [-0.84738594 -0.25842252]]\n",
      "cost:\n",
      "0.152903\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.          0.08726644]\n",
      " [-0.95993089 -0.26179933]\n",
      " [-0.34906578  0.26179933]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [ 0.43633222  0.34906578]\n",
      " [-0.87266444 -0.17453289]\n",
      " [ 0.52359867  0.26179933]\n",
      " [-0.785398    0.17453289]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [ 0.08726644  0.08726644]]\n",
      "prediction:\n",
      "[[-0.07391012  0.03968709]\n",
      " [-0.99166065 -0.43140939]\n",
      " [-0.37921348  0.174858  ]\n",
      " [ 0.99992132 -0.16565162]\n",
      " [ 0.41555732  0.27680707]\n",
      " [-0.95541006 -0.28950641]\n",
      " [ 0.56763589  0.20337625]\n",
      " [-0.87438017  0.10228122]\n",
      " [ 0.41726694 -0.38306856]\n",
      " [-0.0149031   0.03738118]]\n",
      "cost:\n",
      "0.114301\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578 -0.08726644]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [-1.13446378 -0.17453289]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [-0.08726644 -0.34906578]\n",
      " [-0.43633222  0.34906578]\n",
      " [ 0.          0.34906578]\n",
      " [-0.08726644  0.        ]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [-1.04719733 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.31508043 -0.07920844]\n",
      " [ 0.73695326 -0.05965548]\n",
      " [-0.99485385 -0.17312565]\n",
      " [ 0.99988049 -0.06707477]\n",
      " [-0.04399331 -0.36366904]\n",
      " [-0.36300549  0.38089001]\n",
      " [ 0.1171279   0.38267827]\n",
      " [-0.05984312 -0.0044723 ]\n",
      " [ 0.37517023 -0.24264203]\n",
      " [-0.98339307 -0.27256006]]\n",
      "cost:\n",
      "0.13209\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578  0.17453289]\n",
      " [-1.22173022 -0.26179933]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [ 0.52359867  0.26179933]\n",
      " [ 0.26179933  0.        ]\n",
      " [-0.61086511 -0.17453289]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [-0.61086511 -0.34906578]\n",
      " [ 0.26179933  0.        ]\n",
      " [ 0.52359867 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.38069275  0.28772676]\n",
      " [-0.99962592 -0.17844264]\n",
      " [ 0.99970031 -0.04724995]\n",
      " [ 0.47454292  0.42213935]\n",
      " [ 0.17080785  0.03055442]\n",
      " [-0.61579728 -0.15500705]\n",
      " [ 0.45949924 -0.31189454]\n",
      " [-0.62987864 -0.31171888]\n",
      " [ 0.17080785  0.03055442]\n",
      " [ 0.45949924 -0.31189454]]\n",
      "cost:\n",
      "0.0981066\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733  0.34906578]\n",
      " [ 0.61086511  0.08726644]\n",
      " [-0.95993089  0.34906578]\n",
      " [-0.17453289  0.17453289]\n",
      " [-0.08726644  0.17453289]\n",
      " [-0.26179933 -0.17453289]\n",
      " [-0.61086511  0.34906578]\n",
      " [-0.52359867 -0.34906578]\n",
      " [ 0.69813156  0.08726644]\n",
      " [ 0.52359867 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.99605829  0.18808292]\n",
      " [ 0.97513467 -0.02202688]\n",
      " [-0.98636878  0.19742168]\n",
      " [-0.10404516  0.08953024]\n",
      " [ 0.01870897  0.07344946]\n",
      " [-0.23404686 -0.25462234]\n",
      " [-0.62563205  0.20692454]\n",
      " [-0.5274123  -0.45649213]\n",
      " [ 0.99948657 -0.04074704]\n",
      " [ 0.77359819 -0.46407023]]\n",
      "cost:\n",
      "0.18978\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578  0.34906578]\n",
      " [ 0.          0.34906578]\n",
      " [-1.13446378  0.34906578]\n",
      " [-0.61086511 -0.26179933]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [-0.61086511  0.        ]\n",
      " [-0.69813156  0.34906578]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [ 0.785398   -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.34694868  0.23315153]\n",
      " [-0.05658521  0.27695048]\n",
      " [-0.99950105  0.23282504]\n",
      " [-0.63433671 -0.39851552]\n",
      " [ 0.33912852 -0.23474847]\n",
      " [ 0.0920131  -0.24201193]\n",
      " [-0.68906283 -0.03974298]\n",
      " [-0.72308946  0.22816068]\n",
      " [ 0.99926668 -0.37053907]\n",
      " [ 0.96655864 -0.13910766]]\n",
      "cost:\n",
      "0.138619\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378  0.17453289]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [-0.17453289  0.34906578]\n",
      " [-0.95993089  0.        ]\n",
      " [-0.43633222 -0.26179933]\n",
      " [-0.95993089 -0.43633222]\n",
      " [-0.95993089 -0.17453289]\n",
      " [-0.17453289  0.08726644]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [ 0.34906578 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.99994433  0.2554366 ]\n",
      " [ 0.50048    -0.29191688]\n",
      " [-0.20695467  0.46540281]\n",
      " [-0.9300791   0.03936139]\n",
      " [-0.3655403  -0.20374979]\n",
      " [-0.94318134 -0.37253365]\n",
      " [-0.97914332 -0.11067832]\n",
      " [-0.14529394  0.14741099]\n",
      " [ 0.33706591 -0.2109707 ]\n",
      " [ 0.33706591 -0.2109707 ]]\n",
      "cost:\n",
      "0.0784312\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378  0.34906578]\n",
      " [-0.87266444  0.34906578]\n",
      " [-0.26179933  0.08726644]\n",
      " [-0.52359867  0.        ]\n",
      " [-0.52359867 -0.08726644]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [ 0.61086511 -0.26179933]\n",
      " [-0.08726644 -0.08726644]\n",
      " [ 0.785398    0.34906578]\n",
      " [ 0.95993089  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.97062653  0.1971298 ]\n",
      " [-0.99992621  0.26120225]\n",
      " [-0.25283915  0.04949632]\n",
      " [-0.69354218 -0.0609608 ]\n",
      " [-0.67648637 -0.14630874]\n",
      " [ 0.9420253  -0.22754969]\n",
      " [ 0.59800661 -0.56832242]\n",
      " [-0.0843132  -0.14079005]\n",
      " [ 0.71344388  0.26115146]\n",
      " [ 0.9352417  -0.03141442]]\n",
      "cost:\n",
      "0.149799\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444 -0.34906578]\n",
      " [-0.08726644 -0.43633222]\n",
      " [-0.17453289 -0.34906578]\n",
      " [-1.13446378  0.17453289]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [-0.17453289  0.08726644]\n",
      " [-0.43633222  0.17453289]\n",
      " [-0.785398    0.08726644]\n",
      " [ 0.26179933  0.        ]\n",
      " [-0.61086511  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.99955064 -0.33629495]\n",
      " [-0.0330997  -0.41509625]\n",
      " [-0.12464688 -0.32691139]\n",
      " [-0.99912816  0.23689002]\n",
      " [ 0.97070378 -0.25840691]\n",
      " [-0.15894444  0.10684612]\n",
      " [-0.39607829  0.22020321]\n",
      " [-0.86535817  0.11732601]\n",
      " [ 0.22549663  0.00966927]\n",
      " [-0.56072897  0.22590254]]\n",
      "cost:\n",
      "0.0942574\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444 -0.08726644]\n",
      " [ 0.43633222  0.34906578]\n",
      " [-0.95993089  0.34906578]\n",
      " [ 0.08726644  0.17453289]\n",
      " [-1.22173022 -0.17453289]\n",
      " [-0.95993089 -0.17453289]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [ 0.785398   -0.17453289]\n",
      " [ 0.95993089  0.08726644]\n",
      " [ 1.13446378  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.8900016  -0.09937298]\n",
      " [ 0.47498459  0.31510931]\n",
      " [-0.96905565  0.29793042]\n",
      " [ 0.18306699  0.13538568]\n",
      " [-0.99839246 -0.29070592]\n",
      " [-0.99255025 -0.22055432]\n",
      " [ 0.561382   -0.46813953]\n",
      " [ 0.8284182  -0.21497436]\n",
      " [ 0.93201971  0.05755179]\n",
      " [ 0.99272978  0.04912138]]\n",
      "cost:\n",
      "0.0907698\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289 -0.08726644]\n",
      " [-0.34906578 -0.43633222]\n",
      " [-0.52359867  0.08726644]\n",
      " [ 0.17453289  0.26179933]\n",
      " [ 0.17453289  0.34906578]\n",
      " [-0.87266444  0.17453289]\n",
      " [ 0.34906578  0.26179933]\n",
      " [-0.17453289  0.34906578]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [ 0.         -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.24305527 -0.12612931]\n",
      " [-0.36703354 -0.51731282]\n",
      " [-0.60516286  0.02107332]\n",
      " [ 0.17016923  0.16130547]\n",
      " [ 0.17540644  0.22383113]\n",
      " [-0.99954551  0.08655473]\n",
      " [ 0.32866663  0.15278117]\n",
      " [-0.23644336  0.23580033]\n",
      " [ 0.99980682 -0.27804223]\n",
      " [-0.03814285 -0.31059578]]\n",
      "cost:\n",
      "0.111876\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.22173022  0.08726644]\n",
      " [-0.34906578  0.08726644]\n",
      " [-0.785398   -0.17453289]\n",
      " [ 0.34906578  0.08726644]\n",
      " [-0.95993089  0.34906578]\n",
      " [ 0.34906578  0.17453289]\n",
      " [-1.13446378  0.26179933]\n",
      " [ 1.04719733  0.26179933]\n",
      " [-0.17453289 -0.26179933]\n",
      " [ 0.26179933 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.99597758 -0.08134818]\n",
      " [-0.33617517  0.04572563]\n",
      " [-0.86139381 -0.36572528]\n",
      " [ 0.37256318  0.03869817]\n",
      " [-0.9781009   0.32626721]\n",
      " [ 0.38409221  0.12154387]\n",
      " [-0.99806088  0.17392616]\n",
      " [ 0.99732733  0.18935984]\n",
      " [-0.13637793 -0.48601916]\n",
      " [ 0.27123559 -0.28318182]]\n",
      "cost:\n",
      "0.126434\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398    0.26179933]\n",
      " [-0.34906578  0.08726644]\n",
      " [-1.13446378  0.08726644]\n",
      " [-0.26179933  0.        ]\n",
      " [ 0.95993089  0.08726644]\n",
      " [-0.61086511 -0.34906578]\n",
      " [ 0.26179933  0.34906578]\n",
      " [ 0.87266444 -0.26179933]\n",
      " [-0.785398   -0.08726644]\n",
      " [ 0.69813156  0.08726644]]\n",
      "prediction:\n",
      "[[-0.87066156  0.25486845]\n",
      " [-0.32043424  0.02966347]\n",
      " [-0.99890798  0.04235569]\n",
      " [-0.24401283 -0.04724581]\n",
      " [ 0.99854612  0.03234862]\n",
      " [-0.6251846  -0.50404179]\n",
      " [ 0.2344628   0.33957013]\n",
      " [ 0.99087143 -0.37068114]\n",
      " [-0.8501901  -0.12289516]\n",
      " [ 0.79394841  0.02307534]]\n",
      "cost:\n",
      "0.0944851\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.22173022  0.26179933]\n",
      " [ 0.43633222  0.26179933]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [ 0.         -0.08726644]\n",
      " [ 0.34906578 -0.43633222]\n",
      " [ 0.69813156  0.        ]\n",
      " [-0.52359867  0.34906578]\n",
      " [-0.61086511 -0.08726644]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [-0.87266444 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.99717516  0.25077465]\n",
      " [ 0.41069126  0.26391587]\n",
      " [ 0.89346629 -0.34662989]\n",
      " [-0.03688696 -0.06039971]\n",
      " [ 0.32222205 -0.35773996]\n",
      " [ 0.66548645  0.03030845]\n",
      " [-0.52111453  0.35589364]\n",
      " [-0.81425899 -0.06357841]\n",
      " [ 0.30121231 -0.2303136 ]\n",
      " [-0.99989015 -0.21809566]]\n",
      "cost:\n",
      "0.0919706\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.43633222 -0.08726644]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [-0.61086511 -0.26179933]\n",
      " [-0.08726644  0.08726644]\n",
      " [ 0.87266444  0.17453289]\n",
      " [-1.22173022 -0.34906578]\n",
      " [-0.08726644  0.08726644]\n",
      " [-0.87266444 -0.26179933]\n",
      " [-0.34906578  0.17453289]\n",
      " [-0.43633222 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.38721439 -0.06872326]\n",
      " [ 0.0858812  -0.16104904]\n",
      " [-0.50719392 -0.27732253]\n",
      " [-0.0534188   0.13618916]\n",
      " [ 0.99996704  0.35200754]\n",
      " [-0.98766184 -0.36423877]\n",
      " [-0.0534188   0.13618916]\n",
      " [-0.86706322 -0.27976122]\n",
      " [-0.30345377  0.3178876 ]\n",
      " [-0.37721637 -0.17950436]]\n",
      "cost:\n",
      "0.097141\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733  0.        ]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [-0.61086511  0.26179933]\n",
      " [-0.17453289 -0.34906578]\n",
      " [-0.69813156 -0.08726644]\n",
      " [-0.43633222 -0.34906578]\n",
      " [ 0.43633222  0.08726644]\n",
      " [-1.22173022 -0.34906578]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [ 0.43633222 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.98107976  0.16603555]\n",
      " [ 0.69602966 -0.15249071]\n",
      " [-0.57027221  0.49492729]\n",
      " [-0.16638495 -0.22578815]\n",
      " [-0.65360659  0.01051062]\n",
      " [-0.43084958 -0.22094762]\n",
      " [ 0.52871954  0.20533612]\n",
      " [-0.98916906 -0.15255649]\n",
      " [ 0.99989265 -0.29085201]\n",
      " [ 0.52543545 -0.28541422]]\n",
      "cost:\n",
      "0.180164\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089 -0.17453289]\n",
      " [-0.785398   -0.08726644]\n",
      " [ 0.43633222  0.34906578]\n",
      " [-0.34906578 -0.17453289]\n",
      " [-1.04719733 -0.17453289]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [ 0.87266444  0.08726644]\n",
      " [ 0.26179933  0.26179933]\n",
      " [ 0.61086511  0.26179933]\n",
      " [ 0.         -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.98316193 -0.25134245]\n",
      " [-0.94930446 -0.12232232]\n",
      " [ 0.42020166  0.3431693 ]\n",
      " [-0.4064925  -0.25175402]\n",
      " [-0.99988008 -0.28713503]\n",
      " [ 0.92975885 -0.1038297 ]\n",
      " [ 0.93920386  0.09149522]\n",
      " [ 0.25133115  0.24679676]\n",
      " [ 0.56170309  0.25889128]\n",
      " [-0.04882847 -0.37874308]]\n",
      "cost:\n",
      "0.0803799\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.22173022 -0.08726644]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [ 0.785398    0.34906578]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [ 1.13446378  0.08726644]\n",
      " [ 0.08726644 -0.08726644]\n",
      " [-0.43633222  0.34906578]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [ 1.04719733  0.17453289]\n",
      " [-0.87266444  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.67072904 -0.16447663]\n",
      " [ 0.26058209 -0.3435497 ]\n",
      " [ 0.65418708  0.29759428]\n",
      " [ 0.82953942 -0.34692481]\n",
      " [ 0.83435738  0.02157471]\n",
      " [ 0.13465694 -0.12950025]\n",
      " [-0.30607584  0.30513301]\n",
      " [ 0.49394768 -0.33202043]\n",
      " [ 0.81427312  0.12653527]\n",
      " [-0.99998003  0.12050365]]\n",
      "cost:\n",
      "0.205618\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511 -0.43633222]\n",
      " [-0.785398   -0.34906578]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [-1.13446378  0.26179933]\n",
      " [-0.95993089  0.        ]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [ 1.04719733 -0.43633222]\n",
      " [-0.08726644  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.55452698 -0.30177134]\n",
      " [-0.88051021 -0.21868119]\n",
      " [ 0.92112482 -0.06685783]\n",
      " [ 0.98767418 -0.25393927]\n",
      " [-0.99929994  0.50286222]\n",
      " [-0.98732263  0.09454165]\n",
      " [ 0.50938052 -0.00297066]\n",
      " [ 0.35174957 -0.15143873]\n",
      " [ 0.97801793 -0.27897274]\n",
      " [-0.08595265  0.19630745]]\n",
      "cost:\n",
      "0.158619\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.26179933]\n",
      " [ 0.34906578 -0.34906578]\n",
      " [-0.69813156  0.17453289]\n",
      " [ 0.34906578  0.26179933]\n",
      " [-0.87266444  0.17453289]\n",
      " [-0.69813156  0.17453289]\n",
      " [ 0.08726644  0.17453289]\n",
      " [-0.17453289 -0.43633222]\n",
      " [ 0.95993089 -0.26179933]\n",
      " [ 0.43633222  0.34906578]]\n",
      "prediction:\n",
      "[[-0.98962063 -0.23018838]\n",
      " [ 0.33785382 -0.35271907]\n",
      " [-0.69267458  0.10277802]\n",
      " [ 0.28997043  0.20347308]\n",
      " [-0.94323939  0.11223792]\n",
      " [-0.69267547  0.10277654]\n",
      " [-0.01239823  0.11325121]\n",
      " [-0.20114902 -0.43923813]\n",
      " [ 0.99993765 -0.29151163]\n",
      " [ 0.40772137  0.30665126]]\n",
      "cost:\n",
      "0.0725905\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644 -0.08726644]\n",
      " [-0.69813156  0.08726644]\n",
      " [ 0.61086511  0.08726644]\n",
      " [ 0.785398    0.        ]\n",
      " [ 0.95993089 -0.26179933]\n",
      " [ 0.87266444  0.08726644]\n",
      " [-0.52359867 -0.08726644]\n",
      " [ 0.52359867 -0.17453289]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [ 0.69813156  0.        ]]\n",
      "prediction:\n",
      "[[ 0.07037989 -0.08027396]\n",
      " [-0.99995291  0.19840425]\n",
      " [ 0.54974365  0.25413352]\n",
      " [ 0.78640437  0.02860805]\n",
      " [ 0.96540999 -0.57123035]\n",
      " [ 0.89435518  0.23424925]\n",
      " [-0.88147128 -0.11641145]\n",
      " [ 0.45562178 -0.26863697]\n",
      " [ 0.2202771  -0.07076403]\n",
      " [ 0.60995525  0.03800084]]\n",
      "cost:\n",
      "0.176361\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.26179933 -0.08726644]\n",
      " [-0.34906578 -0.26179933]\n",
      " [-0.08726644  0.        ]\n",
      " [-0.95993089 -0.17453289]\n",
      " [ 1.13446378  0.26179933]\n",
      " [-1.04719733 -0.17453289]\n",
      " [-0.17453289  0.08726644]\n",
      " [-0.17453289 -0.34906578]\n",
      " [-0.95993089 -0.17453289]\n",
      " [ 0.17453289  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.26850963 -0.10128862]\n",
      " [-0.34989214 -0.29255643]\n",
      " [-0.08682491  0.00683112]\n",
      " [-0.92654634 -0.15876402]\n",
      " [ 0.99996138  0.3845551 ]\n",
      " [-0.9560234  -0.15951699]\n",
      " [-0.170026    0.12117559]\n",
      " [-0.16112024 -0.41798156]\n",
      " [-0.92654634 -0.15876402]\n",
      " [ 0.17944679  0.35881224]]\n",
      "cost:\n",
      "0.0603056\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289  0.34906578]\n",
      " [ 1.22173022  0.08726644]\n",
      " [ 0.87266444  0.17453289]\n",
      " [-1.22173022 -0.43633222]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [-0.26179933 -0.43633222]\n",
      " [-0.43633222 -0.26179933]\n",
      " [ 0.34906578 -0.34906578]\n",
      " [ 1.04719733 -0.34906578]\n",
      " [-0.785398   -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.21474507  0.42366582]\n",
      " [ 0.9887352   0.23946956]\n",
      " [ 0.89763665  0.2549375 ]\n",
      " [-0.99981248 -0.2694442 ]\n",
      " [ 0.49153915 -0.04468102]\n",
      " [-0.3115108  -0.33753467]\n",
      " [-0.49221548 -0.19339307]\n",
      " [ 0.41418517 -0.26686785]\n",
      " [ 0.96673381 -0.24223071]\n",
      " [-0.95191467 -0.01216957]]\n",
      "cost:\n",
      "0.141484\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.26179933]\n",
      " [-0.87266444 -0.17453289]\n",
      " [-0.87266444  0.26179933]\n",
      " [-1.22173022  0.34906578]\n",
      " [-0.87266444  0.        ]\n",
      " [ 0.          0.17453289]\n",
      " [ 0.95993089  0.26179933]\n",
      " [ 0.52359867 -0.43633222]\n",
      " [-0.34906578  0.08726644]\n",
      " [ 0.87266444  0.17453289]]\n",
      "prediction:\n",
      "[[-0.97169608 -0.32552129]\n",
      " [-0.82602054 -0.23324448]\n",
      " [-0.89410144  0.19250302]\n",
      " [-0.96243948  0.21824479]\n",
      " [-0.63823032 -0.04946132]\n",
      " [ 0.07408579  0.11385628]\n",
      " [ 0.99939543  0.17667109]\n",
      " [ 0.48608059 -0.55442286]\n",
      " [-0.29957467  0.03087905]\n",
      " [ 0.99590844  0.06358232]]\n",
      "cost:\n",
      "0.140669\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398   -0.34906578]\n",
      " [ 0.         -0.17453289]\n",
      " [ 0.785398    0.34906578]\n",
      " [-0.34906578 -0.34906578]\n",
      " [ 0.43633222  0.08726644]\n",
      " [ 1.22173022  0.17453289]\n",
      " [-0.785398    0.26179933]\n",
      " [ 0.785398   -0.08726644]\n",
      " [-1.22173022  0.34906578]\n",
      " [ 0.785398   -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.77035987 -0.32369372]\n",
      " [-0.0337514  -0.16613954]\n",
      " [ 0.72857845  0.31342128]\n",
      " [-0.35623971 -0.34408996]\n",
      " [ 0.36825508  0.10174983]\n",
      " [ 0.99353111  0.13412501]\n",
      " [-0.95679682  0.1976884 ]\n",
      " [ 0.71425402 -0.08313251]\n",
      " [-0.99986124  0.22228557]\n",
      " [ 0.7380656  -0.4194507 ]]\n",
      "cost:\n",
      "0.100148\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.43633222 -0.43633222]\n",
      " [ 0.08726644 -0.43633222]\n",
      " [ 0.26179933  0.08726644]\n",
      " [-0.61086511 -0.08726644]\n",
      " [ 0.52359867  0.34906578]\n",
      " [-0.52359867 -0.08726644]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [-0.61086511 -0.43633222]\n",
      " [ 0.26179933  0.34906578]\n",
      " [-0.26179933  0.        ]]\n",
      "prediction:\n",
      "[[-0.59701943 -0.31932861]\n",
      " [ 0.01061221 -0.34857729]\n",
      " [ 0.2435323   0.09914795]\n",
      " [-0.98167092 -0.05292418]\n",
      " [ 0.59072077  0.38306955]\n",
      " [-0.82833803 -0.05813102]\n",
      " [ 0.99993902 -0.17444739]\n",
      " [-0.9562521  -0.30354843]\n",
      " [ 0.27175111  0.3718403 ]\n",
      " [-0.35939279  0.02513201]]\n",
      "cost:\n",
      "0.182488\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089  0.34906578]\n",
      " [ 0.43633222  0.        ]\n",
      " [-1.22173022 -0.43633222]\n",
      " [ 0.         -0.08726644]\n",
      " [ 0.52359867  0.08726644]\n",
      " [-0.08726644 -0.26179933]\n",
      " [-0.87266444 -0.34906578]\n",
      " [-0.95993089 -0.17453289]\n",
      " [ 0.43633222  0.34906578]\n",
      " [-0.43633222  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.99988174  0.279549  ]\n",
      " [ 0.54837143 -0.00614182]\n",
      " [-0.98738468 -0.3760635 ]\n",
      " [ 0.0789848  -0.08528361]\n",
      " [ 0.61465198  0.06389599]\n",
      " [-0.06160192 -0.29122066]\n",
      " [-0.89598608 -0.35057235]\n",
      " [-0.98053735 -0.17852375]\n",
      " [ 0.45543617  0.28766832]\n",
      " [-0.41164726  0.28389621]]\n",
      "cost:\n",
      "0.0824763\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733  0.        ]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [-0.08726644 -0.34906578]\n",
      " [-0.69813156  0.        ]\n",
      " [ 1.04719733  0.08726644]\n",
      " [-0.95993089  0.17453289]\n",
      " [ 0.17453289  0.        ]\n",
      " [ 1.22173022  0.08726644]\n",
      " [-1.13446378  0.        ]\n",
      " [-0.61086511 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.96953595  0.03050486]\n",
      " [ 0.88082218 -0.06532449]\n",
      " [-0.20157106 -0.40651807]\n",
      " [-0.71138394  0.00681695]\n",
      " [ 0.97385377  0.1495094 ]\n",
      " [-0.99372762  0.30920154]\n",
      " [ 0.17250341  0.02949196]\n",
      " [ 0.98476732  0.21149641]\n",
      " [-0.99803203  0.02438902]\n",
      " [-0.68592745 -0.54517311]]\n",
      "cost:\n",
      "0.105264\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289  0.        ]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [-0.61086511  0.        ]\n",
      " [ 0.17453289  0.26179933]\n",
      " [-0.43633222 -0.43633222]\n",
      " [-0.26179933  0.34906578]\n",
      " [ 0.52359867  0.26179933]\n",
      " [ 0.17453289 -0.43633222]\n",
      " [-0.87266444 -0.34906578]\n",
      " [-0.785398   -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.245711    0.00805735]\n",
      " [ 0.29001984 -0.07415545]\n",
      " [-0.60250854  0.01472408]\n",
      " [ 0.17398621  0.27056518]\n",
      " [-0.38763684 -0.36892101]\n",
      " [-0.13709976  0.3805491 ]\n",
      " [ 0.99991268  0.26392075]\n",
      " [ 0.2282206  -0.3631306 ]\n",
      " [-0.99527156 -0.31099316]\n",
      " [-0.94406503 -0.15511079]]\n",
      "cost:\n",
      "0.128068\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733  0.08726644]\n",
      " [-1.04719733  0.        ]\n",
      " [-0.785398    0.17453289]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [ 0.87266444  0.26179933]\n",
      " [-0.43633222  0.34906578]\n",
      " [ 0.785398    0.26179933]\n",
      " [-1.04719733 -0.17453289]\n",
      " [ 0.61086511  0.08726644]\n",
      " [-0.87266444  0.26179933]]\n",
      "prediction:\n",
      "[[-0.94689155 -0.04402399]\n",
      " [-0.93449104 -0.16186501]\n",
      " [-0.71552253  0.05007056]\n",
      " [ 0.06611562 -0.32952362]\n",
      " [ 0.9997291   0.1535468 ]\n",
      " [-0.39508304  0.27816021]\n",
      " [ 0.98503631  0.13741995]\n",
      " [-0.9513523  -0.57963502]\n",
      " [ 0.66886473 -0.00210707]\n",
      " [-0.83324635  0.15977368]]\n",
      "cost:\n",
      "0.1778\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289 -0.43633222]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [-0.17453289 -0.17453289]\n",
      " [ 1.22173022  0.08726644]\n",
      " [-1.04719733 -0.43633222]\n",
      " [-0.17453289 -0.17453289]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [-0.08726644 -0.26179933]\n",
      " [ 0.08726644  0.34906578]\n",
      " [-0.61086511 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.24623288 -0.29746082]\n",
      " [ 0.6650598  -0.14117578]\n",
      " [-0.16998518 -0.09756184]\n",
      " [ 0.98813641  0.298953  ]\n",
      " [-0.99990475 -0.25959879]\n",
      " [-0.16998518 -0.09756184]\n",
      " [ 0.98198026 -0.02154744]\n",
      " [-0.05071532 -0.18599001]\n",
      " [ 0.12804215  0.5308727 ]\n",
      " [-0.67819279 -0.20747417]]\n",
      "cost:\n",
      "0.157704\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378  0.08726644]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [-1.13446378  0.26179933]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [ 0.95993089  0.        ]\n",
      " [-0.34906578  0.34906578]\n",
      " [ 0.61086511  0.        ]\n",
      " [ 1.22173022  0.26179933]\n",
      " [-0.87266444 -0.26179933]\n",
      " [ 0.43633222  0.17453289]]\n",
      "prediction:\n",
      "[[-0.99689215 -0.00271218]\n",
      " [ 0.1872969  -0.22566789]\n",
      " [-0.9933663   0.18386821]\n",
      " [ 0.71913415 -0.45288587]\n",
      " [ 0.9843933  -0.01487703]\n",
      " [-0.34371299  0.28959817]\n",
      " [ 0.63825047 -0.03243088]\n",
      " [ 0.99609667  0.1846772 ]\n",
      " [-0.90543771 -0.46912462]\n",
      " [ 0.43771881  0.14087379]]\n",
      "cost:\n",
      "0.118334\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.34906578]\n",
      " [-1.13446378  0.26179933]\n",
      " [-1.22173022  0.34906578]\n",
      " [-0.43633222  0.17453289]\n",
      " [ 0.43633222  0.        ]\n",
      " [ 0.17453289 -0.26179933]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [ 0.08726644  0.17453289]\n",
      " [-0.61086511 -0.17453289]\n",
      " [ 1.22173022  0.        ]]\n",
      "prediction:\n",
      "[[-0.95058525 -0.51971984]\n",
      " [-0.96157324  0.24652821]\n",
      " [-0.91310441  0.29582596]\n",
      " [-0.43692869  0.17082568]\n",
      " [ 0.47284409 -0.00864825]\n",
      " [ 0.1655793  -0.29717666]\n",
      " [ 0.34119195 -0.18797159]\n",
      " [ 0.05265315  0.16488819]\n",
      " [-0.54187238 -0.18230441]\n",
      " [ 0.99994546 -0.08797273]]\n",
      "cost:\n",
      "0.117492\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867  0.17453289]\n",
      " [-0.69813156 -0.26179933]\n",
      " [ 0.95993089  0.17453289]\n",
      " [ 1.22173022 -0.08726644]\n",
      " [ 0.785398   -0.34906578]\n",
      " [-0.08726644  0.17453289]\n",
      " [ 0.          0.26179933]\n",
      " [ 0.61086511  0.08726644]\n",
      " [ 1.13446378  0.17453289]\n",
      " [ 0.87266444  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.4891611   0.13322863]\n",
      " [-0.99998146 -0.40431023]\n",
      " [ 0.72275698  0.09530979]\n",
      " [ 0.73870558 -0.25602952]\n",
      " [ 0.70062274 -0.52316278]\n",
      " [ 0.01274569  0.11568291]\n",
      " [ 0.05637547  0.23725162]\n",
      " [ 0.52869749  0.030142  ]\n",
      " [ 0.73064399  0.07597722]\n",
      " [ 0.70474899  0.09770303]]\n",
      "cost:\n",
      "0.222087\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511  0.17453289]\n",
      " [-0.69813156 -0.26179933]\n",
      " [-0.95993089 -0.34906578]\n",
      " [ 0.         -0.26179933]\n",
      " [-0.69813156  0.        ]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [ 1.22173022  0.        ]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [-0.17453289  0.        ]]\n",
      "prediction:\n",
      "[[ 0.49675784  0.5041343 ]\n",
      " [-0.86784977 -0.28360578]\n",
      " [-0.99883366 -0.43224329]\n",
      " [-0.10082169 -0.25636351]\n",
      " [-0.91636509  0.05777808]\n",
      " [ 0.15471743 -0.02092567]\n",
      " [ 0.99896318  0.06670278]\n",
      " [ 0.13061276 -0.13264018]\n",
      " [ 0.98188394 -0.06492367]\n",
      " [-0.25506157  0.04965492]]\n",
      "cost:\n",
      "0.142686\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511 -0.08726644]\n",
      " [-1.22173022  0.26179933]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [-0.34906578 -0.17453289]\n",
      " [-0.43633222 -0.17453289]\n",
      " [ 0.17453289 -0.43633222]\n",
      " [-0.95993089 -0.43633222]\n",
      " [ 1.22173022 -0.34906578]\n",
      " [-0.08726644 -0.17453289]\n",
      " [ 1.22173022  0.17453289]]\n",
      "prediction:\n",
      "[[-0.5925802  -0.01273592]\n",
      " [-0.99919242  0.44594118]\n",
      " [ 0.98605835 -0.06563981]\n",
      " [-0.35586166 -0.0921664 ]\n",
      " [-0.43118188 -0.10121686]\n",
      " [ 0.1882557  -0.35830891]\n",
      " [-0.96365005 -0.34230891]\n",
      " [ 0.97956908 -0.24544807]\n",
      " [-0.14337201 -0.10554316]\n",
      " [ 0.9897629   0.33432138]]\n",
      "cost:\n",
      "0.151311\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578 -0.43633222]\n",
      " [ 1.22173022  0.34906578]\n",
      " [-0.61086511 -0.17453289]\n",
      " [-0.61086511 -0.43633222]\n",
      " [ 0.52359867  0.        ]\n",
      " [-0.87266444 -0.17453289]\n",
      " [-0.95993089  0.        ]\n",
      " [ 1.13446378  0.08726644]\n",
      " [-1.13446378 -0.17453289]\n",
      " [-0.52359867  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.34007329 -0.42421925]\n",
      " [ 0.99202806  0.30820394]\n",
      " [-0.54326701 -0.15822072]\n",
      " [-0.55966544 -0.42052922]\n",
      " [ 0.46293858  0.00504378]\n",
      " [-0.87117803 -0.15882602]\n",
      " [-0.96639848  0.02292093]\n",
      " [ 0.99948925  0.10010976]\n",
      " [-0.98704672 -0.15218893]\n",
      " [-0.52233279  0.3408764 ]]\n",
      "cost:\n",
      "0.076495\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156 -0.34906578]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [-0.26179933 -0.26179933]\n",
      " [-0.69813156  0.17453289]\n",
      " [-1.13446378  0.        ]\n",
      " [ 0.95993089 -0.43633222]\n",
      " [ 0.95993089  0.        ]\n",
      " [ 1.22173022  0.17453289]\n",
      " [ 0.17453289  0.34906578]\n",
      " [ 0.          0.26179933]]\n",
      "prediction:\n",
      "[[ 0.61495483 -0.37789065]\n",
      " [ 0.9286719  -0.19139089]\n",
      " [-0.25943857 -0.27844211]\n",
      " [-0.84026784  0.14814943]\n",
      " [-0.99994642 -0.00719279]\n",
      " [ 0.82161587 -0.45955989]\n",
      " [ 0.88694191 -0.00528062]\n",
      " [ 0.92847121  0.16197127]\n",
      " [ 0.18725786  0.30643636]\n",
      " [ 0.03396743  0.24498875]]\n",
      "cost:\n",
      "0.117994\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.26179933 -0.08726644]\n",
      " [-0.87266444 -0.34906578]\n",
      " [-0.95993089  0.34906578]\n",
      " [ 1.22173022  0.        ]\n",
      " [ 0.61086511 -0.26179933]\n",
      " [ 0.61086511 -0.34906578]\n",
      " [-1.04719733  0.08726644]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [-1.13446378 -0.08726644]\n",
      " [-0.34906578 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.20238709 -0.04727232]\n",
      " [-0.85628831 -0.35189509]\n",
      " [-0.89432597  0.52140832]\n",
      " [ 0.99991232  0.06726664]\n",
      " [ 0.66778833 -0.223167  ]\n",
      " [ 0.68687445 -0.32649222]\n",
      " [-0.9517771   0.17446324]\n",
      " [ 0.34767067 -0.24587432]\n",
      " [-0.97391862 -0.03171588]\n",
      " [-0.38678655 -0.06449565]]\n",
      "cost:\n",
      "0.101172\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.26179933]\n",
      " [-0.17453289  0.        ]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [ 0.26179933  0.26179933]\n",
      " [ 0.43633222  0.        ]\n",
      " [-0.87266444 -0.34906578]\n",
      " [ 0.95993089 -0.43633222]\n",
      " [-0.785398   -0.34906578]\n",
      " [ 0.61086511 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.99961972 -0.16414244]\n",
      " [-0.23513155  0.03428741]\n",
      " [ 0.97003925 -0.0480054 ]\n",
      " [ 0.98797625 -0.14466363]\n",
      " [ 0.29404774  0.58925247]\n",
      " [ 0.49434611  0.063876  ]\n",
      " [-0.96058643 -0.26177981]\n",
      " [ 0.93052232 -0.30571643]\n",
      " [-0.87601912 -0.25929609]\n",
      " [ 0.63166702 -0.13126113]]\n",
      "cost:\n",
      "0.155406\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867  0.17453289]\n",
      " [ 0.61086511  0.08726644]\n",
      " [-0.26179933  0.        ]\n",
      " [-0.34906578  0.08726644]\n",
      " [ 0.17453289  0.08726644]\n",
      " [ 1.22173022  0.26179933]\n",
      " [-0.95993089  0.17453289]\n",
      " [-0.69813156  0.26179933]\n",
      " [-0.34906578 -0.17453289]\n",
      " [ 0.95993089 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.525087    0.06679013]\n",
      " [ 0.59354484 -0.01202274]\n",
      " [-0.23487513 -0.03913381]\n",
      " [-0.34922719  0.02878958]\n",
      " [ 0.2298979   0.02537797]\n",
      " [ 0.99536544  0.09932939]\n",
      " [-0.99979317  0.0855279 ]\n",
      " [-0.84712487  0.19269201]\n",
      " [-0.36152533 -0.27614811]\n",
      " [ 0.98197991 -0.64921498]]\n",
      "cost:\n",
      "0.134129\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644 -0.26179933]\n",
      " [ 0.785398    0.08726644]\n",
      " [ 0.08726644 -0.43633222]\n",
      " [-0.52359867  0.17453289]\n",
      " [-0.69813156  0.17453289]\n",
      " [ 0.87266444  0.34906578]\n",
      " [-1.22173022 -0.17453289]\n",
      " [ 0.69813156  0.17453289]\n",
      " [-0.61086511  0.        ]\n",
      " [-0.61086511  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.1416029  -0.31272614]\n",
      " [ 0.98916537  0.03187231]\n",
      " [ 0.14539483 -0.53618991]\n",
      " [-0.55682147  0.12138227]\n",
      " [-0.76023316  0.10548823]\n",
      " [ 0.99659044  0.29477233]\n",
      " [-0.99951297 -0.3006092 ]\n",
      " [ 0.85074764  0.10965789]\n",
      " [-0.64348495 -0.0436921 ]\n",
      " [-0.63524771  0.0282665 ]]\n",
      "cost:\n",
      "0.123171\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511 -0.08726644]\n",
      " [-0.785398    0.17453289]\n",
      " [-0.52359867 -0.26179933]\n",
      " [ 0.34906578 -0.08726644]\n",
      " [-0.61086511 -0.43633222]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [ 1.22173022  0.26179933]\n",
      " [-0.87266444  0.        ]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [ 0.69813156  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.61935019 -0.06188954]\n",
      " [-0.98370415  0.23765293]\n",
      " [-0.55837607 -0.2640256 ]\n",
      " [ 0.38356617 -0.06596792]\n",
      " [-0.77391225 -0.47813097]\n",
      " [ 0.98949289 -0.14819427]\n",
      " [ 0.99400938  0.38827851]\n",
      " [-0.99900752  0.02815938]\n",
      " [ 0.35603595 -0.2664859 ]\n",
      " [ 0.71314657  0.13076566]]\n",
      "cost:\n",
      "0.0962521\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867  0.        ]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [ 0.95993089  0.26179933]\n",
      " [-0.95993089 -0.43633222]\n",
      " [-0.87266444 -0.17453289]\n",
      " [ 1.04719733  0.17453289]\n",
      " [ 0.34906578  0.08726644]\n",
      " [ 0.26179933  0.34906578]\n",
      " [-0.87266444 -0.26179933]\n",
      " [-0.17453289 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.59643602 -0.00707866]\n",
      " [ 0.39684299 -0.18260145]\n",
      " [ 0.99642086  0.26839417]\n",
      " [-0.98521811 -0.45263427]\n",
      " [-0.97475451 -0.16934897]\n",
      " [ 0.99840367  0.1630407 ]\n",
      " [ 0.30604017  0.07273191]\n",
      " [ 0.23636229  0.34952238]\n",
      " [-0.97224885 -0.25704184]\n",
      " [-0.2273591  -0.2741833 ]]\n",
      "cost:\n",
      "0.0557815\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398    0.17453289]\n",
      " [-0.34906578  0.08726644]\n",
      " [-0.26179933 -0.43633222]\n",
      " [-1.04719733 -0.08726644]\n",
      " [ 0.43633222  0.34906578]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [ 0.785398    0.26179933]\n",
      " [-0.785398    0.34906578]\n",
      " [-0.69813156 -0.34906578]\n",
      " [-1.22173022  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.99794209  0.0693765 ]\n",
      " [-0.40188524  0.02924801]\n",
      " [-0.25676894 -0.5108006 ]\n",
      " [-0.99016505 -0.13818733]\n",
      " [ 0.51284897  0.19455503]\n",
      " [ 0.74426198 -0.12462547]\n",
      " [ 0.99565417  0.11245351]\n",
      " [-0.80613744  0.19410954]\n",
      " [-0.69865716 -0.39408833]\n",
      " [-0.99054402  0.17106286]]\n",
      "cost:\n",
      "0.152867\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444 -0.08726644]\n",
      " [ 0.95993089 -0.34906578]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [-0.52359867  0.34906578]\n",
      " [ 0.87266444  0.26179933]\n",
      " [-0.08726644 -0.43633222]\n",
      " [ 0.08726644  0.17453289]\n",
      " [ 0.17453289  0.34906578]\n",
      " [-0.52359867  0.17453289]\n",
      " [-0.26179933 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.99990064 -0.07727362]\n",
      " [ 0.98592412 -0.29561001]\n",
      " [ 0.92959857 -0.35452515]\n",
      " [-0.58494854  0.24926054]\n",
      " [ 0.96942872  0.17631184]\n",
      " [-0.04110381 -0.39439827]\n",
      " [ 0.1611729   0.10355444]\n",
      " [ 0.24407676  0.24105051]\n",
      " [-0.62492549  0.11536789]\n",
      " [-0.21806434 -0.25085384]]\n",
      "cost:\n",
      "0.098873\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378 -0.17453289]\n",
      " [ 0.34906578  0.17453289]\n",
      " [ 0.43633222  0.08726644]\n",
      " [-0.43633222  0.34906578]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [ 0.87266444 -0.34906578]\n",
      " [-0.87266444 -0.17453289]\n",
      " [ 0.61086511 -0.17453289]\n",
      " [-0.69813156 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.99530691 -0.16173133]\n",
      " [ 0.33727929  0.24549948]\n",
      " [ 0.43499851  0.13440478]\n",
      " [-0.4219223   0.47398457]\n",
      " [ 0.1172502  -0.17689829]\n",
      " [ 0.64448655 -0.25379416]\n",
      " [ 0.90229273 -0.37492862]\n",
      " [-0.99988675 -0.19293439]\n",
      " [ 0.54636455 -0.14762358]\n",
      " [-0.89908016 -0.07351194]]\n",
      "cost:\n",
      "0.0908086\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644  0.        ]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [ 0.          0.        ]\n",
      " [ 1.04719733 -0.34906578]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [-0.87266444 -0.17453289]\n",
      " [-0.87266444  0.26179933]\n",
      " [-0.95993089 -0.34906578]\n",
      " [-1.04719733 -0.26179933]\n",
      " [-1.04719733 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.1231123   0.05139292]\n",
      " [ 0.20373861 -0.11664504]\n",
      " [-0.04524713  0.03587319]\n",
      " [ 0.99997365 -0.30630627]\n",
      " [ 0.30768999 -0.1969049 ]\n",
      " [-0.74415219 -0.10207115]\n",
      " [-0.77776045  0.57098883]\n",
      " [-0.82768297 -0.26109663]\n",
      " [-0.86637175 -0.17823775]\n",
      " [-0.90412778 -0.0725442 ]]\n",
      "cost:\n",
      "0.134775\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867  0.08726644]\n",
      " [-1.22173022  0.08726644]\n",
      " [ 0.17453289  0.08726644]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [ 1.22173022  0.26179933]\n",
      " [-0.08726644  0.        ]\n",
      " [-0.17453289  0.26179933]\n",
      " [-0.785398   -0.26179933]\n",
      " [ 0.08726644  0.34906578]\n",
      " [-0.785398   -0.08726644]]\n",
      "prediction:\n",
      "[[-0.4886325   0.03522751]\n",
      " [-0.99743605 -0.09290534]\n",
      " [ 0.2224862   0.05233166]\n",
      " [ 0.8434155  -0.44804159]\n",
      " [ 0.9998799   0.14207236]\n",
      " [-0.0748402  -0.03012496]\n",
      " [-0.18130867  0.24119177]\n",
      " [-0.83607554 -0.47372326]\n",
      " [ 0.11021847  0.305058  ]\n",
      " [-0.79388744 -0.17331992]]\n",
      "cost:\n",
      "0.130631\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398   -0.17453289]\n",
      " [-0.43633222 -0.43633222]\n",
      " [-0.34906578  0.34906578]\n",
      " [-1.13446378 -0.26179933]\n",
      " [-0.17453289 -0.43633222]\n",
      " [-0.34906578 -0.43633222]\n",
      " [-0.43633222 -0.08726644]\n",
      " [ 0.08726644  0.17453289]\n",
      " [ 0.61086511 -0.26179933]\n",
      " [-0.69813156 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.99980503 -0.07837932]\n",
      " [-0.36429042 -0.25758585]\n",
      " [-0.29708332  0.52051753]\n",
      " [-0.99914443 -0.06784063]\n",
      " [-0.06260375 -0.27406773]\n",
      " [-0.26866975 -0.25343382]\n",
      " [-0.39023608 -0.00753709]\n",
      " [ 0.13020083  0.27497911]\n",
      " [ 0.88282514 -0.15497503]\n",
      " [-0.68444669 -0.24298078]]\n",
      "cost:\n",
      "0.192762\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222  0.08726644]\n",
      " [ 0.69813156  0.34906578]\n",
      " [ 0.34906578 -0.43633222]\n",
      " [ 0.95993089 -0.34906578]\n",
      " [ 0.87266444  0.17453289]\n",
      " [ 1.13446378  0.08726644]\n",
      " [-0.69813156 -0.17453289]\n",
      " [-0.785398    0.17453289]\n",
      " [ 1.22173022 -0.08726644]\n",
      " [-1.04719733 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.42163953  0.07329732]\n",
      " [ 0.69763267  0.381724  ]\n",
      " [ 0.44873241 -0.4706504 ]\n",
      " [ 0.87766558 -0.38022262]\n",
      " [ 0.80119258  0.15199745]\n",
      " [ 0.95262253  0.06320026]\n",
      " [-0.76000625 -0.18865116]\n",
      " [-0.95101923  0.16398112]\n",
      " [ 0.92795837 -0.09958443]\n",
      " [-0.99990416 -0.18269512]]\n",
      "cost:\n",
      "0.107612\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578 -0.08726644]\n",
      " [-0.43633222  0.34906578]\n",
      " [-1.22173022 -0.08726644]\n",
      " [-0.34906578  0.08726644]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [ 0.69813156  0.26179933]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [-0.69813156 -0.17453289]\n",
      " [ 0.08726644 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.36486077 -0.0611503 ]\n",
      " [-0.42462537  0.42015716]\n",
      " [-0.99926716 -0.11115123]\n",
      " [-0.36681753  0.14332685]\n",
      " [ 0.24241853 -0.15259205]\n",
      " [ 0.99983448  0.3294459 ]\n",
      " [ 0.36959645 -0.28380615]\n",
      " [-0.00556761 -0.25653103]\n",
      " [-0.77934295 -0.18766077]\n",
      " [ 0.01392289 -0.39318416]]\n",
      "cost:\n",
      "0.101452\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.43633222  0.08726644]\n",
      " [ 0.          0.08726644]\n",
      " [ 0.61086511  0.26179933]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [-0.08726644 -0.17453289]\n",
      " [-0.61086511 -0.17453289]\n",
      " [-0.26179933  0.17453289]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [ 1.13446378  0.08726644]\n",
      " [-0.87266444 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.53315723  0.0997458 ]\n",
      " [-0.03018127  0.1188731 ]\n",
      " [ 0.50590825  0.33628917]\n",
      " [ 0.99082035 -0.2275884 ]\n",
      " [-0.10488755 -0.20851047]\n",
      " [-0.78226662 -0.2189817 ]\n",
      " [-0.32072219  0.21214773]\n",
      " [ 0.16296621 -0.19673717]\n",
      " [ 0.9960078   0.1329868 ]\n",
      " [-0.99977064 -0.50275046]]\n",
      "cost:\n",
      "0.107869\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444  0.34906578]\n",
      " [ 0.95993089  0.08726644]\n",
      " [ 0.52359867 -0.08726644]\n",
      " [ 0.785398    0.08726644]\n",
      " [-1.04719733 -0.43633222]\n",
      " [-0.785398    0.34906578]\n",
      " [ 0.95993089  0.34906578]\n",
      " [-1.13446378  0.08726644]\n",
      " [-1.04719733  0.34906578]\n",
      " [-1.22173022  0.        ]]\n",
      "prediction:\n",
      "[[ 0.93410534  0.14993018]\n",
      " [ 0.99612153 -0.01563553]\n",
      " [ 0.58803785 -0.15893249]\n",
      " [ 0.90484047 -0.01893093]\n",
      " [-0.9213838  -0.62302446]\n",
      " [-0.74974394  0.16492066]\n",
      " [ 0.97800964  0.16251703]\n",
      " [-0.99207264 -0.04361705]\n",
      " [-0.94195682  0.16697   ]\n",
      " [-0.9772687  -0.16310315]]\n",
      "cost:\n",
      "0.18714\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644  0.08726644]\n",
      " [ 0.08726644  0.08726644]\n",
      " [-0.95993089  0.17453289]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [-0.17453289  0.17453289]\n",
      " [-0.69813156  0.34906578]\n",
      " [-1.13446378 -0.43633222]\n",
      " [ 0.08726644  0.34906578]\n",
      " [-1.04719733  0.        ]\n",
      " [-1.13446378  0.34906578]]\n",
      "prediction:\n",
      "[[-0.21716526 -0.00956821]\n",
      " [ 0.26869091  0.00622504]\n",
      " [-0.88643402  0.04249801]\n",
      " [ 0.99997568 -0.26641884]\n",
      " [-0.28453505  0.05710671]\n",
      " [-0.63971102  0.1894374 ]\n",
      " [-0.67378902 -0.60631752]\n",
      " [ 0.29376644  0.20843127]\n",
      " [-0.88636696 -0.12744685]\n",
      " [-0.89170277  0.15639129]]\n",
      "cost:\n",
      "0.266982\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156 -0.26179933]\n",
      " [ 0.         -0.08726644]\n",
      " [-0.61086511  0.34906578]\n",
      " [-0.26179933 -0.34906578]\n",
      " [-0.69813156  0.17453289]\n",
      " [-0.34906578 -0.26179933]\n",
      " [ 0.52359867 -0.43633222]\n",
      " [-0.43633222  0.17453289]\n",
      " [ 1.22173022  0.08726644]\n",
      " [ 1.22173022 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.70166302 -0.22618017]\n",
      " [-0.01257753 -0.06629611]\n",
      " [-0.90551364  0.39706728]\n",
      " [-0.32174882 -0.32388026]\n",
      " [-0.9996714   0.21365143]\n",
      " [-0.43293899 -0.24130295]\n",
      " [ 0.55959004 -0.38005084]\n",
      " [-0.5664537   0.2229175 ]\n",
      " [ 0.9957121   0.12082911]\n",
      " [ 0.99029964 -0.12101493]]\n",
      "cost:\n",
      "0.148588\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644  0.        ]\n",
      " [-1.04719733  0.34906578]\n",
      " [ 1.13446378  0.08726644]\n",
      " [-0.08726644  0.08726644]\n",
      " [ 0.52359867 -0.43633222]\n",
      " [-1.04719733 -0.08726644]\n",
      " [-1.04719733  0.34906578]\n",
      " [ 1.22173022  0.26179933]\n",
      " [-0.785398   -0.34906578]\n",
      " [-0.26179933 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.0356095  -0.02060324]\n",
      " [-0.96095276  0.29679295]\n",
      " [ 0.9990474   0.02428011]\n",
      " [-0.1371455   0.06628344]\n",
      " [ 0.44388965 -0.45921305]\n",
      " [-0.9773826  -0.10746367]\n",
      " [-0.96095276  0.29679295]\n",
      " [ 0.99715358  0.17238821]\n",
      " [-0.79547578 -0.35974818]\n",
      " [-0.34897956 -0.28308615]]\n",
      "cost:\n",
      "0.0962528\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444 -0.08726644]\n",
      " [-0.785398   -0.08726644]\n",
      " [-0.87266444 -0.26179933]\n",
      " [ 0.69813156  0.34906578]\n",
      " [-0.785398    0.        ]\n",
      " [-1.13446378 -0.43633222]\n",
      " [ 0.785398    0.34906578]\n",
      " [ 0.17453289  0.17453289]\n",
      " [-0.61086511 -0.43633222]\n",
      " [-0.95993089 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.99937958 -0.06022185]\n",
      " [-0.79191184 -0.048358  ]\n",
      " [-0.92726505 -0.21736696]\n",
      " [ 0.91578466  0.34502068]\n",
      " [-0.80020559  0.0260448 ]\n",
      " [-0.97006917 -0.34308928]\n",
      " [ 0.98999047  0.34222585]\n",
      " [ 0.21890248  0.19569963]\n",
      " [-0.5422166  -0.37013009]\n",
      " [-0.96568674 -0.28702894]]\n",
      "cost:\n",
      "0.10876\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444 -0.17453289]\n",
      " [-1.22173022 -0.26179933]\n",
      " [ 1.04719733 -0.26179933]\n",
      " [ 0.95993089 -0.43633222]\n",
      " [-0.61086511 -0.34906578]\n",
      " [ 0.52359867  0.        ]\n",
      " [-0.61086511  0.        ]\n",
      " [ 1.04719733 -0.26179933]\n",
      " [-0.26179933  0.17453289]\n",
      " [ 0.52359867  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.80073392 -0.1345934 ]\n",
      " [-0.99995428 -0.16884489]\n",
      " [ 0.94130409 -0.19350113]\n",
      " [ 0.88787454 -0.3719897 ]\n",
      " [-0.63659447 -0.28139752]\n",
      " [ 0.48129451  0.0405944 ]\n",
      " [-0.66566706  0.03241323]\n",
      " [ 0.94130409 -0.19350113]\n",
      " [-0.24681893  0.27890378]\n",
      " [ 0.49271274  0.47971496]]\n",
      "cost:\n",
      "0.119159\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511 -0.43633222]\n",
      " [ 1.04719733 -0.34906578]\n",
      " [-0.17453289  0.34906578]\n",
      " [-0.87266444 -0.26179933]\n",
      " [-0.08726644  0.        ]\n",
      " [ 0.785398    0.34906578]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [-0.95993089 -0.17453289]\n",
      " [-0.52359867 -0.26179933]\n",
      " [ 0.17453289 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.65614593 -0.26733845]\n",
      " [ 0.99935973 -0.19626755]\n",
      " [-0.14424703  0.40965542]\n",
      " [-0.98506635 -0.1592513 ]\n",
      " [-0.06113302  0.02412663]\n",
      " [ 0.85694629  0.42045048]\n",
      " [ 0.55809462 -0.21426943]\n",
      " [-0.99904841 -0.07981434]\n",
      " [-0.48566613 -0.18268485]\n",
      " [ 0.23511627 -0.28065297]]\n",
      "cost:\n",
      "0.1188\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222  0.34906578]\n",
      " [-1.22173022  0.        ]\n",
      " [-0.34906578  0.26179933]\n",
      " [ 0.          0.34906578]\n",
      " [ 0.17453289 -0.43633222]\n",
      " [ 1.22173022  0.34906578]\n",
      " [ 0.785398    0.08726644]\n",
      " [ 1.22173022  0.34906578]\n",
      " [-0.52359867  0.08726644]\n",
      " [ 1.22173022  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.42671952  0.16019097]\n",
      " [-0.99996823 -0.19999141]\n",
      " [-0.33370811  0.08432678]\n",
      " [ 0.06722818  0.18249264]\n",
      " [ 0.22683291 -0.63196611]\n",
      " [ 0.8639226   0.08878336]\n",
      " [ 0.75586158 -0.04062115]\n",
      " [ 0.8639226   0.08878336]\n",
      " [-0.54061455 -0.029772  ]\n",
      " [ 0.96706307 -0.12611477]]\n",
      "cost:\n",
      "0.25147\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.26179933 -0.34906578]\n",
      " [-0.08726644 -0.34906578]\n",
      " [-0.69813156 -0.43633222]\n",
      " [ 0.87266444  0.        ]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [-1.04719733 -0.34906578]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [-0.69813156  0.17453289]\n",
      " [ 1.13446378 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.29757604 -0.19733112]\n",
      " [-0.08109681 -0.23288052]\n",
      " [-0.7657516  -0.26245624]\n",
      " [ 0.87872869  0.16013074]\n",
      " [ 0.96877015 -0.22827953]\n",
      " [ 0.47798267 -0.08140162]\n",
      " [-0.99989372 -0.16392921]\n",
      " [ 0.39230594 -0.0685378 ]\n",
      " [-0.84225827  0.56658876]\n",
      " [ 0.98701376 -0.0677059 ]]\n",
      "cost:\n",
      "0.195406\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644 -0.43633222]\n",
      " [-1.22173022 -0.43633222]\n",
      " [-1.22173022 -0.08726644]\n",
      " [-0.52359867 -0.17453289]\n",
      " [ 0.87266444  0.        ]\n",
      " [-0.26179933  0.        ]\n",
      " [-0.08726644 -0.43633222]\n",
      " [-0.61086511  0.34906578]\n",
      " [-1.13446378 -0.43633222]\n",
      " [-0.43633222 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.07751372 -0.28795636]\n",
      " [-0.73072755 -0.21354218]\n",
      " [-0.9565382   0.06458288]\n",
      " [-0.51277661 -0.08844262]\n",
      " [ 0.99998128  0.11207952]\n",
      " [-0.19525038  0.06115654]\n",
      " [-0.07751372 -0.28795636]\n",
      " [-0.60216224  0.51462179]\n",
      " [-0.72146535 -0.23562285]\n",
      " [-0.43728647 -0.20308529]]\n",
      "cost:\n",
      "0.225989\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578  0.08726644]\n",
      " [ 1.04719733  0.        ]\n",
      " [ 0.         -0.17453289]\n",
      " [-0.26179933  0.26179933]\n",
      " [ 0.69813156  0.17453289]\n",
      " [-1.22173022 -0.08726644]\n",
      " [-0.87266444  0.17453289]\n",
      " [ 0.87266444 -0.26179933]\n",
      " [-0.69813156  0.34906578]\n",
      " [-1.13446378 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.4005498   0.0450181 ]\n",
      " [ 0.99897236 -0.03818094]\n",
      " [ 0.05864734 -0.29014605]\n",
      " [-0.24569865  0.22722533]\n",
      " [ 0.74747944  0.1331536 ]\n",
      " [-0.99133909 -0.30079338]\n",
      " [-0.89465612  0.12633327]\n",
      " [ 0.99009991 -0.4794406 ]\n",
      " [-0.66973293  0.32059705]\n",
      " [-0.99091727 -0.24269153]]\n",
      "cost:\n",
      "0.122648\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378 -0.17453289]\n",
      " [ 0.          0.26179933]\n",
      " [-0.34906578 -0.26179933]\n",
      " [-0.87266444 -0.43633222]\n",
      " [-0.34906578 -0.08726644]\n",
      " [ 0.43633222  0.        ]\n",
      " [-1.22173022  0.26179933]\n",
      " [ 0.08726644  0.        ]\n",
      " [-0.95993089  0.08726644]\n",
      " [-1.04719733  0.        ]]\n",
      "prediction:\n",
      "[[ 0.99997312 -0.2211273 ]\n",
      " [ 0.01323268  0.31814715]\n",
      " [-0.33870581 -0.30266184]\n",
      " [-0.76985979 -0.52777624]\n",
      " [-0.32595536 -0.09174374]\n",
      " [ 0.47372544 -0.00100091]\n",
      " [-0.92881006  0.28183311]\n",
      " [ 0.09662981  0.01241283]\n",
      " [-0.84972179  0.0924961 ]\n",
      " [-0.92768943 -0.00348565]]\n",
      "cost:\n",
      "0.097995\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156 -0.26179933]\n",
      " [ 1.22173022  0.        ]\n",
      " [-0.87266444 -0.08726644]\n",
      " [-0.34906578  0.17453289]\n",
      " [ 0.52359867  0.        ]\n",
      " [ 0.43633222  0.34906578]\n",
      " [-0.61086511 -0.43633222]\n",
      " [ 1.22173022 -0.34906578]\n",
      " [-0.52359867  0.34906578]\n",
      " [ 0.69813156  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.65034008 -0.2909905 ]\n",
      " [ 0.98808265 -0.05120869]\n",
      " [-0.99993902 -0.12003705]\n",
      " [-0.35305825  0.12984119]\n",
      " [ 0.53164709 -0.01533752]\n",
      " [ 0.43385834  0.28466323]\n",
      " [-0.69547987 -0.45645308]\n",
      " [ 0.95137161 -0.37565365]\n",
      " [-0.5443036   0.29849714]\n",
      " [ 0.63552606  0.12453568]]\n",
      "cost:\n",
      "0.104666\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.22173022 -0.17453289]\n",
      " [ 1.04719733  0.        ]\n",
      " [-0.95993089  0.        ]\n",
      " [-0.43633222  0.17453289]\n",
      " [-1.13446378  0.        ]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [-1.22173022 -0.34906578]\n",
      " [-0.95993089  0.        ]\n",
      " [ 0.43633222  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.99698192 -0.20054208]\n",
      " [ 0.99825835  0.02337338]\n",
      " [-0.95459157  0.01646359]\n",
      " [-0.47265062  0.4434177 ]\n",
      " [-0.98333746  0.06689423]\n",
      " [ 0.47272983 -0.10518704]\n",
      " [ 0.55515575 -0.43370554]\n",
      " [-0.94430828 -0.42537525]\n",
      " [-0.95459157  0.01646359]\n",
      " [ 0.4634982   0.14396657]]\n",
      "cost:\n",
      "0.123319\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289 -0.26179933]\n",
      " [ 0.08726644 -0.08726644]\n",
      " [ 0.69813156  0.26179933]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [-1.13446378  0.26179933]\n",
      " [-0.785398    0.34906578]\n",
      " [ 0.34906578  0.08726644]\n",
      " [ 0.95993089 -0.43633222]\n",
      " [ 0.34906578  0.08726644]\n",
      " [-0.95993089 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.10943461 -0.31665424]\n",
      " [-0.03669518 -0.10662235]\n",
      " [ 0.88095033  0.20964168]\n",
      " [ 0.41458467 -0.11974469]\n",
      " [-0.99518371  0.2023602 ]\n",
      " [-0.80577993  0.30882207]\n",
      " [ 0.2955921   0.05042787]\n",
      " [ 0.99971235 -0.53603292]\n",
      " [ 0.2955921   0.05042787]\n",
      " [-0.9930498  -0.2058621 ]]\n",
      "cost:\n",
      "0.0919139\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867 -0.34906578]\n",
      " [ 0.43633222  0.        ]\n",
      " [-0.69813156  0.34906578]\n",
      " [-0.69813156  0.26179933]\n",
      " [-0.95993089  0.17453289]\n",
      " [-0.08726644  0.        ]\n",
      " [-0.26179933 -0.08726644]\n",
      " [ 1.13446378 -0.08726644]\n",
      " [-0.17453289  0.34906578]\n",
      " [-0.34906578  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.58881152 -0.60390043]\n",
      " [ 0.4583675  -0.06226919]\n",
      " [-0.70089674  0.22278924]\n",
      " [-0.73695695  0.14738069]\n",
      " [-0.99863523  0.06226243]\n",
      " [ 0.00653156 -0.04858864]\n",
      " [-0.21184257 -0.14490142]\n",
      " [ 0.99990076 -0.28069249]\n",
      " [-0.11904041  0.21937211]\n",
      " [-0.3294076   0.08836699]]\n",
      "cost:\n",
      "0.134197\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733  0.34906578]\n",
      " [-0.52359867 -0.17453289]\n",
      " [-0.34906578  0.17453289]\n",
      " [-0.52359867 -0.26179933]\n",
      " [-0.17453289  0.        ]\n",
      " [-0.52359867 -0.17453289]\n",
      " [ 0.785398    0.17453289]\n",
      " [ 1.04719733  0.        ]\n",
      " [-0.34906578  0.34906578]\n",
      " [ 0.08726644 -0.26179933]]\n",
      "prediction:\n",
      "[[  9.96593058e-01   3.01201940e-01]\n",
      " [ -9.77466166e-01  -2.24038690e-01]\n",
      " [ -6.34603977e-01   1.57166228e-01]\n",
      " [ -9.58655953e-01  -4.49732184e-01]\n",
      " [ -3.60839337e-01   7.03975442e-04]\n",
      " [ -9.77466166e-01  -2.24038690e-01]\n",
      " [  8.80504429e-01   1.42187193e-01]\n",
      " [  9.98749793e-01  -9.33634564e-02]\n",
      " [ -5.77152371e-01   3.33279490e-01]\n",
      " [ -6.09313920e-02  -3.34861040e-01]]\n",
      "cost:\n",
      "0.252856\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.43633222  0.        ]\n",
      " [-0.69813156  0.08726644]\n",
      " [ 0.26179933  0.08726644]\n",
      " [-0.17453289  0.08726644]\n",
      " [ 0.52359867 -0.17453289]\n",
      " [-0.95993089 -0.17453289]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [ 0.785398    0.        ]\n",
      " [-0.61086511 -0.17453289]\n",
      " [-0.26179933  0.26179933]]\n",
      "prediction:\n",
      "[[-0.41841677  0.01191318]\n",
      " [-0.71069872  0.13474725]\n",
      " [ 0.27308452  0.11913639]\n",
      " [-0.17262353  0.10300951]\n",
      " [ 0.75113171 -0.26645336]\n",
      " [-0.99909234 -0.40741602]\n",
      " [ 0.16652918 -0.2532061 ]\n",
      " [ 0.99987191  0.02449197]\n",
      " [-0.56991643 -0.30818608]\n",
      " [-0.24980463  0.45669845]]\n",
      "cost:\n",
      "0.123185\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289  0.08726644]\n",
      " [ 0.61086511  0.17453289]\n",
      " [-0.61086511 -0.17453289]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [-0.95993089  0.        ]\n",
      " [ 0.         -0.26179933]\n",
      " [-0.08726644  0.        ]\n",
      " [-0.52359867 -0.34906578]\n",
      " [-0.08726644 -0.08726644]\n",
      " [ 0.61086511  0.26179933]]\n",
      "prediction:\n",
      "[[-0.13613029  0.11486477]\n",
      " [ 0.62707639  0.2698842 ]\n",
      " [-0.6164031  -0.17588775]\n",
      " [ 0.99966562 -0.31824309]\n",
      " [-0.9997201   0.03514819]\n",
      " [ 0.0795624  -0.28753856]\n",
      " [-0.03100793 -0.00695489]\n",
      " [-0.46574703 -0.39920771]\n",
      " [-0.05236097 -0.1113277 ]\n",
      " [ 0.63035762  0.41602749]]\n",
      "cost:\n",
      "0.0846644\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933 -0.26179933]\n",
      " [-0.61086511 -0.34906578]\n",
      " [ 0.          0.34906578]\n",
      " [ 0.87266444 -0.34906578]\n",
      " [ 0.87266444  0.08726644]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [-0.34906578  0.17453289]\n",
      " [-1.13446378  0.17453289]\n",
      " [-0.26179933 -0.43633222]\n",
      " [ 0.95993089  0.26179933]]\n",
      "prediction:\n",
      "[[-0.16497882 -0.23790683]\n",
      " [-0.56475091 -0.31819215]\n",
      " [ 0.12962994  0.31747511]\n",
      " [ 0.93998736 -0.32630536]\n",
      " [ 0.92476314  0.05426563]\n",
      " [ 0.43320301 -0.08258259]\n",
      " [-0.23643759  0.13771029]\n",
      " [-0.99994493  0.17977038]\n",
      " [-0.1667258  -0.41766685]\n",
      " [ 0.98731649  0.23258729]]\n",
      "cost:\n",
      "0.081706\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.22173022 -0.43633222]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [-0.95993089 -0.43633222]\n",
      " [-1.04719733  0.17453289]\n",
      " [ 0.34906578 -0.34906578]\n",
      " [ 1.13446378  0.08726644]\n",
      " [-0.52359867 -0.34906578]\n",
      " [ 0.61086511 -0.26179933]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [ 0.34906578  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.98215252 -0.21280494]\n",
      " [ 0.21734828 -0.10338754]\n",
      " [-0.98629719 -0.28602099]\n",
      " [-0.99943906  0.28205475]\n",
      " [ 0.32347104 -0.23922539]\n",
      " [ 0.99734634  0.22326475]\n",
      " [-0.56971705 -0.21851036]\n",
      " [ 0.55704725 -0.15565647]\n",
      " [ 0.01737459 -0.18377823]\n",
      " [ 0.30751175  0.42665094]]\n",
      "cost:\n",
      "0.143794\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089  0.08726644]\n",
      " [ 0.08726644 -0.08726644]\n",
      " [ 0.52359867  0.34906578]\n",
      " [ 1.04719733  0.08726644]\n",
      " [-0.08726644  0.26179933]\n",
      " [-0.87266444 -0.26179933]\n",
      " [-0.52359867 -0.43633222]\n",
      " [-0.34906578 -0.17453289]\n",
      " [ 0.08726644 -0.08726644]\n",
      " [-0.87266444  0.08726644]]\n",
      "prediction:\n",
      "[[-0.97325957  0.06560574]\n",
      " [ 0.12597913 -0.10285045]\n",
      " [ 0.61116135  0.31613961]\n",
      " [ 0.99996102  0.05276402]\n",
      " [-0.05742487  0.25073257]\n",
      " [-0.93778014 -0.30215752]\n",
      " [-0.49561825 -0.5168792 ]\n",
      " [-0.30000654 -0.19118233]\n",
      " [ 0.12597913 -0.10285045]\n",
      " [-0.92236435  0.06543595]]\n",
      "cost:\n",
      "0.0560735\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089  0.26179933]\n",
      " [ 0.95993089  0.34906578]\n",
      " [-0.08726644  0.34906578]\n",
      " [-0.52359867 -0.26179933]\n",
      " [-0.34906578  0.17453289]\n",
      " [-0.17453289 -0.26179933]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [-1.04719733  0.26179933]\n",
      " [ 0.69813156  0.34906578]\n",
      " [ 0.17453289 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.97911459  0.11542696]\n",
      " [ 0.96529055  0.17885599]\n",
      " [-0.0300587   0.19826061]\n",
      " [-0.52437294 -0.2688871 ]\n",
      " [-0.34405804  0.09634799]\n",
      " [-0.1619626  -0.27812698]\n",
      " [ 0.85996079 -0.38856763]\n",
      " [-0.99995208  0.07496465]\n",
      " [ 0.6240285   0.16696092]\n",
      " [ 0.16535065 -0.39809245]]\n",
      "cost:\n",
      "0.106336\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.22173022  0.        ]\n",
      " [ 0.         -0.26179933]\n",
      " [-0.26179933  0.        ]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [-0.785398    0.34906578]\n",
      " [ 0.69813156 -0.43633222]\n",
      " [ 0.87266444  0.34906578]\n",
      " [-0.785398    0.08726644]\n",
      " [ 0.17453289  0.08726644]]\n",
      "prediction:\n",
      "[[-0.99920654 -0.01710482]\n",
      " [-0.0244823  -0.27939546]\n",
      " [-0.32431856  0.00681761]\n",
      " [ 0.12597355 -0.18167697]\n",
      " [ 0.90882117 -0.18340869]\n",
      " [-0.88801831  0.26204523]\n",
      " [ 0.89718801 -0.53078008]\n",
      " [ 0.99929893  0.27478775]\n",
      " [-0.90701002  0.07335471]\n",
      " [ 0.13226902  0.07661533]]\n",
      "cost:\n",
      "0.124386\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644  0.        ]\n",
      " [-0.87266444  0.08726644]\n",
      " [-0.34906578  0.34906578]\n",
      " [ 0.87266444  0.08726644]\n",
      " [ 0.785398   -0.08726644]\n",
      " [ 0.87266444  0.26179933]\n",
      " [-1.04719733 -0.08726644]\n",
      " [ 0.61086511  0.26179933]\n",
      " [-0.95993089 -0.08726644]\n",
      " [-0.52359867  0.        ]]\n",
      "prediction:\n",
      "[[-0.08708591 -0.04296743]\n",
      " [-0.93427789  0.02607869]\n",
      " [-0.34878689  0.31048974]\n",
      " [ 0.99504983  0.00287243]\n",
      " [ 0.96491462 -0.28243673]\n",
      " [ 0.98995697  0.20377623]\n",
      " [-0.99620759 -0.48625445]\n",
      " [ 0.63445771  0.21887603]\n",
      " [-0.98657328 -0.35314962]\n",
      " [-0.54102802 -0.06058054]]\n",
      "cost:\n",
      "0.149454\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.26179933  0.34906578]\n",
      " [-0.52359867 -0.17453289]\n",
      " [-0.08726644  0.17453289]\n",
      " [-0.17453289 -0.34906578]\n",
      " [-0.34906578  0.26179933]\n",
      " [ 0.08726644  0.26179933]\n",
      " [ 0.95993089 -0.26179933]\n",
      " [ 0.61086511 -0.34906578]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [-0.34906578 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.32806021  0.35246801]\n",
      " [-0.999749   -0.19289938]\n",
      " [-0.05759319  0.15563183]\n",
      " [-0.22439696 -0.35597372]\n",
      " [-0.51784378  0.24285859]\n",
      " [ 0.10378864  0.25103047]\n",
      " [ 0.99934423 -0.28177375]\n",
      " [ 0.68338513 -0.33591703]\n",
      " [ 0.82605624 -0.17073387]\n",
      " [-0.78328073 -0.19436817]]\n",
      "cost:\n",
      "0.149847\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089 -0.26179933]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [-0.52359867  0.17453289]\n",
      " [-0.785398   -0.34906578]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [-0.95993089  0.        ]\n",
      " [ 0.34906578  0.        ]\n",
      " [-0.87266444 -0.43633222]\n",
      " [-0.08726644 -0.43633222]\n",
      " [ 0.26179933  0.        ]]\n",
      "prediction:\n",
      "[[ 0.99330342 -0.17737709]\n",
      " [ 0.9991976  -0.12819414]\n",
      " [-0.61403215  0.54895198]\n",
      " [-0.90402818 -0.23329879]\n",
      " [ 0.18286212 -0.18582664]\n",
      " [-0.99649978  0.10788888]\n",
      " [ 0.30336681  0.04773559]\n",
      " [-0.95664704 -0.30624357]\n",
      " [-0.21055721 -0.32922038]\n",
      " [ 0.21820845  0.05678778]]\n",
      "cost:\n",
      "0.151116\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.26179933  0.17453289]\n",
      " [-0.69813156  0.08726644]\n",
      " [ 1.04719733  0.34906578]\n",
      " [-1.04719733 -0.43633222]\n",
      " [ 0.17453289  0.08726644]\n",
      " [-0.87266444  0.        ]\n",
      " [ 0.785398    0.26179933]\n",
      " [-1.13446378  0.        ]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [ 0.          0.08726644]]\n",
      "prediction:\n",
      "[[ 0.30150294  0.11120886]\n",
      " [-0.67792732  0.02279483]\n",
      " [ 0.98676986  0.29172388]\n",
      " [-0.97118288 -0.57173276]\n",
      " [ 0.21110061  0.02485802]\n",
      " [-0.94126421 -0.04424037]\n",
      " [ 0.84718531  0.19335221]\n",
      " [-0.99681836 -0.08014589]\n",
      " [ 0.9986493  -0.40934527]\n",
      " [-0.01820804  0.03762867]]\n",
      "cost:\n",
      "0.103975\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.         -0.34906578]\n",
      " [-1.04719733 -0.17453289]\n",
      " [-1.22173022  0.34906578]\n",
      " [-0.69813156 -0.43633222]\n",
      " [-0.08726644 -0.26179933]\n",
      " [-0.87266444 -0.26179933]\n",
      " [-1.04719733 -0.34906578]\n",
      " [-0.08726644  0.34906578]\n",
      " [-0.69813156 -0.26179933]\n",
      " [ 0.87266444  0.34906578]]\n",
      "prediction:\n",
      "[[-0.00115389 -0.29760668]\n",
      " [-0.80935955 -0.0710271 ]\n",
      " [-0.72408688  0.3238413 ]\n",
      " [-0.64831549 -0.32437739]\n",
      " [-0.1126923  -0.24091826]\n",
      " [-0.75680399 -0.1678427 ]\n",
      " [-0.7984637  -0.22470008]\n",
      " [-0.13344142  0.34444675]\n",
      " [-0.63354719 -0.18208089]\n",
      " [ 0.99998385  0.33185628]]\n",
      "cost:\n",
      "0.166932\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.26179933 -0.08726644]\n",
      " [ 0.08726644 -0.08726644]\n",
      " [-0.95993089 -0.26179933]\n",
      " [-0.785398    0.08726644]\n",
      " [ 1.04719733  0.34906578]\n",
      " [-0.08726644  0.17453289]\n",
      " [-0.17453289  0.17453289]\n",
      " [-0.43633222 -0.34906578]\n",
      " [-1.22173022  0.08726644]\n",
      " [-0.69813156 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.26928788 -0.09601184]\n",
      " [ 0.03844289 -0.10147519]\n",
      " [-0.91157436 -0.31808132]\n",
      " [-0.69828594  0.08041352]\n",
      " [ 0.99997246  0.34577599]\n",
      " [-0.1078477   0.17311388]\n",
      " [-0.18070075  0.19233914]\n",
      " [-0.39715558 -0.40924335]\n",
      " [-0.97425652  0.07871475]\n",
      " [-0.61597681 -0.41390043]]\n",
      "cost:\n",
      "0.0734844\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398    0.17453289]\n",
      " [ 1.22173022 -0.34906578]\n",
      " [-0.61086511 -0.43633222]\n",
      " [-0.34906578 -0.34906578]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [ 0.08726644  0.34906578]\n",
      " [-0.785398   -0.34906578]\n",
      " [-0.26179933  0.17453289]\n",
      " [-0.34906578 -0.08726644]\n",
      " [ 1.13446378  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.83190262  0.16886275]\n",
      " [ 0.98926663 -0.27607915]\n",
      " [-0.84417081 -0.35487628]\n",
      " [-0.39048651 -0.28984216]\n",
      " [ 0.30645561 -0.15914294]\n",
      " [ 0.07376854  0.32394636]\n",
      " [-0.99985075 -0.28421763]\n",
      " [-0.25664976  0.18918763]\n",
      " [-0.32823688 -0.06615612]\n",
      " [ 0.99146968  0.29635945]]\n",
      "cost:\n",
      "0.110727\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089 -0.08726644]\n",
      " [-0.43633222  0.08726644]\n",
      " [ 0.52359867 -0.43633222]\n",
      " [-0.69813156  0.34906578]\n",
      " [-0.61086511 -0.17453289]\n",
      " [ 0.52359867 -0.08726644]\n",
      " [-0.17453289 -0.26179933]\n",
      " [ 1.04719733  0.34906578]\n",
      " [-0.95993089  0.26179933]\n",
      " [ 0.95993089 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.98757166 -0.07848515]\n",
      " [-0.39507928  0.0971664 ]\n",
      " [ 0.54689717 -0.40603089]\n",
      " [-0.72205389  0.28827581]\n",
      " [-0.58216196 -0.17083992]\n",
      " [ 0.53344536 -0.08236915]\n",
      " [-0.11600876 -0.25138852]\n",
      " [ 0.99860859  0.29193366]\n",
      " [-0.99631542  0.24191697]\n",
      " [ 0.99377203 -0.40101644]]\n",
      "cost:\n",
      "0.0439731\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089  0.26179933]\n",
      " [ 0.785398   -0.26179933]\n",
      " [ 1.13446378 -0.08726644]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [-0.95993089 -0.43633222]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [ 0.52359867 -0.17453289]\n",
      " [ 0.87266444  0.17453289]\n",
      " [ 0.          0.17453289]\n",
      " [ 0.17453289 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.99973142  0.4060882 ]\n",
      " [ 0.78920007 -0.2347903 ]\n",
      " [ 0.98850185 -0.02777488]\n",
      " [ 0.70559788 -0.23985133]\n",
      " [-0.99487478 -0.4417854 ]\n",
      " [ 0.24450706 -0.16259786]\n",
      " [ 0.55216956 -0.15377958]\n",
      " [ 0.9206475   0.27763182]\n",
      " [ 0.08365712  0.22278638]\n",
      " [ 0.24450706 -0.16259786]]\n",
      "cost:\n",
      "0.0780699\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733  0.34906578]\n",
      " [-1.04719733  0.17453289]\n",
      " [ 1.04719733  0.34906578]\n",
      " [ 0.52359867 -0.43633222]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [ 0.52359867  0.34906578]\n",
      " [-1.04719733 -0.34906578]\n",
      " [ 1.22173022  0.17453289]]\n",
      "prediction:\n",
      "[[-0.98824739  0.23124649]\n",
      " [-0.99823177  0.09926932]\n",
      " [ 0.95071983  0.22638464]\n",
      " [ 0.50694799 -0.45283747]\n",
      " [ 0.94086915 -0.11613811]\n",
      " [ 0.70523334 -0.37110874]\n",
      " [ 0.61028636 -0.10282783]\n",
      " [ 0.50316876  0.23122296]\n",
      " [-0.99172914 -0.34939709]\n",
      " [ 0.98368633  0.08443649]]\n",
      "cost:\n",
      "0.0903972\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378  0.26179933]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [-0.87266444  0.08726644]\n",
      " [-0.43633222 -0.08726644]\n",
      " [-0.785398    0.17453289]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [-0.17453289 -0.17453289]\n",
      " [ 0.785398   -0.17453289]\n",
      " [-0.52359867  0.        ]\n",
      " [-1.22173022 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.97210687  0.40188068]\n",
      " [ 0.31997561 -0.26507729]\n",
      " [-0.85286975  0.1402735 ]\n",
      " [-0.45732802 -0.08235106]\n",
      " [-0.77046043  0.27132314]\n",
      " [ 0.98990822 -0.41126651]\n",
      " [-0.15118104 -0.17050034]\n",
      " [ 0.99981254 -0.15051745]\n",
      " [-0.53210783  0.02576317]\n",
      " [-0.96935368 -0.31178582]]\n",
      "cost:\n",
      "0.127098\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867  0.        ]\n",
      " [ 0.52359867 -0.17453289]\n",
      " [ 0.52359867  0.26179933]\n",
      " [ 0.08726644  0.08726644]\n",
      " [ 0.785398   -0.17453289]\n",
      " [ 0.61086511  0.08726644]\n",
      " [-0.69813156 -0.26179933]\n",
      " [-0.34906578  0.17453289]\n",
      " [-0.17453289  0.26179933]\n",
      " [ 0.61086511 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.80878365 -0.05317852]\n",
      " [ 0.54226416 -0.26448503]\n",
      " [ 0.61596596  0.30112937]\n",
      " [ 0.08223945  0.06606479]\n",
      " [ 0.99704576 -0.30533069]\n",
      " [ 0.77481687  0.06417827]\n",
      " [-0.99992484 -0.44786111]\n",
      " [-0.30132872  0.16153543]\n",
      " [-0.15683931  0.2766813 ]\n",
      " [ 0.68313813 -0.27752978]]\n",
      "cost:\n",
      "0.147148\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.22173022  0.        ]\n",
      " [ 0.17453289  0.        ]\n",
      " [ 1.22173022 -0.34906578]\n",
      " [-0.08726644 -0.08726644]\n",
      " [ 1.13446378 -0.17453289]\n",
      " [-0.52359867 -0.43633222]\n",
      " [-0.43633222  0.26179933]\n",
      " [ 0.87266444  0.        ]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [ 0.34906578 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.85560733  0.1585727 ]\n",
      " [ 0.17007858  0.04536208]\n",
      " [ 0.86513817 -0.3086313 ]\n",
      " [-0.09792022 -0.06737969]\n",
      " [ 0.90140575 -0.12677649]\n",
      " [-0.9999671  -0.43686864]\n",
      " [-0.89690089  0.48498908]\n",
      " [ 0.73257542  0.05633866]\n",
      " [ 0.85530281 -0.05266908]\n",
      " [ 0.43173814 -0.25261429]]\n",
      "cost:\n",
      "0.239645\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867 -0.43633222]\n",
      " [-0.08726644  0.08726644]\n",
      " [ 0.61086511  0.        ]\n",
      " [ 0.34906578  0.26179933]\n",
      " [ 1.13446378  0.26179933]\n",
      " [-0.08726644  0.17453289]\n",
      " [ 1.13446378 -0.43633222]\n",
      " [ 0.08726644  0.17453289]\n",
      " [-1.22173022 -0.34906578]\n",
      " [-0.95993089  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.5244168  -0.43984017]\n",
      " [-0.14065829  0.04102571]\n",
      " [ 0.58122444 -0.05441085]\n",
      " [ 0.35603431  0.22278483]\n",
      " [ 0.99544996  0.2086596 ]\n",
      " [-0.17929718  0.11693978]\n",
      " [ 0.98625237 -0.42688063]\n",
      " [ 0.0331268   0.13120946]\n",
      " [-0.99864405 -0.36328945]\n",
      " [-0.99771893  0.12886694]]\n",
      "cost:\n",
      "0.0933882\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.22173022 -0.08726644]\n",
      " [-0.87266444  0.08726644]\n",
      " [-0.95993089  0.08726644]\n",
      " [ 0.785398   -0.17453289]\n",
      " [ 1.13446378 -0.34906578]\n",
      " [-0.26179933 -0.34906578]\n",
      " [-0.61086511 -0.43633222]\n",
      " [ 0.         -0.17453289]\n",
      " [ 0.26179933 -0.08726644]\n",
      " [-1.22173022  0.17453289]]\n",
      "prediction:\n",
      "[[-0.97154272  0.01735364]\n",
      " [-0.83122087  0.17717716]\n",
      " [-0.87751693  0.21101964]\n",
      " [ 0.97706431 -0.13266593]\n",
      " [ 0.99990249 -0.2831834 ]\n",
      " [-0.2924577  -0.31615669]\n",
      " [-0.56939656 -0.39992371]\n",
      " [-0.09355487 -0.15310936]\n",
      " [ 0.19917788 -0.05005619]\n",
      " [-0.94801027  0.42751136]]\n",
      "cost:\n",
      "0.150658\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.26179933  0.34906578]\n",
      " [-0.69813156 -0.26179933]\n",
      " [-0.34906578 -0.34906578]\n",
      " [ 1.13446378  0.08726644]\n",
      " [ 0.785398    0.26179933]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [-0.61086511  0.17453289]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [-0.95993089 -0.34906578]\n",
      " [-0.785398   -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.23304966  0.37142831]\n",
      " [-0.76718128 -0.26256979]\n",
      " [-0.2964344  -0.35879838]\n",
      " [ 0.9993903   0.0958081 ]\n",
      " [ 0.80105233  0.2649143 ]\n",
      " [ 0.06241617 -0.25559828]\n",
      " [-0.59083825  0.15435103]\n",
      " [ 0.96354437 -0.08289088]\n",
      " [-0.99918216 -0.34731665]\n",
      " [-0.93360525 -0.07781439]]\n",
      "cost:\n",
      "0.0643133\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578 -0.08726644]\n",
      " [ 0.87266444  0.08726644]\n",
      " [-0.43633222  0.34906578]\n",
      " [ 0.43633222  0.17453289]\n",
      " [ 0.87266444  0.08726644]\n",
      " [ 0.87266444 -0.34906578]\n",
      " [-0.87266444  0.        ]\n",
      " [-0.34906578 -0.34906578]\n",
      " [-0.26179933  0.08726644]\n",
      " [ 0.785398    0.26179933]]\n",
      "prediction:\n",
      "[[ 0.30953518 -0.13212109]\n",
      " [ 0.91963327  0.02220999]\n",
      " [-0.43034402  0.2943528 ]\n",
      " [ 0.39587131  0.13098742]\n",
      " [ 0.91963327  0.02220999]\n",
      " [ 0.92981398 -0.46366733]\n",
      " [-0.99997306 -0.07631283]\n",
      " [-0.33234546 -0.45537058]\n",
      " [-0.2754924   0.05426984]\n",
      " [ 0.76331568  0.18557931]]\n",
      "cost:\n",
      "0.083393\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089  0.34906578]\n",
      " [ 0.17453289  0.        ]\n",
      " [ 0.26179933  0.17453289]\n",
      " [-0.43633222 -0.08726644]\n",
      " [ 0.34906578  0.26179933]\n",
      " [-0.87266444  0.17453289]\n",
      " [-0.26179933 -0.34906578]\n",
      " [ 0.785398    0.26179933]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [-0.08726644 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.99430847  0.25745741]\n",
      " [ 0.17399515 -0.0235107 ]\n",
      " [ 0.36800075  0.11703073]\n",
      " [-0.4465223  -0.0967619 ]\n",
      " [ 0.4614113   0.178644  ]\n",
      " [-0.99379456  0.10643448]\n",
      " [-0.29896033 -0.41377911]\n",
      " [ 0.99984562  0.16878569]\n",
      " [ 0.6336621  -0.31640425]\n",
      " [-0.08581851 -0.40584505]]\n",
      "cost:\n",
      "0.110471\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156 -0.26179933]\n",
      " [ 0.         -0.43633222]\n",
      " [ 1.04719733  0.08726644]\n",
      " [-0.26179933  0.08726644]\n",
      " [-0.43633222 -0.26179933]\n",
      " [ 0.          0.26179933]\n",
      " [ 0.         -0.34906578]\n",
      " [-0.87266444  0.        ]\n",
      " [ 0.43633222  0.        ]\n",
      " [-1.04719733 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.84939015 -0.20121452]\n",
      " [ 0.03943428 -0.34849522]\n",
      " [ 0.99976981  0.22485755]\n",
      " [-0.25659606  0.13695419]\n",
      " [-0.43122089 -0.20881091]\n",
      " [ 0.08405109  0.41884863]\n",
      " [ 0.05727825 -0.27109981]\n",
      " [-0.98825073  0.05013466]\n",
      " [ 0.47911426  0.03930736]\n",
      " [-0.99767834 -0.28274199]]\n",
      "cost:\n",
      "0.104968\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398   -0.17453289]\n",
      " [-0.17453289 -0.43633222]\n",
      " [-0.69813156 -0.17453289]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [ 1.22173022  0.34906578]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [ 1.04719733  0.17453289]\n",
      " [-0.95993089 -0.08726644]\n",
      " [ 0.26179933 -0.34906578]\n",
      " [ 0.87266444  0.34906578]]\n",
      "prediction:\n",
      "[[-0.96297699 -0.13652171]\n",
      " [-0.22501163 -0.39981928]\n",
      " [-0.81426752 -0.13635945]\n",
      " [ 0.93695498 -0.05675394]\n",
      " [ 0.87877339  0.34306306]\n",
      " [ 0.95655769 -0.20982102]\n",
      " [ 0.94023031  0.20651594]\n",
      " [-0.99985737 -0.0469418 ]\n",
      " [ 0.26284292 -0.32126424]\n",
      " [ 0.76064855  0.35427144]]\n",
      "cost:\n",
      "0.140212\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933  0.34906578]\n",
      " [-0.61086511  0.17453289]\n",
      " [ 1.04719733 -0.17453289]\n",
      " [-0.785398   -0.43633222]\n",
      " [ 0.          0.        ]\n",
      " [ 0.61086511 -0.17453289]\n",
      " [-0.785398    0.08726644]\n",
      " [-0.26179933  0.34906578]\n",
      " [ 0.43633222  0.08726644]\n",
      " [ 0.87266444 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.29359522  0.3006987 ]\n",
      " [-0.78129268  0.1233787 ]\n",
      " [ 0.9992103  -0.23965545]\n",
      " [-0.98680115 -0.53198904]\n",
      " [ 0.04686762 -0.02816241]\n",
      " [ 0.59231186 -0.22954501]\n",
      " [-0.99783826  0.05924071]\n",
      " [-0.29359522  0.3006987 ]\n",
      " [ 0.39735454  0.042613  ]\n",
      " [ 0.98302609 -0.11596783]]\n",
      "cost:\n",
      "0.109788\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867 -0.26179933]\n",
      " [-0.08726644  0.        ]\n",
      " [-0.34906578 -0.43633222]\n",
      " [-0.87266444 -0.34906578]\n",
      " [ 0.785398    0.34906578]\n",
      " [ 0.61086511 -0.34906578]\n",
      " [-0.08726644  0.17453289]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [-0.43633222 -0.26179933]\n",
      " [ 1.13446378  0.26179933]]\n",
      "prediction:\n",
      "[[-0.57745111 -0.19402872]\n",
      " [-0.132507    0.03248734]\n",
      " [-0.29638457 -0.32210946]\n",
      " [-0.99992126 -0.24756564]\n",
      " [ 0.70158088  0.39375126]\n",
      " [ 0.5663681  -0.24947715]\n",
      " [-0.12526642  0.23136181]\n",
      " [ 0.98332924 -0.1185935 ]\n",
      " [-0.42434666 -0.20112242]\n",
      " [ 0.9917509   0.31010702]]\n",
      "cost:\n",
      "0.09764\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378  0.17453289]\n",
      " [ 1.22173022  0.08726644]\n",
      " [-0.43633222  0.08726644]\n",
      " [-0.34906578 -0.34906578]\n",
      " [-0.17453289 -0.08726644]\n",
      " [-0.95993089  0.17453289]\n",
      " [ 0.17453289  0.        ]\n",
      " [-0.785398   -0.17453289]\n",
      " [-0.34906578  0.08726644]\n",
      " [ 0.17453289  0.        ]]\n",
      "prediction:\n",
      "[[-0.97668654  0.1960624 ]\n",
      " [ 0.99997413  0.082457  ]\n",
      " [-0.39123729  0.11380563]\n",
      " [-0.28552619 -0.59104908]\n",
      " [-0.17209551 -0.1183658 ]\n",
      " [-0.94588012  0.19937715]\n",
      " [ 0.16072924  0.00146389]\n",
      " [-0.69446814 -0.27567577]\n",
      " [-0.31827581  0.09881668]\n",
      " [ 0.16072924  0.00146389]]\n",
      "cost:\n",
      "0.0939951\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222  0.        ]\n",
      " [ 0.52359867  0.17453289]\n",
      " [ 0.43633222  0.26179933]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [-0.34906578  0.08726644]\n",
      " [ 1.13446378  0.26179933]\n",
      " [ 0.08726644  0.08726644]\n",
      " [-0.08726644 -0.17453289]\n",
      " [ 0.         -0.34906578]\n",
      " [ 0.26179933  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.40890113 -0.05243743]\n",
      " [ 0.36359584  0.08581243]\n",
      " [ 0.35618898  0.18365352]\n",
      " [ 0.9562273  -0.34811363]\n",
      " [-0.99994779  0.01681286]\n",
      " [ 0.9944374   0.15871367]\n",
      " [-0.06505934  0.0602849 ]\n",
      " [-0.58718228 -0.22738051]\n",
      " [-0.16649649 -0.48771441]\n",
      " [ 0.02840392  0.28832808]]\n",
      "cost:\n",
      "0.261508\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733 -0.17453289]\n",
      " [-0.87266444  0.        ]\n",
      " [-1.13446378 -0.08726644]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [-0.26179933  0.17453289]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [-1.04719733  0.17453289]\n",
      " [-0.43633222 -0.08726644]\n",
      " [ 0.          0.08726644]]\n",
      "prediction:\n",
      "[[-0.93414241 -0.23908356]\n",
      " [-0.81728715  0.01736696]\n",
      " [-0.9479965  -0.12962228]\n",
      " [ 0.99995804 -0.40476987]\n",
      " [ 0.32233667 -0.1981865 ]\n",
      " [-0.27723429  0.34733135]\n",
      " [ 0.84118593 -0.19826941]\n",
      " [-0.92739701  0.36120659]\n",
      " [-0.44136488 -0.10805503]\n",
      " [-0.00750796  0.1323667 ]]\n",
      "cost:\n",
      "0.131571\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.22173022  0.08726644]\n",
      " [ 0.785398    0.34906578]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [ 1.04719733  0.        ]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [-1.04719733 -0.08726644]\n",
      " [ 0.69813156  0.26179933]\n",
      " [ 0.26179933 -0.08726644]\n",
      " [ 0.43633222  0.        ]\n",
      " [-0.34906578 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.9638775   0.01860109]\n",
      " [ 0.58118582  0.39865151]\n",
      " [ 0.05523391 -0.33368444]\n",
      " [ 0.93527955 -0.03779531]\n",
      " [ 0.34221926 -0.40130463]\n",
      " [-0.99997962 -0.10290693]\n",
      " [ 0.56013572  0.31204751]\n",
      " [ 0.20706239 -0.07228591]\n",
      " [ 0.39424339  0.01338426]\n",
      " [-0.38797146 -0.20794398]]\n",
      "cost:\n",
      "0.119089\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933  0.08726644]\n",
      " [-1.22173022 -0.17453289]\n",
      " [-0.95993089 -0.43633222]\n",
      " [ 0.17453289  0.        ]\n",
      " [ 0.95993089  0.34906578]\n",
      " [-0.69813156 -0.43633222]\n",
      " [-0.87266444  0.17453289]\n",
      " [ 0.34906578  0.17453289]\n",
      " [-0.34906578 -0.17453289]\n",
      " [ 0.61086511 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.26162517  0.0963571 ]\n",
      " [-0.98752469 -0.14492056]\n",
      " [-0.90889728 -0.33650753]\n",
      " [ 0.14219138  0.01496826]\n",
      " [ 0.9999547   0.3786009 ]\n",
      " [-0.62409896 -0.33120403]\n",
      " [-0.90100724  0.18220186]\n",
      " [ 0.31645578  0.1976025 ]\n",
      " [-0.34688389 -0.150564  ]\n",
      " [ 0.74499488 -0.32280564]]\n",
      "cost:\n",
      "0.0840334\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222 -0.08726644]\n",
      " [-0.61086511  0.34906578]\n",
      " [-0.17453289 -0.17453289]\n",
      " [-0.69813156  0.34906578]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [-0.785398    0.08726644]\n",
      " [ 0.43633222  0.08726644]\n",
      " [-1.13446378 -0.43633222]\n",
      " [-0.69813156 -0.26179933]\n",
      " [ 0.          0.34906578]]\n",
      "prediction:\n",
      "[[ 0.38294801 -0.0968577 ]\n",
      " [-0.56632614  0.26136166]\n",
      " [-0.21390633 -0.19097203]\n",
      " [-0.66711932  0.25369784]\n",
      " [ 0.99996567 -0.1914033 ]\n",
      " [-0.81163812  0.05658242]\n",
      " [ 0.34541702  0.05423934]\n",
      " [-0.99300635 -0.48502254]\n",
      " [-0.62584865 -0.2847673 ]\n",
      " [-0.03155441  0.28041011]]\n",
      "cost:\n",
      "0.0862079\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644  0.26179933]\n",
      " [-0.95993089 -0.34906578]\n",
      " [-0.34906578 -0.43633222]\n",
      " [ 0.95993089  0.34906578]\n",
      " [ 1.13446378 -0.08726644]\n",
      " [-0.17453289  0.08726644]\n",
      " [-0.26179933 -0.17453289]\n",
      " [ 0.52359867  0.08726644]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [ 0.785398   -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.14087114  0.30816537]\n",
      " [-0.99997723 -0.33818993]\n",
      " [-0.34895432 -0.41346031]\n",
      " [ 0.89538831  0.38360572]\n",
      " [ 0.93564546 -0.09496498]\n",
      " [-0.17211421  0.1027477 ]\n",
      " [-0.24410664 -0.16850121]\n",
      " [ 0.50731766  0.0963374 ]\n",
      " [ 0.92555887 -0.17171027]\n",
      " [ 0.70677191 -0.08464372]]\n",
      "cost:\n",
      "0.0835269\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733 -0.43633222]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [-0.34906578  0.17453289]\n",
      " [ 0.785398   -0.08726644]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [ 0.87266444  0.        ]\n",
      " [-0.34906578  0.34906578]\n",
      " [-0.61086511  0.34906578]\n",
      " [ 0.         -0.08726644]\n",
      " [-0.52359867  0.        ]]\n",
      "prediction:\n",
      "[[ 0.9702695  -0.45334518]\n",
      " [ 0.97323674 -0.1811831 ]\n",
      " [-0.37816739  0.16194592]\n",
      " [ 0.7750231  -0.08455785]\n",
      " [ 0.6334253  -0.37046757]\n",
      " [ 0.89270848  0.00164035]\n",
      " [-0.44156852  0.32163024]\n",
      " [-0.99992597  0.32709724]\n",
      " [-0.03035825 -0.088437  ]\n",
      " [-0.91975945 -0.00625148]]\n",
      "cost:\n",
      "0.113711\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511  0.17453289]\n",
      " [-0.17453289  0.26179933]\n",
      " [-0.08726644 -0.34906578]\n",
      " [ 0.785398   -0.08726644]\n",
      " [-0.61086511  0.17453289]\n",
      " [ 0.43633222  0.        ]\n",
      " [-0.26179933 -0.43633222]\n",
      " [-1.13446378 -0.08726644]\n",
      " [ 0.61086511  0.26179933]\n",
      " [-0.43633222 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.57250834  0.15897298]\n",
      " [-0.13621122  0.26690298]\n",
      " [-0.04570724 -0.36864576]\n",
      " [ 0.99975449 -0.10018568]\n",
      " [-0.57250834  0.15897298]\n",
      " [ 0.46371207 -0.01709119]\n",
      " [-0.22130358 -0.46910882]\n",
      " [-0.99961609 -0.10321602]\n",
      " [ 0.84988177  0.2629106 ]\n",
      " [-0.39532694 -0.19873476]]\n",
      "cost:\n",
      "0.0888928\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089  0.17453289]\n",
      " [ 1.22173022  0.26179933]\n",
      " [ 1.13446378 -0.34906578]\n",
      " [ 0.785398    0.17453289]\n",
      " [-0.87266444  0.08726644]\n",
      " [-0.785398   -0.43633222]\n",
      " [-1.04719733 -0.26179933]\n",
      " [-1.22173022 -0.17453289]\n",
      " [ 0.95993089 -0.26179933]\n",
      " [ 0.785398    0.17453289]]\n",
      "prediction:\n",
      "[[-0.97452325  0.17937571]\n",
      " [ 0.99254543  0.27707106]\n",
      " [ 0.98869014 -0.30425119]\n",
      " [ 0.79974639  0.20810258]\n",
      " [-0.87493801  0.0961145 ]\n",
      " [-0.77037448 -0.39915374]\n",
      " [-0.97933424 -0.25169209]\n",
      " [-0.9930138  -0.18291236]\n",
      " [ 0.95893031 -0.23925734]\n",
      " [ 0.79974639  0.20810258]]\n",
      "cost:\n",
      "0.083987\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398    0.        ]\n",
      " [-0.69813156  0.08726644]\n",
      " [ 0.34906578  0.08726644]\n",
      " [-1.13446378  0.17453289]\n",
      " [-0.61086511  0.        ]\n",
      " [-1.22173022  0.08726644]\n",
      " [-0.08726644 -0.43633222]\n",
      " [-0.785398   -0.43633222]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [-0.785398    0.08726644]]\n",
      "prediction:\n",
      "[[ 0.99997973 -0.00239299]\n",
      " [-0.56717551  0.11483154]\n",
      " [ 0.38338012  0.13904703]\n",
      " [-0.94638848  0.25117093]\n",
      " [-0.49674416  0.00662509]\n",
      " [-0.93379182  0.13294941]\n",
      " [-0.12130306 -0.47221628]\n",
      " [-0.6694054  -0.47184718]\n",
      " [ 0.15458906 -0.16841397]\n",
      " [-0.6792562   0.11473768]]\n",
      "cost:\n",
      "0.132075\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.08726644]\n",
      " [-1.13446378  0.17453289]\n",
      " [-0.26179933  0.34906578]\n",
      " [-0.785398    0.17453289]\n",
      " [ 0.08726644  0.17453289]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [-0.17453289  0.26179933]\n",
      " [ 0.785398    0.17453289]\n",
      " [-0.17453289 -0.08726644]\n",
      " [-0.43633222  0.08726644]]\n",
      "prediction:\n",
      "[[-0.9754771  -0.41572353]\n",
      " [-0.99104732 -0.02345419]\n",
      " [-0.29369476  0.31134179]\n",
      " [-0.82394934  0.05470465]\n",
      " [ 0.09321924  0.0895405 ]\n",
      " [ 0.99986368 -0.48416364]\n",
      " [-0.18815537  0.19453575]\n",
      " [ 0.97332412  0.0719994 ]\n",
      " [-0.13189639 -0.21013945]\n",
      " [-0.45114669 -0.01749181]]\n",
      "cost:\n",
      "0.170063\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289  0.26179933]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [ 0.785398    0.34906578]\n",
      " [ 0.26179933  0.08726644]\n",
      " [ 1.04719733  0.        ]\n",
      " [ 0.785398    0.17453289]\n",
      " [-0.43633222  0.08726644]\n",
      " [ 0.61086511  0.08726644]\n",
      " [-0.17453289  0.17453289]\n",
      " [-0.26179933  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.19951545  0.15104012]\n",
      " [-0.13870424 -0.62943852]\n",
      " [ 0.84253883  0.22657926]\n",
      " [ 0.20729879 -0.03872513]\n",
      " [ 0.97563297 -0.22433075]\n",
      " [ 0.92016244  0.04496956]\n",
      " [-0.99997282 -0.06381357]\n",
      " [ 0.70454407 -0.03637861]\n",
      " [-0.25599292  0.05030884]\n",
      " [-0.39969662  0.13352711]]\n",
      "cost:\n",
      "0.231547\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933  0.34906578]\n",
      " [-0.52359867 -0.17453289]\n",
      " [ 0.69813156  0.        ]\n",
      " [ 0.87266444 -0.34906578]\n",
      " [-0.26179933 -0.26179933]\n",
      " [-0.785398   -0.26179933]\n",
      " [-1.04719733 -0.34906578]\n",
      " [-0.34906578 -0.26179933]\n",
      " [ 0.61086511 -0.17453289]\n",
      " [-1.04719733 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.24374892  0.59076357]\n",
      " [-0.50379324 -0.09080078]\n",
      " [ 0.94914567  0.09464127]\n",
      " [ 0.99984962 -0.22983015]\n",
      " [-0.22635566 -0.16529381]\n",
      " [-0.79338413 -0.14539993]\n",
      " [-0.98840886 -0.19490415]\n",
      " [-0.28074062 -0.16052261]\n",
      " [ 0.68598819 -0.11086537]\n",
      " [-0.98840886 -0.19490415]]\n",
      "cost:\n",
      "0.154112\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733  0.08726644]\n",
      " [-0.52359867 -0.43633222]\n",
      " [ 0.95993089  0.        ]\n",
      " [-0.17453289 -0.26179933]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [ 0.26179933  0.        ]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [ 0.34906578  0.34906578]\n",
      " [-0.87266444  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.84191048  0.12869357]\n",
      " [-0.60670084 -0.465069  ]\n",
      " [ 0.86678541  0.00923807]\n",
      " [-0.08022647 -0.25622234]\n",
      " [ 0.89019358 -0.07637159]\n",
      " [ 0.27540356 -0.00421924]\n",
      " [ 0.86850256 -0.28093863]\n",
      " [ 0.4412668  -0.17390244]\n",
      " [ 0.3980352   0.408539  ]\n",
      " [-0.99998087  0.23026165]]\n",
      "cost:\n",
      "0.123179\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578  0.08726644]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [-0.08726644 -0.26179933]\n",
      " [ 1.22173022  0.26179933]\n",
      " [ 1.13446378  0.26179933]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [ 0.08726644  0.17453289]\n",
      " [-0.43633222  0.34906578]\n",
      " [ 0.43633222  0.26179933]\n",
      " [-0.785398   -0.43633222]]\n",
      "prediction:\n",
      "[[-0.25051981  0.03656821]\n",
      " [ 0.94791543 -0.11690934]\n",
      " [-0.03820811 -0.29083717]\n",
      " [ 0.94203067  0.12775844]\n",
      " [ 0.9538005   0.14655195]\n",
      " [ 0.27753535 -0.31131211]\n",
      " [ 0.13978951  0.11590318]\n",
      " [-0.49313644  0.23455164]\n",
      " [ 0.43205813  0.18144132]\n",
      " [-0.99996972 -0.54095459]]\n",
      "cost:\n",
      "0.137358\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511  0.17453289]\n",
      " [-0.08726644 -0.43633222]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [-0.08726644 -0.26179933]\n",
      " [-0.26179933  0.34906578]\n",
      " [ 0.08726644  0.08726644]\n",
      " [ 0.95993089  0.        ]\n",
      " [-1.13446378  0.17453289]\n",
      " [ 0.26179933  0.08726644]\n",
      " [ 0.17453289  0.        ]]\n",
      "prediction:\n",
      "[[-0.65890282  0.14573881]\n",
      " [-0.12696782 -0.49445114]\n",
      " [ 0.54899496 -0.38551763]\n",
      " [-0.08552479 -0.2787337 ]\n",
      " [-0.27294868  0.33823094]\n",
      " [ 0.09947084  0.08709373]\n",
      " [ 0.99975926 -0.01439958]\n",
      " [-0.99973053  0.14326476]\n",
      " [ 0.241135    0.06976187]\n",
      " [ 0.18673874 -0.01291485]]\n",
      "cost:\n",
      "0.0441111\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.785398    0.34906578]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [-1.04719733 -0.08726644]\n",
      " [ 0.         -0.43633222]\n",
      " [ 0.69813156  0.34906578]\n",
      " [-0.17453289  0.        ]\n",
      " [-1.04719733  0.34906578]\n",
      " [-1.22173022  0.26179933]\n",
      " [-0.785398   -0.17453289]\n",
      " [-0.785398   -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.99976319  0.23221239]\n",
      " [ 0.55722988 -0.19947979]\n",
      " [-0.95904726 -0.11975896]\n",
      " [-0.07552339 -0.53105587]\n",
      " [ 0.99200261  0.23357691]\n",
      " [-0.17352742 -0.00230203]\n",
      " [-0.94375128  0.24816594]\n",
      " [-0.96759695  0.1733104 ]\n",
      " [-0.7667616  -0.22421344]\n",
      " [-0.7667616  -0.22421344]]\n",
      "cost:\n",
      "0.142067\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.22173022 -0.08726644]\n",
      " [-0.43633222 -0.26179933]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [-1.04719733 -0.34906578]\n",
      " [ 0.          0.17453289]\n",
      " [-1.22173022  0.34906578]\n",
      " [-0.69813156  0.17453289]\n",
      " [-0.785398    0.08726644]\n",
      " [-0.43633222 -0.17453289]\n",
      " [ 1.22173022 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.99931031 -0.02107788]\n",
      " [-0.41147161 -0.26587671]\n",
      " [ 0.73709846 -0.23824574]\n",
      " [-0.98998648 -0.33767769]\n",
      " [ 0.08962947  0.22054487]\n",
      " [-0.9869988   0.36324599]\n",
      " [-0.71255517  0.21991751]\n",
      " [-0.84052742  0.13374329]\n",
      " [-0.4148342  -0.18519875]\n",
      " [ 0.99475616 -0.37463284]]\n",
      "cost:\n",
      "0.107596\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933 -0.08726644]\n",
      " [ 0.61086511 -0.08726644]\n",
      " [ 0.61086511  0.17453289]\n",
      " [ 0.         -0.17453289]\n",
      " [-0.43633222 -0.34906578]\n",
      " [ 0.         -0.26179933]\n",
      " [ 1.22173022 -0.34906578]\n",
      " [ 0.785398   -0.34906578]\n",
      " [-0.95993089 -0.34906578]\n",
      " [ 0.87266444  0.08726644]]\n",
      "prediction:\n",
      "[[-0.2600897  -0.01326152]\n",
      " [ 0.58818746 -0.0101261 ]\n",
      " [ 0.56417036  0.50068343]\n",
      " [ 0.05100874 -0.10605139]\n",
      " [-0.44245976 -0.25977445]\n",
      " [ 0.0357039  -0.21002319]\n",
      " [ 0.97814435 -0.20161285]\n",
      " [ 0.76416326 -0.2597675 ]\n",
      " [-0.99997592 -0.27752411]\n",
      " [ 0.9171688   0.30092424]]\n",
      "cost:\n",
      "0.139845\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289  0.34906578]\n",
      " [-0.95993089  0.        ]\n",
      " [-0.785398   -0.17453289]\n",
      " [-0.87266444 -0.26179933]\n",
      " [-1.04719733 -0.08726644]\n",
      " [-0.43633222 -0.26179933]\n",
      " [ 0.52359867 -0.08726644]\n",
      " [-1.13446378  0.26179933]\n",
      " [ 0.95993089  0.08726644]\n",
      " [-0.69813156  0.        ]]\n",
      "prediction:\n",
      "[[-0.170008    0.38726369]\n",
      " [-0.82146281 -0.00227923]\n",
      " [-0.62131172 -0.22463372]\n",
      " [-0.72715575 -0.42339227]\n",
      " [-0.85009325 -0.10612661]\n",
      " [-0.3088662  -0.39696601]\n",
      " [ 0.52978051 -0.1063344 ]\n",
      " [-0.89177603  0.30426285]\n",
      " [ 0.99998426  0.06866266]\n",
      " [-0.58293676 -0.01316617]]\n",
      "cost:\n",
      "0.137629\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089 -0.17453289]\n",
      " [ 0.69813156  0.34906578]\n",
      " [ 0.69813156  0.34906578]\n",
      " [-0.61086511  0.17453289]\n",
      " [-0.43633222  0.26179933]\n",
      " [-0.52359867 -0.08726644]\n",
      " [-0.785398    0.        ]\n",
      " [-1.04719733  0.        ]\n",
      " [-1.22173022 -0.26179933]\n",
      " [-1.22173022  0.        ]]\n",
      "prediction:\n",
      "[[ 0.99996322 -0.31321648]\n",
      " [ 0.7734344   0.23642713]\n",
      " [ 0.7734344   0.23642713]\n",
      " [-0.61464441  0.09969266]\n",
      " [-0.41432062  0.18491191]\n",
      " [-0.50912058 -0.13165486]\n",
      " [-0.75640571 -0.04283633]\n",
      " [-0.93952352 -0.05348565]\n",
      " [-0.91116852 -0.57614309]\n",
      " [-0.94034499 -0.12423223]]\n",
      "cost:\n",
      "0.153835\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222  0.26179933]\n",
      " [-0.26179933 -0.17453289]\n",
      " [ 0.87266444  0.34906578]\n",
      " [-0.69813156 -0.43633222]\n",
      " [-0.43633222 -0.26179933]\n",
      " [-0.785398    0.        ]\n",
      " [-0.61086511 -0.26179933]\n",
      " [ 0.61086511  0.26179933]\n",
      " [ 0.34906578  0.08726644]\n",
      " [-0.17453289 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.42973492  0.25976834]\n",
      " [-0.26688778 -0.15839274]\n",
      " [ 0.99991852  0.31457001]\n",
      " [-0.94468284 -0.45738953]\n",
      " [-0.44950965 -0.26189733]\n",
      " [-0.99733591 -0.00775143]\n",
      " [-0.75281835 -0.25960717]\n",
      " [ 0.77352905  0.24688245]\n",
      " [ 0.26040861  0.08622012]\n",
      " [-0.17270839 -0.26382536]]\n",
      "cost:\n",
      "0.102509\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.95993089  0.        ]\n",
      " [-0.26179933 -0.08726644]\n",
      " [ 0.         -0.43633222]\n",
      " [-0.61086511 -0.08726644]\n",
      " [ 0.          0.        ]\n",
      " [-0.43633222 -0.34906578]\n",
      " [-0.785398    0.        ]\n",
      " [ 0.87266444  0.        ]\n",
      " [ 0.26179933  0.34906578]\n",
      " [ 0.87266444  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.99353564 -0.02063405]\n",
      " [-0.20827308 -0.09387229]\n",
      " [ 0.00561415 -0.50835335]\n",
      " [-0.81331706 -0.09109841]\n",
      " [-0.0451394  -0.00934377]\n",
      " [-0.4523246  -0.40041733]\n",
      " [-0.99992234  0.00185878]\n",
      " [ 0.94942886 -0.01929468]\n",
      " [ 0.26387176  0.34735021]\n",
      " [ 0.95081103  0.27641016]]\n",
      "cost:\n",
      "0.084385\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733  0.        ]\n",
      " [-0.69813156 -0.34906578]\n",
      " [-1.13446378 -0.08726644]\n",
      " [ 0.08726644  0.34906578]\n",
      " [ 1.04719733  0.        ]\n",
      " [-0.61086511 -0.26179933]\n",
      " [-0.95993089  0.34906578]\n",
      " [ 0.61086511  0.26179933]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [ 0.43633222  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.99607271 -0.03254705]\n",
      " [-0.81400836 -0.54934776]\n",
      " [-0.99730116 -0.13854662]\n",
      " [ 0.02545477  0.27859509]\n",
      " [ 0.99607271 -0.03254705]\n",
      " [-0.66136611 -0.37862396]\n",
      " [-0.99472761  0.26090547]\n",
      " [ 0.56964004  0.17673993]\n",
      " [ 0.65996259 -0.10795581]\n",
      " [ 0.36605075  0.03785058]]\n",
      "cost:\n",
      "0.103868\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.43633222 -0.43633222]\n",
      " [ 0.95993089  0.        ]\n",
      " [ 0.52359867  0.26179933]\n",
      " [-0.43633222 -0.43633222]\n",
      " [-0.26179933 -0.08726644]\n",
      " [-1.13446378  0.26179933]\n",
      " [ 0.87266444  0.34906578]\n",
      " [ 0.95993089 -0.43633222]\n",
      " [-0.95993089 -0.08726644]\n",
      " [-0.34906578 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.40831694 -0.36993888]\n",
      " [ 0.99422294  0.01075821]\n",
      " [ 0.5787586   0.26908988]\n",
      " [-0.40841439 -0.36996973]\n",
      " [-0.15843944 -0.06606384]\n",
      " [-0.99900419  0.27796322]\n",
      " [ 0.96009135  0.32619625]\n",
      " [ 0.98450685 -0.36662701]\n",
      " [-0.99437672 -0.06849968]\n",
      " [-0.25877926 -0.13981304]]\n",
      "cost:\n",
      "0.0777808\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.22173022  0.26179933]\n",
      " [-0.87266444  0.17453289]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [ 0.17453289 -0.43633222]\n",
      " [ 0.34906578 -0.08726644]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [ 0.52359867 -0.43633222]\n",
      " [-0.43633222 -0.34906578]\n",
      " [-1.22173022  0.        ]\n",
      " [-1.13446378  0.26179933]]\n",
      "prediction:\n",
      "[[-0.95695782  0.3030138 ]\n",
      " [-0.83682215  0.20072725]\n",
      " [ 0.99993712 -0.14743637]\n",
      " [ 0.16618001 -0.40251687]\n",
      " [ 0.39103612 -0.06469394]\n",
      " [ 0.82323992 -0.05766198]\n",
      " [ 0.55492616 -0.38500234]\n",
      " [-0.46879053 -0.32240155]\n",
      " [-0.96980119  0.03496245]\n",
      " [-0.95588976  0.30373648]]\n",
      "cost:\n",
      "0.111164\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289 -0.34906578]\n",
      " [-0.34906578 -0.34906578]\n",
      " [-0.17453289  0.17453289]\n",
      " [ 0.52359867 -0.08726644]\n",
      " [ 0.785398    0.08726644]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [-1.04719733  0.26179933]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [-0.08726644  0.08726644]\n",
      " [ 0.61086511 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.2090427  -0.40576974]\n",
      " [-0.30990615 -0.43848789]\n",
      " [-0.20990878  0.22354761]\n",
      " [ 0.3716535  -0.06886873]\n",
      " [ 0.89021128  0.13518412]\n",
      " [ 0.37202263 -0.17786257]\n",
      " [-0.99996585  0.35137844]\n",
      " [ 0.99493927 -0.06538288]\n",
      " [-0.09478776  0.097574  ]\n",
      " [ 0.54087311 -0.17512095]]\n",
      "cost:\n",
      "0.0782454\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578  0.34906578]\n",
      " [ 0.87266444  0.17453289]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [-1.04719733  0.26179933]\n",
      " [-1.22173022 -0.17453289]\n",
      " [ 0.52359867  0.17453289]\n",
      " [-0.87266444  0.08726644]\n",
      " [-0.785398    0.34906578]\n",
      " [ 0.26179933  0.26179933]\n",
      " [ 0.785398    0.34906578]]\n",
      "prediction:\n",
      "[[ 0.34946233  0.15288028]\n",
      " [ 0.99966896 -0.02731103]\n",
      " [ 0.17676586 -0.33206883]\n",
      " [-0.98927659  0.06891116]\n",
      " [-0.99176955 -0.61257231]\n",
      " [ 0.60279572  0.01164372]\n",
      " [-0.92669201 -0.06690467]\n",
      " [-0.77313989  0.14559832]\n",
      " [ 0.29737124  0.1036609 ]\n",
      " [ 0.96617109  0.11607626]]\n",
      "cost:\n",
      "0.231728\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398    0.08726644]\n",
      " [-0.43633222  0.        ]\n",
      " [-0.785398   -0.26179933]\n",
      " [-1.04719733  0.17453289]\n",
      " [ 1.13446378  0.17453289]\n",
      " [-0.785398   -0.08726644]\n",
      " [-1.04719733 -0.08726644]\n",
      " [ 0.69813156  0.        ]\n",
      " [ 0.61086511  0.17453289]\n",
      " [ 0.87266444 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.78531843  0.10061135]\n",
      " [-0.46599716 -0.00665585]\n",
      " [-0.79181063 -0.45498708]\n",
      " [-0.98312861  0.19729701]\n",
      " [ 0.99960864  0.1978054 ]\n",
      " [-0.79169714 -0.11770559]\n",
      " [-0.98775321 -0.14313713]\n",
      " [ 0.78671277 -0.00466393]\n",
      " [ 0.60839713  0.23383802]\n",
      " [ 0.98612136 -0.47236568]]\n",
      "cost:\n",
      "0.0941794\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378  0.26179933]\n",
      " [-0.26179933 -0.08726644]\n",
      " [-0.26179933  0.        ]\n",
      " [-1.22173022  0.34906578]\n",
      " [-0.69813156 -0.08726644]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [-0.69813156 -0.26179933]\n",
      " [ 0.08726644  0.        ]\n",
      " [-0.87266444  0.08726644]\n",
      " [-0.61086511  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.99998176  0.23076764]\n",
      " [-0.24354064 -0.10552994]\n",
      " [-0.25586677 -0.01089206]\n",
      " [-0.95893782  0.31181884]\n",
      " [-0.64719677 -0.11955931]\n",
      " [ 0.26010361 -0.44274262]\n",
      " [-0.61642408 -0.45931897]\n",
      " [ 0.05095728  0.00203287]\n",
      " [-0.93195564  0.07083517]\n",
      " [-0.56308293  0.08372978]]\n",
      "cost:\n",
      "0.104248\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289 -0.17453289]\n",
      " [-0.87266444  0.34906578]\n",
      " [-0.52359867  0.08726644]\n",
      " [-0.08726644 -0.17453289]\n",
      " [ 0.61086511  0.08726644]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [ 0.          0.34906578]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [ 0.08726644  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.17920117 -0.19370548]\n",
      " [-0.99990165  0.24963519]\n",
      " [-0.81993377  0.02830668]\n",
      " [-0.10651814 -0.21317561]\n",
      " [ 0.99857014  0.05637119]\n",
      " [ 0.42828581 -0.33053035]\n",
      " [ 0.17512506 -0.09900932]\n",
      " [-0.04167614  0.28367236]\n",
      " [ 0.92146009 -0.47341403]\n",
      " [ 0.1116012   0.19476435]]\n",
      "cost:\n",
      "0.15978\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.43633222 -0.43633222]\n",
      " [ 1.04719733 -0.08726644]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [-0.08726644  0.34906578]\n",
      " [ 0.785398   -0.26179933]\n",
      " [-0.34906578 -0.34906578]\n",
      " [ 0.08726644  0.17453289]\n",
      " [-1.04719733 -0.17453289]\n",
      " [ 0.61086511 -0.26179933]\n",
      " [-0.52359867  0.17453289]]\n",
      "prediction:\n",
      "[[-0.42082438 -0.37504175]\n",
      " [ 0.99359423 -0.0495604 ]\n",
      " [ 0.94738573 -0.13133015]\n",
      " [-0.09534957  0.41769943]\n",
      " [ 0.84623015 -0.20794779]\n",
      " [-0.32004255 -0.31060439]\n",
      " [ 0.09562132  0.20786071]\n",
      " [-0.99994373 -0.07875206]\n",
      " [ 0.57671821 -0.21947399]\n",
      " [-0.57083476  0.21829119]]\n",
      "cost:\n",
      "0.067354\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156  0.17453289]\n",
      " [ 0.95993089 -0.43633222]\n",
      " [-0.52359867  0.17453289]\n",
      " [-0.69813156 -0.26179933]\n",
      " [-1.13446378  0.17453289]\n",
      " [-0.43633222  0.        ]\n",
      " [-0.95993089  0.34906578]\n",
      " [-0.69813156  0.08726644]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [ 0.95993089  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.79132354  0.06315671]\n",
      " [ 0.99676734 -0.50584614]\n",
      " [-0.57350367  0.11005834]\n",
      " [-0.72711611 -0.30401611]\n",
      " [-0.99652106  0.06090918]\n",
      " [-0.48245645 -0.03833505]\n",
      " [-0.97241974  0.24885885]\n",
      " [-0.72964931  0.02249258]\n",
      " [ 0.35654163 -0.33684182]\n",
      " [ 0.99855876  0.2400665 ]]\n",
      "cost:\n",
      "0.0959395\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.87266444 -0.43633222]\n",
      " [-0.87266444  0.08726644]\n",
      " [-0.08726644  0.08726644]\n",
      " [-1.22173022 -0.34906578]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [-0.95993089 -0.08726644]\n",
      " [ 0.69813156  0.17453289]\n",
      " [ 0.52359867  0.17453289]\n",
      " [-0.17453289  0.17453289]\n",
      " [-1.22173022  0.08726644]]\n",
      "prediction:\n",
      "[[-0.87293243 -0.48388442]\n",
      " [-0.86809963  0.06961084]\n",
      " [-0.12725918  0.07377727]\n",
      " [-0.95142514 -0.41319555]\n",
      " [ 0.99839866 -0.20658164]\n",
      " [-0.93364638 -0.1223373 ]\n",
      " [ 0.99879122  0.19982038]\n",
      " [ 0.83339089  0.19753991]\n",
      " [-0.20104176  0.20058101]\n",
      " [-0.96165431  0.07046218]]\n",
      "cost:\n",
      "0.164175\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289 -0.26179933]\n",
      " [ 0.08726644  0.17453289]\n",
      " [ 1.22173022  0.17453289]\n",
      " [ 0.34906578  0.08726644]\n",
      " [ 0.52359867  0.34906578]\n",
      " [-0.785398   -0.08726644]\n",
      " [-0.95993089 -0.43633222]\n",
      " [-0.785398    0.08726644]\n",
      " [ 0.43633222 -0.34906578]\n",
      " [ 0.43633222  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.08099157 -0.2767517 ]\n",
      " [-0.0457526   0.15785311]\n",
      " [ 0.99987131  0.13375421]\n",
      " [ 0.32678849  0.06570485]\n",
      " [ 0.52342188  0.35057658]\n",
      " [-0.90501803 -0.08739806]\n",
      " [-0.99861896 -0.453087  ]\n",
      " [-0.91146743  0.08134957]\n",
      " [ 0.43014869 -0.35980293]\n",
      " [ 0.39938179  0.06344727]]\n",
      "cost:\n",
      "0.083123\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867  0.17453289]\n",
      " [ 0.95993089 -0.34906578]\n",
      " [-0.26179933 -0.08726644]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [-1.13446378  0.34906578]\n",
      " [ 0.43633222  0.26179933]\n",
      " [ 0.87266444  0.17453289]\n",
      " [ 1.13446378 -0.08726644]\n",
      " [-0.87266444 -0.17453289]\n",
      " [ 0.26179933 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.54751623  0.17774284]\n",
      " [ 0.95108289 -0.35898641]\n",
      " [-0.23933341 -0.09460249]\n",
      " [ 0.66771448 -0.18133068]\n",
      " [-0.99985194  0.31775981]\n",
      " [ 0.45908439  0.27584067]\n",
      " [ 0.90977103  0.18298963]\n",
      " [ 0.97517794 -0.07419086]\n",
      " [-0.99165666 -0.18829124]\n",
      " [ 0.24564399 -0.38039231]]\n",
      "cost:\n",
      "0.0610078\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.26179933  0.17453289]\n",
      " [ 0.26179933  0.34906578]\n",
      " [-0.43633222  0.        ]\n",
      " [ 0.61086511  0.08726644]\n",
      " [-0.69813156  0.        ]\n",
      " [ 0.34906578  0.08726644]\n",
      " [-0.08726644 -0.26179933]\n",
      " [ 0.785398   -0.17453289]\n",
      " [ 1.13446378  0.34906578]\n",
      " [-0.17453289  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.20426655  0.09925767]\n",
      " [ 0.17318666  0.2588535 ]\n",
      " [-0.66375279 -0.0830982 ]\n",
      " [ 0.5461024  -0.00484037]\n",
      " [-0.99993443 -0.14718449]\n",
      " [ 0.32099587  0.01190185]\n",
      " [-0.04831975 -0.43749338]\n",
      " [ 0.84596956 -0.42247507]\n",
      " [ 0.99840206  0.18771936]\n",
      " [-0.14450185  0.25677365]]\n",
      "cost:\n",
      "0.173543\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.34906578  0.34906578]\n",
      " [-0.08726644  0.26179933]\n",
      " [-0.26179933 -0.17453289]\n",
      " [-0.52359867 -0.43633222]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [-1.04719733 -0.26179933]\n",
      " [ 0.43633222  0.34906578]\n",
      " [-0.61086511  0.26179933]\n",
      " [-0.43633222 -0.34906578]\n",
      " [ 0.17453289 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.96090311  0.29533738]\n",
      " [ 0.27578911  0.22943272]\n",
      " [-0.15354148 -0.16620205]\n",
      " [-0.53380626 -0.37176245]\n",
      " [ 0.35378945 -0.25999263]\n",
      " [-0.99988735 -0.19989158]\n",
      " [ 0.99849546  0.29087934]\n",
      " [-0.60461116  0.23646289]\n",
      " [-0.35706097 -0.3044399 ]\n",
      " [ 0.44680953 -0.07613506]]\n",
      "cost:\n",
      "0.245182\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.26179933  0.        ]\n",
      " [-0.17453289  0.08726644]\n",
      " [-0.785398   -0.34906578]\n",
      " [-0.87266444 -0.08726644]\n",
      " [-1.13446378 -0.43633222]\n",
      " [-0.69813156  0.        ]\n",
      " [-0.17453289  0.08726644]\n",
      " [ 0.52359867 -0.43633222]\n",
      " [-0.26179933 -0.43633222]\n",
      " [ 0.         -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.37653223  0.04196613]\n",
      " [-0.16561791  0.35119587]\n",
      " [-0.77807951 -0.2253145 ]\n",
      " [-0.8643471   0.06196085]\n",
      " [-0.98644203 -0.25291839]\n",
      " [-0.63549328  0.18941762]\n",
      " [-0.16562098  0.35120228]\n",
      " [ 0.99997652 -0.33101004]\n",
      " [-0.1714441  -0.33026689]\n",
      " [ 0.00335427 -0.21849933]]\n",
      "cost:\n",
      "0.20296\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222  0.34906578]\n",
      " [-0.52359867  0.17453289]\n",
      " [-0.61086511  0.        ]\n",
      " [ 0.34906578 -0.08726644]\n",
      " [ 0.61086511  0.        ]\n",
      " [ 0.          0.34906578]\n",
      " [ 0.17453289 -0.26179933]\n",
      " [ 1.22173022 -0.34906578]\n",
      " [ 0.87266444  0.17453289]\n",
      " [-0.61086511  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.47472948  0.22752261]\n",
      " [-0.96027189  0.07408497]\n",
      " [-0.99154758 -0.07046693]\n",
      " [ 0.28780761 -0.13057116]\n",
      " [ 0.56241345 -0.06786084]\n",
      " [-0.26297954  0.25009263]\n",
      " [ 0.0398485  -0.34369051]\n",
      " [ 0.99909878 -0.53634083]\n",
      " [ 0.98767948  0.06051846]\n",
      " [-0.99458241  0.22276276]]\n",
      "cost:\n",
      "0.241655\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289 -0.26179933]\n",
      " [ 0.785398   -0.26179933]\n",
      " [-0.87266444  0.17453289]\n",
      " [-0.08726644  0.08726644]\n",
      " [ 1.13446378  0.34906578]\n",
      " [ 0.785398    0.        ]\n",
      " [ 0.785398   -0.08726644]\n",
      " [ 1.04719733  0.17453289]\n",
      " [-0.34906578 -0.34906578]\n",
      " [-1.13446378 -0.34906578]]\n",
      "prediction:\n",
      "[[  2.17459545e-01  -2.63784111e-01]\n",
      " [  7.86110878e-01  -2.64938295e-01]\n",
      " [ -9.91312146e-01   2.02711493e-01]\n",
      " [ -4.55630384e-02   1.19365871e-01]\n",
      " [  9.79034245e-01   3.96760285e-01]\n",
      " [  7.71565259e-01   7.89150421e-04]\n",
      " [  7.57123947e-01  -8.38094652e-02]\n",
      " [  9.71204519e-01   2.03513086e-01]\n",
      " [ -2.82286406e-01  -3.59751731e-01]\n",
      " [ -9.99813497e-01  -3.66723865e-01]]\n",
      "cost:\n",
      "0.0710452\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.34906578]\n",
      " [ 0.08726644  0.34906578]\n",
      " [ 1.13446378  0.26179933]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [-0.69813156 -0.43633222]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [-0.52359867 -0.08726644]\n",
      " [ 0.26179933  0.26179933]\n",
      " [-1.04719733  0.17453289]\n",
      " [-0.52359867 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.99322057 -0.34337279]\n",
      " [ 0.12576941  0.3235406 ]\n",
      " [ 0.9991684   0.24958734]\n",
      " [ 0.29909313 -0.25874284]\n",
      " [-0.68846321 -0.41229942]\n",
      " [ 0.99500585 -0.07510532]\n",
      " [-0.48448348 -0.07683905]\n",
      " [ 0.30547133  0.24324733]\n",
      " [-0.99360555  0.1717414 ]\n",
      " [-0.49098152 -0.24552549]]\n",
      "cost:\n",
      "0.0601892\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289  0.34906578]\n",
      " [ 1.22173022  0.17453289]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [-0.08726644 -0.26179933]\n",
      " [-0.26179933 -0.34906578]\n",
      " [-0.785398   -0.34906578]\n",
      " [-0.17453289 -0.34906578]\n",
      " [-1.13446378 -0.17453289]\n",
      " [ 0.69813156 -0.17453289]\n",
      " [ 0.69813156 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.28414255  0.52000958]\n",
      " [ 0.99949014  0.32618195]\n",
      " [ 0.11550124 -0.17117311]\n",
      " [-0.00500299 -0.17253153]\n",
      " [-0.24608542 -0.25846753]\n",
      " [-0.88857609 -0.23169366]\n",
      " [-0.13310543 -0.24433315]\n",
      " [-0.99978036 -0.0647665 ]\n",
      " [ 0.73762012 -0.08993611]\n",
      " [ 0.72139031 -0.16193777]]\n",
      "cost:\n",
      "0.141893\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511  0.34906578]\n",
      " [-0.17453289  0.08726644]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [ 0.08726644  0.26179933]\n",
      " [ 1.13446378 -0.08726644]\n",
      " [ 0.87266444  0.26179933]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [ 0.26179933 -0.34906578]\n",
      " [ 0.785398   -0.17453289]\n",
      " [-0.87266444 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.83853382  0.33317107]\n",
      " [-0.23313236  0.071111  ]\n",
      " [ 0.26700774 -0.26056153]\n",
      " [ 0.03128481  0.23857231]\n",
      " [ 0.99185789 -0.06393117]\n",
      " [ 0.90269929  0.28246334]\n",
      " [ 0.67390466 -0.34156907]\n",
      " [ 0.2800526  -0.35268015]\n",
      " [ 0.81316698 -0.16756986]\n",
      " [-0.99995434 -0.25442651]]\n",
      "cost:\n",
      "0.073603\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398    0.26179933]\n",
      " [ 1.04719733 -0.17453289]\n",
      " [ 0.17453289 -0.43633222]\n",
      " [ 0.08726644 -0.34906578]\n",
      " [ 0.26179933  0.17453289]\n",
      " [ 0.785398   -0.26179933]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [-0.785398    0.34906578]\n",
      " [-0.43633222  0.        ]\n",
      " [-0.17453289  0.17453289]]\n",
      "prediction:\n",
      "[[-0.99676567  0.22845535]\n",
      " [ 0.99974632 -0.15996432]\n",
      " [ 0.20680128 -0.45434192]\n",
      " [ 0.05298901 -0.37165383]\n",
      " [ 0.28482285  0.15082407]\n",
      " [ 0.9099282  -0.24855874]\n",
      " [ 0.22417599 -0.08802246]\n",
      " [-0.99445683  0.30897489]\n",
      " [-0.42675003 -0.01169591]\n",
      " [-0.18222009  0.14244841]]\n",
      "cost:\n",
      "0.0810533\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933  0.08726644]\n",
      " [ 0.26179933  0.34906578]\n",
      " [-1.22173022  0.26179933]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [-1.13446378 -0.26179933]\n",
      " [-0.08726644 -0.43633222]\n",
      " [-0.52359867  0.        ]\n",
      " [-1.22173022  0.17453289]\n",
      " [-0.52359867 -0.43633222]\n",
      " [-1.04719733 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.24220881  0.10497873]\n",
      " [ 0.98070115  0.32658345]\n",
      " [-0.89298248  0.24323317]\n",
      " [ 0.99993759 -0.22140571]\n",
      " [-0.93678349 -0.17385273]\n",
      " [-0.16538921 -0.38244256]\n",
      " [-0.52983648  0.02324435]\n",
      " [-0.87773764  0.18643542]\n",
      " [-0.64347655 -0.35818562]\n",
      " [-0.84885395 -0.27074805]]\n",
      "cost:\n",
      "0.267587\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.26179933 -0.08726644]\n",
      " [-0.87266444 -0.34906578]\n",
      " [ 0.17453289  0.26179933]\n",
      " [-0.87266444  0.08726644]\n",
      " [-0.34906578 -0.17453289]\n",
      " [-0.17453289  0.26179933]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [-0.34906578  0.26179933]\n",
      " [ 0.26179933  0.        ]\n",
      " [-1.04719733  0.        ]]\n",
      "prediction:\n",
      "[[ 0.33930424 -0.11108985]\n",
      " [-0.92600632 -0.43845934]\n",
      " [ 0.47298527  0.26114765]\n",
      " [-0.9175899   0.04444364]\n",
      " [-0.36788219 -0.20128599]\n",
      " [-0.05284981  0.25331956]\n",
      " [ 0.99995416 -0.42866224]\n",
      " [-0.23189878  0.24169585]\n",
      " [ 0.30861056 -0.02218131]\n",
      " [-0.99152184 -0.04709878]]\n",
      "cost:\n",
      "0.142695\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933 -0.34906578]\n",
      " [ 0.52359867 -0.34906578]\n",
      " [-0.26179933  0.17453289]\n",
      " [-1.22173022 -0.26179933]\n",
      " [-1.22173022  0.08726644]\n",
      " [ 0.34906578  0.26179933]\n",
      " [-0.26179933  0.17453289]\n",
      " [ 0.08726644  0.        ]\n",
      " [-0.08726644  0.08726644]\n",
      " [ 0.34906578  0.08726644]]\n",
      "prediction:\n",
      "[[-0.29031798 -0.43269408]\n",
      " [ 0.99789101 -0.4510493 ]\n",
      " [-0.25340581  0.16678624]\n",
      " [-0.99906588 -0.28103527]\n",
      " [-0.99435151  0.08238608]\n",
      " [ 0.77805507  0.23717555]\n",
      " [-0.25340581  0.16678624]\n",
      " [ 0.58085102 -0.03610702]\n",
      " [ 0.09961985  0.07594325]\n",
      " [ 0.97563958  0.0564056 ]]\n",
      "cost:\n",
      "0.278642\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.22173022 -0.26179933]\n",
      " [ 0.52359867  0.08726644]\n",
      " [-0.69813156  0.17453289]\n",
      " [ 0.95993089  0.26179933]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [-0.34906578 -0.08726644]\n",
      " [ 0.         -0.08726644]\n",
      " [-0.52359867 -0.34906578]\n",
      " [-0.26179933 -0.08726644]\n",
      " [-1.04719733 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.98792243 -0.26456746]\n",
      " [ 0.66417062  0.16577855]\n",
      " [-0.63886511  0.27429858]\n",
      " [ 0.99993819  0.44863388]\n",
      " [ 0.61002761 -0.29780611]\n",
      " [-0.32626241 -0.07564206]\n",
      " [ 0.03594732 -0.08922952]\n",
      " [-0.52361262 -0.38625696]\n",
      " [-0.26343021 -0.08537132]\n",
      " [-0.9827317  -0.17937934]]\n",
      "cost:\n",
      "0.0961512\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867  0.17453289]\n",
      " [-0.08726644 -0.17453289]\n",
      " [-0.43633222  0.        ]\n",
      " [ 0.26179933  0.        ]\n",
      " [-0.69813156 -0.08726644]\n",
      " [ 0.785398    0.17453289]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [-1.04719733  0.08726644]\n",
      " [ 0.95993089  0.08726644]\n",
      " [ 1.22173022  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.50259352  0.1841508 ]\n",
      " [-0.04193784 -0.36073458]\n",
      " [-0.39871106 -0.07382383]\n",
      " [ 0.26816577 -0.02528294]\n",
      " [-0.83832997 -0.20808783]\n",
      " [ 0.767717    0.1646131 ]\n",
      " [ 0.90113682 -0.52067816]\n",
      " [-0.99996126  0.0098016 ]\n",
      " [ 0.94660342  0.05537901]\n",
      " [ 0.95174837  0.31255153]]\n",
      "cost:\n",
      "0.127407\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.43633222 -0.08726644]\n",
      " [-1.13446378 -0.43633222]\n",
      " [ 0.08726644  0.26179933]\n",
      " [-0.95993089 -0.17453289]\n",
      " [-0.785398   -0.17453289]\n",
      " [ 1.13446378 -0.34906578]\n",
      " [ 1.22173022  0.26179933]\n",
      " [ 0.95993089 -0.26179933]\n",
      " [-0.08726644  0.        ]\n",
      " [ 0.785398    0.        ]]\n",
      "prediction:\n",
      "[[-0.43605658 -0.07855196]\n",
      " [-0.9966386  -0.40256757]\n",
      " [ 0.09898286  0.33054084]\n",
      " [-0.99738199 -0.14551251]\n",
      " [-0.88328445 -0.15242849]\n",
      " [ 0.98918706 -0.33026731]\n",
      " [ 0.98664266  0.38939807]\n",
      " [ 0.96114457 -0.24843861]\n",
      " [-0.04600001  0.00963934]\n",
      " [ 0.78496271  0.02513812]]\n",
      "cost:\n",
      "0.0862989\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644 -0.08726644]\n",
      " [-1.13446378  0.08726644]\n",
      " [ 0.52359867  0.08726644]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [-0.95993089 -0.34906578]\n",
      " [-0.08726644 -0.43633222]\n",
      " [ 0.52359867 -0.08726644]\n",
      " [ 0.          0.34906578]\n",
      " [ 0.69813156 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.1448395  -0.0667054 ]\n",
      " [-0.9992981   0.21387264]\n",
      " [ 0.52759337  0.13550664]\n",
      " [ 0.21843788 -0.05957817]\n",
      " [ 0.99941349 -0.25251806]\n",
      " [-0.99140775 -0.34017092]\n",
      " [-0.10870808 -0.43821973]\n",
      " [ 0.52755272 -0.06330679]\n",
      " [ 0.04745957  0.41212469]\n",
      " [ 0.74453127 -0.14885812]]\n",
      "cost:\n",
      "0.0779627\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867 -0.17453289]\n",
      " [ 0.17453289 -0.43633222]\n",
      " [ 0.52359867 -0.26179933]\n",
      " [-0.08726644 -0.34906578]\n",
      " [-0.785398    0.17453289]\n",
      " [ 0.69813156  0.17453289]\n",
      " [-0.52359867 -0.34906578]\n",
      " [-0.61086511  0.08726644]\n",
      " [ 0.87266444  0.26179933]\n",
      " [ 1.04719733 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.55133891 -0.13414861]\n",
      " [ 0.18492183 -0.35689676]\n",
      " [ 0.55481106 -0.20215948]\n",
      " [-0.15191087 -0.29629412]\n",
      " [-0.99990207  0.23042037]\n",
      " [ 0.65397727  0.2251071 ]\n",
      " [-0.59862971 -0.26628804]\n",
      " [-0.90069699  0.11874899]\n",
      " [ 0.93480062  0.35634527]\n",
      " [ 0.99667871 -0.2522637 ]]\n",
      "cost:\n",
      "0.119426\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156  0.34906578]\n",
      " [ 1.04719733  0.17453289]\n",
      " [-0.785398    0.17453289]\n",
      " [-0.43633222  0.26179933]\n",
      " [-0.52359867  0.17453289]\n",
      " [ 1.13446378  0.34906578]\n",
      " [-0.69813156 -0.43633222]\n",
      " [-0.52359867 -0.43633222]\n",
      " [-0.785398    0.17453289]\n",
      " [-0.61086511 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.80882722  0.19526827]\n",
      " [ 0.99938834  0.05581236]\n",
      " [-0.96152729  0.05336356]\n",
      " [-0.32903934  0.158271  ]\n",
      " [-0.44008124  0.08462549]\n",
      " [ 0.99901116  0.15998425]\n",
      " [-0.70868278 -0.41456744]\n",
      " [-0.51662844 -0.41954985]\n",
      " [-0.96152729  0.05336356]\n",
      " [-0.59786582 -0.41161507]]\n",
      "cost:\n",
      "0.131973\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644 -0.34906578]\n",
      " [ 0.785398    0.26179933]\n",
      " [ 0.34906578 -0.34906578]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [ 0.69813156  0.08726644]\n",
      " [-0.43633222  0.34906578]\n",
      " [-0.87266444  0.        ]\n",
      " [-0.43633222 -0.08726644]\n",
      " [ 0.43633222  0.08726644]\n",
      " [ 1.22173022  0.08726644]]\n",
      "prediction:\n",
      "[[-0.07722834 -0.46615234]\n",
      " [ 0.8299287   0.21998182]\n",
      " [ 0.39822096 -0.45718274]\n",
      " [ 0.14257953 -0.19642702]\n",
      " [ 0.65272319  0.0514255 ]\n",
      " [-0.4154484   0.32441598]\n",
      " [-0.9999553  -0.02699624]\n",
      " [-0.42711213 -0.10462601]\n",
      " [ 0.41779965  0.07219128]\n",
      " [ 0.99660289  0.0519101 ]]\n",
      "cost:\n",
      "0.0848569\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.17453289 -0.26179933]\n",
      " [-0.52359867 -0.34906578]\n",
      " [-1.22173022  0.34906578]\n",
      " [-1.04719733 -0.08726644]\n",
      " [ 0.61086511  0.08726644]\n",
      " [ 0.         -0.08726644]\n",
      " [-0.87266444 -0.34906578]\n",
      " [-0.785398   -0.17453289]\n",
      " [-0.785398   -0.43633222]\n",
      " [-0.34906578 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.16047704 -0.19321242]\n",
      " [-0.51083553 -0.24499048]\n",
      " [-0.70268071  0.51821733]\n",
      " [-0.90276241 -0.0123121 ]\n",
      " [ 0.99998641  0.20168671]\n",
      " [-0.20039138 -0.0433681 ]\n",
      " [-0.81675225 -0.24739316]\n",
      " [-0.68455124 -0.09628436]\n",
      " [-0.66798604 -0.33592781]\n",
      " [-0.36346099 -0.16884737]]\n",
      "cost:\n",
      "0.198647\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.22173022 -0.34906578]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [ 0.26179933  0.        ]\n",
      " [-0.34906578  0.26179933]\n",
      " [-0.87266444  0.17453289]\n",
      " [-1.13446378 -0.17453289]\n",
      " [-0.785398   -0.43633222]\n",
      " [ 0.34906578 -0.34906578]\n",
      " [ 1.13446378 -0.34906578]\n",
      " [-0.61086511 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.95817643 -0.26339138]\n",
      " [ 0.4855426  -0.07366299]\n",
      " [ 0.33062178  0.02645656]\n",
      " [-0.39257801  0.45739084]\n",
      " [-0.80201548  0.3043187 ]\n",
      " [-0.95374513 -0.12139458]\n",
      " [-0.76469141 -0.34556815]\n",
      " [ 0.29760066 -0.27781257]\n",
      " [ 0.99997133 -0.25853965]\n",
      " [-0.53428912 -0.05483646]]\n",
      "cost:\n",
      "0.13647\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.87266444  0.26179933]\n",
      " [ 0.26179933 -0.08726644]\n",
      " [-0.43633222  0.08726644]\n",
      " [-0.95993089 -0.17453289]\n",
      " [-1.13446378 -0.34906578]\n",
      " [-0.95993089 -0.17453289]\n",
      " [-0.785398    0.17453289]\n",
      " [-0.87266444  0.17453289]\n",
      " [-0.08726644  0.34906578]\n",
      " [ 0.69813156  0.        ]]\n",
      "prediction:\n",
      "[[ 0.99991554  0.17849438]\n",
      " [ 0.23599371 -0.15707162]\n",
      " [-0.41703027  0.03589858]\n",
      " [-0.93129206 -0.23605616]\n",
      " [-0.95160991 -0.59236848]\n",
      " [-0.93129206 -0.23605616]\n",
      " [-0.73167843  0.11849951]\n",
      " [-0.79744589  0.12241443]\n",
      " [-0.04002292  0.26948276]\n",
      " [ 0.97756487 -0.04043159]]\n",
      "cost:\n",
      "0.12655\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644 -0.08726644]\n",
      " [-0.69813156 -0.34906578]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [-0.08726644  0.34906578]\n",
      " [-0.34906578  0.26179933]\n",
      " [ 0.785398    0.34906578]\n",
      " [ 0.95993089  0.26179933]\n",
      " [-0.43633222 -0.43633222]\n",
      " [-0.61086511 -0.08726644]\n",
      " [-0.26179933 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.05803182 -0.0875676 ]\n",
      " [-0.99934989 -0.34497246]\n",
      " [ 0.18321812 -0.09365385]\n",
      " [-0.16528672  0.27703407]\n",
      " [-0.39207235  0.19423313]\n",
      " [ 0.91603452  0.25878993]\n",
      " [ 0.99979383  0.21462288]\n",
      " [-0.55720091 -0.40483335]\n",
      " [-0.79262984 -0.10153468]\n",
      " [-0.26550925 -0.42078787]]\n",
      "cost:\n",
      "0.107131\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933 -0.17453289]\n",
      " [ 0.         -0.08726644]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [ 0.87266444  0.17453289]\n",
      " [ 0.785398   -0.08726644]\n",
      " [-0.87266444  0.26179933]\n",
      " [ 0.61086511  0.17453289]\n",
      " [ 0.87266444  0.08726644]\n",
      " [ 0.43633222  0.08726644]\n",
      " [ 0.95993089  0.26179933]]\n",
      "prediction:\n",
      "[[-0.19276391 -0.35869995]\n",
      " [ 0.02490433 -0.16972838]\n",
      " [ 0.89431363 -0.54778999]\n",
      " [ 0.72697967  0.11774694]\n",
      " [ 0.61866689 -0.20532691]\n",
      " [-0.99998665  0.24003448]\n",
      " [ 0.51166487  0.1423097 ]\n",
      " [ 0.69424081  0.00913359]\n",
      " [ 0.33137667  0.02748112]\n",
      " [ 0.82711679  0.2525754 ]]\n",
      "cost:\n",
      "0.170464\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378  0.34906578]\n",
      " [-0.69813156  0.        ]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [-0.69813156  0.17453289]\n",
      " [-0.785398   -0.17453289]\n",
      " [ 1.22173022 -0.08726644]\n",
      " [ 0.43633222  0.        ]\n",
      " [-0.26179933  0.34906578]\n",
      " [ 0.34906578 -0.43633222]\n",
      " [-1.04719733 -0.34906578]]\n",
      "prediction:\n",
      "[[  9.92367506e-01   3.16036612e-01]\n",
      " [ -8.23147535e-01   1.84875517e-03]\n",
      " [  4.36708570e-01  -8.16254988e-02]\n",
      " [ -7.70653248e-01   1.61977664e-01]\n",
      " [ -9.04490709e-01  -1.92776307e-01]\n",
      " [  9.98870015e-01  -1.59832075e-01]\n",
      " [  4.49230582e-01   4.85748023e-04]\n",
      " [ -3.05014729e-01   3.39970678e-01]\n",
      " [  3.10656190e-01  -4.66864616e-01]\n",
      " [ -9.99053359e-01  -3.95550817e-01]]\n",
      "cost:\n",
      "0.0878086\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222  0.17453289]\n",
      " [-1.22173022  0.26179933]\n",
      " [-0.43633222 -0.43633222]\n",
      " [-0.87266444  0.34906578]\n",
      " [ 0.26179933 -0.08726644]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [ 0.          0.26179933]\n",
      " [-0.08726644  0.08726644]\n",
      " [ 0.08726644  0.17453289]\n",
      " [ 0.26179933 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.9986611   0.1223676 ]\n",
      " [-0.99961925  0.1629809 ]\n",
      " [-0.29118076 -0.49356058]\n",
      " [-0.98584896  0.24693482]\n",
      " [ 0.61559522 -0.12311516]\n",
      " [ 0.93762964 -0.21328664]\n",
      " [ 0.08406829  0.19556712]\n",
      " [ 0.00785482  0.04637807]\n",
      " [ 0.10525483  0.1129467 ]\n",
      " [ 0.63455939 -0.41572285]]\n",
      "cost:\n",
      "0.271516\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156  0.        ]\n",
      " [-0.43633222  0.17453289]\n",
      " [-0.785398   -0.17453289]\n",
      " [-0.95993089 -0.43633222]\n",
      " [ 0.69813156  0.        ]\n",
      " [-1.22173022 -0.34906578]\n",
      " [-0.87266444 -0.08726644]\n",
      " [ 0.          0.17453289]\n",
      " [ 0.52359867  0.08726644]\n",
      " [ 0.         -0.43633222]]\n",
      "prediction:\n",
      "[[-0.69600534  0.05173111]\n",
      " [-0.47861391  0.35351008]\n",
      " [-0.67952859 -0.14143258]\n",
      " [-0.88295865 -0.39277628]\n",
      " [ 0.99996656  0.02502889]\n",
      " [-0.95432615 -0.27617258]\n",
      " [-0.87756741 -0.04435863]\n",
      " [-0.23674667  0.28878579]\n",
      " [ 0.92652881  0.13360542]\n",
      " [-0.07337701 -0.39539632]]\n",
      "cost:\n",
      "0.181075\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733 -0.26179933]\n",
      " [-1.22173022  0.        ]\n",
      " [ 0.34906578  0.08726644]\n",
      " [ 0.26179933  0.34906578]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [ 0.61086511  0.        ]\n",
      " [ 1.22173022  0.        ]\n",
      " [ 0.26179933  0.        ]\n",
      " [ 0.95993089 -0.26179933]\n",
      " [-0.95993089  0.34906578]]\n",
      "prediction:\n",
      "[[ 0.91382933 -0.40987253]\n",
      " [-0.99989223 -0.05743051]\n",
      " [ 0.39331922  0.066714  ]\n",
      " [ 0.23395509  0.35767427]\n",
      " [ 0.3750219  -0.22535644]\n",
      " [ 0.65697896 -0.02286777]\n",
      " [ 0.979931   -0.07408372]\n",
      " [ 0.28763786 -0.02735933]\n",
      " [ 0.90409309 -0.40352473]\n",
      " [-0.98971456  0.33793294]]\n",
      "cost:\n",
      "0.108956\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289  0.17453289]\n",
      " [-1.22173022 -0.08726644]\n",
      " [-0.34906578 -0.08726644]\n",
      " [-0.87266444  0.08726644]\n",
      " [ 0.52359867  0.34906578]\n",
      " [-0.08726644 -0.26179933]\n",
      " [-1.13446378 -0.43633222]\n",
      " [-0.61086511 -0.08726644]\n",
      " [ 1.13446378  0.17453289]\n",
      " [-1.13446378  0.        ]]\n",
      "prediction:\n",
      "[[-0.2689161   0.15630826]\n",
      " [-0.89423472 -0.13596556]\n",
      " [-0.39211565 -0.09590168]\n",
      " [-0.77539456  0.07820763]\n",
      " [ 0.51291484  0.3534804 ]\n",
      " [-0.15948357 -0.28508559]\n",
      " [-0.75148255 -0.5521307 ]\n",
      " [-0.60947323 -0.09303932]\n",
      " [ 0.99998438  0.17153466]\n",
      " [-0.90070301 -0.01938556]]\n",
      "cost:\n",
      "0.143138\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089  0.17453289]\n",
      " [-0.26179933 -0.08726644]\n",
      " [ 0.          0.17453289]\n",
      " [-0.34906578 -0.43633222]\n",
      " [-0.43633222 -0.17453289]\n",
      " [ 0.17453289 -0.17453289]\n",
      " [-0.52359867  0.34906578]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [-0.95993089 -0.43633222]\n",
      " [-0.17453289  0.        ]]\n",
      "prediction:\n",
      "[[-0.98608398  0.21754083]\n",
      " [-0.24978355 -0.07625704]\n",
      " [ 0.04162281  0.20048682]\n",
      " [-0.27140898 -0.39840671]\n",
      " [-0.38856602 -0.16996846]\n",
      " [ 0.20944893 -0.14956462]\n",
      " [-0.45766464  0.39047337]\n",
      " [ 0.99997467 -0.05859082]\n",
      " [-0.94918478 -0.42099494]\n",
      " [-0.19419508  0.015246  ]]\n",
      "cost:\n",
      "0.0544981\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289  0.08726644]\n",
      " [-0.26179933 -0.43633222]\n",
      " [ 0.         -0.08726644]\n",
      " [-0.95993089  0.34906578]\n",
      " [-0.08726644  0.        ]\n",
      " [ 0.52359867  0.        ]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [-0.43633222  0.26179933]\n",
      " [ 0.69813156 -0.43633222]\n",
      " [ 0.52359867  0.34906578]]\n",
      "prediction:\n",
      "[[-0.16564129  0.05537178]\n",
      " [-0.25898689 -0.43490916]\n",
      " [ 0.0810369  -0.10111807]\n",
      " [-0.99991179  0.27685645]\n",
      " [-0.09086084 -0.01718181]\n",
      " [ 0.73645872 -0.01032742]\n",
      " [ 0.1550446  -0.25655901]\n",
      " [-0.42203     0.20095344]\n",
      " [ 0.99901885 -0.40283406]\n",
      " [ 0.73814154  0.27490535]]\n",
      "cost:\n",
      "0.109191\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156  0.17453289]\n",
      " [-0.34906578 -0.26179933]\n",
      " [ 0.785398    0.17453289]\n",
      " [-1.22173022 -0.08726644]\n",
      " [-0.52359867 -0.26179933]\n",
      " [ 0.26179933  0.17453289]\n",
      " [-0.95993089  0.08726644]\n",
      " [-0.34906578 -0.34906578]\n",
      " [-0.785398   -0.43633222]\n",
      " [ 0.26179933 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.97753131  0.26701835]\n",
      " [-0.36056834 -0.22000387]\n",
      " [ 0.99981731  0.28448328]\n",
      " [-0.99513549  0.01232279]\n",
      " [-0.52029443 -0.21771419]\n",
      " [ 0.25107539  0.26757514]\n",
      " [-0.96673357  0.16924149]\n",
      " [-0.34475267 -0.28309914]\n",
      " [-0.79053438 -0.37095124]\n",
      " [ 0.25932449 -0.30161157]]\n",
      "cost:\n",
      "0.122547\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733  0.08726644]\n",
      " [-0.26179933 -0.43633222]\n",
      " [ 0.95993089  0.34906578]\n",
      " [ 0.26179933 -0.43633222]\n",
      " [ 1.22173022 -0.26179933]\n",
      " [-0.87266444 -0.34906578]\n",
      " [ 0.34906578  0.34906578]\n",
      " [-1.22173022  0.        ]\n",
      " [-0.61086511 -0.34906578]\n",
      " [-1.13446378 -0.08726644]]\n",
      "prediction:\n",
      "[[-0.93175852  0.123849  ]\n",
      " [-0.30788106 -0.32207018]\n",
      " [ 0.99291933  0.36044124]\n",
      " [ 0.15185842 -0.32053301]\n",
      " [ 0.99977738 -0.1632143 ]\n",
      " [-0.83031648 -0.25991613]\n",
      " [ 0.32404584  0.35992905]\n",
      " [-0.96187872  0.06433301]\n",
      " [-0.58249688 -0.26135367]\n",
      " [-0.96863502 -0.04235429]]\n",
      "cost:\n",
      "0.133939\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289  0.08726644]\n",
      " [-0.08726644 -0.34906578]\n",
      " [ 0.52359867 -0.43633222]\n",
      " [ 0.17453289 -0.34906578]\n",
      " [-0.87266444 -0.08726644]\n",
      " [ 0.87266444  0.        ]\n",
      " [ 0.87266444 -0.43633222]\n",
      " [ 0.17453289  0.26179933]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [ 1.22173022  0.17453289]]\n",
      "prediction:\n",
      "[[-0.18999712  0.13701668]\n",
      " [-0.08746104 -0.25180775]\n",
      " [ 0.51578939 -0.33860373]\n",
      " [ 0.16539621 -0.2421231 ]\n",
      " [-0.99997717 -0.02566979]\n",
      " [ 0.85986549  0.05026507]\n",
      " [ 0.88291508 -0.33478084]\n",
      " [ 0.16850811  0.3680701 ]\n",
      " [ 0.06347018 -0.18382874]\n",
      " [ 0.98057348  0.32890198]]\n",
      "cost:\n",
      "0.112439\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.43633222]\n",
      " [-0.87266444 -0.17453289]\n",
      " [-0.61086511  0.34906578]\n",
      " [ 0.34906578 -0.34906578]\n",
      " [ 0.69813156  0.26179933]\n",
      " [ 0.34906578  0.26179933]\n",
      " [-1.04719733 -0.43633222]\n",
      " [-0.785398    0.        ]\n",
      " [-0.87266444 -0.08726644]\n",
      " [ 0.26179933 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.95242703 -0.30312884]\n",
      " [-0.76687688 -0.15115835]\n",
      " [-0.59651315  0.33477011]\n",
      " [ 0.52829754 -0.28179538]\n",
      " [ 0.99997264  0.27206162]\n",
      " [ 0.36959654  0.25076535]\n",
      " [-0.94614261 -0.31974721]\n",
      " [-0.53356242  0.0245391 ]\n",
      " [-0.745516   -0.06046814]\n",
      " [ 0.33234775 -0.29059598]]\n",
      "cost:\n",
      "0.149981\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222  0.        ]\n",
      " [ 1.04719733 -0.17453289]\n",
      " [-0.69813156  0.08726644]\n",
      " [-0.61086511 -0.26179933]\n",
      " [-0.08726644  0.        ]\n",
      " [-0.61086511 -0.43633222]\n",
      " [ 1.04719733  0.08726644]\n",
      " [-0.87266444 -0.17453289]\n",
      " [ 0.26179933  0.        ]\n",
      " [ 0.26179933 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.40364131  0.10885283]\n",
      " [ 0.99771959 -0.11902444]\n",
      " [-0.90845686  0.28171664]\n",
      " [-0.64054775 -0.25629666]\n",
      " [-0.15354092  0.07494322]\n",
      " [-0.58088142 -0.51193786]\n",
      " [ 0.99503678  0.26405069]\n",
      " [-0.99951607 -0.15034337]\n",
      " [ 0.27567372  0.08149225]\n",
      " [ 0.21408542 -0.25022572]]\n",
      "cost:\n",
      "0.113124\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.22173022 -0.26179933]\n",
      " [ 0.61086511  0.26179933]\n",
      " [-0.95993089 -0.17453289]\n",
      " [-1.04719733 -0.26179933]\n",
      " [ 0.69813156  0.        ]\n",
      " [ 0.17453289 -0.43633222]\n",
      " [-1.04719733 -0.17453289]\n",
      " [ 0.785398   -0.17453289]\n",
      " [-0.26179933  0.        ]\n",
      " [ 0.26179933  0.34906578]]\n",
      "prediction:\n",
      "[[-0.96696067 -0.21027327]\n",
      " [ 0.62386817  0.32965642]\n",
      " [-0.94983673 -0.15081692]\n",
      " [-0.94498217 -0.24159068]\n",
      " [ 0.99162209  0.05384357]\n",
      " [ 0.15580551 -0.39997301]\n",
      " [-0.96759838 -0.14055952]\n",
      " [ 0.9996292  -0.15336031]\n",
      " [-0.35466927  0.01043511]\n",
      " [ 0.1740784   0.42947632]]\n",
      "cost:\n",
      "0.131255\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867 -0.08726644]\n",
      " [ 0.17453289 -0.26179933]\n",
      " [-0.785398    0.34906578]\n",
      " [-1.13446378 -0.08726644]\n",
      " [ 0.08726644 -0.26179933]\n",
      " [-0.43633222 -0.34906578]\n",
      " [-0.17453289  0.08726644]\n",
      " [-0.69813156  0.26179933]\n",
      " [-1.13446378 -0.34906578]\n",
      " [ 1.22173022 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.45201936 -0.0686029 ]\n",
      " [ 0.21559538 -0.23000792]\n",
      " [-0.69324219  0.42627224]\n",
      " [-0.95144069 -0.01895207]\n",
      " [ 0.1106179  -0.239078  ]\n",
      " [-0.36424199 -0.30409035]\n",
      " [-0.14885403  0.11552165]\n",
      " [-0.62245333  0.33853006]\n",
      " [-0.93096805 -0.2649861 ]\n",
      " [ 0.9999817  -0.25272161]]\n",
      "cost:\n",
      "0.116694\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511  0.08726644]\n",
      " [ 1.04719733 -0.26179933]\n",
      " [-0.26179933 -0.17453289]\n",
      " [-0.26179933 -0.43633222]\n",
      " [-0.17453289 -0.34906578]\n",
      " [ 1.13446378  0.        ]\n",
      " [ 0.61086511 -0.43633222]\n",
      " [-0.26179933  0.17453289]\n",
      " [-0.785398    0.        ]\n",
      " [-0.61086511 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.7786485   0.23893481]\n",
      " [ 0.99202371 -0.12687853]\n",
      " [-0.23042527 -0.12025264]\n",
      " [-0.26541492 -0.35723829]\n",
      " [-0.10196092 -0.26440987]\n",
      " [ 0.99865913  0.2340624 ]\n",
      " [ 0.62916803 -0.32962009]\n",
      " [-0.19264108  0.37221837]\n",
      " [-0.99958819  0.12912095]\n",
      " [-0.76628947 -0.24813813]]\n",
      "cost:\n",
      "0.164905\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.61086511 -0.17453289]\n",
      " [ 0.87266444  0.17453289]\n",
      " [-0.95993089  0.26179933]\n",
      " [ 0.26179933 -0.43633222]\n",
      " [ 0.17453289 -0.26179933]\n",
      " [ 0.34906578  0.        ]\n",
      " [-1.22173022  0.08726644]\n",
      " [-0.17453289  0.26179933]\n",
      " [ 1.22173022  0.08726644]\n",
      " [ 1.04719733 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.64577132 -0.19673753]\n",
      " [ 0.90429842  0.14745595]\n",
      " [-0.99658656  0.24995469]\n",
      " [ 0.35708648 -0.55858028]\n",
      " [ 0.25148571 -0.30565399]\n",
      " [ 0.38853228 -0.01093597]\n",
      " [-0.99966413  0.03524153]\n",
      " [-0.15080988  0.24253894]\n",
      " [ 0.97838295  0.06564112]\n",
      " [ 0.97554141 -0.09785382]]\n",
      "cost:\n",
      "0.0981431\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644 -0.26179933]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [ 0.87266444  0.        ]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [ 1.04719733  0.26179933]\n",
      " [-0.87266444 -0.26179933]\n",
      " [-0.785398   -0.34906578]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [-0.52359867  0.26179933]\n",
      " [ 1.22173022 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.07333165 -0.26116055]\n",
      " [ 0.3431007  -0.25768951]\n",
      " [ 0.91053295  0.05916413]\n",
      " [ 0.29632071 -0.04967795]\n",
      " [ 0.97056705  0.39575973]\n",
      " [-0.99972081 -0.26006249]\n",
      " [-0.98962092 -0.33672845]\n",
      " [ 0.59016955 -0.05831707]\n",
      " [-0.55805254  0.36542919]\n",
      " [ 0.99161816 -0.14146383]]\n",
      "cost:\n",
      "0.127727\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.61086511 -0.17453289]\n",
      " [-0.43633222  0.26179933]\n",
      " [-0.17453289 -0.17453289]\n",
      " [ 0.95993089 -0.26179933]\n",
      " [-1.13446378 -0.43633222]\n",
      " [-1.13446378 -0.17453289]\n",
      " [ 0.87266444  0.08726644]\n",
      " [-1.22173022  0.17453289]\n",
      " [-0.52359867  0.34906578]\n",
      " [-0.26179933  0.34906578]]\n",
      "prediction:\n",
      "[[-0.64516962 -0.20228979]\n",
      " [-0.46989107  0.18803658]\n",
      " [-0.24785528 -0.22385262]\n",
      " [ 0.99972755 -0.32193148]\n",
      " [-0.90240383 -0.45436728]\n",
      " [-0.95731425 -0.20474669]\n",
      " [ 0.99745435  0.04291343]\n",
      " [-0.95817548  0.13799527]\n",
      " [-0.52984506  0.25129977]\n",
      " [-0.25847512  0.26771161]]\n",
      "cost:\n",
      "0.127601\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578 -0.26179933]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [-0.69813156  0.08726644]\n",
      " [-1.22173022  0.17453289]\n",
      " [-0.87266444 -0.08726644]\n",
      " [ 1.13446378  0.26179933]\n",
      " [-0.08726644 -0.43633222]\n",
      " [-0.26179933 -0.17453289]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [-1.22173022 -0.34906578]]\n",
      "prediction:\n",
      "[[-0.3443259  -0.22495267]\n",
      " [ 0.99590516 -0.03545432]\n",
      " [-0.66903603  0.16972743]\n",
      " [-0.98937637  0.288701  ]\n",
      " [-0.90231335 -0.03699842]\n",
      " [ 0.99928975  0.38387346]\n",
      " [-0.01637587 -0.40296921]\n",
      " [-0.26751268 -0.13835658]\n",
      " [ 0.73949373 -0.21265824]\n",
      " [-0.98249805 -0.31225649]]\n",
      "cost:\n",
      "0.110831\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867 -0.34906578]\n",
      " [-0.17453289  0.34906578]\n",
      " [ 0.52359867  0.34906578]\n",
      " [ 0.61086511 -0.17453289]\n",
      " [ 0.08726644 -0.43633222]\n",
      " [-0.69813156  0.26179933]\n",
      " [ 1.22173022  0.        ]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [ 0.785398   -0.08726644]\n",
      " [-1.13446378 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.4964233  -0.34047845]\n",
      " [-0.27919531  0.30637118]\n",
      " [ 0.4464511   0.29560268]\n",
      " [ 0.58267152 -0.16759707]\n",
      " [ 0.05981226 -0.4223589 ]\n",
      " [-0.86988676  0.21508542]\n",
      " [ 0.99793059  0.03283659]\n",
      " [ 0.38434452 -0.25954172]\n",
      " [ 0.83338708 -0.06797133]\n",
      " [-0.99992299 -0.09061841]]\n",
      "cost:\n",
      "0.093777\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.26179933]\n",
      " [ 0.17453289  0.17453289]\n",
      " [ 1.04719733  0.17453289]\n",
      " [-0.34906578  0.34906578]\n",
      " [-0.52359867 -0.17453289]\n",
      " [-0.08726644 -0.17453289]\n",
      " [ 0.87266444  0.17453289]\n",
      " [ 0.87266444 -0.26179933]\n",
      " [-0.43633222 -0.26179933]\n",
      " [ 0.69813156  0.34906578]]\n",
      "prediction:\n",
      "[[-0.99995649 -0.32814625]\n",
      " [ 0.20914     0.13600296]\n",
      " [ 0.99153405  0.11136726]\n",
      " [-0.26545647  0.30128253]\n",
      " [-0.53859419 -0.22013019]\n",
      " [-0.02385786 -0.20503271]\n",
      " [ 0.92372042  0.11310787]\n",
      " [ 0.89079428 -0.35462546]\n",
      " [-0.39276257 -0.33543679]\n",
      " [ 0.6576395   0.25766531]]\n",
      "cost:\n",
      "0.0860608\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578 -0.26179933]\n",
      " [-1.13446378 -0.08726644]\n",
      " [-1.04719733  0.26179933]\n",
      " [ 0.08726644 -0.34906578]\n",
      " [-0.95993089 -0.17453289]\n",
      " [ 0.61086511 -0.43633222]\n",
      " [-0.785398    0.26179933]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [-1.04719733 -0.43633222]\n",
      " [ 0.17453289 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.34889179 -0.17033717]\n",
      " [-0.91078621  0.02956954]\n",
      " [-0.86716193  0.39056227]\n",
      " [ 0.03133963 -0.24929115]\n",
      " [-0.87908083 -0.0777098 ]\n",
      " [ 0.74515897 -0.2922599 ]\n",
      " [-0.64471471  0.38118395]\n",
      " [ 0.99997866 -0.00431484]\n",
      " [-0.88945532 -0.26584446]\n",
      " [ 0.11805428 -0.29942265]]\n",
      "cost:\n",
      "0.171947\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644 -0.34906578]\n",
      " [-0.17453289 -0.17453289]\n",
      " [ 0.785398    0.17453289]\n",
      " [-0.43633222 -0.43633222]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [ 0.61086511 -0.26179933]\n",
      " [-0.785398    0.08726644]\n",
      " [-0.26179933  0.34906578]\n",
      " [ 0.08726644  0.17453289]\n",
      " [ 0.34906578 -0.43633222]]\n",
      "prediction:\n",
      "[[-0.06031058 -0.29325706]\n",
      " [-0.15429126 -0.14839846]\n",
      " [ 0.9098779   0.1963395 ]\n",
      " [-0.53456676 -0.33230487]\n",
      " [ 0.99889702 -0.05343036]\n",
      " [ 0.52731633 -0.21434528]\n",
      " [-0.99991435  0.11974224]\n",
      " [-0.30395475  0.36709952]\n",
      " [ 0.03295463  0.18524165]\n",
      " [ 0.27910024 -0.34017602]]\n",
      "cost:\n",
      "0.0949266\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.22173022 -0.34906578]\n",
      " [ 0.52359867  0.26179933]\n",
      " [-0.34906578  0.        ]\n",
      " [-0.61086511 -0.26179933]\n",
      " [ 0.43633222  0.26179933]\n",
      " [-0.08726644 -0.26179933]\n",
      " [-0.17453289 -0.17453289]\n",
      " [ 0.34906578 -0.43633222]\n",
      " [ 0.43633222  0.34906578]\n",
      " [ 0.69813156  0.        ]]\n",
      "prediction:\n",
      "[[-0.99981511 -0.31565306]\n",
      " [ 0.63763523  0.2377965 ]\n",
      " [-0.34442085  0.01347739]\n",
      " [-0.66578496 -0.23386277]\n",
      " [ 0.35723671  0.24736132]\n",
      " [-0.12236334 -0.2292067 ]\n",
      " [-0.20163496 -0.1437906 ]\n",
      " [ 0.26332989 -0.3969062 ]\n",
      " [ 0.3836872   0.32257935]\n",
      " [ 0.99968076  0.00428214]]\n",
      "cost:\n",
      "0.104098\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867  0.34906578]\n",
      " [ 0.69813156  0.        ]\n",
      " [ 0.61086511 -0.43633222]\n",
      " [-0.52359867 -0.43633222]\n",
      " [ 0.61086511  0.34906578]\n",
      " [ 0.          0.26179933]\n",
      " [ 0.43633222 -0.26179933]\n",
      " [-0.08726644  0.08726644]\n",
      " [ 0.26179933  0.34906578]\n",
      " [-0.69813156  0.        ]]\n",
      "prediction:\n",
      "[[ 0.55183041  0.20476188]\n",
      " [ 0.9970848  -0.05540378]\n",
      " [ 0.80244553 -0.42667449]\n",
      " [-0.90609103 -0.41838008]\n",
      " [ 0.81412101  0.19150937]\n",
      " [-0.03347035  0.14888208]\n",
      " [ 0.41260147 -0.30163097]\n",
      " [-0.05682704  0.02572265]\n",
      " [ 0.18352039  0.20782508]\n",
      " [-0.9999314  -0.06738402]]\n",
      "cost:\n",
      "0.19865\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222 -0.17453289]\n",
      " [-0.08726644 -0.34906578]\n",
      " [ 0.26179933  0.08726644]\n",
      " [ 0.17453289 -0.26179933]\n",
      " [-0.69813156  0.34906578]\n",
      " [-0.26179933  0.        ]\n",
      " [ 0.52359867 -0.43633222]\n",
      " [-0.69813156  0.        ]\n",
      " [ 0.08726644  0.17453289]\n",
      " [-0.52359867 -0.17453289]]\n",
      "prediction:\n",
      "[[ 0.96190554 -0.15161464]\n",
      " [-0.22273977 -0.31962815]\n",
      " [ 0.40688372  0.11008269]\n",
      " [ 0.24220973 -0.23306774]\n",
      " [-0.99740219  0.42032093]\n",
      " [-0.21662441  0.01889694]\n",
      " [ 0.99973387 -0.41245747]\n",
      " [-0.98834163  0.00868603]\n",
      " [ 0.14875792  0.22578266]\n",
      " [-0.71292108 -0.15574981]]\n",
      "cost:\n",
      "0.227908\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089  0.26179933]\n",
      " [ 0.785398    0.26179933]\n",
      " [ 0.26179933 -0.43633222]\n",
      " [-0.95993089  0.34906578]\n",
      " [ 0.61086511  0.26179933]\n",
      " [-0.785398   -0.08726644]\n",
      " [ 1.22173022  0.17453289]\n",
      " [-0.08726644  0.26179933]\n",
      " [-0.43633222 -0.34906578]\n",
      " [ 0.17453289  0.26179933]]\n",
      "prediction:\n",
      "[[-0.99385267  0.12157927]\n",
      " [ 0.85932457  0.08966749]\n",
      " [ 0.21163319 -0.53386301]\n",
      " [-0.99098557  0.16751386]\n",
      " [ 0.55168444  0.10727617]\n",
      " [-0.75139773 -0.14122418]\n",
      " [ 0.99987584 -0.00527823]\n",
      " [-0.04524063  0.14141795]\n",
      " [-0.4043451  -0.42337108]\n",
      " [ 0.12967031  0.13744718]]\n",
      "cost:\n",
      "0.148088\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.08726644  0.        ]\n",
      " [-0.26179933 -0.34906578]\n",
      " [-1.13446378  0.        ]\n",
      " [ 0.08726644  0.34906578]\n",
      " [-0.52359867  0.17453289]\n",
      " [ 0.34906578 -0.17453289]\n",
      " [ 0.61086511  0.        ]\n",
      " [-0.43633222  0.17453289]\n",
      " [-0.17453289  0.34906578]\n",
      " [-0.87266444  0.26179933]]\n",
      "prediction:\n",
      "[[-0.05897627 -0.04480711]\n",
      " [-0.26342097 -0.5916456 ]\n",
      " [-0.98630893 -0.12817995]\n",
      " [ 0.17967516  0.23363724]\n",
      " [-0.4548341   0.07205962]\n",
      " [ 0.39348844 -0.26898682]\n",
      " [ 0.99996883 -0.06977673]\n",
      " [-0.41815037  0.08118416]\n",
      " [-0.14410748  0.22911194]\n",
      " [-0.97357422  0.14802527]]\n",
      "cost:\n",
      "0.163337\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.08726644]\n",
      " [-0.69813156 -0.08726644]\n",
      " [-0.87266444  0.17453289]\n",
      " [-1.13446378  0.17453289]\n",
      " [ 0.69813156  0.08726644]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [ 0.          0.08726644]\n",
      " [ 0.52359867  0.08726644]\n",
      " [ 0.52359867 -0.43633222]\n",
      " [ 1.04719733  0.34906578]]\n",
      "prediction:\n",
      "[[-0.99395925 -0.16546172]\n",
      " [-0.69133162 -0.11989881]\n",
      " [-0.92430562  0.1224843 ]\n",
      " [-0.99429083  0.11135431]\n",
      " [ 0.67705572  0.03831999]\n",
      " [ 0.99629277 -0.12846552]\n",
      " [-0.01987263  0.0762983 ]\n",
      " [ 0.50215411  0.037457  ]\n",
      " [ 0.49390239 -0.62102664]\n",
      " [ 0.99726945  0.28106585]]\n",
      "cost:\n",
      "0.0877802\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222 -0.26179933]\n",
      " [ 0.69813156 -0.43633222]\n",
      " [ 0.26179933  0.17453289]\n",
      " [ 0.87266444  0.08726644]\n",
      " [ 0.87266444  0.34906578]\n",
      " [ 1.22173022  0.26179933]\n",
      " [-1.13446378  0.        ]\n",
      " [-0.08726644  0.17453289]\n",
      " [-0.17453289  0.34906578]\n",
      " [ 0.69813156  0.        ]]\n",
      "prediction:\n",
      "[[ 0.45429388 -0.35901245]\n",
      " [ 0.69419527 -0.55860543]\n",
      " [ 0.20903207  0.09863428]\n",
      " [ 0.81830043  0.01325996]\n",
      " [ 0.74932587  0.21177946]\n",
      " [ 0.95824879  0.11426778]\n",
      " [-0.99998564 -0.16528037]\n",
      " [-0.08016382  0.08155166]\n",
      " [-0.23505746  0.21811238]\n",
      " [ 0.59477663 -0.03279174]]\n",
      "cost:\n",
      "0.145101\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.26179933 -0.26179933]\n",
      " [ 1.04719733  0.34906578]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [ 0.61086511 -0.43633222]\n",
      " [-0.785398    0.26179933]\n",
      " [-0.08726644 -0.17453289]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [-0.785398    0.34906578]\n",
      " [-0.08726644  0.34906578]\n",
      " [ 0.34906578 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.21046165 -0.27188358]\n",
      " [ 0.99748176  0.25350308]\n",
      " [ 0.34560663 -0.27119362]\n",
      " [ 0.62727177 -0.44460854]\n",
      " [-0.9983291   0.19671747]\n",
      " [-0.08444796 -0.15617535]\n",
      " [ 0.9815762  -0.19999383]\n",
      " [-0.99820328  0.25929999]\n",
      " [-0.11165188  0.27862638]\n",
      " [ 0.31313652 -0.07597464]]\n",
      "cost:\n",
      "0.0884669\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.22173022  0.17453289]\n",
      " [ 0.52359867  0.34906578]\n",
      " [ 0.95993089  0.17453289]\n",
      " [ 0.26179933  0.08726644]\n",
      " [ 0.785398    0.26179933]\n",
      " [-0.87266444  0.17453289]\n",
      " [-1.13446378  0.        ]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [-0.69813156 -0.26179933]\n",
      " [ 0.17453289 -0.17453289]]\n",
      "prediction:\n",
      "[[-0.99415201  0.04099797]\n",
      " [ 0.57853603  0.30100998]\n",
      " [ 0.99593294  0.11055409]\n",
      " [ 0.27226004  0.05290496]\n",
      " [ 0.86099672  0.19372553]\n",
      " [-0.93445069  0.11190156]\n",
      " [-0.99573267 -0.10456753]\n",
      " [ 0.99475098 -0.28683764]\n",
      " [-0.66066527 -0.52591932]\n",
      " [ 0.21267462 -0.28972289]]\n",
      "cost:\n",
      "0.13153\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.17453289  0.        ]\n",
      " [-0.43633222 -0.08726644]\n",
      " [ 0.87266444 -0.34906578]\n",
      " [ 0.95993089  0.17453289]\n",
      " [ 0.26179933 -0.34906578]\n",
      " [-1.13446378 -0.26179933]\n",
      " [-1.13446378 -0.43633222]\n",
      " [-0.08726644  0.17453289]\n",
      " [ 0.69813156  0.26179933]\n",
      " [-0.785398   -0.26179933]]\n",
      "prediction:\n",
      "[[-0.19295156  0.01190791]\n",
      " [-0.49170747 -0.07538385]\n",
      " [ 0.98958725 -0.26997119]\n",
      " [ 0.99908531  0.24747567]\n",
      " [ 0.25214124 -0.27263045]\n",
      " [-0.99750942 -0.20227116]\n",
      " [-0.98485059 -0.32489207]\n",
      " [-0.13514389  0.23707476]\n",
      " [ 0.81896728  0.41185287]\n",
      " [-0.84545416 -0.20712848]]\n",
      "cost:\n",
      "0.106809\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733 -0.08726644]\n",
      " [ 1.04719733  0.        ]\n",
      " [ 0.17453289  0.17453289]\n",
      " [ 0.26179933 -0.43633222]\n",
      " [ 0.34906578  0.        ]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [ 0.61086511  0.17453289]\n",
      " [ 0.785398   -0.26179933]\n",
      " [ 0.34906578  0.17453289]\n",
      " [-0.34906578  0.26179933]]\n",
      "prediction:\n",
      "[[-0.99998236 -0.13081104]\n",
      " [ 0.97470272  0.0164645 ]\n",
      " [ 0.15183827  0.17233434]\n",
      " [ 0.27736741 -0.52737725]\n",
      " [ 0.2898722  -0.02299744]\n",
      " [ 0.84879386 -0.19875014]\n",
      " [ 0.54816818  0.19002098]\n",
      " [ 0.766096   -0.32177654]\n",
      " [ 0.31675246  0.17698324]\n",
      " [-0.30832532  0.25877228]]\n",
      "cost:\n",
      "0.0552092\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867 -0.17453289]\n",
      " [-0.08726644 -0.08726644]\n",
      " [ 1.13446378  0.08726644]\n",
      " [ 0.34906578 -0.43633222]\n",
      " [ 0.26179933 -0.08726644]\n",
      " [ 0.17453289  0.34906578]\n",
      " [ 0.69813156 -0.43633222]\n",
      " [ 0.785398    0.17453289]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [-1.13446378 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.57516611 -0.14139885]\n",
      " [-0.10862968 -0.06600951]\n",
      " [ 0.97898901  0.20084144]\n",
      " [ 0.33630404 -0.33933714]\n",
      " [ 0.25734353 -0.05690239]\n",
      " [ 0.14073139  0.44456518]\n",
      " [ 0.60331291 -0.32064068]\n",
      " [ 0.7221092   0.28056654]\n",
      " [ 0.94014835 -0.20814715]\n",
      " [-0.99997455 -0.20357615]]\n",
      "cost:\n",
      "0.1135\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378  0.26179933]\n",
      " [-0.17453289 -0.34906578]\n",
      " [-0.43633222 -0.17453289]\n",
      " [ 0.52359867  0.08726644]\n",
      " [ 0.08726644  0.34906578]\n",
      " [-0.69813156 -0.34906578]\n",
      " [-0.08726644 -0.34906578]\n",
      " [-0.69813156 -0.43633222]\n",
      " [ 1.13446378  0.26179933]\n",
      " [ 0.26179933  0.17453289]]\n",
      "prediction:\n",
      "[[-0.99897295  0.21769792]\n",
      " [-0.16349117 -0.30252725]\n",
      " [-0.36296111 -0.1527123 ]\n",
      " [ 0.57666898  0.07697313]\n",
      " [ 0.07509686  0.30645019]\n",
      " [-0.67885602 -0.2921192 ]\n",
      " [-0.07408337 -0.31336701]\n",
      " [-0.66692913 -0.3649106 ]\n",
      " [ 0.99991727  0.23296864]\n",
      " [ 0.25266668  0.16165547]]\n",
      "cost:\n",
      "0.0694747\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.34906578  0.08726644]\n",
      " [-0.61086511 -0.17453289]\n",
      " [ 0.17453289 -0.08726644]\n",
      " [ 0.61086511 -0.17453289]\n",
      " [ 0.785398   -0.43633222]\n",
      " [ 0.95993089 -0.43633222]\n",
      " [ 0.95993089 -0.26179933]\n",
      " [-0.08726644  0.        ]\n",
      " [-0.08726644  0.08726644]\n",
      " [ 0.17453289  0.34906578]]\n",
      "prediction:\n",
      "[[-0.86658299  0.1335296 ]\n",
      " [-0.99994445 -0.14515775]\n",
      " [ 0.19226767 -0.06078651]\n",
      " [ 0.58764958 -0.14323245]\n",
      " [ 0.83417892 -0.35272354]\n",
      " [ 0.98015189 -0.34766051]\n",
      " [ 0.98154593 -0.210013  ]\n",
      " [-0.16402239  0.02299194]\n",
      " [-0.12576485  0.13267234]\n",
      " [ 0.14475508  0.50933647]]\n",
      "cost:\n",
      "0.152714\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.52359867  0.17453289]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [-0.87266444 -0.34906578]\n",
      " [-0.785398    0.        ]\n",
      " [ 0.43633222 -0.34906578]\n",
      " [ 0.785398    0.26179933]\n",
      " [ 0.61086511  0.        ]\n",
      " [ 1.13446378  0.34906578]\n",
      " [ 0.08726644  0.26179933]\n",
      " [ 0.34906578  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.52863318  0.10781574]\n",
      " [ 0.90206099 -0.2226326 ]\n",
      " [-0.99969661 -0.46178445]\n",
      " [-0.99643618 -0.0524981 ]\n",
      " [ 0.42680129 -0.46533072]\n",
      " [ 0.76195562  0.16770944]\n",
      " [ 0.57928795 -0.04950577]\n",
      " [ 0.99416429  0.22525948]\n",
      " [ 0.11377939  0.18452764]\n",
      " [ 0.33733732  0.17401026]]\n",
      "cost:\n",
      "0.11403\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.43633222  0.34906578]\n",
      " [-1.13446378 -0.17453289]\n",
      " [-0.95993089  0.26179933]\n",
      " [ 0.26179933  0.34906578]\n",
      " [-0.17453289 -0.17453289]\n",
      " [-0.43633222 -0.26179933]\n",
      " [-0.95993089 -0.17453289]\n",
      " [-0.95993089 -0.17453289]\n",
      " [-1.22173022  0.34906578]\n",
      " [ 0.08726644 -0.43633222]]\n",
      "prediction:\n",
      "[[ 0.99998301  0.28342912]\n",
      " [-0.86752945 -0.18096547]\n",
      " [-0.72118902  0.2047769 ]\n",
      " [ 0.69359577  0.27931681]\n",
      " [-0.20436952 -0.18069088]\n",
      " [-0.42034701 -0.2646932 ]\n",
      " [-0.86622417 -0.17371455]\n",
      " [-0.86622417 -0.17371455]\n",
      " [-0.77685237  0.22145189]\n",
      " [-0.1158909  -0.46514919]]\n",
      "cost:\n",
      "0.241946\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.13446378 -0.17453289]\n",
      " [-1.04719733  0.        ]\n",
      " [ 0.         -0.26179933]\n",
      " [ 0.87266444 -0.08726644]\n",
      " [-1.04719733  0.        ]\n",
      " [-0.61086511 -0.34906578]\n",
      " [ 0.         -0.26179933]\n",
      " [ 1.22173022 -0.34906578]\n",
      " [-0.43633222  0.26179933]\n",
      " [-0.61086511 -0.34906578]]\n",
      "prediction:\n",
      "[[ 0.99757028 -0.07346931]\n",
      " [-0.9959327   0.14672242]\n",
      " [ 0.04489555 -0.20358872]\n",
      " [ 0.95020795 -0.02215596]\n",
      " [-0.9959327   0.14672242]\n",
      " [-0.59449631 -0.26588988]\n",
      " [ 0.04489555 -0.20358872]\n",
      " [ 0.99132222 -0.26905087]\n",
      " [-0.40089312  0.51346529]\n",
      " [-0.59449631 -0.26588988]]\n",
      "cost:\n",
      "0.139688\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.69813156 -0.17453289]\n",
      " [ 1.13446378 -0.26179933]\n",
      " [-1.22173022 -0.08726644]\n",
      " [-0.43633222  0.34906578]\n",
      " [ 0.17453289  0.08726644]\n",
      " [-0.26179933 -0.34906578]\n",
      " [-1.13446378 -0.43633222]\n",
      " [-0.52359867 -0.26179933]\n",
      " [ 1.22173022  0.17453289]\n",
      " [-0.61086511 -0.08726644]]\n",
      "prediction:\n",
      "[[ 0.68437403 -0.15142958]\n",
      " [ 0.99709594 -0.21745543]\n",
      " [-0.99842966 -0.02083109]\n",
      " [-0.38870665  0.42505193]\n",
      " [ 0.21006781  0.12286646]\n",
      " [-0.21831462 -0.29982066]\n",
      " [-0.97950757 -0.37080094]\n",
      " [-0.49490649 -0.2188025 ]\n",
      " [ 0.99797279  0.2679821 ]\n",
      " [-0.60994577 -0.05732971]]\n",
      "cost:\n",
      "0.110226\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398   -0.08726644]\n",
      " [ 0.785398   -0.26179933]\n",
      " [ 0.95993089 -0.17453289]\n",
      " [-0.34906578  0.        ]\n",
      " [ 0.785398    0.        ]\n",
      " [-0.69813156  0.17453289]\n",
      " [ 0.61086511 -0.17453289]\n",
      " [-0.785398    0.26179933]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [ 0.95993089  0.17453289]]\n",
      "prediction:\n",
      "[[-0.99770451 -0.11523937]\n",
      " [ 0.8369807  -0.39020142]\n",
      " [ 0.9893651  -0.217649  ]\n",
      " [-0.45341703 -0.01416655]\n",
      " [ 0.7826314  -0.00682854]\n",
      " [-0.95732105  0.21216968]\n",
      " [ 0.59524536 -0.21375793]\n",
      " [-0.99645668  0.36411679]\n",
      " [ 0.7164824  -0.39137632]\n",
      " [ 0.98734206  0.22386542]]\n",
      "cost:\n",
      "0.124339\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.785398    0.08726644]\n",
      " [-1.22173022 -0.43633222]\n",
      " [ 0.08726644 -0.34906578]\n",
      " [ 0.17453289  0.17453289]\n",
      " [-0.26179933  0.34906578]\n",
      " [ 0.08726644 -0.43633222]\n",
      " [-0.08726644  0.26179933]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [ 0.95993089 -0.34906578]\n",
      " [-0.26179933  0.08726644]]\n",
      "prediction:\n",
      "[[-0.93041462  0.07418487]\n",
      " [-0.99853748 -0.32727355]\n",
      " [ 0.10491282 -0.30994877]\n",
      " [ 0.18486595  0.14075598]\n",
      " [-0.30635756  0.3358753 ]\n",
      " [ 0.10145352 -0.37232327]\n",
      " [-0.1050697   0.23028533]\n",
      " [ 0.43187377 -0.08354923]\n",
      " [ 0.99993008 -0.29826102]\n",
      " [-0.24242532  0.05851601]]\n",
      "cost:\n",
      "0.0725615\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.08726644 -0.34906578]\n",
      " [-0.95993089  0.34906578]\n",
      " [-0.43633222  0.17453289]\n",
      " [-0.34906578  0.08726644]\n",
      " [ 0.43633222  0.        ]\n",
      " [-0.785398    0.17453289]\n",
      " [ 0.95993089 -0.08726644]\n",
      " [ 0.26179933 -0.26179933]\n",
      " [ 1.13446378  0.        ]\n",
      " [-0.34906578  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.09479135 -0.54286212]\n",
      " [-0.99939364  0.27729273]\n",
      " [-0.41415104  0.11960115]\n",
      " [-0.3201409   0.03397278]\n",
      " [ 0.44327623 -0.04347454]\n",
      " [-0.96954399  0.08901729]\n",
      " [ 0.99001282 -0.14584175]\n",
      " [ 0.31195271 -0.38522625]\n",
      " [ 0.9988938  -0.09320298]\n",
      " [-0.31556854  0.21078967]]\n",
      "cost:\n",
      "0.10674\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.52359867  0.08726644]\n",
      " [-1.04719733 -0.26179933]\n",
      " [ 0.87266444 -0.34906578]\n",
      " [ 0.87266444 -0.17453289]\n",
      " [ 0.61086511 -0.43633222]\n",
      " [-0.61086511 -0.26179933]\n",
      " [ 0.17453289 -0.43633222]\n",
      " [-0.95993089 -0.26179933]\n",
      " [-1.13446378  0.26179933]\n",
      " [-0.61086511  0.26179933]]\n",
      "prediction:\n",
      "[[-0.52899444  0.15686148]\n",
      " [-0.97157103 -0.15295401]\n",
      " [ 0.99862617 -0.21601062]\n",
      " [ 0.99886519 -0.09058581]\n",
      " [ 0.65914083 -0.29367384]\n",
      " [-0.61220682 -0.17328086]\n",
      " [ 0.17444769 -0.35183799]\n",
      " [-0.95387268 -0.16748634]\n",
      " [-0.98128408  0.37610134]\n",
      " [-0.5930447   0.37010053]]\n",
      "cost:\n",
      "0.125615\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.95993089 -0.34906578]\n",
      " [-0.26179933  0.08726644]\n",
      " [ 0.          0.34906578]\n",
      " [ 1.13446378 -0.34906578]\n",
      " [ 0.95993089 -0.26179933]\n",
      " [ 1.04719733  0.        ]\n",
      " [-1.13446378 -0.34906578]\n",
      " [-0.785398   -0.43633222]\n",
      " [-0.17453289 -0.43633222]\n",
      " [ 0.87266444  0.34906578]]\n",
      "prediction:\n",
      "[[-0.99328953 -0.2247185 ]\n",
      " [-0.25187805  0.09363653]\n",
      " [-0.00955544  0.39480439]\n",
      " [ 0.98592889 -0.21794535]\n",
      " [ 0.95797014 -0.1833638 ]\n",
      " [ 0.987216    0.03846433]\n",
      " [-0.99916607 -0.21233585]\n",
      " [-0.81623816 -0.28911275]\n",
      " [-0.12384108 -0.31230569]\n",
      " [ 0.88396585  0.36382881]]\n",
      "cost:\n",
      "0.103045\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378 -0.34906578]\n",
      " [-1.22173022  0.        ]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [ 0.         -0.17453289]\n",
      " [ 0.87266444  0.26179933]\n",
      " [-1.04719733 -0.34906578]\n",
      " [-0.52359867 -0.17453289]\n",
      " [-0.08726644  0.08726644]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [ 0.34906578 -0.26179933]]\n",
      "prediction:\n",
      "[[-0.96264756 -0.31161559]\n",
      " [-0.97291231  0.17795511]\n",
      " [ 0.41372135 -0.05142828]\n",
      " [-0.03772761 -0.14514188]\n",
      " [ 0.99996626  0.51025724]\n",
      " [-0.9463318  -0.31629327]\n",
      " [-0.51254565 -0.13815248]\n",
      " [-0.12651037  0.17189498]\n",
      " [ 0.41875929 -0.14950621]\n",
      " [ 0.30715635 -0.23567189]]\n",
      "cost:\n",
      "0.116846\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733  0.        ]\n",
      " [-0.87266444  0.26179933]\n",
      " [-0.34906578  0.        ]\n",
      " [-0.95993089 -0.34906578]\n",
      " [-0.43633222  0.17453289]\n",
      " [-1.22173022 -0.34906578]\n",
      " [-0.34906578 -0.26179933]\n",
      " [-1.04719733 -0.34906578]\n",
      " [ 0.785398   -0.08726644]\n",
      " [ 1.13446378 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.99817979  0.07401238]\n",
      " [-0.8580156   0.44889209]\n",
      " [-0.39205146  0.03326297]\n",
      " [-0.94635177 -0.30056721]\n",
      " [-0.53028369  0.29996878]\n",
      " [-0.96911764 -0.2715795 ]\n",
      " [-0.38213623 -0.21461441]\n",
      " [-0.97135401 -0.30328876]\n",
      " [ 0.8897506  -0.05101211]\n",
      " [ 0.99896884 -0.20553035]]\n",
      "cost:\n",
      "0.12055\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.26179933 -0.17453289]\n",
      " [-0.43633222  0.17453289]\n",
      " [ 0.26179933 -0.17453289]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [-0.87266444  0.08726644]\n",
      " [-0.69813156 -0.43633222]\n",
      " [-1.22173022  0.34906578]\n",
      " [-0.785398   -0.43633222]\n",
      " [-0.52359867  0.        ]]\n",
      "prediction:\n",
      "[[-0.12022078 -0.1337571 ]\n",
      " [-0.39111134  0.25271872]\n",
      " [ 0.32346514 -0.12841754]\n",
      " [ 0.99508512 -0.04308529]\n",
      " [ 0.99972636 -0.1970963 ]\n",
      " [-0.92853224  0.14356275]\n",
      " [-0.70904124 -0.37266383]\n",
      " [-0.99524677  0.42447454]\n",
      " [-0.81976628 -0.37919161]\n",
      " [-0.44057253  0.03190643]]\n",
      "cost:\n",
      "0.146158\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733 -0.34906578]\n",
      " [-0.95993089 -0.26179933]\n",
      " [ 0.34906578 -0.26179933]\n",
      " [ 0.61086511  0.08726644]\n",
      " [-0.69813156 -0.26179933]\n",
      " [-1.22173022 -0.26179933]\n",
      " [ 1.04719733 -0.17453289]\n",
      " [-0.785398   -0.26179933]\n",
      " [ 0.26179933 -0.43633222]\n",
      " [-1.04719733  0.17453289]]\n",
      "prediction:\n",
      "[[ 0.9977659  -0.20255758]\n",
      " [-0.94638133 -0.14825839]\n",
      " [ 0.33268335 -0.17695411]\n",
      " [ 0.60220265  0.28771192]\n",
      " [-0.66776842 -0.16020063]\n",
      " [-0.99068266 -0.03894345]\n",
      " [ 0.99902123 -0.0368275 ]\n",
      " [-0.77118486 -0.14835173]\n",
      " [ 0.22986099 -0.33502021]\n",
      " [-0.97143126  0.5015738 ]]\n",
      "cost:\n",
      "0.168522\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.04719733 -0.34906578]\n",
      " [-0.61086511 -0.26179933]\n",
      " [-0.95993089  0.26179933]\n",
      " [-0.61086511 -0.17453289]\n",
      " [ 0.785398    0.08726644]\n",
      " [-0.52359867  0.26179933]\n",
      " [-0.95993089  0.17453289]\n",
      " [ 0.95993089  0.26179933]\n",
      " [ 0.61086511  0.34906578]\n",
      " [ 1.13446378  0.        ]]\n",
      "prediction:\n",
      "[[-0.98644578 -0.49790165]\n",
      " [-0.54739928 -0.37349516]\n",
      " [-0.97662133  0.18183802]\n",
      " [-0.53004897 -0.24949878]\n",
      " [ 0.85467285  0.0046353 ]\n",
      " [-0.48741174  0.17734911]\n",
      " [-0.98217797  0.08560131]\n",
      " [ 0.9946214   0.17972592]\n",
      " [ 0.63020307  0.23723388]\n",
      " [ 0.999107   -0.12423541]]\n",
      "cost:\n",
      "0.115884\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.22173022  0.17453289]\n",
      " [ 0.          0.17453289]\n",
      " [ 0.          0.08726644]\n",
      " [-0.69813156 -0.43633222]\n",
      " [ 1.22173022 -0.17453289]\n",
      " [ 0.         -0.34906578]\n",
      " [-1.04719733 -0.17453289]\n",
      " [-1.13446378 -0.43633222]\n",
      " [ 0.52359867  0.26179933]\n",
      " [ 0.26179933  0.26179933]]\n",
      "prediction:\n",
      "[[ 0.99794573  0.18550682]\n",
      " [-0.03119348  0.18149416]\n",
      " [-0.02228935  0.10362275]\n",
      " [-0.71891528 -0.37373936]\n",
      " [ 0.99561727 -0.17717001]\n",
      " [ 0.01295321 -0.33017188]\n",
      " [-0.99817377 -0.14998078]\n",
      " [-0.99460149 -0.34494731]\n",
      " [ 0.56155276  0.26912752]\n",
      " [ 0.29032528  0.28274322]]\n",
      "cost:\n",
      "0.0894593\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733  0.34906578]\n",
      " [ 0.52359867  0.        ]\n",
      " [ 0.          0.17453289]\n",
      " [-1.04719733  0.26179933]\n",
      " [-0.61086511  0.17453289]\n",
      " [ 0.43633222 -0.17453289]\n",
      " [-0.34906578  0.17453289]\n",
      " [ 0.785398    0.17453289]\n",
      " [-0.08726644 -0.43633222]\n",
      " [-0.785398    0.26179933]]\n",
      "prediction:\n",
      "[[ 0.99952441  0.201452  ]\n",
      " [ 0.52044529 -0.07331902]\n",
      " [ 0.02085506  0.09108211]\n",
      " [-0.99968821  0.08714116]\n",
      " [-0.63088346  0.04200124]\n",
      " [ 0.42436236 -0.26936263]\n",
      " [-0.38407266  0.06562032]\n",
      " [ 0.95656228  0.05284954]\n",
      " [-0.12554526 -0.62949312]\n",
      " [-0.89589417  0.10502803]]\n",
      "cost:\n",
      "0.143827\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 0.         -0.26179933]\n",
      " [ 0.34906578  0.        ]\n",
      " [ 0.87266444  0.26179933]\n",
      " [-1.04719733 -0.34906578]\n",
      " [-0.95993089  0.34906578]\n",
      " [-0.43633222  0.34906578]\n",
      " [-1.22173022  0.26179933]\n",
      " [ 0.08726644  0.17453289]\n",
      " [-1.04719733 -0.43633222]\n",
      " [-0.785398    0.17453289]]\n",
      "prediction:\n",
      "[[-0.07677998 -0.29689339]\n",
      " [ 0.40532213 -0.04634478]\n",
      " [ 0.99998742  0.14115204]\n",
      " [-0.86876553 -0.39609632]\n",
      " [-0.77703404  0.21483789]\n",
      " [-0.39972031  0.23571223]\n",
      " [-0.90032101  0.0943899 ]\n",
      " [-0.00423828  0.11038609]\n",
      " [-0.85684848 -0.48151666]\n",
      " [-0.64148378  0.09582192]]\n",
      "cost:\n",
      "0.169704\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378  0.34906578]\n",
      " [ 0.52359867 -0.08726644]\n",
      " [ 0.34906578  0.34906578]\n",
      " [ 1.13446378  0.        ]\n",
      " [-1.22173022 -0.26179933]\n",
      " [ 0.         -0.34906578]\n",
      " [-1.22173022  0.34906578]\n",
      " [ 1.22173022  0.17453289]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [-0.87266444  0.17453289]]\n",
      "prediction:\n",
      "[[-0.98039442  0.22160412]\n",
      " [ 0.60534507 -0.11615773]\n",
      " [ 0.3090997   0.2665785 ]\n",
      " [ 0.99802834 -0.09396377]\n",
      " [-0.99165791 -0.43668994]\n",
      " [-0.04014921 -0.47014233]\n",
      " [-0.97671294  0.20219947]\n",
      " [ 0.99655765  0.05852849]\n",
      " [ 0.76766753 -0.12606953]\n",
      " [-0.86147982  0.092388  ]]\n",
      "cost:\n",
      "0.166203\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156  0.08726644]\n",
      " [ 0.08726644  0.26179933]\n",
      " [-0.34906578  0.        ]\n",
      " [-0.17453289  0.08726644]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [-0.69813156  0.34906578]\n",
      " [ 0.69813156  0.34906578]\n",
      " [-0.52359867 -0.26179933]\n",
      " [-0.34906578 -0.34906578]\n",
      " [ 0.69813156  0.17453289]]\n",
      "prediction:\n",
      "[[-0.98252958  0.01806252]\n",
      " [ 0.24252267  0.17468856]\n",
      " [-0.25741637 -0.05734777]\n",
      " [-0.05040601  0.02941749]\n",
      " [ 0.98561245 -0.14206342]\n",
      " [-0.99942744  0.22753862]\n",
      " [ 0.98773193  0.21801132]\n",
      " [-0.65479553 -0.41747963]\n",
      " [-0.35991511 -0.54489458]\n",
      " [ 0.99151874  0.07950382]]\n",
      "cost:\n",
      "0.23593\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.22173022 -0.26179933]\n",
      " [ 0.785398    0.        ]\n",
      " [-0.69813156 -0.34906578]\n",
      " [ 0.34906578 -0.34906578]\n",
      " [-1.04719733 -0.43633222]\n",
      " [ 0.17453289 -0.43633222]\n",
      " [ 0.26179933  0.08726644]\n",
      " [-0.17453289  0.        ]\n",
      " [ 0.87266444  0.08726644]\n",
      " [-0.34906578 -0.26179933]]\n",
      "prediction:\n",
      "[[ 0.99457985 -0.03784028]\n",
      " [ 0.89451104  0.21135058]\n",
      " [-0.90270644 -0.2568053 ]\n",
      " [ 0.34990469 -0.25886315]\n",
      " [-0.99992096 -0.31271651]\n",
      " [ 0.1539216  -0.32673824]\n",
      " [ 0.3031688   0.24872641]\n",
      " [-0.13052945  0.05025176]\n",
      " [ 0.96011853  0.40958264]\n",
      " [-0.39065233 -0.18673487]]\n",
      "cost:\n",
      "0.176859\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[ 1.04719733 -0.43633222]\n",
      " [ 0.         -0.08726644]\n",
      " [-1.22173022 -0.26179933]\n",
      " [-0.08726644 -0.08726644]\n",
      " [ 0.69813156 -0.34906578]\n",
      " [-0.87266444  0.        ]\n",
      " [-0.785398    0.08726644]\n",
      " [ 0.43633222 -0.08726644]\n",
      " [ 0.26179933  0.34906578]\n",
      " [ 0.17453289  0.08726644]]\n",
      "prediction:\n",
      "[[ 0.99984419 -0.40813801]\n",
      " [-0.03047952 -0.07809464]\n",
      " [-0.99794948 -0.23194146]\n",
      " [-0.14113209 -0.08234156]\n",
      " [ 0.87901652 -0.31354707]\n",
      " [-0.96929926  0.02525782]\n",
      " [-0.87826693  0.15988828]\n",
      " [ 0.4481411  -0.07148743]\n",
      " [ 0.42051256  0.49767184]\n",
      " [ 0.16148759  0.11349157]]\n",
      "cost:\n",
      "0.103533\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156  0.34906578]\n",
      " [ 0.61086511  0.17453289]\n",
      " [-0.69813156  0.26179933]\n",
      " [ 0.61086511  0.        ]\n",
      " [ 1.04719733 -0.26179933]\n",
      " [ 0.08726644  0.26179933]\n",
      " [ 0.08726644 -0.17453289]\n",
      " [-0.34906578  0.08726644]\n",
      " [-0.52359867  0.34906578]\n",
      " [ 1.22173022  0.        ]]\n",
      "prediction:\n",
      "[[ -9.93784726e-01   2.29611546e-01]\n",
      " [  6.27075613e-01   7.05534890e-02]\n",
      " [ -9.97061670e-01   1.29455909e-01]\n",
      " [  6.08778000e-01  -8.51169154e-02]\n",
      " [  9.95855689e-01  -5.42525053e-01]\n",
      " [  5.41818794e-03   1.90834478e-01]\n",
      " [ -9.64522071e-04  -2.70006537e-01]\n",
      " [ -5.93964756e-01   3.93789448e-03]\n",
      " [ -7.45462060e-01   2.52878815e-01]\n",
      " [  9.97762918e-01  -2.64330953e-01]]\n",
      "cost:\n",
      "0.220684\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.22173022  0.08726644]\n",
      " [ 1.04719733 -0.43633222]\n",
      " [ 0.69813156 -0.08726644]\n",
      " [-1.22173022  0.26179933]\n",
      " [ 1.04719733  0.26179933]\n",
      " [ 1.04719733 -0.17453289]\n",
      " [-0.87266444  0.34906578]\n",
      " [ 0.17453289  0.08726644]\n",
      " [-0.43633222  0.26179933]\n",
      " [ 1.22173022  0.08726644]]\n",
      "prediction:\n",
      "[[-0.99821669 -0.01827558]\n",
      " [ 0.91847599 -0.6063019 ]\n",
      " [ 0.68560743 -0.12062752]\n",
      " [-0.99716341  0.12000792]\n",
      " [ 0.9606356   0.15654002]\n",
      " [ 0.97280592 -0.24180557]\n",
      " [-0.9195289   0.22684772]\n",
      " [ 0.20963123  0.05945269]\n",
      " [-0.39911249  0.163802  ]\n",
      " [ 0.97755527 -0.03313532]]\n",
      "cost:\n",
      "0.155094\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-1.13446378  0.26179933]\n",
      " [-0.95993089  0.08726644]\n",
      " [ 1.04719733  0.26179933]\n",
      " [-0.785398   -0.26179933]\n",
      " [-0.43633222  0.17453289]\n",
      " [-0.87266444  0.34906578]\n",
      " [ 0.69813156 -0.43633222]\n",
      " [-0.17453289 -0.17453289]\n",
      " [ 0.61086511 -0.26179933]\n",
      " [ 0.          0.08726644]]\n",
      "prediction:\n",
      "[[-0.98395008  0.17347069]\n",
      " [-0.9281289   0.04127972]\n",
      " [ 0.99996012  0.1985949 ]\n",
      " [-0.77357095 -0.29652569]\n",
      " [-0.42004547  0.12807964]\n",
      " [-0.86840868  0.27671513]\n",
      " [ 0.79034072 -0.48741841]\n",
      " [-0.10904656 -0.20084448]\n",
      " [ 0.55696011 -0.301359  ]\n",
      " [ 0.03741112  0.08001061]]\n",
      "cost:\n",
      "0.0748683\n",
      "Optimization Finished!\n",
      "training...\n",
      "   augmenting for training...\n",
      "   done\n",
      "(290, 128, 128, 1)\n",
      "gt:\n",
      "[[-0.69813156 -0.34906578]\n",
      " [ 0.69813156 -0.26179933]\n",
      " [-1.13446378 -0.17453289]\n",
      " [ 0.87266444  0.26179933]\n",
      " [ 0.95993089 -0.43633222]\n",
      " [-0.08726644 -0.08726644]\n",
      " [-0.52359867  0.        ]\n",
      " [-0.43633222  0.        ]\n",
      " [-1.13446378  0.34906578]\n",
      " [ 1.22173022  0.17453289]]\n",
      "prediction:\n",
      "[[-0.67061388 -0.35064641]\n",
      " [ 0.72321498 -0.24862151]\n",
      " [-0.99748749 -0.17539898]\n",
      " [ 0.95287007  0.28130645]\n",
      " [ 0.95855522 -0.43678325]\n",
      " [-0.05319653 -0.07282139]\n",
      " [-0.49288836  0.00501964]\n",
      " [-0.41642976  0.00804288]\n",
      " [-0.99480963  0.36034566]\n",
      " [ 0.99866009  0.21384105]]\n",
      "cost:\n",
      "0.0733074\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "regress = RegressCNN()\n",
    "regress.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %% We now create a new session to actually perform the initialization the\n",
    "# variables:\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# %% We'll train in minibatches and report accuracy:\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "for epoch_i in range(n_epochs):\n",
    "    for batch_i in range(mnist.train.num_examples // batch_size):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        sess.run(train_step, feed_dict={\n",
    "            x: batch_xs, y: batch_ys, is_training: True})\n",
    "    print(sess.run(accuracy,\n",
    "                   feed_dict={\n",
    "                       x: mnist.validation.images,\n",
    "                       y: mnist.validation.labels,\n",
    "                       is_training: False\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-15873d8bb83a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'l' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
