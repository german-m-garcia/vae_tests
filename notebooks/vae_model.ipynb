{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Class that implements a VAE\n",
    "\"\"\"\n",
    "from ipywidgets import *\n",
    "import tensorflow as tf\n",
    "import vae_tests.tfutils as ut\n",
    "import vae_tests.config as config\n",
    "import numpy as np\n",
    "import vae_tests.augmentation as aug\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import gen_nn_ops\n",
    "\n",
    "@ops.RegisterGradient(\"MaxPoolWithArgmax\")\n",
    "def _MaxPoolWithArgmaxGrad(op, grad, some_other_arg):\n",
    "  return gen_nn_ops._max_pool_grad(op.inputs[0],\n",
    "                                   op.outputs[0],\n",
    "                                   grad,\n",
    "                                   op.get_attr(\"ksize\"),\n",
    "                                   op.get_attr(\"strides\"),\n",
    "                                   padding=op.get_attr(\"padding\"),\n",
    "                                   data_format='NHWC')\n",
    "\n",
    "class VAE():\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Training Parameters\n",
    "        self.learning_rate   = 0.001 #0.001\n",
    "        self.training_epochs = 1000\n",
    "        self.batch_size      = 10\n",
    "        self.display_step    = 1\n",
    "        self.latent_variables = 2 #16\n",
    "\n",
    "            \n",
    "        self.scope=\"vaeengines\"\n",
    "        self.sess = tf.InteractiveSession()\n",
    "    \n",
    "    \n",
    "    def buildDecoder(self):\n",
    "        \n",
    "        #-----------------------\n",
    "        # decoder p(x|z)\n",
    "        #-----------------------\n",
    "        with tf.variable_scope(self.scope):\n",
    "            #first, need to sample from unit Gaussian and scale the result(reparametrization trick)\n",
    "            gaussian_sampled = sampleGaussian(mu=z_mean, log_sigma=z_log_sigma)\n",
    "\n",
    "            print('gaussian_sampled')\n",
    "            print(gaussian_sampled.get_shape())    \n",
    "\n",
    "            deconv_dense = ut.full_layer_with_bn(gaussian_sampled, [latent_variables, 256], phase, name=\"deconv4\")   \n",
    "            #deconv_dense = ut.full_layer_with_bn(gaussian_sampled, tf.pack([in_batch,pool4.get_shape()[1]*pool4.get_shape()[2]*pool4.get_shape()[3]]), phase, name=\"deconv4\")   \n",
    "\n",
    "\n",
    "            print('deconv_dense')\n",
    "            print(deconv_dense.get_shape())\n",
    "\n",
    "            full_deconv = ut.full_layer_with_bn(deconv_dense, [256, 8*8*256], phase, name=\"full_deconv\")   \n",
    "\n",
    "            deconv4 = tf.reshape(full_deconv, tf.pack([in_batch,8,8,256]))\n",
    "\n",
    "            print('deconv4')\n",
    "            print(deconv4.get_shape())\n",
    "\n",
    "            #in_batch = tf.shape(deconv4)[0]#deconv4.get_shape()[0]\n",
    "            ksize=4\n",
    "            factor=2\n",
    "            number_of_classes = int(int(deconv4.get_shape()[3]) / factor)\n",
    "            in_features = deconv4.get_shape()[3].value\n",
    "            deconv3 = ut.deconv_layer_koo(deconv4, [ksize, ksize, 256, 256], \n",
    "                                          tf.pack([in_batch,16, 16, 256]) , \n",
    "                                          stride=2, name=\"deconv3\")\n",
    "\n",
    "            print('deconv3')\n",
    "            print(deconv3.get_shape())\n",
    "\n",
    "            deconv2 = ut.deconv_layer_koo(deconv3, [ksize, ksize, 128, 256], \n",
    "                                          tf.pack([in_batch,32, 32, 128]) , \n",
    "                                          stride=2, name=\"deconv2\")\n",
    "\n",
    "            print('deconv2')\n",
    "            print(deconv2.get_shape())\n",
    "\n",
    "            deconv1 = ut.deconv_layer_koo(deconv2, [ksize, ksize, 64, 128], \n",
    "                                          tf.pack([in_batch,64, 64, 64]) ,                                  \n",
    "                                          stride=2, name=\"deconv1\")\n",
    "\n",
    "\n",
    "            print('deconv1')\n",
    "            print(deconv1.get_shape())\n",
    "            x_reconstructed = ut.deconv_layer_koo(deconv1, [ksize, ksize, 1, 64], \n",
    "                                                  tf.pack([in_batch,128, 128, 1]) , stride=2, name=\"x_reconstructed\")\n",
    "\n",
    "    \n",
    "    def buildEncoder(self):\n",
    "        with tf.variable_scope(self.scope):\n",
    "            self.x_in_depth = tf.placeholder(tf.float32, [None, 128, 128, 1])\n",
    "\n",
    "            self.phase = tf.placeholder(tf.bool, name='phase_train')\n",
    "\n",
    "\n",
    "\n",
    "            #-----------------------\n",
    "            # encoder p(z|x)\n",
    "            #-----------------------\n",
    "            self.conv1 = ut.conv_layer_with_bn(\n",
    "                            self.x_in_depth, [3, 3, 1, 32], phase, name=\"conv1\")\n",
    "             # see https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/vf8eH9YMwVA\n",
    "            dyn_input_shape = tf.shape(conv1)\n",
    "            in_batch = dyn_input_shape[0]\n",
    "            self.pool1, self.pool1_indices = tf.nn.max_pool_with_argmax(\n",
    "                            self.conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],padding='SAME', name='pool1')        \n",
    "            self.conv2 = ut.conv_layer_with_bn(\n",
    "                            self.pool1, [3, 3, 32, 64], phase, name=\"conv2\")\n",
    "            self.pool2, self.pool2_indices = tf.nn.max_pool_with_argmax(\n",
    "                            self.conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool2')       \n",
    "            self.conv31 = ut.conv_layer_with_bn(\n",
    "                            self.pool2, [3, 3, 64, 128], phase, name=\"conv31\")\n",
    "            self.conv32 = ut.conv_layer_with_bn(\n",
    "                            self.conv31, [3, 3, 128, 128], phase, name=\"conv32\")\n",
    "            self.pool3, self.pool3_indices = tf.nn.max_pool_with_argmax(\n",
    "                            self.conv32, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool3')        \n",
    "            self.conv41 = ut.conv_layer_with_bn(\n",
    "                            self.pool3, [3, 3, 128, 256], phase, name=\"conv41\")\n",
    "            self.conv42 = ut.conv_layer_with_bn(\n",
    "                            self.conv41, [3, 3, 256, 256], phase, name=\"conv42\")\n",
    "            self.pool4, pool4_indices = tf.nn.max_pool_with_argmax(\n",
    "                            self.conv42, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool4')\n",
    "\n",
    "            \n",
    "            print('pool4')\n",
    "            print(self.pool4.get_shape())\n",
    "            self.dense = tf.reshape(self.pool4, [in_batch, self.pool4.get_shape().as_list()[1]*self.pool4.get_shape().as_list()[2]*256])\n",
    "            print('dense')\n",
    "            print(self.dense.get_shape())\n",
    "            self.full = ut.full_layer_with_bn(self.dense, [self.dense.get_shape().as_list()[1], self.latent_variables], phase, name=\"full\")\n",
    "            print('full')\n",
    "            print(self.full.get_shape())\n",
    "            #-----------------------\n",
    "            #the latent variables   \n",
    "            self.z_mean = ut.full_layer_with_bn(self.full, [self.full.get_shape().as_list()[1], self.latent_variables], phase, name=\"z_mean\")        \n",
    "            self.z_log_sigma = ut.full_layer_with_bn(self.full, [self.full.get_shape().as_list()[1], self.latent_variables], phase, name=\"z_log_sigma\")       \n",
    "            print('z_mean')\n",
    "            print(self.z_mean.get_shape())\n",
    "            \n",
    "            #---------------------------------\n",
    "            # at this point define the KL loss\n",
    "            #---------------------------------\n",
    "            self.kl_loss = kullbackLeibler(self.z_mean, self.z_log_sigma)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Utility functions from https://github.com/fastforwardlabs/vae-tf/blob/master/vae.py\n",
    "    \"\"\"\n",
    "    def sampleGaussian(mu, log_sigma):\n",
    "            \"\"\"(Differentiably!) draw sample from Gaussian with given shape, subject to random noise epsilon\"\"\"\n",
    "            with tf.name_scope(\"sample_gaussian\"):\n",
    "                # reparameterization trick\n",
    "                epsilon = tf.random_normal(tf.shape(log_sigma), name=\"epsilon\")\n",
    "                return mu + epsilon * tf.exp(log_sigma) # N(mu, I * sigma**2)\n",
    "\n",
    "\n",
    "    def crossEntropy(obs, actual, offset=1e-7):\n",
    "        \"\"\"Binary cross-entropy, per training example\"\"\"\n",
    "        # (tf.Tensor, tf.Tensor, float) -> tf.Tensor\n",
    "        with tf.name_scope(\"cross_entropy\"):\n",
    "            # bound by clipping to avoid nan\n",
    "            obs_ = tf.clip_by_value(obs, offset, 1 - offset)\n",
    "            return -tf.reduce_sum(actual * tf.log(obs_) +\n",
    "                                  (1 - actual) * tf.log(1 - obs_), 1)\n",
    "\n",
    "\n",
    "    def l1_loss(obs, actual):\n",
    "        \"\"\"L1 loss (a.k.a. LAD), per training example\"\"\"\n",
    "        # (tf.Tensor, tf.Tensor, float) -> tf.Tensor\n",
    "        with tf.name_scope(\"l1_loss\"):\n",
    "            return tf.reduce_sum(tf.abs(obs - actual) , 1)\n",
    "\n",
    "\n",
    "    def l2_loss(obs, actual):\n",
    "        \"\"\"L2 loss (a.k.a. Euclidean / LSE), per training example\"\"\"\n",
    "        # (tf.Tensor, tf.Tensor, float) -> tf.Tensor\n",
    "        with tf.name_scope(\"l2_loss\"):\n",
    "            return tf.reduce_sum(tf.square(obs - actual), 1)\n",
    "\n",
    "\n",
    "    def kullbackLeibler(mu, log_sigma):\n",
    "        \"\"\"(Gaussian) Kullback-Leibler divergence KL(q||p), per training example\"\"\"\n",
    "        # (tf.Tensor, tf.Tensor) -> tf.Tensor\n",
    "        with tf.name_scope(\"KL_divergence\"):\n",
    "            # = -0.5 * (1 + log(sigma**2) - mu**2 - sigma**2)\n",
    "            return -0.5 * tf.reduce_sum(1 + 2 * log_sigma - mu**2 - tf.exp(2 * log_sigma), 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
